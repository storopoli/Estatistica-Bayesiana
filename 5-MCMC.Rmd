---
title: "Markov Chain Monte Carlo"
author:
  - name: Jose Storopoli
    url: https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en
    affiliation: UNINOVE
    affiliation_url: https://www.uninove.br
    orcid_id: 0000-0002-0559-5176
date: August 2, 2020
citation_url: https://storopoli.github.io/Estatistica-Bayesiana/5-MCMC.html
slug: storopoli2020mcmcR
bibliography: bibliografia.bib
csl: apa.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css"/>

A principal barreira computacional para estatística bayesiana é o denominador $P(\text{data})$ da fórmula de Bayes:

$$P(\theta | \text{data})=\frac{P(\theta) \cdot P(\text{data} | \theta)}{P(\text{data})}$$

Em casos discretos podemos fazer o denominador virar a soma de todos os paramêtros usando a regra da cadeia de probabilidade:

$$P(A,B|C)=P(A|B,C) \times P(B|C)$$

Isto também é chamado de marginalização:

$$P(\text{data})=\sum_{\theta} P(\text{data} | \theta) \times P(\theta)$$

Porém no caso de valores contínuos o denominador $P(\text{data})$ vira uma integral bem grande e complicada de calcular:

$$P(\text{data})=\int_{\theta} P(\text{data} | \theta) \times P(\theta)d \theta$$

Em muitos casos essa integral vira *intrátavel* (incalculável) e portanto devemos achar outras maneiras de cálcular a probabilidade posterior $P(\theta | \text{data})$ de Bayes sem usar o denominador $P(\text{data})$.

## Para quê serve o denominador $P(\text{data})$?

Para normalizar a posterior com o intuito de torná-la uma distribuição probabilística válida. Isto quer dizer que a soma de todas as probabilidades dos eventos possíveis da distribuição probabilística devem ser iguais a 1:

-   no caso de distribuição probabilística discreta: $\sum_{\theta} P(\theta | \text{data}) = 1$
-   no caso de distribuição probabilística contínua: $\int_{\theta} P(\theta | \text{data})d \theta = 1$

## Se removermos o denominador de Bayes o que temos?

Ao removermos o denominador $(\text{data})$ temos que a posterior $P(\theta | \text{data})$ é **proporcional** à prior vezes a verossimilhança $P(\theta) \cdot P(\text{data} | \theta)$

$$P(\theta | \text{data}) \propto P(\theta) \cdot P(\text{data} | \theta)$$

Este [vídeo do YouTube](https://youtu.be/8FbqSVFzmoY) explica muito bem o problema do denominador.

## Simulação Montecarlo

Aí que entra simulação Montecarlo. Simulação Montecarlo é usada quando não é possível coletar amostras de $\theta$ direto da distribuição probabilística posterior $P(\theta | \text{data})$. Ao invés disso, nos coletamos amostras de maneira iterativa que a cada passo do processo nós esperamos que a distribuição da qual amostramos se torna cada vez mais similar à posterior $P(\theta | \text{data})$.

> Não vamos cobrir a parte computacional ou a base matemática por trás de Markov Chain Monte Carlo (MCMC). Quem quiser, pode ler os capítulos 11 e 12 do livro Bayesian Data Analysis (3rd edition) de Gelman et al. (2014)

## Implementação com o `rstanarm`

Como configuração padrão, o pacote `rstanarm` utiliza uma modalidade de MCMC que usa dinâmicas Hamiltoneanas chamada **Hamiltonian Monte Carlo** (HMC). HMC é a modalidade de MCMC mais eficiente para gerar inferências Bayesianas. Em especial, `rstanarm` e a linguagem `Stan` usam HMC com uma técnica chamada **No-U-Turn Sampling** (NUTS), que faz HMC ser bem eficiente e não desperdiça amostragens.

Além disso, os argumentos padrões do HMC no `rstanarm` são o 4 correntes Markov de amostragem (`chains = 4`) e o 2.000 iterações de cada corrente (`iter = 2000`). Sendo que, por padrão, HMC descarta a primeira metade (1.000) das iterações como aquecimento (`warmup = floor(iter/2)`).

Relembrando o exemplo da aula de regressão linear, vamos usar o mesmo *dataset* `kidiq`. São dados de uma *survey* de mulheres adultas norte-americanas e seus respectivos filhos. Datado de 2007 possui 434 observações e 4 variáveis:

-   `kid_score`: QI da criança;
-   `mom_hs`: binária (0 ou 1) se a mãe possui diploma de ensino médio;
-   `mom_iq`: QI da mãe; e
-   `mom_age`: idade da mãe.

Vamos estimar um modelo de regressão linear Bayesiano na qual a variável dependente é `kid_score` e as independentes são `mom_hs` e `mom_iq`.

```{r dataset-kidiq}
options(mc.cores = parallel::detectCores())
options(Ncpus = parallel::detectCores())

library(rstanarm)
model <- stan_glm(
  kid_score ~ mom_hs + mom_iq,
  data = kidiq
  )
```

### Métricas da simulação MCMC

Um modelo estimado pelo `rstanarm` pode ser inspecionado em relação ao desempenho da amostragem MCMC. Ao chamarmos a função `summary()` no modelo estimado há uma parte chamada `MCMC diagnostics`.

```{r model_summary}
summary(model)
```

A seção `MCMC diagnostics` possui três colunas de valores para cada parâmetro estimado do modelo.

No nosso caso, temos três parâmetros importantes:

1.  valor do coeficiente da variável `mom_hs`
2.  valor do coeficiente da variável `mom_iq`
3.  valor do erro residual do modelo linear `sigma`

As três métricas são:

-   `mcse`: *Monte Carlo Standard Error*, o erro de mensuração da amostragem Monte Carlo do parâmetro
-   `n_eff`: uma aproximação crua do número de amostras efetivas amostradas pelo MCMC
-   `Rhat`: uma métrica de convergência e estabilidade da corrente Markov

A métrica mais importante para levarmos em consideração é a `Rhat` que é uma métrica que mensura se as correntes Markov são estáveis e convergiram para um valor durante o progresso total das simulações. Ela é basicamente a proporção de variação ao compararmos duas metades das correntes. Valor de $1$ implica em convergência e estabilidade. Como padrão o `Rhat` deve ser menor que $1.05$ para que a estimação Bayesiana seja válida.

### O que fazer se não obtermos convergência?

Dependendo do modelo e dos dados é possível que HMC (mesmo com NUTS) não atinja convergência. Nesse caso, ao rodar o modelo `rstanarm` dará diversos avisos de divergências.

```{r MCMC-warnings}
bad_model <- stan_glm(
  kid_score ~ mom_hs + mom_iq,
  data = kidiq,
  chains = 2,
  iter = 200
  )
```

E vemos que o `Rhat` dos parâmetros estimados do modelo estão bem acima do limiar de $1.05$.

```{r bad_model-summary}
summary(bad_model)
```

## Gráficos de Diagnósticos do MCMC

O pacote `rstanarm` tem diversos gráficos interessantes de diagnósticos de convergência das simulações MCMC.

### Traceplot

O *traceplot* é a sobreposição das amostragens MCMC das correntes para cada parâmetro estimado. A ideia é que as correntes se misturam e que não haja nenhuma inclinação ao longo das iterações.

Detalhe: aqui o *traceplot* usa somente as iterações válidas, após a remoção das iterações de `warmup`.

```{r plot-diagnostics}
plot(model, "trace")
plot(bad_model, "trace")
```

### *Posterior Predictive Check*

Um bom gráfico de diagnóstico é o *posterior predictive check* que compara o histograma da variável dependente $y$ contra o histograma variáveis dependentes simuladas pelo modelo $y_{\text{rep}}$. A ideia é que os histogramas reais e simulados se misturem e não haja divergências.

```{r pp-checks}
pp_check(model)
pp_check(bad_model)
```

## O quê fazer para que as métricas sejam convergentes

Se o seu modelo Bayesiano está com problemas de convergência há alguns passos que podem ser tentados. Aqui listados do mais simples para o mais complexo:

1.  **Aumentar o número de iterações e correntes**: primeira opção é aumentar o número de iterações do MCMC com o argumento `iter = XXX` e também é possível aumentar o número de correntes com o argumento `chains = X`. Lembrando que o padrão é `iter = 2000` e `chains = 4`.
2.  **Alterar a rotina de adaptação do HMC**: a segunda opção é fazer com que o algoritmo de amostragem HMC fique mais conservador (com proposições de pulos menores). Isto pode ser alterado com o argumento `adapt_delta` da lista de opções `control`. `control=list(adapt_delta=0.9)`. O padrão do `adapt_delta` é `control=list(adapt_delta=0.8)`. Então quaquer valor entre $0.8$ e $1.0$ o torna mais conservador.
3.  **Reparametrização do Modelo**: a terceira opção é reparametrizar o modelo. Há duas maneiras de parametrizar o modelo: a primeira com parametrização centrada (*centered parameterization*) e a segunda com parametrização não-centrada (*non-centered parameterization*). Não são assuntos que vamos cobrir aqui no curso. Recomendo o [material de um dos desenvolvedores da linguagem `Stan`, Michael Betancourt](https://mc-stan.org/users/documentation/case-studies/divergences_and_bias.html).
4.  **Coletar mais dados**: às vezes o modelo é complexo demais e precisamos de uma amostragem maior para conseguirmos estimativas estáveis.
5.  **Repensar o modelo**: falha de convergência quando temos uma amostragem adequada geralmente é por conta de uma especificação de priors e verossimilhança que não são compatíveis com os dados. Nesse caso, é preciso repensar o processo generativo de dados no qual os pressupostos do modelo estão ancorados.

## Ambiente

```{r SessionInfo}
sessionInfo()
```
