---
title: "Markov Chain Monte Carlo"
author:
  - name: Jose Storopoli
    url: https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en
    affiliation: UNINOVE
    affiliation_url: https://www.uninove.br
    orcid_id: 0000-0002-0559-5176
date: August 2, 2021
citation_url: https://storopoli.github.io/Estatistica-Bayesiana/5-MCMC.html
slug: storopoli2021mcmcR
bibliography: bib/bibliografia.bib
csl: bib/apa.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(123)
```

<link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css"/>

A principal barreira computacional para estatística bayesiana é o denominador $P(\text{data})$ da fórmula de Bayes:

$$P(\theta | \text{data})=\frac{P(\theta) \cdot P(\text{data} | \theta)}{P(\text{data})}$$

Em casos discretos podemos fazer o denominador virar a soma de todos os paramêtros usando a regra da cadeia de probabilidade:

$$P(A,B|C)=P(A|B,C) \times P(B|C)$$

Isto também é chamado de marginalização:

$$P(\text{data})=\sum_{\theta} P(\text{data} | \theta) \times P(\theta)$$

Porém no caso de valores contínuos o denominador $P(\text{data})$ vira uma integral bem grande e complicada de calcular:

$$P(\text{data})=\int_{\theta} P(\text{data} | \theta) \times P(\theta)d \theta$$

Em muitos casos essa integral vira *intrátavel* (incalculável) e portanto devemos achar outras maneiras de cálcular a probabilidade posterior $P(\theta | \text{data})$ de Bayes sem usar o denominador $P(\text{data})$.

## Para quê serve o denominador $P(\text{data})$?

Para normalizar a posterior com o intuito de torná-la uma distribuição probabilística válida. Isto quer dizer que a soma de todas as probabilidades dos eventos possíveis da distribuição probabilística devem ser iguais a 1:

-   no caso de distribuição probabilística discreta: $\sum_{\theta} P(\theta | \text{data}) = 1$
-   no caso de distribuição probabilística contínua: $\int_{\theta} P(\theta | \text{data})d \theta = 1$

## Se removermos o denominador de Bayes o que temos?

Ao removermos o denominador $(\text{data})$ temos que a posterior $P(\theta | \text{data})$ é **proporcional** à prior vezes a verossimilhança $P(\theta) \cdot P(\text{data} | \theta)$[^1].

[^1]: o símbolo $\propto$ (`\propto`) deve ser lido como "proporcional à".

$$P(\theta | \text{data}) \propto P(\theta) \cdot P(\text{data} | \theta)$$

Este [vídeo do YouTube](https://youtu.be/8FbqSVFzmoY) explica muito bem o problema do denominador.

\<iframe width="560" height="315" src="[https://www.youtube.com/embed/8FbqSVFzmoY?controls=0"](https://www.youtube.com/embed/8FbqSVFzmoY?controls=0") frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen\>\</iframe\>

## Simulação Montecarlo com correntes Markov -- (MCMC)

Aí que entra simulação Montecarlo com correntes Markov (do inglês *Markov Chain Monte Carlo* -- MCMC). MCMC é uma classe ampla de ferramentas computacionais para aproximação de integrais e geração de amostras de uma probabilidade posterior [\@brooksHandbookMarkovChain2011]. Simulação Montecarlo é usada quando não é possível coletar amostras de $\theta$ direto da distribuição probabilística posterior $P(\theta | \text{data})$. Ao invés disso, nos coletamos amostras de maneira iterativa que a cada passo do processo nós esperamos que a distribuição da qual amostramos se torna cada vez mais similar à posterior $P(\theta | \text{data})$.

### Simulações -- Setup

```{r setup_mmc}
library(ggplot2)
theme_set(theme_minimal())
library(plotly)
library(tidyr)
library(gganimate)
library(ggforce)
library(mnormt)
library(MASS)
library(latex2exp)
library(rstan)
```

Vamos começar com um problema didático de uma distribuição normal multivariada de $X$ e $Y$, onde

$$
\begin{bmatrix}
X \\
Y
\end{bmatrix} \sim \text{Normal Multivariada} \left(
\begin{bmatrix}
\mu_X \\
\mu_Y
\end{bmatrix}, \mathbf{\Sigma}
\right) \\
\mathbf{\Sigma} \sim
\begin{pmatrix}
\sigma^2_{X} & \sigma_{X}\sigma_{Y} \rho \\
\sigma_{X}\sigma_{Y} \rho & \sigma^2_{Y}
\end{pmatrix}
$$

Se designarmos $\mu_X = \mu_Y = 0$ e $\sigma_X = \sigma_Y = 1$ (média 0 e desvio padrão 1), temos a seguinte formulação

$$
\begin{bmatrix}
X \\
Y
\end{bmatrix} \sim \text{Normal Multivariada} \left(
\begin{bmatrix}
0 \\
0
\end{bmatrix}, \mathbf{\Sigma}
\right) \\
\mathbf{\Sigma} \sim
\begin{pmatrix}
1 & \rho \\
\rho & 1
\end{pmatrix}
$$

só faltando designar um valor de $\rho$ para a correlação entre $X$ e $Y$. Para o nosso exemplo vamos usar alguns valores de $\rho$. Inicialmente em $\rho = 0.8$:

```{r mrnorm_setup}
mus  <- c(0, 0)
sigmas <- c(1, 1)
r <- 0.8
Sigma <- diag(sigmas)
Sigma[1, 2] <- r
Sigma[2, 1] <- r
dft <- data.frame(rmnorm(1e5, mus, Sigma))
```

```{r plot_mnorm}
ggplot(dft, aes(X1, X2)) +
  geom_density2d_filled() +
  coord_cartesian(xlim = c(-3, 3), ylim = c(-3, 3)) +
  labs(title = "Multivariada Normal",
       subtitle = TeX("$\\mu = 0 , \\sigma = 1, \\rho = 0.8$"),
       caption = "10.000 simulações",
       x = TeX("$X$"), y = TeX("$Y$")) +
  theme(legend.position = "NULL")
```

```{r plot_3d_mnorm}
dens <- kde2d(dft$X1, dft$X2)
plot_ly(x = dens$x,
        y = dens$y,
        z = dens$z) %>% add_surface()
```

### Metropolis

Falar da história do M-H.

Falar da diferença entre M e M-H.

#### Algoritmo

1.  Draw a starting point $\theta^0$ for which $p(\theta^0|y) > 0$, from a starting distribution $p_0 (\theta)$. $p_0(\theta)$ can be a normal or a prior on $\theta$ --- $p(\theta)$.

2.  For $t = 1, 2, \dots$:

    -   Sample a proposal $\theta^*$ from a jumping distribution (or proposal distribution) at time $t$, $J_t (\theta^* | \theta^{t-1})$:

        -   **Metropolis Algorithm**: $J_t(\theta^* | \theta^{t-1})$ must be symmetric $J_t (\theta_A | \theta_B) = J_t(\theta_B|\theta_A)$
        -   **Metropolis-Hastings Algorithm**: $J_t(\theta^* | \theta^{t-1})$ does **not** need to be symmetric $J_t (\theta_A | \theta_B) \neq J_t(\theta_B|\theta_A)$

    -   Calculate the ratio densities:

        -   **Metropolis Algorithm**: $r = \frac{p(\theta^* | y)}{p(\theta^{t-1} | y)}$
        -   **Metropolis-Hastings Algorithm**: $r = \frac{\frac{p(\theta^* | y)}{J_t(\theta^*|\theta^{t-1})}}{\frac{p(\theta^{t-1} | y)}{J_t(\theta^{t-1}|\theta^*)}}$

    -   Set

        $$\theta^t =
          \begin{cases}
          \theta^* & \text{with probability min($r$,1)}\\
          \theta^{t-1} & \text{otherwise}
          \end{cases}$$

#### Metropolis -- Implementação

No nosso exemplo didático temos que $J_t(\theta^* | \theta^{t-1})$ é simétrico à $J_t (\theta_A | \theta_B) = J_t(\theta_B|\theta_A)$, portanto vamos apenas demonstrar o algoritmo de Metropolis (e não o algorimo de Metropolis-Hastings)

```{r metropolis}
metropolis <- function(S, half_width,
                       mu_X = 0, mu_Y = 0,
                       sigma_X = 1, sigma_Y = 1,
                       rho,
                       start_x, start_y,
                       seed = 123) {
   set.seed(seed)
   Sigma <- diag(2)
   Sigma[1, 2] <- rho
   Sigma[2, 1] <- rho
   draws <- matrix(nrow = S, ncol = 2)
   x <- start_x
   y <- start_y
   accepted <- 0
   draws[1, 1] <- x
   draws[1, 2] <- y
   for (s in 2:S) {
      x_ <- runif(1, x - half_width, x + half_width)
      y_ <- runif(1, y - half_width, y + half_width)
      r <- exp(mnormt::dmnorm(c(x_, y_), mean = c(mu_X, mu_Y), varcov = Sigma, log = TRUE) -
                        mnormt::dmnorm(c(x, y), mean = c(mu_X, mu_Y), varcov = Sigma, log = TRUE))
      if (r > runif(1, 0, 1)) {
        x <- x_
        y <- y_
        accepted <- accepted + 1
      }
      draws[s, 1] <- x
      draws[s, 2] <- y
   }
   print(paste0("Acceptance rate is ", accepted / S))
   return(draws)
}
```

```{r n_sim}
n_sim <- 1e4
```

Vamos simular, com `r format(n_sim, big.mark =",")` amostras.

```{r metropolis_sim}
X <- metropolis(
  S = n_sim, half_width = 2.75,
  mu_X = 0, mu_Y = 0,
  sigma_X = 1, sigma_Y = 1,
  rho = r,
  start_x = -2.5, start_y = 2.5
)
head(X, 7)
```

Aceitação dos pulos em 20.8%

Usar a função `rstan::monitor()` que simula um `print(stanfit)` mas para matrizes 3-D (sendo que a terceira dimensão é o número do correntes markov `chains`).

```{r monitor_metropolis}
# Reshape the matrix to rstan::monitor()
dim(X) <- c(dim(X), 1)

res <- monitor(X, digits_summary = 1)
neff <- res[, "n_eff"]
reff <- mean(neff / (nrow(X))) #  9.5%
```

`reff` contando tudo com o warmup.

##### Metropolis -- Intuição Visual

Falar da intuição visual e que vamos usar as 100 primeiras simulações do algoritmo num GIF animado.

`HPD` = *Highest Probability Density*

```{r metropolis_gif}
df100 <- data.frame(
    id = rep(1, 100),
    iter = 1:100,
    th1 = X[1:100, 1, ],
    th2 = X[1:100, 2, ],
    th1l = c(X[1, 1, ], X[1:(100 - 1), 1, ]),
    th2l = c(X[1, 2, ], X[1:(100 - 1), 2, ])
)

labs1 <- c("Amostras", "Iterações do Algoritmo", "90% HPD")

p1 <- ggplot() +
  geom_jitter(data = df100, width = 0.05, height = 0.05,
             aes(th1, th2, group = id, color = "1"), alpha = 0.3) +
  geom_segment(data = df100, aes(x = th1, xend = th1l, color = "2",
                                 y = th2, yend = th2l)) +
  stat_ellipse(data = dft, aes(x = X1, y = X2, color = "3"), level = 0.9) +
  coord_cartesian(xlim = c(-3, 3), ylim = c(-3, 3)) +
  labs(title = "Metropolis", subtitle = "100 Amostragens Iniciais", x = TeX("$\\theta_1$"), y = TeX("$\\theta_2$")) +
  scale_color_manual(values = c("red", "forestgreen", "blue"), labels = labs1) +
  guides(color = guide_legend(override.aes = list(
    shape = c(16, NA, NA), linetype = c(0, 1, 1)))) +
  theme(legend.position = "bottom", legend.title = element_blank())

animate(p1 +
  transition_reveal(along = iter) +
  shadow_trail(0.01),
  # animation options
  height = 7, width = 7, units = "in", res = 300
)
```

E agora falar de como ficou nas primeiras 1.000 simulações depois do warmup de 1.000

```{r metropolis_first_1000}
# Take all the 10,000 observations after warmup of 1,000
warm <- 1e3
dfs <- data.frame(
  th1 = X[(warm + 1):nrow(X), 1, ],
  th2 = X[(warm + 1):nrow(X), 2, ]
)

labs2 <- c("Amostras", "90% HPD")

ggplot() +
  geom_point(data = dfs[1:1000, ],
             aes(th1, th2, color = "1"), alpha = 0.3) +
  stat_ellipse(data = dft, aes(x = X1, y = X2, color = "2"), level = 0.9) +
  coord_cartesian(xlim = c(-3, 3), ylim = c(-3, 3)) +
  labs(title = "Metropolis", subtitle = "1.000 Amostragens Iniciais", x = TeX("$\\theta_1$"), y = TeX("$\\theta_2$")) +
  scale_color_manual(values = c("steelblue", "blue"), labels = labs2) +
  guides(color = guide_legend(override.aes = list(
    shape = c(16, NA), linetype = c(0, 1), alpha = c(1, 1)))) +
  theme(legend.position = "bottom", legend.title = element_blank())
```

E agora falar de como nas restantes 9.000 simulações depois do warmup de 1.000 (total 10.000)

```{r metropolis_all}
# Show all 10,000 samples
ggplot() +
  geom_point(data = dfs,
             aes(th1, th2, color = "1"), alpha = 0.3) +
  stat_ellipse(data = dft, aes(x = X1, y = X2, color = "2"), level = 0.9) +
  coord_cartesian(xlim = c(-3, 3), ylim = c(-3, 3)) +
  labs(title = "Metropolis", subtitle = "10.000 Amostragens", x = TeX("$\\theta_1$"), y = TeX("$\\theta_2$")) +
  scale_color_manual(values = c("steelblue", "blue"), labels = labs2) +
  guides(color = guide_legend(override.aes = list(
    shape = c(16, NA), linetype = c(0, 1), alpha = c(1, 1)))) +
  theme(legend.position = "bottom", legend.title = element_blank())
```

### Gibbs

Falar da história do Gibbs

#### Algoritmo

1.  Define $p(\theta_1), p(\theta_2), \dots, p(\theta_n$)

2.  Draw a starting point $\theta^0_1, \theta^0_2, \dots, \theta^0_n$. Can be a normal or a prior.

3.  For $t = 1,2,\dots$:

    $$\begin{aligned}
     \theta^t_1 &\sim p(\theta_1 | \theta^0_2, \dots, \theta^0_n) \\
     \theta^t_2 &\sim p(\theta_2 | \theta^{t-1}_1, \dots, \theta^0_n) \\
     &\vdots \\
     \theta^t_n &\sim p(\theta_n | \theta^{t-1}_1, \dots, \theta^{t-1}_{n-1})
     \end{aligned}$$

Gibbs is a special case of Metropolis-Hastings because **every jump is accepted**.

#### Gibbs -- Implementação

```{r gibbs}
gibbs <- function(S,
                  mu_X = 0, mu_Y = 0,
                  sigma_X = 1, sigma_Y = 1,
                  rho,
                  start_x, start_y,
                  seed = 123) {
   set.seed(seed)
   Sigma <- diag(2)
   Sigma[1, 2] <- rho
   Sigma[2, 1] <- rho
   draws <- matrix(nrow = S, ncol = 2)
   x <- start_x
   y <- start_y
   beta <- rho * sigma_Y / sigma_X
   lambda <- rho * sigma_X / sigma_Y
   sqrt1mrho2 <- sqrt(1 - rho^2)
   sigma_YX <- sigma_Y * sqrt1mrho2
   sigma_XY <- sigma_X * sqrt1mrho2
   draws[1, 1] <- x
   draws[1, 2] <- y
   for (s in 2:S) {
     if (s %% 2 == 0) {
        y <- rnorm(1, mu_Y + beta * (x - mu_X), sigma_YX)
     }
     else {
        x <- rnorm(1, mu_X + lambda * (y - mu_Y), sigma_XY)
     }
     draws[s, 1] <- x
     draws[s, 2] <- y
   }
   return(draws)
}
```

Vamos simular, com `r format(n_sim, big.mark =",")` amostras.

```{r gibbs_sim}
X <- gibbs(
  S = n_sim,
  mu_X = 0, mu_Y = 0,
  sigma_X = 1, sigma_Y = 1,
  rho = r,
  start_x = -2.5, start_y = 2.5
)
head(X, 7)
```

```{r monitor_gibbs}
# Reshape the matrix to rstan::monitor()
dim(X) <- c(dim(X), 1)

res <- monitor(X, digits_summary = 1)
neff <- res[, "n_eff"]
reff <- mean(neff / (nrow(X))) #  12%
```

`reff` contando tudo com o warmup.

##### Gibbs -- Intuição Visual

Falar da intuição visual e que vamos usar as 100 primeiras simulações do algoritmo num GIF animado.

`HPD` = *Highest Probability Density*

```{r gibbs_gif}
df100 <- data.frame(
    id = rep(1, 100),
    iter = 1:100,
    th1 = X[1:100, 1, ],
    th2 = X[1:100, 2, ],
    th1l = c(X[1, 1, ], X[1:(100 - 1), 1, ]),
    th2l = c(X[1, 2, ], X[1:(100 - 1), 2, ])
)

labs1 <- c("Amostras", "Iterações do Algoritmo", "90% HPD")

ind1 <- (1:50) * 2 - 1
df100s <- df100
df100s[ind1 + 1, 3:4] <- df100s[ind1, 3:4]
p1 <- ggplot() +
  geom_point(data = df100s,
             aes(th1, th2, group = id, color = "1")) +
  geom_segment(data = df100, aes(x = th1, xend = th1l, color = "2",
                                 y = th2, yend = th2l)) +
  stat_ellipse(data = dft, aes(x = X1, y = X2, color = "3"), level = 0.9) +
  coord_cartesian(xlim = c(-3, 3), ylim = c(-3, 3)) +
  labs(title = "Gibbs", subtitle = "100 Amostragens Iniciais", x = TeX("$\\theta_1$"), y = TeX("$\\theta_2$")) +
  scale_color_manual(values = c("red", "forestgreen", "blue"), labels = labs1) +
  guides(color = guide_legend(override.aes = list(
    shape = c(16, NA, NA), linetype = c(0, 1, 1)))) +
  theme(legend.position = "bottom", legend.title = element_blank())

animate(p1 +
  transition_reveal(along = iter) +
  shadow_trail(0.01),
  # animation options
  height = 7, width = 7, units = "in", res = 300
)
```

E agora falar de como ficou nas primeiras 1.000 simulações depois do warmup de 1.000

```{r gibbs_first_1000}
# Take all the 10,000 observations after warmup of 1,000
warm <- 1e3
dfs <- data.frame(
  th1 = X[(warm + 1):nrow(X), 1, ],
  th2 = X[(warm + 1):nrow(X), 2, ]
)

labs2 <- c("Amostras", "90% HPD")

ggplot() +
  geom_point(data = dfs[1:1000, ],
             aes(th1, th2, color = "1"), alpha = 0.3) +
  stat_ellipse(data = dft, aes(x = X1, y = X2, color = "2"), level = 0.9) +
  coord_cartesian(xlim = c(-3, 3), ylim = c(-3, 3)) +
  labs(title = "Gibbs", subtitle = "1.000 Amostragens Iniciais", x = TeX("$\\theta_1$"), y = TeX("$\\theta_2$")) +
  scale_color_manual(values = c("steelblue", "blue"), labels = labs2) +
  guides(color = guide_legend(override.aes = list(
    shape = c(16, NA), linetype = c(0, 1), alpha = c(1, 1)))) +
  theme(legend.position = "bottom", legend.title = element_blank())
```

E agora falar de como nas restantes 9.000 simulações depois do warmup de 1.000 (total 10.000)

```{r gibbs_all}
# Show all 10,000 samples
ggplot() +
  geom_point(data = dfs,
             aes(th1, th2, color = "1"), alpha = 0.3) +
  stat_ellipse(data = dft, aes(x = X1, y = X2, color = "2"), level = 0.9) +
  coord_cartesian(xlim = c(-3, 3), ylim = c(-3, 3)) +
  labs(title = "Gibbs", subtitle = "10.000 Amostragens", x = TeX("$\\theta_1$"), y = TeX("$\\theta_2$")) +
  scale_color_manual(values = c("steelblue", "blue"), labels = labs2) +
  guides(color = guide_legend(override.aes = list(
    shape = c(16, NA), linetype = c(0, 1), alpha = c(1, 1)))) +
  theme(legend.position = "bottom", legend.title = element_blank())
```

### O que acontece quando rodamos correntes Markov em paralelo?

O mesmo exemplo didático, mas agora com 4 correntes Markov com diferentes pontos de início.

```{r starting_points}
starts <- list(c(-2.5, 2.5),
               c(2.5, -2.5),
               c(-2.5, -2.5),
               c(2.5, 2.5)
               )
```

#### Correntes Markov em Paralelo -- Metropolis

```{r metropolis_multi, warning=FALSE, message=FALSE}
library(dplyr)
n_sim <- 100
Xs <- bind_rows(
  as_tibble(metropolis(S = n_sim, half_width = 2.75,
                       mu_X = 0, mu_Y = 0,
                       sigma_X = 1, sigma_Y = 1,
                       rho = r,
                       start_x = -2.5, start_y = 2.5,
                       seed = 1)),
  as_tibble(metropolis(S = n_sim, half_width = 2.75,
                       mu_X = 0, mu_Y = 0,
                       sigma_X = 1, sigma_Y = 1,
                       rho = r,
                       start_x = 2.5, start_y = -2.5,
                       seed = 2)),
  as_tibble(metropolis(S = n_sim, half_width = 2.75,
                       mu_X = 0, mu_Y = 0,
                       sigma_X = 1, sigma_Y = 1,
                       rho = r,
                       start_x = -2.5, start_y = -2.5,
                       seed = 3)),
  as_tibble(metropolis(S = n_sim, half_width = 2.75,
                       mu_X = 0, mu_Y = 0,
                       sigma_X = 1, sigma_Y = 1,
                       rho = r,
                       start_x = 2.5, start_y = 2.5,
                       seed = 4)),
  .id = "chain")
```

Não houveram mudanças significativas na taxa de aprovação das propostas Metropolis. Todas ficaram em torno de 20%, igual ao exemplo com uma corrente Markov.

```{r metropolis_multi_gif}
dfs100 <- Xs %>%
  group_by(chain) %>%
  transmute(
    chain,
    iter = 1:n_sim,
    th1 = V1,
    th2 = V2,
    th1l = dplyr::lag(V1, default = V1[1]),
    th2l = dplyr::lag(V2, default = V2[1])
  ) %>% 
  ungroup()
p1 <- ggplot(dfs100) +
  geom_jitter(width = 0.05, height = 0.05,
              aes(th1, th2, group = chain, color = chain), alpha = 0.3) +
  geom_segment(aes(x = th1, xend = th1l, y = th2, yend = th2l,
                   color = chain)) +
  #geom_point(aes(x = th1, y = th2, color = chain)) +
  stat_ellipse(data = dft, aes(x = X1, y = X2), color = "black", level = 0.9) +
  coord_cartesian(xlim = c(-3, 3), ylim = c(-3, 3)) +
  labs(title = "Metropolis", subtitle = "100 Amostragens Iniciais", x = TeX("$\\theta_1$"), y = TeX("$\\theta_2$")) +
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "NULL")

animate(p1 +
          transition_reveal(along = iter) +
          shadow_trail(0.01),
        # animation options
        height = 7, width = 7, units = "in", res = 300
)
```

#### Correntes Markov em Paralelo -- Gibbs

```{r gibbs_multi}
Xs <- bind_rows(
  as_tibble(gibbs(S = n_sim,
                       mu_X = 0, mu_Y = 0,
                       sigma_X = 1, sigma_Y = 1,
                       rho = r,
                       start_x = -2.5, start_y = 2.5,
                       seed = 1)),
  as_tibble(gibbs(S = n_sim,
                       mu_X = 0, mu_Y = 0,
                       sigma_X = 1, sigma_Y = 1,
                       rho = r,
                       start_x = 2.5, start_y = -2.5,
                       seed = 2)),
  as_tibble(gibbs(S = n_sim,
                       mu_X = 0, mu_Y = 0,
                       sigma_X = 1, sigma_Y = 1,
                       rho = r,
                       start_x = -2.5, start_y = -2.5,
                       seed = 3)),
  as_tibble(gibbs(S = n_sim,
                       mu_X = 0, mu_Y = 0,
                       sigma_X = 1, sigma_Y = 1,
                       rho = r,
                       start_x = 2.5, start_y = 2.5,
                       seed = 4)),
  .id = "chain")
```

```{r gibbs_multi_gif}
dfs100 <- Xs %>%
  group_by(chain) %>%
  transmute(
    chain,
    iter = 1:n_sim,
    th1 = V1,
    th2 = V2,
    th1l = dplyr::lag(V1, default = V1[1]),
    th2l = dplyr::lag(V2, default = V2[1])
  ) %>% 
  ungroup()
p1 <- ggplot(dfs100) +
  geom_point(aes(x = th1, y = th2, group = chain, color = chain)) +
  geom_segment(aes(x = th1, xend = th1l, y = th2, yend = th2l,
                   color = chain)) +
  stat_ellipse(data = dft, aes(x = X1, y = X2), color = "black", level = 0.9) +
  coord_cartesian(xlim = c(-3, 3), ylim = c(-3, 3)) +
  labs(title = "Gibbs", subtitle = "100 Amostragens Iniciais", x = TeX("$\\theta_1$"), y = TeX("$\\theta_2$")) +
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "NULL")

animate(p1 +
  transition_reveal(along = iter) +
  shadow_trail(0.01),
  # animation options
  height = 7, width = 7, units = "in", res = 300
)
```

## Hamiltonean Monte Carlo -- HMC

Falar do que muda. Falar da revolução que é as dinâmicas Hamiltoneanas quando aplicadas para particulas explorando a geometria de uma probabilidade posterior. Falar do momento. Em algumas simulações Metropolis possui taxa de aceitação de aproximadamente 23%, enquanto HMC 65%. Além de explorar melhor a geometria da posterior e tolerar geometrias complexas, HMC é muito mais eficiente que Metropolis e não sofre do problema de correlação dos parâmetros que Gibbs.

### Algorithm

1.  Update $\phi$ from $N(0,\mathbf{M})$

2.  Simultaneous update of $(\theta,\phi)$ involving $L$ *leapfrog steps* each scaled by a factor $\epsilon$. In a leapfrog steps, both $\theta$ and $\phi$ are changed, each in relation to the other. Repeat the following steps $L$ times:

    1.  Use the gradient of the log-posterior density of $\theta$ to make a half-step of $\phi$:

        $$\phi \leftarrow \phi + \frac{1}{2} \epsilon \frac{d \log p(\theta | y)}{d \theta}$$

    2.  Use the momentum vector $\phi$ to update the position vector $\theta$:

        $$\theta \leftarrow \theta + \epsilon \mathbf{M}^{-1} \phi$$

    3.  Again set the gradient of $\theta$ to half-update $\phi$:

        $$\phi \leftarrow \phi + \frac{1}{2} \epsilon \frac{d \log p(\theta | y)}{d \theta}$$

3.  Label $\theta^{t-1}, \phi^{t-1}$ as the value of the parameter and momentum vectors at the start of the leapfrog process and $\theta^*, \phi^*$ as the value after $L$ steps. In the accept-reject step we compute

    $$r = \frac{p(\theta^* | y) p(\phi^*)}{p(\theta^{t-1} | y) p(\phi^{-1})}$$

4.  Set

    $$\theta^t
     \begin{cases}
     \theta^* & \text{with probability min($r$,1)} \\
     \theta^{t-1} & \text{otherwise}
     \end{cases}$$

### HMC -- Implementação

Para HMC, não vou codificar o algoritmo na mão, pois envolve derivadas que não vai ser muito eficiente no R. Para isso temos o Stan. O arquivo `hmc.rds` possui 1.000 amostragens com um leapfrog $L = 40$, então no total são 40.000 iterações. O exemplo é o mesmo que usamos para Metropolis e Gibbs, uma distribuição normal multivariada de $X$ e $Y$, com correlação 0.8 ($\rho = 0.8$):

$$
\begin{bmatrix}
X \\
Y
\end{bmatrix} \sim \text{Normal Multivariada} \left(
\begin{bmatrix}
0 \\
0
\end{bmatrix}, \mathbf{\Sigma}
\right) \\
\mathbf{\Sigma} \sim
\begin{pmatrix}
1 & 0.8 \\
0.8 & 1
\end{pmatrix}
$$

```{r load_hmc}
load(here::here("R", "hmc.RData"))
df <- tibble(id = rep(1,40000),
                 iter = rep(1:1000, each = 40), 
                 th1 = tt[1:40000, 1],
                 th2 = tt[1:40000, 2],
                 th1l = c(tt[1, 1], tt[1:(40000-1), 1]),
                 th2l = c(tt[1, 2], tt[1:(40000-1), 2]))
```

Usar a função `rstan::monitor()` que simula um `print(stanfit)` mas para matrizes 3-D (sendo que a terceira dimensão é o número do correntes markov `chains`).

```{r monitor_hmc}
X <- tt[seq(1,40000,by = 40), ]
res <- monitor(X, digits_summary = 1)
neff <- res[, "n_eff"]
reff <- mean(neff / (nrow(X))) #  63%!!!
```

Comentar essa eficiência de 63%!! `reff` contando tudo com o warmup.

##### HMC -- Intuição Visual

Falar da intuição visual e que vamos usar as 100 primeiras simulações do algoritmo num GIF animado.

`HPD` = *Highest Probability Density*

```{r hmc_gif}
labs3 <- c("Amostras", "Iterações do Algoritmo", "90% HPD", "Leapfrog")
# base plot
p0 <- ggplot() +
  stat_ellipse(data = dft, aes(x = X1, y = X2, color = "3"), level = 0.9) +
  coord_cartesian(xlim = c(-3, 3), ylim = c(-3, 3)) +
  labs(title = "HMC", subtitle = "50 Amostragens Iniciais", x = TeX("$\\theta_1$"), y = TeX("$\\theta_2$")) +
  scale_color_manual(values = c("red", "forestgreen", "blue", "yellow"), labels = labs3) +
  guides(color = guide_legend(override.aes = list(
    shape = c(16, NA, NA, 16), linetype = c(0, 1, 1, 0)))) +
  theme(legend.position = "bottom", legend.title = element_blank())

# first 100 iterations
df50 <- df %>% filter(iter <= 50)
pp <- p0 + geom_point(data = df50, 
                      aes(th1, th2, color = "4"), alpha = 0.3, size = 1) +
  geom_segment(data = df50,
               aes(x = th1, xend = th1l, color = "2", y = th2, yend = th2l),
               alpha = 0.5) +
        geom_point(data = df50[seq(1, nrow(df50), by = 40), ], 
                   aes(th1, th2, color = "1"), size = 2)

animate(pp +
  transition_manual(iter, cumulative = T) +
  shadow_trail(0.05),
  # animation options
  height = 7, width = 7, units = "in", res = 300
)
```

E agora falar de como ficou nas primeiras 1.000 simulações depois do warmup de 1.000

```{r hmc_first_1000}
# Take all the 1,000 observations after warmup of 1,000
warm <- 1e3
dfs <- data.frame(
  th1 = tt[(warm + 1):nrow(tt), 1],
  th2 = tt[(warm + 1):nrow(tt), 2]
)

ggplot() +
  geom_point(data = dfs[seq(1, nrow(dfs), by = 40), ],
             aes(th1, th2, color = "1"), alpha = 0.3) +
  stat_ellipse(data = dft, aes(x = X1, y = X2, color = "2"), level = 0.9) +
  coord_cartesian(xlim = c(-3, 3), ylim = c(-3, 3)) +
  labs(title = "HMC", subtitle = "1.000 Amostragens", x = TeX("$\\theta_1$"), y = TeX("$\\theta_2$")) +
  scale_color_manual(values = c("steelblue", "blue"), labels = labs2) +
  guides(color = guide_legend(override.aes = list(
    shape = c(16, NA), linetype = c(0, 1), alpha = c(1, 1)))) +
  theme(legend.position = "bottom", legend.title = element_blank())
```

## Implementação com o `rstanarm`

Como configuração padrão, o pacote `rstanarm` utiliza uma modalidade de MCMC que usa dinâmicas Hamiltoneanas chamada **Hamiltonian Monte Carlo** (HMC). HMC é a modalidade de MCMC mais eficiente para gerar inferências Bayesianas. Em especial, `rstanarm` e a linguagem `Stan` usam HMC com uma técnica chamada **No-U-Turn Sampling** (NUTS), que faz HMC ser bem eficiente e não desperdiça amostragens.

Além disso, os argumentos padrões do HMC no `rstanarm` são o 4 correntes Markov de amostragem (`chains = 4`) e o 2.000 iterações de cada corrente (`iter = 2000`). Sendo que, por padrão, HMC descarta a primeira metade (1.000) das iterações como aquecimento (`warmup = floor(iter/2)`).

Relembrando o exemplo da aula de regressão linear, vamos usar o mesmo *dataset* `kidiq`. São dados de uma *survey* de mulheres adultas norte-americanas e seus respectivos filhos. Datado de 2007 possui 434 observações e 4 variáveis:

-   `kid_score`: QI da criança;
-   `mom_hs`: binária (0 ou 1) se a mãe possui diploma de ensino médio;
-   `mom_iq`: QI da mãe; e
-   `mom_age`: idade da mãe.

Vamos estimar um modelo de regressão linear Bayesiano na qual a variável dependente é `kid_score` e as independentes são `mom_hs` e `mom_iq`.

```{r dataset-kidiq}
options(mc.cores = parallel::detectCores())
options(Ncpus = parallel::detectCores())

library(rstanarm)
model <- stan_glm(
  kid_score ~ mom_hs + mom_iq,
  data = kidiq
  )
```

### Métricas da simulação MCMC

Um modelo estimado pelo `rstanarm` pode ser inspecionado em relação ao desempenho da amostragem MCMC. Ao chamarmos a função `summary()` no modelo estimado há uma parte chamada `MCMC diagnostics`.

```{r model_summary}
summary(model)
```

A seção `MCMC diagnostics` possui três colunas de valores para cada parâmetro estimado do modelo.

No nosso caso, temos três parâmetros importantes:

1.  valor do coeficiente da variável `mom_hs`
2.  valor do coeficiente da variável `mom_iq`
3.  valor do erro residual do modelo linear `sigma`

As três métricas são:

-   `mcse`: *Monte Carlo Standard Error*, o erro de mensuração da amostragem Monte Carlo do parâmetro
-   `n_eff`: uma aproximação crua do número de amostras efetivas amostradas pelo MCMC
-   `Rhat`: uma métrica de convergência e estabilidade da corrente Markov

A métrica mais importante para levarmos em consideração é a `Rhat` que é uma métrica que mensura se as correntes Markov são estáveis e convergiram para um valor durante o progresso total das simulações. Ela é basicamente a proporção de variação ao compararmos duas metades das correntes. Valor de $1$ implica em convergência e estabilidade. Como padrão o `Rhat` deve ser menor que $1.05$ para que a estimação Bayesiana seja válida.

### O que fazer se não obtermos convergência?

Dependendo do modelo e dos dados é possível que HMC (mesmo com NUTS) não atinja convergência. Nesse caso, ao rodar o modelo `rstanarm` dará diversos avisos de divergências.

```{r MCMC-warnings}
bad_model <- stan_glm(
  kid_score ~ mom_hs + mom_iq,
  data = kidiq,
  chains = 2,
  iter = 200
  )
```

E vemos que o `Rhat` dos parâmetros estimados do modelo estão bem acima do limiar de $1.05$.

```{r bad_model-summary}
summary(bad_model)
```

## Gráficos de Diagnósticos do MCMC

O pacote `rstanarm` tem diversos gráficos interessantes de diagnósticos de convergência das simulações MCMC.

### Traceplot

O *traceplot* é a sobreposição das amostragens MCMC das correntes para cada parâmetro estimado. A ideia é que as correntes se misturam e que não haja nenhuma inclinação ao longo das iterações.

Detalhe: aqui o *traceplot* usa somente as iterações válidas, após a remoção das iterações de `warmup`.

```{r plot-diagnostics}
plot(model, "trace")
plot(bad_model, "trace")
```

### *Posterior Predictive Check*

Um bom gráfico de diagnóstico é o *posterior predictive check* que compara o histograma da variável dependente $y$ contra o histograma variáveis dependentes simuladas pelo modelo $y_{\text{rep}}$. A ideia é que os histogramas reais e simulados se misturem e não haja divergências.

```{r pp-checks}
pp_check(model)
pp_check(bad_model)
```

## O quê fazer para que as métricas sejam convergentes

Se o seu modelo Bayesiano está com problemas de convergência há alguns passos que podem ser tentados. Aqui listados do mais simples para o mais complexo:

1.  **Aumentar o número de iterações e correntes**: primeira opção é aumentar o número de iterações do MCMC com o argumento `iter = XXX` e também é possível aumentar o número de correntes com o argumento `chains = X`. Lembrando que o padrão é `iter = 2000` e `chains = 4`.
2.  **Alterar a rotina de adaptação do HMC**: a segunda opção é fazer com que o algoritmo de amostragem HMC fique mais conservador (com proposições de pulos menores). Isto pode ser alterado com o argumento `adapt_delta` da lista de opções `control`. `control=list(adapt_delta=0.9)`. O padrão do `adapt_delta` é `control=list(adapt_delta=0.8)`. Então quaquer valor entre $0.8$ e $1.0$ o torna mais conservador.
3.  **Reparametrização do Modelo**: a terceira opção é reparametrizar o modelo. Há duas maneiras de parametrizar o modelo: a primeira com parametrização centrada (*centered parameterization*) e a segunda com parametrização não-centrada (*non-centered parameterization*). Não são assuntos que vamos cobrir aqui no curso. Recomendo o [material de um dos desenvolvedores da linguagem `Stan`, Michael Betancourt](https://mc-stan.org/users/documentation/case-studies/divergences_and_bias.html).
4.  **Coletar mais dados**: às vezes o modelo é complexo demais e precisamos de uma amostragem maior para conseguirmos estimativas estáveis.
5.  **Repensar o modelo**: falha de convergência quando temos uma amostragem adequada geralmente é por conta de uma especificação de priors e verossimilhança que não são compatíveis com os dados. Nesse caso, é preciso repensar o processo generativo de dados no qual os pressupostos do modelo estão ancorados.

## Ambiente

```{r SessionInfo}
writeLines(readLines("~/.R/Makevars"))
sessionInfo()
```
