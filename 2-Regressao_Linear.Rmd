---
title: "Regressão Linear Bayesiana"
author:
  - name: Jose Storopoli
    url: https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en
    affiliation: UNINOVE
    affiliation_url: https://www.uninove.br
    orcid_id: 0000-0002-0559-5176
date: August 2, 2021
citation_url: https://storopoli.github.io/Estatistica-Bayesiana/2-Regressao_Linear.html
slug: storopoli2021regressaolinearbayesR
bibliography: bib/bibliografia.bib
csl: bib/apa.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css"/>

A principal ferramenta para computação Bayesiana é a linguagem probabilística [`Stan`](https://mc-stan.org/). O nome homenageia [Stanislaw Ulam](https://en.wikipedia.org/wiki/Stanislaw_Ulam): um matemático polonês membro do projeto Manhattan (bomba atômica americana) e um dos principais criadores do método de Monte Carlo de simulação. `Stan` foi lançado em 2012 e é a principal ferramenta utilizada hoje para inferência estatística Bayesiana. O programa roda em linguagem `C++`, mas possui interfaces para `R`, `Python`, `MATLAB`, `Julia`, `Stata`, `Mathematica`, `Scala` e `Shell`.

O problema do `Stan` é que ele é uma **linguagem de programação** e, portanto, possui um acesso dificultado a não-programadores. Abaixo um código que mostra como é um programa escrito em `Stan`:

```{stan exemplo_stan, eval=FALSE, output.var = 'model', engine.opts = list(model_name = 'model')}
data {
  int<lower=0> N;
  vector<lower=0, upper=200>[N] kid_score;
  vector<lower=0, upper=200>[N] mom_iq;
}
parameters {
  vector[2] beta;
  real<lower=0> sigma;
}
model {
  sigma ~ cauchy(0, 2.5);
  kid_score ~ normal(beta[1] + beta[2] * mom_iq, sigma);
}
```

## `rstanarm`

Para remediar isso, temos interfaces abstratas que interpretam a intenção do usuário e lidam com a parte mais *obral* de codificação. A principal delas é o pacote `rstanarm`, que a etmologia pode ser quebrada em:

-   `r`: pacote para `R`
-   `stan`: usa a linguagem probabilística `Stan`
-   `arm`: acrônimo para *Applied Regression Modeling*

O código anterior de `Stan` ficaria assim no `rstanarm`:

```{r exemplo_rstanarm, eval=FALSE}
stan_glm(kid_score ~ mom_iq, data = dataset)
```

# Regressão Linear

A ideia aqui é modelar uma variável dependente sendo a combinação linear de variáveis independentes.

$$y = \alpha + \boldsymbol{\beta} \textbf{X} + \epsilon$$

Aonde $y$ é a variável dependente, $\alpha$ um constante, $\boldsymbol{\beta}$ um vetor de coeficientes, $\textbf{X}$ uma matriz de dados e $\epsilon$ o erro do modelo.

## Exemplo - Score de QI de crianças

Vamos aplicar modelagem estatística Bayesiana em um *dataset* famoso chamado `kidiq`. São dados de uma *survey* de mulheres adultas norte-americanas e seus respectivos filhos. Datado de 2007 possui 434 observações e 4 variáveis:

-   `kid_score`: QI da criança;
-   `mom_hs`: binária (0 ou 1) se a mãe possui diploma de ensino médio;
-   `mom_iq`: QI da mãe; e
-   `mom_age`: idade da mãe.

Vamos usar 4 modelos para modelar QI da criança (`kid_score`). Os primeiros dois modelos terão apenas um único preditor (`mom_hs` ou `mom_iq`), o terceiro usará dois preditores (`mom_hs + mom_iq`) e o quarto incluirá uma interação entre esses dois preditores (`mom_hs * mom_iq`),

### Descritivo das variáveis

Antes de tudo, analise **SEMPRE** os dados em mãos. Graficamente e com tabelas.

#### Gráficos

```{r boxplot}
# Detectar quantos cores/processadores
options(mc.cores = parallel::detectCores())
options(Ncpus = parallel::detectCores())

library(rstanarm)
data(kidiq)

boxplot(kidiq)
```

#### Tabelas

Pessoalmente uso o pacote `skimr` com a função `skim()`:

```{r skimr}
library(skimr)

skim(kidiq)
```

### Modelo 1 - `mom_hs`

Primeiro modelo é apenas a variável `mom_hs` como preditora:

```{r model_1}
model_1 <- stan_glm(
  kid_score ~ mom_hs,
  data = kidiq
  )
```

Para ver os valores estimados pelo modelo usamos a função `print`:

```{r print_model_1}
print(model_1)
```

Além disso, temos a função `summary` que traz tudo que queremos:

```{r summary_model_1}
summary(model_1)
```

### Modelo 2 - `mom_iq`

Segundo modelo é apenas a variável `mom_iq` como preditora:

```{r model_2}
model_2 <- stan_glm(
  kid_score ~ mom_iq,
  data = kidiq
  )
```

Podemos também especificar os percentis desejados no sumário:

```{r summary_model_2}
summary(model_2, probs = c(0.025, 0.975))
```

### Modelo 3 - `mom_hs + mom_iq`

Terceiro modelo usa as duas variáveis `mom_hs` e `mom_iq` como preditoras:

```{r model_3}
model_3 <- stan_glm(
  kid_score ~ mom_hs + mom_iq,
  data = kidiq
  )
```

```{r summary_model_3}
print(model_3)
```

### Modelo 4 - `mom_hs * mom_iq`

Quarto modelo usa as duas variáveis `mom_hs` e `mom_iq` como preditoras por meio de uma interação entre as duas:

```{r model_4}
model_4 <- stan_glm(
  kid_score ~ mom_hs * mom_iq,
  data = kidiq
  )
```

```{r summary_model_4}
print(model_4)
```

## Variáveis qualitativas

Para as variáveis qualitativas, o R usa um tipo especial de variável chamado `factor`. A codificação é em números inteiros $1,2,\dots,K$ mas a relação é distinta/nominal. Ou seja 1 é distinto de 2 e não 1 é 2x menor que 2. Não há relação quantitativa entre os valores das variáveis `factor`.

Isso resolve o problema de termos variáveis qualitativas (também chamadas de *dummy*) em modelos de regressão. Para um `factor` com $K$ quantidade de classes distintas, temos a possibilidade de criar $K-1$ coeficientes de regressão. Um para cada classe e usando uma como basal (*baseline*).

```{r model_5}
library(gapminder)
levels(gapminder$continent)

model_5 <- stan_glm(lifeExp ~ gdpPercap + factor(continent), data = gapminder)
```

```{r print_model_5}
print(model_5)
```

*Obs: para mudar o basal de referência de um `factor` use a função `relevel()` do R.*

## Atividade Prática

Dois *datasets* estão disponíveis na pasta `datasets/`:

1.  [WHO Life Expectancy Kaggle Dataset](https://www.kaggle.com/kumarajarshi/life-expectancy-who): `datasets/WHO_Life_Exp.csv`
2.  [Wine Quality Kaggle Dataset](https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009): `datasets/Wine_Quality.csv`

### WHO Life Expectancy

Esse dataset possui 193 países nos últimos 15 anos.

#### Variáveis

-   `country`
-   `year`
-   `status`
-   `life_expectancy`
-   `adult_mortality`
-   `infant_deaths`
-   `alcohol`
-   `percentage_expenditure`
-   `hepatitis_b`
-   `measles`
-   `bmi`
-   `under_five_deaths`
-   `polio`
-   `total_expenditure`
-   `diphtheria`
-   `hiv_aids`
-   `gdp`
-   `population`
-   `thinness_1_19_years`
-   `thinness_5_9_years`
-   `income_composition_of_resources`
-   `schooling`

### Wine Quality Kaggle Dataset

Esse dataset possui 1599 vinhos e estão relacionados com variantes tintas do vinho "Vinho Verde" português. Para mais detalhes, consulte a referência [Cortez et al., 2009]. Devido a questões de privacidade e logística, apenas variáveis físico-químicas (entradas) e sensoriais (a saída) estão disponíveis (por exemplo, não há dados sobre os tipos de uva, marca de vinho, preço de venda do vinho, etc.).

-   `fixed_acidity`
-   `volatile_acidity`
-   `citric_acid`
-   `residual_sugar`
-   `chlorides`
-   `free_sulfur_dioxide`
-   `total_sulfur_dioxide`
-   `density`
-   `p_h`
-   `sulphates`
-   `alcohol`
-   `quality`

```{r atividade}
###
```

## Referências

P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.

## Ambiente

```{r SessionInfo}
writeLines(readLines("~/.R/Makevars"))
sessionInfo()
```
