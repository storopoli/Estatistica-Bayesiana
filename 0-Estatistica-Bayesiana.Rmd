---
title: "O que é Estatística Bayesiana?"
description: "Noções de Probabilidade, Estatística Frequentista versus Estatística Bayesiana"
author:
  - name: Jose Storopoli
    url: https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en
    affiliation: UNINOVE
    affiliation_url: https://www.uninove.br
    orcid_id: 0000-0002-0559-5176
date: August 2, 2020
citation_url: https://storopoli.io/Estatistica-Bayesiana/0-Estatistica-Bayesiana.html
slug: storopoli2021estatisticabayesianaintroR
bibliography: bib/bibliografia.bib
csl: bib/apa.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      fig.align = "center",
                      fig.retina = 3)
```

<link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css"/>

A estatística Bayesiana^[maiúsculo, pois se refere ao teorema de Bayes que é um sobrenome.] é uma abordagem de análise de dados baseada no teorema de Bayes, onde o conhecimento disponível sobre os parâmetros em um modelo estatístico é atualizado com as informações dos dados observados [@gelman2013bayesian]. O conhecimento prévio é expresso como uma distribuição *a priori*^[do inglês *prior distribution*.] e combinado com os dados observados na forma de uma função de verossimilhança^[do inglês *likelihood function*.] para determinar a distribuição *a posteriori*^[do inglês *posterior distribution*] . A *posteriori* também pode ser usada para fazer previsões sobre eventos futuros.

Estatística Bayesiana está revolucionando todos os campos das ciências baseadas em evidências^[pessoalmente, como um bom Popperiano, não acreditado que haja ciência sem ser baseada em evidências; o que não usa evidências pode ser considerado como filosofia (ex: matemática) ou práticas sociais (não menos ou mais importantes que a ciência, apenas uma demarcação do que é ciência e do que não é; ex: direito).] [@vandeschootBayesianStatisticsModelling2021]. A insatisfação com métodos tradicionais de inferência estatística (estatística frequentista) e o advento dos computadores com o crescimento exponencial de poder computacional^[seu smartphone (iPhone 12 - 4GB RAM) possui 1.000.000x (1 milhão) mais poder computacional que o computador de bordo da Apollo 11 (4kB RAM) que levou o homem à lua. Detalhe: esse computador de bordo era responsável pela navegação, rota e controles do módulo lunar.] proporcionaram a ascensão da estatística Bayesiana por ser uma abordagem robusta à más-práticas científicas porém computacionalmente intensiva.

Porém antes de entrarmos em estatística Bayesiana, temos que falar de probabilidade: o motor da inferência Bayesiana.

## O que é probabilidade?

> Probabilidade não existe!
>
> @definettiTheoryProbability1974^[caso o leitor queira uma discussão aprofundada veja @nauFinettiWasRight2001.]

Essas são as primeiras palavras no prefácio do célebre livro de [Bruno de Finetti](https://en.wikipedia.org/wiki/Bruno_de_Finetti) (figura \@ref(fig:finetti)), um dos mais importantes matemáticos e filósofos da probabilidade. Sim, a probabilidade não existe. Ou melhor, probabilidade como uma quantidade física, chance objetiva, **NÃO existe**. De Finetti mostrou que, em certo sentido preciso, se dispensarmos a questão da chance objetiva *nada se perde*. A matemática do raciocínio indutivo permanece **exatamente a mesma**.

```{r finetti, echo=FALSE, fig.cap='Bruno de Finetti. Figura de https://www.wikipedia.org', out.extra='class=external'}
knitr::include_graphics("images/finetti.jpg")
```

Considere jogar uma moeda de enviesada. As tentativas são consideradas independentes e, como resultado, exibem outra propriedade importante. **A ordem não importa**. Dizer que a ordem não importa é dizer que se você pegar qualquer sequência finita de cara e coroa e permutar os resultados da maneira que quiser, a sequência resultante terá a mesma probabilidade. Dizemos que essa probabilidade é **invariante sob permutações**.

Ou, dito de outra forma, a única coisa que importa é a frequência relativa. As sequências de resultados que têm as mesmas frequências de cara e coroa consequentemente possuem a mesma probabilidade. A frequência é considerada uma **estatística suficiente**^[do inglês *sufficient statistic*.]. Dizer que a ordem não importa ou dizer que a única coisa que importa é a frequência são duas maneiras de dizer exatamente a mesma coisa. Essa propriedade é chamada de **permutabilidade** por de Finetti. E é a mais importantes propriedade da probabilidade que faz com que possamos manipulá-la matematicamente (ou filosoficamente) mesmo que ela não exista como uma "coisa" física.

Ainda desenvolvendo o argumento: "O raciocínio probabilístico –-sempre entendido como subjetivo-– decorre apenas da incerteza de algo. Não faz diferença se a incerteza diz respeito a um futuro imprevisível^[observação minha: relacionado à abordagem Bayesiana subjetiva.], ou a um passado despercebido, ou a um passado duvidosamente relatado ou esquecido^[observação minha: relacionado à abordagem frequentista objetiva.]... A única coisa relevante é a incerteza -- a extensão de nosso próprio conhecimento e ignorância. O fato real de se os eventos considerados são ou não determinados em algum sentido, ou conhecidos por outras pessoas, e assim por diante, é irrelevante" (tradução minha de @definettiTheoryProbability1974).

Concluindo: não importa o que é probabilidade, você consegue usá-la de qualquer maneira, mesmo que ela seja um frequência absoluta (ex: probabilidade de eu plantar bananeira de sunga na Avenida Paulista é ZERO pois a probabilidade de um evento que nunca ocorreu ocorrer no futuro é ZERO) ou um palpite subjetivo (ex: talvez a probabilidade não seja ZERO, mas 0,00000000000001; bem improvável, mas não impossível).

### Definição Matemática

Com a intuição filosófica de probabilidade elaborada, vamos às intuições matemáticas. A probabilidade de um evento é um número real^[um número que pode ser expressado como um ponto em uma linha contínua que se origina em menos infinito e termina e mais infinito $(-\infty, +\infty)$; para quem gosta de computação é um ponto flutuante `float` ou `double`.] entre 0 e 1, onde, grosso modo, 0 indica a impossibilidade do evento e 1 indica a certeza. Quanto maior a probabilidade de um evento, mais provável é que o evento ocorrerá. Um exemplo simples é o lançamento de uma moeda justa (imparcial). Como a moeda é justa, os dois resultados ("cara" e "coroa") são igualmente prováveis; a probabilidade de "cara" é igual à probabilidade de "coroa"; e uma vez que nenhum outro resultado é possível, a probabilidade de "cara" ou "coroa" é 1/2 (que também pode ser escrita como 0,5 ou 50%).

Sobre notação, definimos que $A$ é um evento e $P(A)$ a probabilidade do evento, logo:

$$
\{P(A) \in \mathbb{R} : 0 \geq P(A) \geq 1 \}.
$$

Isto quer dizer o "probabilidade do evento A ocorrer é o conjunto de todos os numeros reais entre 0 e 1; incluindo 0 e 1". Além disso temos três axiomas^[na matemática axiomas são afirmações pressupostas como verdadeiras que servem como premissas or pontos de partidas para elaboração de argumentos e teoremas. Muitas vezes os axiomas são questionáveis, por exemplo geometria não-Euclidiana refuta o quinto axioma de Euclides sobre linhas paralelas. Até agora não há nenhum questionamento que tenha suportado o escrutínio do tempo e da ciência sobre os três axiomas da probabilidade], oriundos de @kolmogorovFoundationsTheoryProbability1933 (figura \@ref(fig:kolmogorov)):

1. **Não-negatividade**: Para todo $A$, $P(A) \geq 0$. Toda probabilidade é positiva (maior ou igual a zero), independente do evento.
2. **Aditividade**: Para dois mutuamente exclusivos $A$ e $B$ (não podem ocorrer ao mesmo tempo ^[por exemplo, o resultado de uma moeda dado é um dos 2 eventos mutualmente exclusivos: cara ou coroa.]): $P(A) = 1 - P(B)$ e $P(B) = 1 - P(A)$.
3. **Normalização**: A probabilidade de todos os eventos possíveis $A_1, A_2, \dots$ devem somar 1: $\sum_{n \in mathbb{N}} A_n = 1$.

```{r kolmogorov, echo=FALSE, fig.cap='Andrey Nikolaevich Kolmogorov. Figura de https://www.wikipedia.org', out.extra='class=external'}
knitr::include_graphics("images/kolmogorov.jpg")
```

Com esses três simples (e intuitivos) axiomas, conseguimos derivar e construir toda a matemática da probabilidade.

### Probabilidade Condicional

Um conceito importante é a probabilidade condicional que podemos definir como "probabilidade de um evento ocorrer caso outro tenha ocorrido ou não". A notação que usamos é $P( A \mid B )$, que lê-se como "a probabilidade de observamos $A$ dado que já observamos $B$".

Um bom exemplo é o jogo de Poker Texas Hold'em, onde o jogador recebe duas cartas e podem utilizar mais cinco cartas comunitárias para montar sua "mão". A probabilidade de você receber um Rei &#127150; ($K$) é $\frac{4}{52}$:

$$
P(K) = \left(\frac{4}{52}\right) = \left(\frac{1}{13}\right).
$$

E a probabilidade de você receber um Ás &#127137; ($A$) também é $\frac{4}{52}$:

$$
P(A) = \left(\frac{4}{52}\right) = \left(\frac{1}{13}\right).
$$

Porém a probabilidade de você receber um Rei &#127150; como segunda carta dado que você recebeu um Ás &#127137; como primeira carta é:

$$
P(K \mid A) = \left(\frac{4}{51}\right).
$$

Como temos uma carta a menos $51$ já que você recebeu o Ás &#127137; (visto que $A$ foi observado), temos 4 Reis ainda no baralho &#127150; &#127166; &#127182; &#127198;, logo $\frac{4}{51}$.

### Probabilidade Conjunta

Probabilidade condicional nos leva à um outro conceito importante: probabilidade conjunta. Probabilidade conjunta é a "probabilidade de observados dois eventos ocorrem". Continuando no nosso exemplo do Poker, a probabilidade de você receber como duas cartas iniciais um Ás &#127137; ($A$) e um Rei &#127150; ($K$) é:

$$
\begin{aligned}
P(A,K) &= P(A) \cdot P(K \mid A) \\
&= P \left(\frac{1}{13}\right) \cdot P \left(\frac{4}{51}\right)\\
&= P \left(\frac{4}{51 \cdot 13}\right) \\
&\approx 0.006.
\end{aligned}
$$

Note que $P(A,K) = P(K,A)$:

$$
\begin{aligned}
P(K,A) = P(K) \cdot P(A \mid K) \\
&= P \left(\frac{1}{13}\right) \cdot P \left(\frac{4}{51}\right)\\
&= P \left(\frac{4}{51 \cdot 13}\right) \\
&\approx 0.006.
\end{aligned}
$$

No nosso exemplo de Poker temos uma certa simetria:

$$
P(K \mid A) = P(A \mid K).
$$

Mas sem sempre essa simetria existe (Na verdade muito raramente ela existe). A identidade que temos é a seguinte:

$$
P(A) \cdot P(K \mid A) = P(K) \cdot P(A \mid K).
$$

Então essa simetria só existe quando as taxas basais dos eventos condicionais são iguais:

$$
P(A) = P(K).
$$

Que é o que ocorre no nosso exemplo.

#### Probabilidade Condicional não é "comutativa"

$$P(A \mid B) \neq P(B \mid A)$$

Veja um exemplo prático. Digamos que eu estou me sentindo bem e começo a tossir na fila do mercado. O que você acha que irá acontecer? Todo mundo vai achar que estou com COVID, o que é equivalente à pensar em $P(\text{tosse} \mid \text{covid})$. Vendo os sintomas mais comuns do COVID, **caso você esteja com COVID, a chance de você tossir é muito alta**. Mas na verdade tossimos muito mais frequentemente que temos COVID ($P(\text{tosse}) \neq P(\text{COVID})$), logo:

$$
P(\text{COVID} \mid \text{tosse}) \neq P(\text{tosse} \mid \text{COVID}).
$$

### Teorema de Bayes

Este é o ultimo conceito de probabilidade que precisamos abordar antes de mergulhar na estatística Bayesiana^[palavra de escoteiro.], mas é o mais importante. Note que não é coincidência semântica que estatística Bayesiana e teorema de Bayes possuem o mesmo prefixo.

Thomas Bayes (1701 - 1761, figura \@ref(fig:bayes)) foi um estatístico, filósofo e ministro presbiteriano inglês conhecido por formular um caso específico do teorema que leva seu nome: o teorema de Bayes. Bayes nunca publicou o que se tornaria sua realização mais famosa; suas notas foram editadas e publicadas após sua morte pelo seu amigo Richard Price^[o nome formal do teorema é Bayes-Price-Laplace, pois Thomas Bayes foi o primeiro a descobrir, Richard Price pegou seus rascunhos, formalizou em notação matemática e apresentou para a Royal Society of London, e Pierre Laplace redescobriu o teorema sem ter tido contato prévio no final do século XVIII na França ao usar probabilidade para inferência estatística com dados do Censo na era Napoleônica.]. Em seus últimos anos, Bayes se interessou profundamente por probabilidade. Alguns especulam que ele foi motivado a refutar o argumento de David Hume contra a crença em milagres com base nas evidências do testemunho em "An Inquiry Concerning Human Understanding".

```{r bayes, echo=FALSE, fig.cap='Thomas Bayes. Figura de https://www.wikipedia.org', out.extra='class=external'}
knitr::include_graphics("images/thomas_bayes.gif")
```

Vamos logo para o Teorema. Lembra que temos a seguinte identidade na probabilidade:

$$
\begin{aligned}
P(A,B) &= P(B,A) \\
P(A) \cdot P(B \mid A) &= P(B) \cdot P(A \mid B).
\end{aligned}
$$

Pois bem, agora passe o $P(B)$ do lado direito para o lado esquerdo dividindo:

$$
\begin{aligned}
P(A) \cdot P(B \mid A) &= \overbrace{P(B)}^{\text{isso vai para $\leftarrow$}} \cdot P(A \mid B) \\
\frac{P(A) \cdot P(B \mid A)}{P(B)} &= P(A \mid B) \\
P(A \mid B) &= \frac{P(A) \cdot P(B \mid A)}{P(B)}.
\end{aligned}
$$

E esse é o resultado final:

$$
P(A \mid B) &= \frac{P(A) \cdot P(B \mid A)}{P(B)}.
$$

A estatística Bayesiana usa esse teorema como **motor de inferência** dos **parâmetros** de um modelo **condicionado** aos **dados observados**.

## Estatística Bayesiana

Agora que você já sabe o que é probabilidade e o que é o teorema de Bayes, vou propor o seguinte modelo:

$$
\underbrace{P(\theta \mid y)}_{\textit{Posteriori}} = \frac{\overbrace{P(y \mid  \theta)}^{\text{Verossimilhança}} \cdot \overbrace{P(\theta)}^{\textit{Priori}}}{\underbrace{P(y)}_{\text{Constante Normalizadora}}},
$$

onde:

* $\theta$ -- parâmetro(s) de interesses
* $y$ -- dados observados
* *Priori* -- probabilidade prévia do valor do(s) parâmetro(s)^[vou cobrir probabilidades prévias --*priori*-- no conteúdo da aula [3 - Priors](3-Priors.html)]
* Verossimilhança -- probabilidade dos dados observados condicionados aos valores do(s) parâmetro(s)
* *Posteriori* -- probabilidade posterior do valor do(s) parâmetros após observamos os dados $y$

A estatísica Bayesiana nos permite **quantificar diretamente a incerteza** relacionada ao valor de um ou mais parâmetros do nosso modelo condicionado ao dados observados. Isso é a **característica principal** da estatística Bayesiana. Pois estamos estimando diretamente $P(\theta \mid y)$ por meio do teorema de Bayes. A estimativa resultante é totalmente intuitiva: simplesmente quantifica a intercerteza que temos sobre o valor de um ou mais parâmetro condicionado nos dados, nos pressupostos do nosso modelo (verossimilhança) e na probabilidade prévia que temos sobre tais valores.

## Estatística Frequentista

Para contrastar com a estatística Bayesiana, vamos ver como a estatística clássica frequentista^[também chamada de ortodoxa.]. E já aviso, **não é algo intuitivo** que nem a estatística Bayesiana.

Para a estatística frequentista o pesquisador está **proibido de fazer conjecturas probabilísticas sobre parâmetros**. Pois eles não são incertos, muito pelo contrário é uma quantidade determinada. A única questão é que não observamos diretamente os parâmetros, mas eles são determinísticos e não permitem qualquer margem de incerteza. Logo, para a abordagem frequentista, parâmetros são quantidades de interesse não observadas na qual não fazemos conjecturas probabilísticas.

O que é então incerto na estatística frequentista? Resposta curta: **os dados observados**. Para a abordagem frequentista a sua amostra é incerta. É sobre ela que você pode fazer conjecturas probabilísticas. Portanto, a incerteza é expressa na probabilidade de eu obter dados similares aos que eu obtive se eu amostrasse de uma população de interesse infinitas amostras do mesmo tamanho que a minha amostra^[eu avisei que não era intuitivo...]. A incerteza é condicionada à uma abordagem frequentista, em outras palavras, a incerteza só existe se eu considerar um processo de amostragem infinito e extrair desse processo uma frequência. **A probabilidade só existe se representar uma frequência**. Mesmo se isso ocasionar em um "processo de amostragem infinito de uma população que eu nunca observei", por mais estranho que isso soe^[seu "sentido aranha" deve estar disparando agora...].

Para a abordagem frequentista não existe probabilidade *posteriori* nem *priori* pois ambas envolvem parâmetros, e vimos que isso é proibido em solo frequentista. Tudo o que é necessário para a inferência estatística está **contida na verossimilhança**. Além disso, por razões de facilidade de computação, pois boa parte desses métodos foram inventados na primeira métade do século XX (sem a ajuda do computador), apenas é computado o valor dos parâmetros que maximizam a função da verossimilhança^[para os que gostam de matemática, calculamos em qual ponto de $\theta$ a derivada da verossimilhança é zero -- $\mathcal{L}^\prime = 0$.]. Desse processo de otimização extraímos a **moda** da verossimilhança. A moda funciona perfeitamente no mundo de conto de fadas que se pressupõe que tudo segue uma distribuição normal, pois a moda é igual a mediana e a média -- $\text{média} = \text{mediana} \text{moda}$. Só tem um problema, raramente esse pressuposto é verdadeiro (figura \@ref(assumptions-vs-reality)), ainda mais quando falamos de parâmetros num contexto de pluralidade de parâmetros e relações complexas entre parâmetros (modelos complexos).

```{r assumptions-vs-reality, fig.cap='Pressupostos vs Realidade. Figura de [Katherine Hoffman](https://www.khstats.com/blog/tmle/tutorial/). Reprodução Autorizada., out.extra='class=external'}}
knitr::include_graphics("images/assumptions-vs-reality.jpeg")
```

Vale aqui uma breve explicação sociológica e computacional porque a estatística clássica proíbe conjecturas probabilísticas sobre parâmetros e trabalhamos com otimização (achar o valor máximo de uma função) do que aproximação ou estimação da **densidade completa da verossimilhança** (em outras palavras, "levantar a capivara toda" da verossimilhança ao invés de somente a moda).

Sobre a questão sociológica, a ciência no começo do século XX partia do princípio que ela é objetiva e toda subjetividade deve ser banida. Logo, como a estimação da probabilidade a *posteriori* de parâmetros envolve a elucidação de uma probabilidade a *priori* de parâmetros, tal método não deve ser permitido na ciência, pois traz subjetividade (sabemos hoje que nada no comportamento humano é puramente objetivo, e a subjetividade impregna todas as empreitadas humanas).

Sobre a questão computacional, na década de 1930s sem computadores era muito mais fácil usar pressupostos fortes sobre os dados para conseguir uma resposta de uma estimação estatística usando derivações matemáticas do que calcular na mão a estimação estatística sem depender de tais pressupostos. Por exemplo: o famoso teste $t$ de Student é um teste que diz quando conseguimos rejeitar que a média de um certo parâmetro de interesse entre dois grupos é igual (famosa hipótese nula -- $H_0$). Esse teste parte do pressuposto que se o parâmetro de interesse for distribuído conforme uma distribuição normal (pressuposto 1 -- normalidade da variável dependente), se a variância do parâmetro de interesse varia de maneira homogênea dentre os grupos (pressuposto 2 -- homogeneidade das variâncias) e se o número de observações nos dois grupos de interesse é similar (pressuposto 3 -- homogeneidade do tamanho dos grupos) a diferença entre os grupos ponderada pela variânca dos grupos segue uma distribuição $t$ de Student (por isso o nome do teste). Então a estimação estatística se resume a calcular a média de dois grupos, a variância de cada um deles para um parâmetro de interesse e buscar o tal do $p$-valor numa tabela e ver se conseguimos rejeitar a $H_0$. Isto é válido quando tudo o que fazemos é calculado na mão, hoje com um computador 1 milhão de vezes mais potente que o computador da Apollo 11 (levou a humanidade à lua) no seu bolso, não sei se ainda é valido.

Para concluir, vamos falar sobre os famosos intervalos de confiança, que não são uma medida que quantifica a incerteza do valor de um parâmetro (lembre-se conjecturas probabilísticas sobre parâmetros são proibidos em frequentist-land). Segure seu queixo, intervalos de confiança são:

> Um intervalo de confiança de X% para um parâmetro é um intervalo $(a, b)$ gerado por um procedimento que em amostragem repetida tem uma probabilidade de X% de conter o valor verdadeiro do parâmetro, para todos os valores possíveis do parâmetro
>
> @neyman1937outline (o "pai" dos intervalos de confiança)

Mais uma vez a ideia da amostragem repetida infinita vezes de uma população que você nunca viu. Por exemplo: digamos que você executou uma análise estatística para comparar eficácia de uma política pública em dois grupos e você obteve a diferença entre a média desses grupos. Você pode expressar essa diferença como um intervalo de confiança. Geralmente escolhemos a confiança de 95%. Você então escreve no seu artigo que a “diferença entre grupos observada é de 10.5 - 23.5 (95% IC).” Isso quer dizer que 95 estudos de 100, que usem o mesmo tamanho de amostra e população-alvo, aplicando o mesmo teste estatístico, esperarão encontrar um resultado de diferenças de média entre grupos entre 10.5 e 23.5. Aqui as unidades são arbitrárias, mas para continuar o exemplo vamos supor que sejam expectativa de vida.

Infelizmente com estatística frequentista você tem que escolher uma das duas qualidades para explicações: intuitiva ou precisa^[isto foi copiado de Andrew Gelman -- Estatístico Bayesiano.].

## Estatística Bayesiana vs Frequentista

O que discutimos acima de resume nessa tabela abaixo:

|               | Estatística Bayesiana                | Estatística Frequentista                                            |
|---------------|--------------------------------------|---------------------------------------------------------------------|
| Dados         | Fixos -- Não Aleatórios              | Incertos -- Aleatórios                                              |
| Parâmetros    | Incertos -- Aleatorios               | Fixos -- Não Aleatórios                                             |
| Inferência    | Incerteza sobre o valor do parâmetro | Incerteza sobre um processo de amostragem de uma população infinita |
| Probabilidade | Subjetiva                            | Objetiva (mas com diversos pressupostos dos modelos)                |

### Exemplo Prático

Imagine que você está avaliando um jogador de basquete. Você precisa decidir se irá contratá-lo para o seu time. A principal característica que você examinará será a taxa de acerto de cestas de 3 pontos. Esse é o nosso parâmetro de interesse e a partir de agora vamos chamá-lo de $\theta$ (letra grega^[na estatística geralmente temos a convenção de usar letras romanas ($a, b, c, d, \dots$) para quantidades que sabemos o valor (exemplo: média de uma amostra); e letras gregas ($\alpha, \beta, \gamma, \dots$) para quantidades que não sabemos o valor preciso e queremos estimar (exemplo: média de uma população estimada a partir da média de uma amostra).] theta). $\theta$ pode assumir qualquer valor entre 0 e 1, sendo 0 representando uma taxa de acerto de 0% do jogador---ele *sempre erra* as tentativas de cestas de 3 pontos; e 1 representando uma taxa de acerto 100% do jogador--- ele *sempre acerta* as tentativas de cestas de 3 pontos.

É claro que $\theta$ raramente será 0 ou 1, mas sim um valor entre esses dois extremos. Podemos representar $\theta$ com uma distribuição beta. A distribuição beta é especificada por dois parâmetros com valores sempre positivos ($\geq 0$): $\alpha$^[letra grega alpha.] e $\beta$^[letra grega beta.]. Você pode pensar em $\alpha - 1$ como o número de acertos e $\beta - 1$ como o número de erros. Na figura \@ref(fig:dist-beta-1) é possível ver uma distribuição beta para vários valores iguais de parâmetros $\alpha$ e $\beta$. Veja que conforme o valor de $\alpha$ e $\beta$ aumentam a probabilidade de $\theta$ tende a convergir para o valor de 0.5 (50%).

```{r dist-beta-1, fig.cap='Comparativo de Distribuições Beta -- Valores Iguais de $\\alpha$ e $\\beta$'}
library(ggplot2)
theme_set(theme_minimal())

ggplot(data = data.frame(x = c(0, 1))) +
  labs(
    title = "Comparativo de Distribuições Beta",
    subtitle = expression(alpha == beta),
    x = expression(theta),
    y = "Densidade",
    color = "Parâmetros"
  ) +
  stat_function(aes(color = "list(alpha, beta) ==  1"), fun = dbeta, args = list(
    shape1 = 1, shape2 = 1), size = 2) +
  stat_function(aes(color = "list(alpha, beta) ==  2"), fun = dbeta, args = list(
    shape1 = 2, shape2 = 2), size = 2) +
  stat_function(aes(color = "list(alpha, beta) ==  3"), fun = dbeta, args = list(
    shape1 = 3, shape2 = 3), size = 2) +
    stat_function(aes(color = "list(alpha, beta) ==  4"), fun = dbeta, args = list(
    shape1 = 4, shape2 = 4), size = 2) +
  scale_color_brewer(palette = "Set1",
    labels = scales::label_parse())
```

Conforme os valores de $\alpha$ e $\beta$ diferem um do outro começamos a ver a probabilidade de $\theta$ se distanciar de 0.5 e a distribuição começa a ser assimétrica, tendenciando para algum extremo. Na figura \@ref(fig:dist-beta-2) é possível ver uma distribuição beta para vários valores diferentes de parâmetros $\alpha$ e $\beta$.

```{r dist-beta-2, fig.cap='Comparativo de Distribuições Beta -- Valores Diferentes de $\\alpha$ e $\\beta$'}
library(ggplot2)

ggplot(data = data.frame(x = c(0, 1))) +
  labs(
    title = "Comparativo de Distribuições Beta",
    subtitle = expression(alpha != beta),
    x = expression(theta),
    y = "Densidade",
    color = "Parâmetros"
  ) +
  stat_function(aes(color = "list(alpha == 3, beta == 2)"), fun = dbeta, args = list(
    shape1 = 3, shape2 = 2), size = 2) +
  stat_function(aes(color = "list(alpha == 2, beta ==  3)"), fun = dbeta, args = list(
    shape1 = 2, shape2 = 3), size = 2) +
  stat_function(aes(color = "list(alpha == 4, beta ==  2)"), fun = dbeta, args = list(
    shape1 = 4, shape2 = 2), size = 2) +
    stat_function(aes(color = "list(alpha == 2, beta ==  4)"), fun = dbeta, args = list(
    shape1 = 2, shape2 = 4), size = 2) +
  scale_color_brewer(palette = "Set1",
    labels = scales::label_parse())
```

## O que é o maldito $p$-valor?

Teste t: ￼$P(D \mid \text{efeito nulo})$
ANOVA: ￼$P(D \mid \text{não há diferença entre os grupos})$
Regressão: ￼$P(D \mid \text{coeficiente é nulo})$
Shapiro-Wilk: $P(D \mid \text{amostra é normal})$

Mas o que estamos realmente interessados é na $P(H_0)$

## Teorema de Bayes

Ranca fora a constante Normalizadora

$$\underbrace{P(\theta \mid y)}_{\text{Posterior}} \propto \overbrace{P(y \mid \theta)}^{\text{Likelihood}} \cdot \overbrace{P(\theta)}^{\text{Prior}} = \underbrace{P(\theta, y)}_{\text{Probabilidade Conjunta}}$$

$\propto$ (comando $\LaTeX$ `\propto`) quer dizer "proporcional à".

* Animação com uma distribuição beta de um flip of a coin com updated beliefs by posterior


## Vantagens da Estatística Bayesiana

* Abordagem Natural para expressar incerteza
* Habilidade de incorporar informações prévia
* Maior flexibilidade do modelo
* Distribuição posterior completa dos parâmetros
  * Intervalos de Confiança vs Intervalos de Credibilidade
  * Point Estimate vs Full Posterior Density
  * Mesmo com Intervalos de Confiança você está falando ainda de Point Estimate -- Optimization of Likelihood when the derivative is at zero
  * MLE estimation is the value of the parameters such that the most likely dataset of size N to randomly draw from a population is the dataset that you actually drew. Every other potential dataset that could be drawn from this population is going to fit worse than the dataset that you actually have.
* Propagação natural da incerteza

* Fisher — "were Fisher alive today, he would be a Bayesian"
    * Fisher published an article (Fisher, 1962) examining the possibilities of Bayesian methods, but with the prior probabilities to be determined experimentally!
    * Fisher, R. A. (1962), ‘Some examples of Bayes’ method of the experimental determination of probability a priori’, J. Roy. Stat. Soc. B 24, 118–124.

* Modelos hierárquicos. lme4 não computa p-valores para os random effects
* Exemplo do teste t normal e o bayesiano

## Desvantagens

* Velocidade lenta de estimativa do modelo (30 segundos ao invés de 3 segundos)

Falar do poder computacional — flops
Falar da facilidade de testes ortodoxos de computação

## Stan

```{r stan_billions}
knitr::include_graphics("images/stan_billions_subtitled.mp4")
```

* rstan
* rstanarm
* brms

## Ambiente

```{r SessionInfo}
sessionInfo()
```
