{
  "articles": [
    {
      "path": "0-Estatistica-Bayesiana.html",
      "title": "O que é Estatística Bayesiana?",
      "description": "Noções de Probabilidade, Estatística Frequentista versus Estatística Bayesiana",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 1, 2021",
      "contents": "\n\nContents\nO que é probabilidade?\nDefinição Matemática\nProbabilidade Condicional\nProbabilidade Conjunta\nTeorema de Bayes\nParâmetros Discretos vs Contínuos\n\nEstatística Bayesiana\nEstatística Frequentista\n\\(p\\)-valores\nO que o \\(p\\)-valor não é\nIntervalos de Confiança\n\nEstatística Bayesiana vs Frequentista\nVantagens da Estatística Bayesiana\nO começo do fim da Estatística Frequentista\nStan\nHistória do Stan\n\nAmbiente\n\n\nA estatística Bayesiana1 é uma abordagem de análise de dados baseada no teorema de Bayes, onde o conhecimento disponível sobre os parâmetros em um modelo estatístico é atualizado com as informações dos dados observados (Gelman et al., 2013). O conhecimento prévio é expresso como uma distribuição a priori2 e combinado com os dados observados na forma de uma função de verossimilhança3 para determinar a distribuição a posteriori4 . A posteriori também pode ser usada para fazer previsões sobre eventos futuros.\nEstatística Bayesiana está revolucionando todos os campos das ciências baseadas em evidências5 (van de Schoot et al., 2021). A insatisfação com métodos tradicionais de inferência estatística (estatística frequentista) e o advento dos computadores com o crescimento exponencial de poder computacional6 proporcionaram a ascensão da estatística Bayesiana por ser uma abordagem alinhada com a intuição humana de incerteza, robusta à más-práticas científicas, porém computacionalmente intensiva.\nPorém antes de entrarmos em estatística Bayesiana, temos que falar de probabilidade: o motor da inferência Bayesiana.\nO que é probabilidade?\n\nProbabilidade não existe!\nde Finetti (1974)7\n\nEssas são as primeiras palavras no prefácio do célebre livro de Bruno de Finetti (figura 1), um dos mais importantes matemáticos e filósofos da probabilidade. Sim, a probabilidade não existe. Ou melhor, probabilidade como uma quantidade física, chance objetiva, NÃO existe. De Finetti mostrou que, em certo sentido preciso, se dispensarmos a questão da chance objetiva nada se perde. A matemática do raciocínio indutivo permanece exatamente a mesma.\n\n\n\nFigure 1: Bruno de Finetti. Figura de https://www.wikipedia.org\n\n\n\nConsidere jogar uma moeda de enviesada. As tentativas são consideradas independentes e, como resultado, exibem outra propriedade importante. A ordem não importa. Dizer que a ordem não importa é dizer que se você pegar qualquer sequência finita de cara e coroa e permutar os resultados da maneira que quiser, a sequência resultante terá a mesma probabilidade. Dizemos que essa probabilidade é invariante sob permutações.\nOu, dito de outra forma, a única coisa que importa é a frequência relativa. As sequências de resultados que têm as mesmas frequências de cara e coroa consequentemente possuem a mesma probabilidade. A frequência é considerada uma estatística suficiente8. Dizer que a ordem não importa ou dizer que a única coisa que importa é a frequência são duas maneiras de dizer exatamente a mesma coisa. Essa propriedade é chamada de permutabilidade por de Finetti. E é a mais importantes propriedade da probabilidade que faz com que possamos manipulá-la matematicamente (ou filosoficamente) mesmo que ela não exista como uma “coisa” física.\nAinda desenvolvendo o argumento: “O raciocínio probabilístico –sempre entendido como subjetivo– decorre apenas da incerteza de algo. Não faz diferença se a incerteza diz respeito a um futuro imprevisível9, ou a um passado despercebido, ou a um passado duvidosamente relatado ou esquecido10… A única coisa relevante é a incerteza – a extensão de nosso próprio conhecimento e ignorância. O fato real de se os eventos considerados são ou não determinados em algum sentido, ou conhecidos por outras pessoas, e assim por diante, é irrelevante” (tradução minha de de Finetti (1974)).\nConcluindo: não importa o que é probabilidade, você consegue usá-la de qualquer maneira, mesmo que ela seja um frequência absoluta (ex: probabilidade de eu plantar bananeira de sunga na Avenida Paulista é ZERO pois a probabilidade de um evento que nunca ocorreu ocorrer no futuro é ZERO) ou um palpite subjetivo (ex: talvez a probabilidade não seja ZERO, mas 0,00000000000001; bem improvável, mas não impossível).\nDefinição Matemática\nCom a intuição filosófica de probabilidade elaborada, vamos às intuições matemáticas. A probabilidade de um evento é um número real11 entre 0 e 1, onde, grosso modo, 0 indica a impossibilidade do evento e 1 indica a certeza do evento. Quanto maior a probabilidade de um evento, mais provável é que o evento ocorrerá. Um exemplo simples é o lançamento de uma moeda justa (imparcial). Como a moeda é justa, os dois resultados (“cara” e “coroa”) são igualmente prováveis; a probabilidade de “cara” é igual à probabilidade de “coroa”; e uma vez que nenhum outro resultado é possível, a probabilidade de “cara” ou “coroa” é \\(\\frac{1}{2}\\) (que também pode ser escrita como 0,5 ou 50%).\nSobre notação, definimos que \\(A\\) é um evento e \\(P(A)\\) a probabilidade do evento, logo:\n\\[\n\\{P(A) \\in \\mathbb{R} : 0 \\geq P(A) \\geq 1 \\}.\n\\]\nIsto quer dizer o “probabilidade do evento A ocorrer é o conjunto de todos os numeros reais entre 0 e 1; incluindo 0 e 1.” Além disso temos três axiomas12, oriundos de Kolmogorov (1933) (figura 2):\nNão-negatividade: Para todo \\(A\\), \\(P(A) \\geq 0\\). Toda probabilidade é positiva (maior ou igual a zero), independente do evento.\nAditividade: Para dois mutuamente exclusivos \\(A\\) e \\(B\\) (não podem ocorrer ao mesmo tempo13): \\(P(A) = 1 - P(B)\\) e \\(P(B) = 1 - P(A)\\).\nNormalização: A probabilidade de todos os eventos possíveis \\(A_1, A_2, \\dots\\) devem somar 1: \\(\\sum_{n \\in \\mathbb{N}} A_n = 1\\).\n\n\n\nFigure 2: Andrey Nikolaevich Kolmogorov. Figura de https://www.wikipedia.org\n\n\n\nCom esses três simples (e intuitivos) axiomas, conseguimos derivar e construir toda a matemática da probabilidade.\nProbabilidade Condicional\nUm conceito importante é a probabilidade condicional que podemos definir como “probabilidade de um evento ocorrer caso outro tenha ocorrido ou não.” A notação que usamos é \\(P( A \\mid B )\\), que lê-se como “a probabilidade de observamos \\(A\\) dado que já observamos \\(B\\).”\nUm bom exemplo é o jogo de Poker Texas Hold’em, onde o jogador recebe duas cartas e podem utilizar mais cinco cartas comunitárias para montar sua “mão.” A probabilidade de você receber um Rei (\\(K\\)) é \\(\\frac{4}{52}\\):\n\\[\nP(K) = \\left(\\frac{4}{52}\\right) = \\left(\\frac{1}{13}\\right).\n\\]\nE a probabilidade de você receber um Ás (\\(A\\)) também é \\(\\frac{4}{52}\\):\n\\[\nP(A) = \\left(\\frac{4}{52}\\right) = \\left(\\frac{1}{13}\\right).\n\\]\nPorém a probabilidade de você receber um Rei como segunda carta dado que você recebeu um Ás como primeira carta é:\n\\[\nP(K \\mid A) = \\left(\\frac{4}{51}\\right).\n\\]\nComo temos uma carta a menos (\\(52 - 1 = 51\\)) já que você recebeu o Ás (visto que \\(A\\) foi observado), temos 4 Reis ainda no baralho, logo \\(\\frac{4}{51}\\).\nProbabilidade Conjunta\nProbabilidade condicional nos leva à um outro conceito importante: probabilidade conjunta. Probabilidade conjunta é a “probabilidade de observados dois eventos ocorrem.” Continuando no nosso exemplo do Poker, a probabilidade de você receber como duas cartas iniciais um Ás (\\(A\\)) e um Rei (\\(K\\)) é:\n\\[\n\\begin{aligned}\nP(A,K) &= P(A) \\cdot P(K \\mid A) \\\\\n&= P \\left(\\frac{1}{13}\\right) \\cdot P \\left(\\frac{4}{51}\\right)\\\\\n&= P \\left(\\frac{4}{51 \\cdot 13}\\right) \\\\\n&\\approx 0.006.\n\\end{aligned}\n\\]\nNote que \\(P(A,K) = P(K,A)\\):\n\\[\n\\begin{aligned}\nP(K,A) &= P(K) \\cdot P(A \\mid K) \\\\\n&= P \\left(\\frac{1}{13}\\right) \\cdot P \\left(\\frac{4}{51}\\right)\\\\\n&= P \\left(\\frac{4}{51 \\cdot 13}\\right) \\\\\n&\\approx 0.006.\n\\end{aligned}\n\\]\nNo nosso exemplo de Poker temos uma certa simetria:\n\\[\nP(K \\mid A) = P(A \\mid K).\n\\]\nMas sem sempre essa simetria existe (na verdade muito raramente ela existe). A identidade que temos é a seguinte:\n\\[\nP(A) \\cdot P(K \\mid A) = P(K) \\cdot P(A \\mid K).\n\\]\nEntão essa simetria só existe quando as taxas basais dos eventos condicionais são iguais:\n\\[\nP(A) = P(K).\n\\]\nQue é o que ocorre no nosso exemplo.\nProbabilidade Condicional não é “comutativa”\n\\[P(A \\mid B) \\neq P(B \\mid A)\\]\nVeja um exemplo prático. Digamos que eu estou me sentindo bem e começo a tossir na fila do mercado. O que você acha que irá acontecer? Todo mundo vai achar que estou com COVID, o que é equivalente à pensar em \\(P(\\text{tosse} \\mid \\text{covid})\\). Vendo os sintomas mais comuns do COVID, caso você esteja com COVID, a chance de você tossir é muito alta. Mas na verdade tossimos muito mais frequentemente que temos COVID – \\(P(\\text{tosse}) \\neq P(\\text{COVID})\\), logo:\n\\[\nP(\\text{COVID} \\mid \\text{tosse}) \\neq P(\\text{tosse} \\mid \\text{COVID}).\n\\]\nTeorema de Bayes\nEste é o ultimo conceito de probabilidade que precisamos abordar antes de mergulhar na estatística Bayesiana14, mas é o mais importante. Note que não é coincidência semântica que estatística Bayesiana e teorema de Bayes possuem o mesmo prefixo.\nThomas Bayes (1701 - 1761, figura 3) foi um estatístico, filósofo e ministro presbiteriano inglês conhecido por formular um caso específico do teorema que leva seu nome: o teorema de Bayes. Bayes nunca publicou o que se tornaria sua realização mais famosa; suas notas foram editadas e publicadas após sua morte pelo seu amigo Richard Price15. Em seus últimos anos, Bayes se interessou profundamente por probabilidade. Alguns especulam que ele foi motivado a refutar o argumento de David Hume contra a crença em milagres com base nas evidências do testemunho em “An Inquiry Concerning Human Understanding.”\n\n\n\nFigure 3: Thomas Bayes. Figura de https://www.wikipedia.org\n\n\n\nVamos logo para o Teorema. Lembra que temos a seguinte identidade na probabilidade:\n\\[\n\\begin{aligned}\nP(A,B) &= P(B,A) \\\\\nP(A) \\cdot P(B \\mid A) &= P(B) \\cdot P(A \\mid B).\n\\end{aligned}\n\\]\nPois bem, agora passe o \\(P(B)\\) do lado direito para o lado esquerdo dividindo:\n\\[\n\\begin{aligned}\nP(A) \\cdot P(B \\mid A) &= \\overbrace{P(B)}^{\\text{isso vai para $\\leftarrow$}} \\cdot P(A \\mid B) \\\\\n&\\\\\n\\frac{P(A) \\cdot P(B \\mid A)}{P(B)} &= P(A \\mid B) \\\\\nP(A \\mid B) &= \\frac{P(A) \\cdot P(B \\mid A)}{P(B)}.\n\\end{aligned}\n\\]\nE esse é o resultado final:\n\\[\nP(A \\mid B) = \\frac{P(A) \\cdot P(B \\mid A)}{P(B)}.\n\\]\nA estatística Bayesiana usa esse teorema como motor de inferência dos parâmetros de um modelo condicionado aos dados observados.\nParâmetros Discretos vs Contínuos\nTudo o que foi exposto até agora partiu do pressuposto que os parâmetros são discretos. Isto foi feito com o intuito de prover uma melhor intuição do que é probabilidade. Nem sempre trabalhamos com parâmetros discretos. Os parâmetros podem ser contínuos, como por exemplo: idade, altura, peso etc. Mas não se desespere, todas as regras e axiomas da probabilidade são válidos também para parâmetros contínuos. A única coisa que temos que fazer é trocar todas as somas \\(\\sum\\) por integrais \\(\\int\\). Por exemplo o terceiro axioma de Normalização para variáveis aleatórias contínuas se torna:\n\\[\n\\int_{x \\in X} p(x) dx = 1.\n\\]\nEstatística Bayesiana\nAgora que você já sabe o que é probabilidade e o que é o teorema de Bayes, vou propor o seguinte modelo:\n\\[\n\\underbrace{P(\\theta \\mid y)}_{\\textit{Posteriori}} = \\frac{\\overbrace{P(y \\mid  \\theta)}^{\\text{Verossimilhança}} \\cdot \\overbrace{P(\\theta)}^{\\textit{Priori}}}{\\underbrace{P(y)}_{\\text{Constante Normalizadora}}},\n\\]\nonde:\n\\(\\theta\\) – parâmetro(s) de interesse\n\\(y\\) – dados observados\nPriori – probabilidade prévia do valor do(s) parâmetro(s)16\nVerossimilhança – probabilidade dos dados observados condicionados aos valores do(s) parâmetro(s)\nPosteriori – probabilidade posterior do valor do(s) parâmetros após observamos os dados \\(y\\)\nConstante Normalizadora – \\(P(y)\\) não faz sentido intuitivo. Essa probabilidade é transformada e pode ser interepretada como algo que existe apenas para que o resultado de \\(P(y \\mid \\theta) P(\\theta)\\) seja algo entre 0 e 1 – uma probabilidade válida. Vamos falar mais sobre essa constante na Aula 5 - Markov Chain Montecarlo – MCMC\nA estatísica Bayesiana nos permite quantificar diretamente a incerteza relacionada ao valor de um ou mais parâmetros do nosso modelo condicionado ao dados observados. Isso é a característica principal da estatística Bayesiana. Pois estamos estimando diretamente \\(P(\\theta \\mid y)\\) por meio do teorema de Bayes. A estimativa resultante é totalmente intuitiva: simplesmente quantifica a intercerteza que temos sobre o valor de um ou mais parâmetro condicionado nos dados, nos pressupostos do nosso modelo (verossimilhança) e na probabilidade prévia que temos sobre tais valores.\nEstatística Frequentista\nPara contrastar com a estatística Bayesiana, vamos ver como a estatística clássica frequentista17. E já aviso, não é algo intuitivo que nem a estatística Bayesiana.\nPara a estatística frequentista o pesquisador está proibido de fazer conjecturas probabilísticas sobre parâmetros. Pois eles não são incertos, muito pelo contrário é uma quantidade determinada. A única questão é que não observamos diretamente os parâmetros, mas eles são determinísticos e não permitem qualquer margem de incerteza. Logo, para a abordagem frequentista, parâmetros são quantidades de interesse não observadas na qual não fazemos conjecturas probabilísticas.\nO que é então incerto na estatística frequentista? Resposta curta: os dados observados. Para a abordagem frequentista a sua amostra é incerta. É sobre ela que você pode fazer conjecturas probabilísticas. Portanto, a incerteza é expressa na probabilidade de eu obter dados similares aos que eu obtive se eu amostrasse de uma população de interesse infinitas amostras do mesmo tamanho que a minha amostra18. A incerteza é condicionada à uma abordagem frequentista, em outras palavras, a incerteza só existe se eu considerar um processo de amostragem infinito e extrair desse processo uma frequência. A probabilidade só existe se representar uma frequência. Mesmo se isso ocasionar em um “processo de amostragem infinito de uma população que eu nunca observei,” por mais estranho que isso soe19.\nPara a abordagem frequentista não existe probabilidade posteriori nem priori pois ambas envolvem parâmetros, e vimos que isso é proibido em solo frequentista. Tudo o que é necessário para a inferência estatística está contida na verossimilhança20.\nAlém disso, por razões de facilidade de computação, pois boa parte desses métodos foram inventados na primeira métade do século XX (sem a ajuda do computador), apenas é computado o valor dos parâmetros que maximizam a função da verossimilhança21. Desse processo de otimização extraímos a moda da verossimilhança. A estimativa de maximização da verossimilhança é o valor dos parâmetros de forma que a amostra de tamanho \\(N\\) amostrada de maneira aleatória de uma população (os dados que você tem) é a amostra de tamanho \\(N\\) mais provável da população. Todas as outras amostras potenciais que poderiam ser extraídos dessa população terão uma estimação pior do que a amostra que você realmente tem22.\nA moda funciona perfeitamente no mundo de conto de fadas que se pressupõe que tudo segue uma distribuição normal, pois a moda é igual a mediana e a média – \\(\\text{média} = \\text{mediana} = \\text{moda}\\). Só tem um problema, raramente esse pressuposto é verdadeiro (figura 4), ainda mais quando falamos de parâmetros num contexto de pluralidade de parâmetros e relações complexas entre parâmetros (modelos complexos).\n\n\n\nFigure 4: Pressupostos vs Realidade. Figura de Katherine Hoffman. Reprodução Autorizada.\n\n\n\nVale aqui uma breve explicação sociológica e computacional porque a estatística clássica proíbe conjecturas probabilísticas sobre parâmetros e trabalhamos com otimização (achar o valor máximo de uma função) do que aproximação ou estimação da densidade completa da verossimilhança (em outras palavras, “levantar a capivara toda” da verossimilhança ao invés de somente a moda).\nSobre a questão sociológica, a ciência no começo do século XX partia do princípio que ela é objetiva e toda subjetividade deve ser banida. Logo, como a estimação da probabilidade a posteriori de parâmetros envolve a elucidação de uma probabilidade a priori de parâmetros, tal método não deve ser permitido na ciência, pois traz subjetividade (sabemos hoje que nada no comportamento humano é puramente objetivo, e a subjetividade impregna todas as empreitadas humanas).\nSobre a questão computacional, na década de 1930s sem computadores era muito mais fácil usar pressupostos fortes sobre os dados para conseguir uma resposta de uma estimação estatística usando derivações matemáticas do que calcular na mão a estimação estatística sem depender de tais pressupostos. Por exemplo: o famoso teste \\(t\\) de Student é um teste que indica quando conseguimos rejeitar que a média de um certo parâmetro de interesse entre dois grupos é igual (famosa hipótese nula – \\(H_0\\)). Esse teste parte do pressuposto que se o parâmetro de interesse for distribuído conforme uma distribuição normal (pressuposto 1 – normalidade da variável dependente), se a variância do parâmetro de interesse varia de maneira homogênea dentre os grupos (pressuposto 2 – homogeneidade das variâncias) e se o número de observações nos dois grupos de interesse é similar (pressuposto 3 – homogeneidade do tamanho dos grupos) a diferença entre os grupos ponderada pela variância dos grupos segue uma distribuição \\(t\\) de Student (por isso o nome do teste).\nEntão a estimação estatística se resume a calcular a média de dois grupos, a variância de cada um deles para um parâmetro de interesse e buscar o tal do \\(p\\)-valor numa tabela e ver se conseguimos rejeitar a \\(H_0\\). Isto é válido quando tudo o que fazemos é calculado na mão, hoje com um computador 1 milhão de vezes mais potente que o computador da Apollo 11 (levou a humanidade à lua) no seu bolso23, não sei se ainda é valido.\n\\(p\\)-valores\n\n\\(p\\)-valores são de difícil entendimento, \\(p < 0.05\\).\n\n\n\n\nJá que mencionamos \\(p\\)-valor, vamos então explicar o que é o \\(p\\)-valor. Primeiramente a definição estatística:\n\n\\(p\\)-valor é a probabilidade de obter resultados no mínimo tão extremos quanto os que foram observados, dado que a hipótese nula \\(H_0\\) é verdadeira.\n\nSe você escrever essa definição em qualquer prova, livro ou artigo científico, você estará 100% preciso e correto na definição do que é um \\(p\\)-valor. Agora, a compreensão dessa definição é algo complicado. Para isso, vamos quebrar essa definição em algumas partes para melhor compreensão:\n“probabilidade de obter resultados…”: vejam que \\(p\\)-valores são uma característica dos seus dados e não da sua teoria ou hipótese.\n“…no mínimo tão extremos quanto os que foram observados…”: “no minimo tão” implica em definir um limiar para a caracterização de algum achado relevante, que é comumente chamado de \\(\\alpha\\). Geralmente estipulamos alpha em 5% (\\(\\alpha = 0.05\\)) e qualquer coisa mais extrema que alpha (ou seja menor que 5%) caracterizamos como significante.\n“..dado que a hipótese nula é verdadeira…”: Todo teste estatístico que possui um \\(p\\)-valor possui uma Hipótese Nula (geralmente escrita como \\(H_0\\)). Hipótese nula, sempre tem a ver com algum efeito nulo. Por exemplo, a hipótese nula do teste Shapiro-Wilk e Komolgorov-Smirnov é “os dados são distribuídos conforme uma distribuição Normal” e a do teste de Levene é “as variâncias dos dados são iguais.” Sempre que ver um \\(p\\)-valor, se pergunte: “Qual a hipótese nula que este teste presupõe correta?”\nPara entender o \\(p\\)-valor qualquer teste estatístico primeiro descubra qual é a hipótese nula por trás daquele teste. A definição do \\(p\\)-valor não mudará. Em todo teste ela é sempre a mesma. O que muda com o teste é a hipótese nula. Cada teste possui sua \\(H_0\\). Por exemplo, alguns testes estatísticos comuns:\nTeste t: \\(P(D \\mid \\text{efeito nulo})\\)\nANOVA: \\(P(D \\mid \\text{não há diferença entre os grupos})\\)\nRegressão: \\(P(D \\mid \\text{coeficiente é nulo})\\)\nShapiro-Wilk: \\(P(D \\mid \\text{amostra é normal})\\)\n\\(p\\)-valor é a probabilidade dos dados que você obteve dado que a hipótese nula é verdadeira. Para os que gostam do formalismo matemático: \\(p = P(D \\mid H_0)\\). Em português, essa expressão significa “a probabilidade de \\(D\\) condicionado à \\(H_0\\).” Antes de avançarmos para alguns exemplos e tentativas de formalizar uma intuição sobre os \\(p\\)-valores, é importante ressaltar que \\(p\\)-valores dizem algo à respeito dos dados e não de hipóteses. Para o \\(p\\)-valor, a hipótese nula é verdadeira, e estamos apenas avaliando se os dados se conformam à essa hipótese nula ou não. Se vocês saírem desse tutorial munidos com essa intuição, o mundo será agraciado com pesquisadores mais preparados para qualificar e interpretar evidências (\\(p < 0.05\\)).\nExemplo intuitivo:\n\nImagine que você tem uma moeda que suspeita ser enviesada para uma probabilidade maior de dar cara. (Sua hipótese nula é então que a moeda é justa.) Você joga a moeda 100 vezes e obtém mais cara do que coroa. O \\(p\\)-valor não dirá se a moeda é justa, mas dirá a probabilidade de você obter pelo menos tantas caras quanto se a moeda fosse justa. É isso - nada mais.\n\n\nApesar de mencionar anteriormente que definições intuitivas não são precisas, elas sem dúvida facilitam o entendimento do \\(p\\)-valor.\n\\(p\\)-valores – Algumas questões históricas\nNão tem como entendermos \\(p\\)-valores se não compreendermos as suas origens e trajetória histórica. A primeira menção do termo foi feita pelo estatístico Ronald Fisher[A controvérsia da personalidade e vida de Ronald Fisher merece uma nota de rodapé. Suas contribuições, sem dúvida, foram cruciais para o avanço da ciência e da estatística. Seu intelecto era brilhante e seu talento já floresceu jovem: antes de completar 33 anos de idade ele tinha proposto o método de estimação por máxima verossimilhança (maximum likelihood estimation) (Stigler & others, 2007) e também criou o conceito de graus de liberdade (degrees of freedom) ao propor uma correção no teste de chi-quadrado de Pearson (Baird, 1983). Também inventou a Análise de Variância (ANOVA) e foi o primeiro a propor randomização como uma maneira de realizar experimentos, sendo considerado o “pai” dos ensaios clínicos randomizados. Nem tudo é florido na vida de Fisher, ele foi um eugenista e possuía uma visão muito forte sobre etnia e raça preconizando a superioridade de certas etnias. Além disso, era extremamente invariante, perseguindo, prejudicando e debochando qualquer crítico à suas teorias e publicações. O que vemos hoje no monopólio do paradigma Neyman-Pearson (Neyman & Pearson, 1933) com \\(p\\)-valores e hipóteses nulas é resultado desse esforço Fisheriano em calar os críticos e deixar apenas sua voz ecoar.] em 1925 (Fisher, 1925) que define o \\(p\\)-valor como um “índice que mede a força da evidência contra a hipótese nula.” Para quantificar a força da evidência contra a hipótese nula, Fisher defendeu “\\(p<0.05\\) (5% de significância) como um nível padrão para concluir que há evidência contra a hipótese testada, embora não como uma regra absoluta.” Fisher não parou por aí mas classificou a força da evidência contra a hipótese nula. Ele propôs “se \\(p\\) está entre 0.1 e 0.9, certamente não há razão para suspeitar da hipótese testada. Se estiver abaixo de 0.02, é fortemente indicado que a hipótese falha em explicar o conjunto dos fatos. Não seremos frequentemente perdidos se traçarmos uma linha convencional de 0.05” Desde que Fisher fez esta declaração há quase 100 anos, o limiar de 0.05 foi usado por pesquisadores e cientistas em todo o mundo e tornou-se ritualístico usar 0.05 como limiar como se outros limiares não pudessem ser usados.\n\n\n\nFigure 5: Ronald Fisher. Figura de https://www.wikipedia.org\n\n\n\nApós isso, o limiar de 0.05 agora instaurado como inquestionável influenciou fortemente a estatística e a ciência. Mas não há nenhuma razão contra a adoção de outros limiares (\\(\\alpha\\)) como 0.1 ou 0.01. Se bem argumentados, a escolha de limiares diferentes de 0.05 pode ser bem-vista por editores, revisores e orientadores. Como o \\(p\\)-valor é uma probabilidade, ele não é um quantidade contínua. Não há razão para diferenciarmos um \\(p\\) de 0.049 contra um \\(p\\) de 0.051. Robert Rosenthal, um psicólogo já dizia “Deus ama \\(p\\) de 0.06 tanto quanto um \\(p\\) de 0.05” (Rosnow & Rosenthal, 1989).\nNo último ano de sua vida, Fisher publicou um artigo (Fisher, 1962) examinando as possibilidades dos métodos Bayesianos, mas com as probabilidades a priori a serem determinadas experimentalmente. Inclusive alguns autores especulam (Jaynes, 2003) que se Fisher estivesse vivo hoje, ele provavelmente seria um “Bayesiano.”\nO que o \\(p\\)-valor não é\nCom a definição e intuição do que é um \\(p\\)-valor bem ancoradas, podemos avançar para o que o \\(p\\)-valor não é!\n\n\n\n\\(p\\)-valor não é a probabilidade da Hipótese nula - Famosa confusão entre \\(P(D \\mid H_0)\\) e \\(P(H_0 \\mid D)\\). \\(p\\)-valor não é a probabilidade da hipótese nula, mas sim a probabilidade dos dados que você obteve. Para obter a $P(H_0 D) você precisa de estatística Bayesiana.\n\\(p\\)-valor não é a probabilidade dos dados serem produzidos pelo acaso - Não! Ninguém falou nada de acaso. Mais uma vez: \\(p\\)-valor é probabilidade de obter resultados no mínimo tão extremos quanto os que foram observados, dado que a hipótese nula é verdadeira.\n\\(p\\)-valor mensura o tamanho do efeito de um teste estatístico - Também não… \\(p\\)-valor não diz nada sobre o tamanho do efeito. Apenas sobre se o quanto os dados observados divergem do esperado sob a hipótese nula. É claro que efeitos grandes são mais prováveis de serem estatisticamente significantes que efeitos pequenos. Mas isto não é via de regra e nunca julguem um achado pelo seu \\(p\\)-valor, mas sim pelo seu tamanho de efeito. Além disso, \\(p\\)-valores podem ser “hackeados” de diversas maneiras (Head, Holman, Lanfear, Kahn, & Jennions, 2015) e muitas vezes seu valor é uma consequência direta do tamanho da amostra.\nIntervalos de Confiança\nPara concluir, vamos falar sobre os famosos intervalos de confiança, que não são uma medida que quantifica a incerteza do valor de um parâmetro (lembre-se conjecturas probabilísticas sobre parâmetros são proibidos em frequentist-land). Segure seu queixo, intervalos de confiança são:\n\nUm intervalo de confiança de X% para um parâmetro é um intervalo \\((a, b)\\) gerado por um procedimento que em amostragem repetida tem uma probabilidade de X% de conter o valor verdadeiro do parâmetro, para todos os valores possíveis do parâmetro\nNeyman (1937) (o “pai” dos intervalos de confiança, figura 6)\n\n\n\n\nFigure 6: Jerzy Neyman. Figura de https://www.wikipedia.org\n\n\n\nMais uma vez a ideia da amostragem repetida infinita vezes de uma população que você nunca viu. Por exemplo: digamos que você executou uma análise estatística para comparar eficácia de uma política pública em dois grupos e você obteve a diferença entre a média desses grupos. Você pode expressar essa diferença como um intervalo de confiança. Geralmente escolhemos a confiança de 95%. Você então escreve no seu artigo que a “diferença entre grupos observada é de 10.5 - 23.5 (95% IC).” Isso quer dizer que 95 estudos de 100, que usem o mesmo tamanho de amostra e população-alvo, aplicando o mesmo teste estatístico, esperarão encontrar um resultado de diferenças de média entre grupos entre 10.5 e 23.5. Aqui as unidades são arbitrárias, mas para continuar o exemplo vamos supor que sejam expectativa de vida.\nInfelizmente com estatística frequentista você tem que escolher uma das duas qualidades para explicações: intuitiva ou precisa24.\nIntervalos de Confiança (Frequentista) vs Intervalos de Credibilidade (Bayesiana)\nA estatística Bayesiana possui um conceito análogo ao de intervalos de confiança da estatística frequentista. Esse conceito se chama intervalo de credibilidade25 e, ao contrário do intervalo de confiança, a sua definição é intuitiva. Intervalo de credibilidade mensura um intervalo no qual temos certeza que o valor do parâmetro de interesse é, com base na verossimilhança condicionada aos dados observados – \\(P(y \\mid \\theta)\\); e na probabilidade priori do parâmetro – \\(P(\\theta)\\). Ele é basicamente uma “fatia” da probabilidade posteriori do parâmetro restrita a um certo nível de certeza. Por exemplo: um intervalo de credibilidade 95% mostra o intervalo que temos 95% de certeza que o valor do nosso parâmetro se encontra. Simples assim…\nPara exemplificar veja na figura 7 que mostra uma distribuição Log-Normal com média 0 e desvio padrão 2. O gráfico na parte superior mostra a estimativa da máxima verossimilhança26 do valor de \\(\\theta\\) que é a moda da distribuição. E no gráfico de baixo temos o intervalo de credibilidade 50% do valor de \\(\\theta\\) que é o intervalo entre o percentil 25% e o percentil 75%. Nesse exemplo, estimação por máxima verossimilhança nos leva à valores estimados que não são condizentes com a real densidade probabilística do valor de \\(\\theta\\).\n\n\n\nFigure 7: De baixo para cima: Estimação de Máxima Verossimilhança e Intervalo de Credibilidade\n\n\n\nAgora um exemplo de uma distribuição multimodal27. A figura 8 mostra uma distribuição bimodal com duas modas 2 e 1028. O gráfico na parte superior mostra a estimativa da máxima verossimilhança do valor de \\(\\theta\\) que é a moda da distribuição. Vejam que mesmo com 2 modas, maxima verossimilhança se “agarra” na maior moda29. E no gráfico de baixo temos o intervalo de credibilidade 50% do valor de \\(\\theta\\) que é o intervalo entre o percentil 25% e o percentil 75%. Nesse exemplo, estimação por máxima verossimilhança de novo nos leva à valores estimados que não são condizentes com a real densidade probabilística do valor de \\(\\theta\\).\n\n\n\nFigure 8: De baixo para cima: Estimação de Máxima Verossimilhança e Intervalo de Credibilidade\n\n\n\nEstatística Bayesiana vs Frequentista\nO que discutimos acima de resume nessa tabela abaixo:\n\nEstatística Bayesiana\nEstatística Frequentista\nDados\nFixos – Não Aleatórios\nIncertos – Aleatórios\nParâmetros\nIncertos – Aleatorios\nFixos – Não Aleatórios\nInferência\nIncerteza sobre o valor do parâmetro\nIncerteza sobre um processo de amostragem de uma população infinita\nProbabilidade\nSubjetiva\nObjetiva (mas com diversos pressupostos dos modelos)\nIncerteza\nIntervalo de Credibilidade – \\(P(\\theta \\mid y)\\)\nIntervalo de Confiança – \\(P(y \\mid \\theta)\\)\nVantagens da Estatística Bayesiana\nPor fim, eu sumarizo as principais vantagens da estatística Bayesiana:\nAbordagem Natural para expressar incerteza\nHabilidade de incorporar informações prévia\nMaior flexibilidade do modelo\nDistribuição posterior completa dos parâmetros\nIntervalos de Confiança vs Intervalos de Credibilidade\n\nPropagação natural da incerteza\nE eu acredito que preciso também mostrar a principal desvantagem:\nVelocidade lenta de estimativa do modelo (30 segundos ao invés de 3 segundos na abordagem frequentista)\nO começo do fim da Estatística Frequentista\nCaro leitor, saiba que você está em um momento da história no qual a Estatística está passando por grandes mudanças. Acredito que a estatística frequentista, em especial a maneira que qualificamos evidências e hipóteses com \\(p\\)-valores se transformará de maneira “significante.” Há cinco anos atrás, a American Statistical Association (ASA, maior organização profissional de estatística do mundo) publicou uma declaração sobre \\(p\\)-valores (Wasserstein & Lazar, 2016). A declaração diz exatamente o que falamos aqui. Os conceitos principais do teste de significância de hipótese nula e, em particular \\(p\\)-valores não conseguem prover o que os pesquisadores requerem deles. Apesar do que dizem muitos livros de estatística, materiais de ensinos e artigos publicados, \\(p\\)-valores abaixo de 0,05 não “provam” a realidade de nada. Nem, chegando a esse ponto, os \\(p\\)-valores acima de 0,05 refutam alguma coisa. A declaração da ASA tem mais de 3.600 citações provocando impacto relevante. Como um exemplo, um simpósio internacional foi promovido em 2017 que originou uma edição especial de acesso aberto da The American Statistician dedicada à maneiras práticas de abandonarmos \\(p < 0.05\\) (Wasserstein, Schirm, & Lazar, 2019).\nLogo na sequência vieram mais tentativas e reivindicações. Em setembro de 2017, a Nature Human Behaviour publicou um editorial propondo que o nível de significância do \\(p\\)-valor seja reduzido de \\(0.05\\) para \\(0.005\\) (Benjamin et al., 2018). Diversos autores, inclusive muitos estatísticos altamente influentes e importantes argumentaram que esse simples passo ajudaria a combater o problema da crise de replicabilidade da ciência, que muitos acreditam ser a principal consequência do uso abusivo de \\(p\\)-valores (Ioannidis, 2019). Além disso, muitos foram um passo além e sugerem que a ciência descarte de uma vez por todas \\(p\\)-valores (“It’s time to talk about ditching statistical significance,” 2019; Lakens et al., 2018). Muitos sugerem (eu inclusive) que a principal ferramenta de inferência seja a estatística Bayesiana (Amrhein, Greenland, & McShane, 2019; Goodman, 2016; van de Schoot et al., 2021)\nStan\nStan (Carpenter et al., 2017) é uma plataforma para modelagem e computação estatística de alto desempenho. Milhares de usuários contam com Stan para modelagem estatística, análise de dados e previsão nas ciências sociais, biológicas e físicas, engenharia e negócios. Stan tem mais de 3.600 citações no Google Scholar30. Além disso, Stan tem o suporte financeiro da NumFOCUS, uma fundação sem fins lucrativos que dá apoio financeiro à projetos de softwares opensource. Dentre os patrocinadores da NumFOCUS podemos citar AWS Amazon, Bloomberg, Microsoft, IBM, RStudio, Facebook, NVIDIA, Netflix, entre outras.\nOs modelos em Stan são especificados pela sua própria linguagem (similar à C++) e são compilados em um arquivo executável que gera inferências estatísticas Bayesiana com amostragem Monte Carlo de correntes Markov (Markov Chain Monte Carlo – MCMC) de alto desempenho. Stan possui interfaces para as seguintes linguagens de programação31:\nR: RStan e CmdStanR\nPython: PyStan e CmdStanPy\nShell (Linha de Comando): CmdStan\nJulia: Stan.jl\nScala: ScalaStan\nMatlab: MatlabStan\nStata: StataStan\nMathematica: MathematicaStan\nPara instalar Stan o usuário deve possuir um compilador C++ no seu sistema operacional32. Essa é a principal dependência do Stan, uma vez que todas suas outras dependências (Boost e Eigen) são bibliotecas header-only e não precisam de configurações adicionais a não ser um compilador C++ funcional.\nA linguagem Stan possui uma curva de aprendizagem bem desafiadora, por isso Stan possui um ecossistema de pacotes de interfaces que muitas vezes ajudam e simplificam a sua utilização:\nrstanarm: ajuda o usuário a especificar modelos usando a síntaxe familiar de fórmulas do R.\nbrms: similar ao rstanarm pois usa a síntaxe familiar de fórmulas do R, mas dá maior flexibilidade na especificação de modelos mais complexos33.\nStan34 usa um amostrador MCMC que utiliza dinâmica Hamiltoniana (Hamiltonian Monte Carlo – HMC) para guiar as propostas de amostragem de novos parâmetros no sentido do gradiente da densidade de probabilidade da posterior. Isto implica em um amostrador mais eficiente e que consegue explorar todo o espaço amostral da posterior com menos iterações; e também mais eficaz que consegue tolerar diferentes topologias de espaços amostrais da posterior. Em outras palavras, Stan usa técnicas de amostragem avançadas que permite com que modelos complexos Bayesianos atinjam convergência de maneira rápida. No Stan, raramente deve-se ajustar os parâmetros do algoritmo HMC, pois geralmente os parâmetros padrões (out-of-the-box) funcionam muito bem. Assim, o usuário foca no que é importante: a especificação dos componentes probabilísticos do seu modelo Bayesiano.\nStan é a ferramenta mais popular e poderosa de inferência Bayesiana, veja abaixo um vídeo de uma série popular chamada Billions, temporada 3 episódio 9. Interessante aqui é que não se menciona outras ferramentas extremamente populares em análise de dados35 e coloca Stan no mesmo patamar que Python, Julia e C++.\n\n\nHistória do Stan\nStan é uma homenagem ao matemático Stanislaw Ulam (figura 9), que participou do projeto Manhattan e ao tentar calcular o processo de difusão de neutrons para a bomba de hidrogênio acabou criando uma classe de métodos chamada Monte Carlo.\n\n\n\nFigure 9: Stanislaw Ulam. Figura de https://www.wikipedia.org\n\n\n\nMétodos de Monte Carlo possuem como conceito subjacente o uso a aleatoriedade para resolver problemas que podem ser determinísticos em princípio. Eles são freqüentemente usados em problemas físicos e matemáticos e são mais úteis quando é difícil ou impossível usar outras abordagens. Os métodos de Monte Carlo são usados principalmente em três classes de problemas: otimização, integração numérica e geração de sorteios a partir de uma distribuição de probabilidade.\nA ideia do método veio enquanto jogava paciência durante sua recuperação de uma cirurgia, Ulam pensou em jogar centenas de jogos para estimar estatisticamente a probabilidade de um resultado bem-sucedido. Conforme ele mesmo menciona em Eckhardt (1987):\n\nOs primeiros pensamentos e tentativas que fiz para praticar [o Método de Monte Carlo] foram sugeridos por uma pergunta que me ocorreu em 1946 quando eu estava convalescendo de uma doença e jogando paciência. A questão era quais são as chances de que um jogo de paciência com 52 cartas obtivesse sucesso? Depois de passar muito tempo tentando estimá-los por meio de cálculos combinatórios puros, me perguntei se um método mais prático do que o “pensamento abstrato” não seria expô-lo, digamos, cem vezes e simplesmente observar e contar o número de jogadas bem-sucedidas. Isso já era possível imaginar com o início da nova era de computadores rápidos, e eu imediatamente pensei em problemas de difusão de nêutrons e outras questões de física matemática e, de forma mais geral, como mudar os processos descritos por certas equações diferenciais em uma forma equivalente interpretável como uma sucessão de operações aleatórias. Mais tarde [em 1946], descrevi a ideia para John von Neumann e começamos a planejar cálculos reais.\n\nPor ser secreto, o trabalho de von Neumann e Ulam exigia um codinome. Um colega de von Neumann e Ulam, Nicholas Metropolis36, sugeriu usar o nome Monte Carlo, que se refere ao Casino Monte Carlo em Mônaco, onde o tio de Ulam (Michał Ulam) pedia dinheiro emprestado a parentes para jogar.\nCaso o leitor se interesse na história por trás da criação do Stan veja esse vídeo abaixo do Youtube da StanCon 2018.\n\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.4 (2021-02-15)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] tibble_3.1.0    ggplot2_3.3.3   patchwork_1.1.1 cowplot_1.1.1  \n\nloaded via a namespace (and not attached):\n [1] bslib_0.2.4       compiler_4.0.4    pillar_1.5.1     \n [4] jquerylib_0.1.3   highr_0.8         tools_4.0.4      \n [7] digest_0.6.27     downlit_0.2.1     jsonlite_1.7.2   \n[10] evaluate_0.14     lifecycle_1.0.0   gtable_0.3.0     \n[13] pkgconfig_2.0.3   rlang_0.4.10      DBI_1.1.1        \n[16] distill_1.2       yaml_2.2.1        parallel_4.0.4   \n[19] xfun_0.22         withr_2.4.1       dplyr_1.0.5      \n[22] stringr_1.4.0     knitr_1.31        generics_0.1.0   \n[25] vctrs_0.3.6       sass_0.3.1        systemfonts_1.0.1\n[28] tidyselect_1.1.0  grid_4.0.4        glue_1.4.2       \n[31] R6_2.5.0          textshaping_0.3.3 jpeg_0.1-8.1     \n[34] fansi_0.4.2       rmarkdown_2.7     farver_2.1.0     \n[37] purrr_0.3.4       magrittr_2.0.1    scales_1.1.1     \n[40] htmltools_0.5.1.1 ellipsis_0.3.1    assertthat_0.2.1 \n[43] colorspace_2.0-0  labeling_0.4.2    ragg_1.1.2       \n[46] utf8_1.2.1        stringi_1.5.3     munsell_0.5.0    \n[49] crayon_1.4.1     \n\n\n\n\nAmrhein, V., Greenland, S., & McShane, B. (2019). Scientists rise up against statistical significance. Nature, 567(7748), 305–307. https://doi.org/10.1038/d41586-019-00857-9\n\n\nBaird, D. (1983). The fisher/pearson chi-squared controversy: A turning point for inductive inference. The British Journal for the Philosophy of Science, 34(2), 105–118. Retrieved from http://www.jstor.org/stable/687444\n\n\nBenjamin, D. J., Berger, J. O., Johannesson, M., Nosek, B. A., Wagenmakers, E.-J., Berk, R., … Johnson, V. E. (2018). Redefine statistical significance. Nature Human Behaviour, 2(1), 6–10. https://doi.org/10.1038/s41562-017-0189-z\n\n\nde Finetti, B. (1974). Theory of Probability (Volume 1). New York: John Wiley & Sons.\n\n\nEckhardt, R. (1987). Stan Ulam, John von Neumann, and the Monte Carlo Method. Los Alamos Science, 15(30), 131–136.\n\n\nFisher, R. A. (1925). Statistical methods for research workers. Oliver; Boyd.\n\n\nFisher, R. A. (1962). Some Examples of Bayes’ Method of the Experimental Determination of Probabilities A Priori. Journal of the Royal Statistical Society. Series B (Methodological), 24(1), 118–124. Retrieved from https://www.jstor.org/stable/2983751\n\n\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian Data Analysis. Chapman and Hall/CRC.\n\n\nGoodman, S. N. (2016). Aligning statistical and scientific reasoning. Science, 352(6290), 1180–1181. https://doi.org/10.1126/science.aaf5406\n\n\nHead, M. L., Holman, L., Lanfear, R., Kahn, A. T., & Jennions, M. D. (2015). The extent and consequences of p-hacking in science. PLoS Biol, 13(3), e1002106.\n\n\nIoannidis, J. P. A. (2019). What Have We (Not) Learnt from Millions of Scientific Papers with <i>P<\/i> Values? The American Statistician, 73(sup1), 20–25. https://doi.org/10.1080/00031305.2018.1447512\n\n\nIt’s time to talk about ditching statistical significance. (2019). Nature, 567(7748, 7748), 283–283. https://doi.org/10.1038/d41586-019-00874-8\n\n\nJaynes, E. T. (2003). Probability theory: The logic of science. Cambridge university press.\n\n\nKolmogorov, A. N. (1933). Foundations of the Theory of Probability. Berlin: Julius Springer.\n\n\nLakens, D., Adolfi, F. G., Albers, C. J., Anvari, F., Apps, M. A. J., Argamon, S. E., … Zwaan, R. A. (2018). Justify your alpha. Nature Human Behaviour, 2(3), 168–171. https://doi.org/10.1038/s41562-018-0311-x\n\n\nNau, R. F. (2001). De Finetti was Right: Probability Does Not Exist. Theory and Decision, 51(2), 89–124. https://doi.org/10.1023/A:1015525808214\n\n\nNeyman, J. (1937). Outline of a theory of statistical estimation based on the classical theory of probability. Philosophical Transactions of the Royal Society of London. Series A, Mathematical and Physical Sciences, 236(767), 333–380.\n\n\nNeyman, J., & Pearson, E. S. (1933). On the problem of the most efficient tests of statistical hypotheses. Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character, 231(694-706), 289–337.\n\n\nRosnow, R. L., & Rosenthal, R. (1989). Statistical procedures and the justification of knowledge in psychological science. American Psychologist, 44, 1276–1284.\n\n\nStigler, S. M., & others. (2007). The epic story of maximum likelihood. Statistical Science, 22(4), 598–620.\n\n\nvan de Schoot, R., Depaoli, S., King, R., Kramer, B., Märtens, K., Tadesse, M. G., … Yau, C. (2021). Bayesian statistics and modelling. Nature Reviews Methods Primers, 1(1, 1), 1–26. https://doi.org/10.1038/s43586-020-00001-2\n\n\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA’s Statement on p-Values: Context, Process, and Purpose. American Statistician, 70(2), 129–133. https://doi.org/10.1080/00031305.2016.1154108\n\n\nWasserstein, R. L., Schirm, A. L., & Lazar, N. A. (2019). Moving to a World Beyond “p \\(<\\) 0.05.” American Statistician, 73, 1–19. https://doi.org/10.1080/00031305.2019.1583913\n\n\nmaiúsculo, pois se refere ao teorema de Bayes que é um sobrenome.↩︎\ndo inglês prior distribution.↩︎\ndo inglês likelihood function.↩︎\ndo inglês posterior distribution↩︎\npessoalmente, como um bom Popperiano, não acredito que haja ciência sem ser baseada em evidências; o que não usa evidências pode ser considerado como lógica, filosofia ou práticas sociais (não menos ou mais importantes que a ciência, apenas uma demarcação do que é ciência e do que não é; ex: matemática e direito).↩︎\nseu smartphone (iPhone 12 - 4GB RAM) possui 1.000.000x (1 milhão) mais poder computacional que o computador de bordo da Apollo 11 (4kB RAM) que levou o homem à lua. Detalhe: esse computador de bordo era responsável pela navegação, rota e controles do módulo lunar.↩︎\ncaso o leitor queira uma discussão aprofundada veja Nau (2001).↩︎\ndo inglês sufficient statistic.↩︎\nobservação minha: relacionado à abordagem Bayesiana subjetiva.↩︎\nobservação minha: relacionado à abordagem frequentista objetiva.↩︎\num número que pode ser expressado como um ponto em uma linha contínua que se origina em menos infinito e termina e mais infinito \\((-\\infty, +\\infty)\\); para quem gosta de computação é um ponto flutuante float ou double.↩︎\nna matemática axiomas são afirmações pressupostas como verdadeiras que servem como premissas or pontos de partidas para elaboração de argumentos e teoremas. Muitas vezes os axiomas são questionáveis, por exemplo geometria não-Euclidiana refuta o quinto axioma de Euclides sobre linhas paralelas. Até agora não há nenhum questionamento que tenha suportado o escrutínio do tempo e da ciência sobre os três axiomas da probabilidade.↩︎\npor exemplo, o resultado de uma moeda dado é um dos 2 eventos mutualmente exclusivos: cara ou coroa.↩︎\npalavra de escoteiro.↩︎\no nome formal do teorema é Bayes-Price-Laplace, pois Thomas Bayes foi o primeiro a descobrir, Richard Price pegou seus rascunhos, formalizou em notação matemática e apresentou para a Royal Society of London, e Pierre Laplace redescobriu o teorema sem ter tido contato prévio no final do século XVIII na França ao usar probabilidade para inferência estatística com dados do Censo na era Napoleônica.↩︎\nvou cobrir probabilidades prévias –priori– no conteúdo da Aula 4 - Priors↩︎\ntambém chamada de ortodoxa.↩︎\neu avisei que não era intuitivo…↩︎\nseu “sentido aranha” deve estar disparando agora…↩︎\nalgo que vale notar: a verossimilhança também carrega muita subjetividade.↩︎\npara os que gostam de matemática, calculamos em qual ponto de \\(\\theta\\) a derivada da verossimilhança é zero – \\(\\mathcal{L}^\\prime = 0\\).↩︎\neu já avisei que não é tão intuitivo?↩︎\nseu smartphone (iPhone 12 - 4GB RAM) possui 1.000.000x (1 milhão) mais poder computacional que o computador de bordo da Apollo 11 (4kB RAM) que levou o homem à lua. Detalhe: esse computador de bordo era responsável pela navegação, rota e controles do módulo lunar.↩︎\nisto foi copiado de Andrew Gelman – Estatístico Bayesiano.↩︎\ndo inglês credible interval.↩︎\ndo inglês: Maximum Likelihood Estimation – MLE.↩︎\no que não é muito raro de se ver no mundo real.↩︎\npara os curiosos é uma mistura de duas distribuições normais ambas com desvio padrão 1, mas com médias diferentes. Para completar atribui os pesos de 60% para a distribuição com média 2 e 40% para a distribuição com média 10.↩︎\npara ser mais preciso, estimação por máxima verossimilhança em funções não-convexas não consegue achar uma solução analítica e, se formos usar um outro procedimento iterativo de maximização, há um risco de ficarmos preso na segunda – menor – moda da distribuição.↩︎\nconforme consulta em 14 de Março de 2021.↩︎\nestou riscando as linguagens que não são opensource por uma questão de princípios.↩︎\no que ocasiona muitas frustações, mas quase todos os problemas são solucionados se o usuário seguir as instruções no repositório GitHub do Stan sobre compiladores C++.↩︎\ne geralmente a amostragem é um pouco mais rápida que o rstanarm.↩︎\ne consequentemente todas suas interfaces com diversas linguagens de programação e todos os pacotes do seu ecossistema.↩︎\nnada de TensorFlow, PyTorch, Pandas, Scikit-Learn, etc…↩︎\ntambém mencionado na Aula 5 - Markov Chain Montecarlo – MCMC.↩︎\n",
      "last_modified": "2021-03-30T18:54:19-03:00"
    },
    {
      "path": "1-Comandos_Basicos.html",
      "title": "Comandos Básicos de R",
      "description": "Introdução ao R e aos comandos básicos do R",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 1, 2021",
      "contents": "\n\nContents\nLendo Arquivos de Dados\nCSV\nExcel\n\nGráficos\nAmbiente\n\n\nEste arquivo é um documento R Markdown. Ele é uma proposta de prosa com código em R, além de ser o formato preferido nosso de comunicar nossas análises. Quando renderizamos o documento no formato desejado. Todo código que é inserido nele é executado e as saídas são incorporadas no documento final. Isto vale para tabelas e gráficos. Por exemplo, podemos pedir para o R imprimir algo com a função print() e o resultado será o código que foi executado e o seu resultado.\n\n\nprint(\"Você executou um código\")\n\n\n[1] \"Você executou um código\"\n\nO formato R Markdown é muito flexível. Podemos fazer relatórios (em PDF, Word e HTML), apresentações (em PDF, PowerPoint e HTML), artigos acadêmicos, livros, websites1, blogs, CVs, etc.\n\nO site do autor foi feito usando a biblioteca {postcards}(Kross, 2021) de R. O CV também foi feito em R usando a biblioteca {vitae} (O’Hara-Wild & Hyndman, 2021).\nLendo Arquivos de Dados\nCom o R conseguimos ler diversos tipo de arquivos de dados: CSV, texto, HTML, Excel, Stata, SPSS, Planilhas Google, Banco de Dados Relacionais, entre outros… Vamos demonstrar como ler arquivos de dados dos dois formatos mais comuns: CSV e Excel.\nCSV\nPara ler um arquivo CSV (.csv) no R execute a função read.csv() para arquivos CSV formato americano (vírgula como separador e decimais como ponto) ou a função read.csv2() para arquivos CSV formato europeu/brasileiro (ponto-e-vírgula como separador e decimais como vírgula). Não esqueça de designar a leitura para uma variável com o designador <-.\n\n\ndf <- read.csv2(\"datasets/mtcars.csv\", row.names = 1)\nhead(df)\n\n\n                  mpg cyl disp  hp drat  wt qsec vs am gear carb\nMazda RX4          21   6  160 110  3.9 2.6   16  0  1    4    4\nMazda RX4 Wag      21   6  160 110  3.9 2.9   17  0  1    4    4\nDatsun 710         23   4  108  93  3.9 2.3   19  1  1    4    1\nHornet 4 Drive     21   6  258 110  3.1 3.2   19  1  0    3    1\nHornet Sportabout  19   8  360 175  3.1 3.4   17  0  0    3    2\nValiant            18   6  225 105  2.8 3.5   20  1  0    3    1\n\nExcel\nPara ler um arquivo Excel (.xls ou .xlsx) no R é necessário importar um pacote chamado {readxl} (Wickham & Bryan, 2019) que contem a função read_excel. Para importar um pacote no R executamos o comando library() com um argumento único sendo o nome do pacote. Caso não tenha o pacote instalado, deve instalar ele com o comando install.packages(). Não esqueça de colocar o nome do pacote entre aspas \"nome_do_pacote\" dentro do parênteses da função.\n\n\n# install.packages(\"readxl\")\nlibrary(readxl)\ndf <- read_excel(\"datasets/mtcars.xlsx\")\nhead(df)\n\n\n# A tibble: 6 x 12\n  ...1       mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear\n  <chr>    <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1 Mazda R…  21       6   160   110  3.9   2.62  16.5     0     1     4\n2 Mazda R…  21       6   160   110  3.9   2.88  17.0     0     1     4\n3 Datsun …  22.8     4   108    93  3.85  2.32  18.6     1     1     4\n4 Hornet …  21.4     6   258   110  3.08  3.22  19.4     1     0     3\n5 Hornet …  18.7     8   360   175  3.15  3.44  17.0     0     0     3\n6 Valiant   18.1     6   225   105  2.76  3.46  20.2     1     0     3\n# … with 1 more variable: carb <dbl>\n\nGráficos\nGeralmente no R você pode plotar mostrar graficamente diversos objetos com o comando plot(). Quando você plota um dataset (conjunto de dados lido de um aquivo), o R retorna um gráfico chamado Pair Plot:\nNa diagonal: nome da variável (coluna do dataset)\nFora da diagonal: um gráfico de dispersão entre a variável no eixo horizontal e a variável no eixo vertical\nExemplo: na figura 1 veja a relação entre disp (cilindrada) e hp (cavalos de potência). Ela é uma relação positiva. Quanto maior disp maior hp.\n\n\nplot(mtcars)\n\n\n\n\nFigure 1: Pair Plot do dataset mtcars\n\n\n\nPara maior customização e elaboração avançada de gráficos a biblioteca {ggplot2} (Wickham, 2016).\n\n\nlibrary(ggplot2)\n\nggplot(mtcars, aes(mpg, hp)) +\n  geom_point(col = \"steelblue\") +\n  labs(\n    title = \"Diagrama de Dispersão\",\n    x = \"Milhas por Galão\",\n    y = \"Cavalos de Potência\",\n    caption = \"Quanto maior a potência menor a autonomia\"\n  ) +\n  theme_classic()\n\n\n\n\nFigure 2: Gráficos com {ggplot2}\n\n\n\nAmbiente\nEm todos os arquivos dessa disciplina, mostrarei o ambiente computacional usado para replicação.\n\n\nsessionInfo()\n\n\nR version 4.0.4 (2021-02-15)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] readxl_1.3.1    tibble_3.1.0    ggplot2_3.3.3   patchwork_1.1.1\n[5] cowplot_1.1.1  \n\nloaded via a namespace (and not attached):\n [1] tidyselect_1.1.0  xfun_0.22         bslib_0.2.4      \n [4] purrr_0.3.4       colorspace_2.0-0  vctrs_0.3.6      \n [7] generics_0.1.0    htmltools_0.5.1.1 yaml_2.2.1       \n[10] utf8_1.2.1        rlang_0.4.10      jquerylib_0.1.3  \n[13] pillar_1.5.1      glue_1.4.2        withr_2.4.1      \n[16] DBI_1.1.1         jpeg_0.1-8.1      lifecycle_1.0.0  \n[19] stringr_1.4.0     cellranger_1.1.0  munsell_0.5.0    \n[22] gtable_0.3.0      ragg_1.1.2        evaluate_0.14    \n[25] labeling_0.4.2    knitr_1.31        parallel_4.0.4   \n[28] fansi_0.4.2       highr_0.8         Rcpp_1.0.6       \n[31] scales_1.1.1      jsonlite_1.7.2    farver_2.1.0     \n[34] systemfonts_1.0.1 textshaping_0.3.3 distill_1.2      \n[37] digest_0.6.27     stringi_1.5.3     bookdown_0.21    \n[40] dplyr_1.0.5       grid_4.0.4        rprojroot_2.0.2  \n[43] cli_2.3.1         tools_4.0.4       magrittr_2.0.1   \n[46] sass_0.3.1        crayon_1.4.1      pkgconfig_2.0.3  \n[49] downlit_0.2.1     ellipsis_0.3.1    xml2_1.3.2       \n[52] lubridate_1.7.10  assertthat_0.2.1  rmarkdown_2.7    \n[55] rstudioapi_0.13   R6_2.5.0          compiler_4.0.4   \n\n\n\n\nKross, S. (2021). Postcards: Create beautiful, simple personal websites. Retrieved from https://CRAN.R-project.org/package=postcards\n\n\nO’Hara-Wild, M., & Hyndman, R. (2021). Vitae: Curriculum vitae for r markdown. Retrieved from https://CRAN.R-project.org/package=vitae\n\n\nWickham, H. (2016). Ggplot2: Elegant Graphics for Data Analysis. Retrieved from https://ggplot2.tidyverse.org\n\n\nWickham, H., & Bryan, J. (2019). Readxl: Read excel files. Retrieved from https://CRAN.R-project.org/package=readxl\n\n\nesse website foi todo feito com R↩︎\n",
      "last_modified": "2021-03-29T16:45:11-03:00"
    },
    {
      "path": "10-Regressao_Multinivel.html",
      "title": "Modelos Multiníveis Bayesianos",
      "description": "Modelos Multiníveis ou Modelos Hierárquicos",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 1, 2021",
      "contents": "\n\nContents\nQuando usar Modelos Multiníveis?\nHiperpriori (Hyperprior)\nAbordagem Frequentista vs Abordagem Bayesiana\nTrês abordagens de Modelos Multiníveis\nRandom Intercept Model\nRandom Slope Model\nRandom Intercept-Slope Model\n\nPrioris de Modelos Multiníveis\nExemplo com o dataset cheese\nRandom Intercept Model\nRandom Slope Model\nRandom Intercept-Slope Model\n\nModelos multiníveis no brms\nAtividade Prática\nAmbiente\n\n\nModelos hierárquicos Bayesianos (também chamados de modelos multiníveis) são um modelo estatístico escrito em níveis múltiplos (forma hierárquica) que estima os parâmetros da distribuição posterior usando a abordagem Bayesiana. Os submodelos se combinam para formar o modelo hierárquico, e o teorema de Bayes é usado para integrá-los aos dados observados e contabilizar toda a incerteza que está presente. O resultado dessa integração é a distribuição posterior, também conhecida como estimativa de probabilidade atualizada, à medida que evidências adicionais da função de verossimilhança são integradas juntamente com a distribuição priori dos parâmetros.\nA modelagem hierárquica é usada quando as informações estão disponíveis em vários níveis diferentes de unidades de observação. A forma hierárquica de análise e organização auxilia no entendimento de problemas multiparâmetros e também desempenha um papel importante no desenvolvimento de estratégias computacionais.\nOs modelos hierárquicos são descrições matemáticas que envolvem vários parâmetros, de modo que as estimativas de alguns parâmetros dependem significativamente dos valores de outros parâmetros. A figura 1 mostra um modelo hierárquico no qual há um hiperparamêtro \\(\\phi\\) que parametriza os parâmetros \\(\\theta_1, \\theta_2, \\dots, \\theta_N\\) que por fim são usados para inferir a densidade posterior de alguma variável de interesse \\(\\mathbf{y} = y_1, y_2, \\dots, y_N\\).\n\n\n\nFigure 1: Modelo Hierárquico\n\n\n\nQuando usar Modelos Multiníveis?\nModelos multiníveis são particularmente apropriados para projetos de pesquisa onde os dados dos participantes são organizados em mais de um nível (ou seja, dados aninhados – nested data). As unidades de análise geralmente são indivíduos (em um nível inferior) que estão aninhados em unidades contextuais/agregadas (em um nível superior). Um exemplo é quando estamos mensurando desempenho de indivíduos e temos informações adicionais sobre pertencimento à grupos distintos como sexo, faixa etária, nível hierárquico, nível educacional ou estado de moradia.\nHá um pressuposto principal que não pode ser violado em modelos multiníveis que é o de permutabilidade1 (de Finetti, 1974; Nau, 2001). Sim, esse é o mesmo pressuposto que discutimos na Aula 0 - O que é Estatística Bayesiana. Esse pressuposto parte do princípio que os grupos são permutáveis. A figura 2 mostra uma representação gráfica da permutabilidade. Os grupos mostrados como “copos” que contém observações mostradas como “bolas.” Se esse pressuposto é violado na sua inferência, então modelos multiníveis não são apropriados. Isto quer dizer que, uma vez que não há justificação teórica para sustentar a permutabilidade, as inferências do modelo multinível não são robustas e o modelo pode sofrer de diversas patologias e não deve ser usado para qualquer análise científica ou prática.\n\n\n\nFigure 2: Permutabilidade – Figuras de Michael Betancourt – https://betanalpha.github.io/\n\n\n\nHiperpriori (Hyperprior)\nComo as prioris dos parâmetros são amostradas de uma outra priori do hiperparâmetro (parâmetro do nível superior), as prioris do nível superior são chamadas de hiperprioris (do inglês hyperprior). Isso faz com que estimativas de um grupo ajudem o modelo a estimar melhor os outros grupos proporcionando estimativas mais robustas e estáveis.\nChamamos os parâmetros globais de efeitos populacionais (population-level effects, também às vezes chamados de efeitos fixos, fixed effects) e os parâmetros de cada grupo de efeitos de grupo (group-level effects, também às vezes chamados de efeitos aleatórios, random effects). Por isso que os modelos multiníveis são conhecidos também como modelos mistos (mixed models) no qual temos efeitos fixos e efeitos aleatórios.\nAbordagem Frequentista vs Abordagem Bayesiana\nExistem modelos multíveis também na estatística frequentista. Todos esses estão disponíveis no pacote lme4 (Bates, Mächler, Bolker, & Walker, 2015). rstanarm e brms usam a mesma síntaxe de fórmula do lme4 para especificar parâmetros populacionais e parâmetros de grupo. Mas aqui há uma grande diferença da abordagem frequentista vs a abordagem Bayesiana.\nPrimeiro, a abordagem frequentista (como já cobrimos na Aula 0 - O que é Estatística Bayesiana) usa um procedimento de otimização da função de verossimilhança na qual busca-se o conjunto de parâmetros que maximizam a função de verossimilhança do modelo. Na prática isso significa achar a moda de todos os parâmetros condicionados na função de verossimilhança que, pelo pressuposto de que todos os parâmetros são distribuídos como uma distribuição normal e também por conta do pressuposto de erros gaussianos, equivale à média e à mediana do parâmetro (note que na distribuição normal média, mediana e moda possuem o mesmo valor). Procure em fóruns de estatística ou no stackoverflow e você achará um monte de perguntas e pedidos de ajuda sobre modelos multiníveis lme4 que não convergem. Aliás, muitos são convencidos para a abordagem Bayesiana (e se tornam Bayesianos) quando eles tentam executar o mesmo modelo lme4 que falhou a convergência no rstanarm ou brms (lembrando que a síntaxe da fórmula é a mesma, então é muito fácil traduzir modelos frequentistas do lme4 para modelos bayesianos do rstanarm e brms) e o modelo converge na sua primeira tentativa.\nSegundo, na abordagem frequentista, modelos multiníveis não computam \\(p\\)-valores dos efeitos de grupo (veja a explicação aqui do Douglas Bates autor do pacote lme4). Por conta da contorção matemática de diversas aproximações que a estatística frequentista tem que fazer (na sua determinação cega de não usar o teorema de Bayes pois conjecturas probabilísticas dos parâmetros são proibidas), o cálculo de \\(p\\)-valores de efeitos de grupo possuem fortes pressupostos. O principal é que os grupos são balanceados. Ou seja, os grupos são homogêneos no seu tamanho. Qualquer desbalanço na composição dos grupos (um grupo com mais observações que outros) resulta em \\(p\\)-valores patológicos e que não podem ser confiáveis.\nSumarizando, a abordagem frequentista para modelos multiníveis não é robusta tanto no processo da inferência (falhas de convergência da estimação de máxima verossimilhança), quanto nos resultados dessa inferência (não computa \\(p\\)-valores por conta de fortes pressupostos que quase sempre são violados).\nTrês abordagens de Modelos Multiníveis\nModelos multiníveis geralmente se dividem em três abordagens:\nRandom intercept model: Modelo no qual cada grupo recebe uma constante (intercept) diferente além da constante global\nRandom slope model: Modelo no qual cada grupo recebe um coeficiente diferente para cada variável independente além dos coeficientes globais\nRandom intercept-slope model: Modelo no qual cada grupo recebe tanto uma constante (intercept) quanto um coeficiente diferente para cada variável independente além da constante global e dos coeficientes globais\nrstanarm e brms possuem as funcionalidades completas para rodar modelos multiníveis e a única coisa a se fazer é alterar a fórmula. Para rstanarm, há uma segunda mudança também que não usamos mais a função stan_glm() mas sim a função stan_glmer(). Para brms não há mudança e usamos a mesma função brm().\nRandom Intercept Model\nA primeira abordagem é o random intercept model na qual especificamos para cada grupo uma constante diferente, além da constante global. Essas constantes são amostradas de uma hiperpriori.\nNo caso de random intercept model, a fórmula a ser usada segue este padrão:\ny ~ (1 | group) + x1 + x2\nO (1 | group) na fórmula sinaliza que a constante 1 deve ser também especificada para cada um dos grupos listados nos valores da variável group (aqui você substitui group por qualquer variável que quiser). Na prática essa fórmula, tanto no rstanarm quanto no brms é expandida para:\ny ~ 1 + (1 | group) + x1 + x2\nIsto indica que há uma constante global (nível populacional) e também uma constante para cada grupo. Caso queira remover do modelo a constante global (algo que eu recomendo apenas se tiver muita fundamentação teórica para tal manobra) é só especificar o 0 como constante global. Isto sinaliza que o modelo possui apenas constantes para cada grupo e que não há uma constante global a ser estimada:\ny ~ 0 + (1 | group) + x1 + x2\nAlém disso você pode especificar uma constante para quantos grupos quiser. É só adicioná-los na fórmula:\ny ~ (1 | group1) + (1 | group2) + x1 + x2\nRandom Slope Model\nA segunda abordagem é o random slope model na qual especificamos para cada grupo um coeficiente diferente para cada variável independente desejada, além dos coeficientes globais. Esses coeficientes são amostrados de uma hiperpriori.\nNo caso de random slope model, a formula a ser usada segue este padrão. Ela indica que o coeficiente da variável independente deve ser estimado de maneira global juntamente com coeficientes para cada grupo. Note que usamos o 0 pois neste caso sinalizamos que apenas a variável independente deve possuir coeficientes para cada grupo e não a constante:\ny ~ (0 + x1 | group) + (0 + x2 | group)\nNote que para rstanarm e brms a fórmula se transforma em:\ny ~ 1 + (0 + x1 | group) + (0 + x2 | group)\nIndicando que há uma constante global e coeficientes globais e de grupo para as variáveis independentes.\nRandom Intercept-Slope Model\nA terceira abordagem é o random intercept-slope model na qual especificamos para cada grupo uma constante diferente juntamente com coeficientes diferentes para cada variável independente desejada. É claro também resulta em costante e coeficientes globais. Essas constantes e coeficientes à nível de grupo são amostrados de duas ou mais hiperprioris.\nNo caso de random intercept-slope model, a formula a ser usada segue este padrão:\ny ~ (1 + x1 | group) + (1 + x2 | group)\nNote novamente que para rstanarm e brms a fórmula se transforma em:\ny ~ 1 + (1 + x1 | group) + (1 + x2 | group)\nPrioris de Modelos Multiníveis\nAntes de nos aventurarmos em estimar modelos, vamos relembrar as prioris da da Aula 4 - Priors:\nArgumento\nUsado em\nAplica-se à\nprior_intercept\nTodas funções de modelagem exceto stan_polr and stan_nlmer\nConstante (intercept) do modelo, após centralização dos preditores\nprior\nTodas funções de modelagem\nCoeficientes de Regressão, não inclui coeficientes que variam por grupo em modelos multiníveis (veja prior_covariance)\nprior_aux\nstan_glm, stan_glmer, stan_gamm4, stan_nlmer\nParâmetro auxiliar (ex: desvio padrão (standard error - DP), interpretação depende do modelo\nprior_covariance\nstan_glmer, stan_gamm4, stan_nlmer\nMatrizes de covariância em modelos multiníveis\nEm especial, foquem no prior_covariance que é a priori matriz de covariância em modelos multiníveis.\nOs modelos hierárquicos geralmente são especificados assim. Temos \\(N\\) observações organizadas em \\(J\\) grupos com \\(K\\) variáveis independentes. O truque aqui é que inserimos uma coluna de \\(1\\) na matrix de dados \\(\\mathbf{X}\\). Matematicamente isto se comporta como se esta coluna fosse uma variável de identidade (pois o número \\(1\\) na operação de multiplicação \\(1 \\cdot \\beta\\) é o elemento identidade. Ele mapeia \\(x \\to x\\) mantendo o valor de \\(x\\)) e, consequentemente, podemos interpretar o coeficiente dessa coluna como a constante do modelo2.\nEntão temos os dados como uma matriz:\n\\[\n\\mathbf{X} =\n\\begin{bmatrix}\n1 & x_{11} & x_{12} & \\cdots & x_{1K} \\\\\n1 & x_{21} & x_{22} & \\cdots & x_{2K} \\\\\n\\vdots & \\cdots & \\cdots & \\ddots & \\vdots \\\\\n1 & x_{N1} & x_{N2} & \\cdots & x_{NK}\n\\end{bmatrix}\n\\]\nAssim nosso modelo (aqui representado com uma função de verossimilhança Gaussiana/Normal) fica:\n\\[\n\\begin{aligned}\ny &\\sim \\text{Normal}(\\alpha + \\mathbf{X} \\cdot \\boldsymbol{\\beta}_{j}, \\sigma) \\\\\n\\boldsymbol{\\beta}_j &\\sim \\text{Normal Multivariada}(\\boldsymbol{\\mu}_j, \\boldsymbol{\\Sigma})\n\\quad \\text{para}\\quad j \\in \\{ 1, \\dots, J \\} \\\\\n\\alpha &\\sim \\text{Normal}(\\mu_\\alpha, \\sigma_\\alpha) \\\\\n\\sigma &\\sim \\text{Exponencial}(\\lambda_\\sigma)\n\\end{aligned}\n\\]\nCada vetor de coeficientes \\(\\boldsymbol{\\beta}_j\\) representa os coeficientes das colunas de \\(\\mathbf{X}\\) para cada grupo \\(j \\in J\\). Lembre-se que a primeira coluna de \\(\\mathbf{X}\\) é um monte de \\(1\\), então \\(\\beta_{j1}\\) é a constante para cada grupo. Junte isso com o que já vimos em aulas anteriores sobre \\(\\alpha\\) e \\(\\sigma\\) e temos um modelo multinível para um conjunto de grupos \\(J\\).\nCaso queira mais grupos é só adicioná-los ao modelo como \\(J_1, J_2, \\dots\\):\n\\[\n\\begin{aligned}\ny &\\sim \\text{Normal}(\\alpha + \\mathbf{X} \\cdot \\boldsymbol{\\beta}_{j1} + \\mathbf{X} \\cdot \\boldsymbol{\\beta}_{j2}, \\sigma) \\\\\n\\boldsymbol{\\beta}_{j1} &\\sim \\text{Normal Multivariada}(\\boldsymbol{\\mu}_{j1}, \\boldsymbol{\\Sigma}_1)\n\\quad \\text{para}\\quad j_1 \\in \\{ 1, \\dots, J_1 \\} \\\\\n\\boldsymbol{\\beta}_{j2} &\\sim \\text{Normal Multivariada}(\\boldsymbol{\\mu}_{j2}, \\boldsymbol{\\Sigma}_2)\n\\quad \\text{para}\\quad j_2 \\in \\{ 1, \\dots, J_2 \\} \\\\\n\\alpha &\\sim \\text{Normal}(\\mu_\\alpha, \\sigma_\\alpha) \\\\\n\\sigma &\\sim \\text{Exponencial}(\\lambda_\\sigma)\n\\end{aligned}\n\\]\nPodemos especificar uma priori para a matriz de covariância \\(\\boldsymbol{\\Sigma}\\) no rstanarm com prior_covariance = decov(1)3.\nPara eficiência computacional o rstanarm modifica a matriz de covariância \\(\\boldsymbol{\\Sigma}\\). Especificamente, fazemos com que ela vire uma matriz de correlação. Toda matriz de covariância pode ser decomposta em:\n\\[\n\\boldsymbol{\\Sigma}=\\text{diag}_\\text{matrix}(\\boldsymbol{\\tau}) \\cdot \\boldsymbol{\\Omega} \\cdot \\text{diag}_\\text{matrix}(\\boldsymbol{\\tau})\n\\]\nna qual \\(\\boldsymbol{\\Omega}\\) é uma matriz de correlação com \\(1\\) na sua diagonal e os demais elementos entre -1 e 1 \\(\\rho \\in (-1, 1)\\). \\(\\boldsymbol{\\tau}\\) é um vetor composto pelas variâncias das variáveis de \\(\\boldsymbol{\\Sigma}\\) (a diagonal de \\(\\boldsymbol{\\Sigma}\\)).\nAdicionalmente a matriz de correlação \\(\\boldsymbol{\\Omega}\\) pode ser decomposta mais uma vez para maior eficiência computacional. Como toda matriz de correlação é simétrica e definitiva positiva (todos seus autovalores são numeros reais \\(\\mathbb{R}\\) e positivos \\(>0\\)), podemos usar a Decomposição Cholesky para decompô-la em uma matriz triangular (que é muito mais eficiente computacionalmente):\n\\[\n\\boldsymbol{\\Omega} = \\mathbf{L}_\\Omega \\mathbf{L}^T_\\Omega\n\\]\nonde \\(\\mathbf{L}_\\Omega\\) é uma matriz triangular.\nO que falta é definirmos então uma priori para a matriz de correlação \\(\\boldsymbol{\\Omega}\\). Até pouco tempo atrás, usávamos uma distribuição de Wishart como priori (Gelman et al., 2013). Mas essa prática foi abandonada após a proposição da distribuição LKJ de Lewandowski, Kurowicka, & Joe (2009) (LKJ são os nomes dos autores – Lewandowski, Kurowicka e Joe) como priori de matrizes de correlação.\nEnfim, embaixo do capô rstanarm faz todas essas decomposições e transformações para nós, sem termos que nos preocupar.\nExemplo com o dataset cheese\nO dataset cheese (Boatwright, McCulloch, & Rossi, 1999) possui 160 observações de avaliações de queijo. Um grupo de 10 avaliadores “rurais” e 10 “urbanos” avaliaram 4 queijos diferentes \\((A,B,C,D)\\) em duas amostras. Portanto \\(4 \\cdot 20 \\cdot 2 = 160\\). Possui 4 variáveis:\ncheese: tipo do queijo, \\((A,B,C,D)\\)\nrater: avaliador, \\((1,\\dots, 10)\\)\nbackground: origem do avaliador em “urbano” ou “rural”\ny: variável dependente, nota da avaliação\n\n\ncheese <- read_csv2(\"datasets/cheese.csv\", col_types = \"fffi\")\n\n\n\nComo sempre eu gosto de usar o pacote skimr (Waring et al., 2021) com a função skim():\n\n\nlibrary(skimr)\nskim(cheese)\n\n\nTable 1: Data summary\nName\ncheese\nNumber of rows\n160\nNumber of columns\n4\n_______________________\n\nColumn type frequency:\n\nfactor\n3\nnumeric\n1\n________________________\n\nGroup variables\nNone\nVariable type: factor\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\ncheese\n0\n1\nFALSE\n4\nA: 40, B: 40, C: 40, D: 40\nrater\n0\n1\nFALSE\n10\n1: 16, 2: 16, 3: 16, 4: 16\nbackground\n0\n1\nFALSE\n2\nrur: 80, urb: 80\nVariable type: numeric\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\ny\n0\n1\n71\n12\n33\n64\n72\n80\n91\n▁▂▆▇▆\n\nRandom Intercept Model\nNo primeiro exemplo vamos usar um modelo que cada grupo de cheese recebe uma constante diferente:\n\n\n# Detectar quantos cores/processadores\noptions(mc.cores = parallel::detectCores())\noptions(Ncpus = parallel::detectCores())\n\nlibrary(rstanarm)\nrandom_intercept <- stan_glmer(\n  y ~ (1 | cheese) + background,\n  data = cheese,\n  prior_intercept = normal(mean(cheese$y), 2.5 * sd(cheese$y)),\n  prior_covariance = decov(1)\n)\n\n\n\nNo sumário do modelo random intercept vemos que os avaliadores urbanos avaliam melhor os queijos que os avaliadores rurais, mas também observamos que cada queijo possui uma “taxa basal” de avaliação (cada queijo tem sua constante). Sendo \\(B\\) o pior queijo e \\(C\\) o melhor queijo:\n\n\nsummary(random_intercept)\n\n\n\nModel Info:\n function:     stan_glmer\n family:       gaussian [identity]\n formula:      y ~ (1 | cheese) + background\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 160\n groups:       cheese (4)\n\nEstimates:\n                                        mean   sd    10%   50%   90%\n(Intercept)                            67.3    5.5  60.8  67.2  73.8\nbackgroundurban                         7.4    1.1   5.9   7.4   8.9\nb[(Intercept) cheese:A]                 3.7    5.6  -2.8   3.9  10.4\nb[(Intercept) cheese:B]               -14.2    5.6 -20.9 -14.0  -7.6\nb[(Intercept) cheese:C]                 8.4    5.6   1.9   8.5  15.2\nb[(Intercept) cheese:D]                 1.3    5.6  -5.3   1.4   8.0\nsigma                                   7.1    0.4   6.6   7.1   7.6\nSigma[cheese:(Intercept),(Intercept)] 131.6  118.4  42.4  95.2 254.7\n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 70.9    0.8 69.9  70.9  71.9 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n                                      mcse Rhat n_eff\n(Intercept)                           0.2  1.0  1315 \nbackgroundurban                       0.0  1.0  3392 \nb[(Intercept) cheese:A]               0.2  1.0  1337 \nb[(Intercept) cheese:B]               0.2  1.0  1346 \nb[(Intercept) cheese:C]               0.2  1.0  1349 \nb[(Intercept) cheese:D]               0.2  1.0  1343 \nsigma                                 0.0  1.0  3576 \nSigma[cheese:(Intercept),(Intercept)] 3.0  1.0  1579 \nmean_PPD                              0.0  1.0  3719 \nlog-posterior                         0.1  1.0  1241 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nVamos verificar o Posterior Predictive Check do modelo random intercept na figura 3:\n\n\npp_check(random_intercept)\n\n\n\n\nFigure 3: Posterior Preditive Check do modelo random intercept\n\n\n\nRandom Slope Model\nNo segundo exemplo vamos usar um modelo que cada grupo de cheese recebe um coeficiente diferente para background:\n\n\nrandom_slope <- stan_glmer(\n  y ~ (0 + background | cheese),\n  data = cheese,\n  prior_intercept = normal(mean(cheese$y), 2.5 * sd(cheese$y)),\n  prior_covariance = decov(1)\n)\n\n\n\nAqui vemos que todos os queijos recebem a mesma constante mas cada queijo possui um coeficiente diferente para background do avaliador:\n\n\nsummary(random_slope)\n\n\n\nModel Info:\n function:     stan_glmer\n family:       gaussian [identity]\n formula:      y ~ (0 + background | cheese)\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 160\n groups:       cheese (4)\n\nEstimates:\n                                                mean   sd    10%\n(Intercept)                                    69.9    5.9  62.9\nb[backgroundrural cheese:A]                     0.8    6.0  -6.5\nb[backgroundurban cheese:A]                     8.8    6.1   1.5\nb[backgroundrural cheese:B]                   -15.7    6.2 -23.2\nb[backgroundurban cheese:B]                   -10.3    5.9 -17.4\nb[backgroundrural cheese:C]                     5.4    5.9  -1.9\nb[backgroundurban cheese:C]                    13.7    6.1   6.2\nb[backgroundrural cheese:D]                    -0.7    6.0  -7.7\nb[backgroundurban cheese:D]                     5.4    6.0  -1.9\nsigma                                           7.1    0.4   6.6\nSigma[cheese:backgroundrural,backgroundrural] 134.0  121.8  40.6\nSigma[cheese:backgroundurban,backgroundrural]  76.4  102.8   3.4\nSigma[cheese:backgroundurban,backgroundurban] 167.7  164.0  52.2\n                                                50%   90%\n(Intercept)                                    70.1  76.9\nb[backgroundrural cheese:A]                     0.7   7.9\nb[backgroundurban cheese:A]                     8.5  16.0\nb[backgroundrural cheese:B]                   -15.8  -8.1\nb[backgroundurban cheese:B]                   -10.4  -3.3\nb[backgroundrural cheese:C]                     5.2  12.5\nb[backgroundurban cheese:C]                    13.5  21.1\nb[backgroundrural cheese:D]                    -0.7   6.5\nb[backgroundurban cheese:D]                     5.3  12.9\nsigma                                           7.1   7.6\nSigma[cheese:backgroundrural,backgroundrural]  99.0 262.6\nSigma[cheese:backgroundurban,backgroundrural]  52.6 172.9\nSigma[cheese:backgroundurban,backgroundurban] 120.3 328.3\n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 70.8    0.8 69.8  70.8  71.8 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n                                              mcse Rhat n_eff\n(Intercept)                                   0.2  1.0   722 \nb[backgroundrural cheese:A]                   0.2  1.0   726 \nb[backgroundurban cheese:A]                   0.2  1.0   744 \nb[backgroundrural cheese:B]                   0.2  1.0   738 \nb[backgroundurban cheese:B]                   0.2  1.0   774 \nb[backgroundrural cheese:C]                   0.2  1.0   736 \nb[backgroundurban cheese:C]                   0.2  1.0   742 \nb[backgroundrural cheese:D]                   0.2  1.0   744 \nb[backgroundurban cheese:D]                   0.2  1.0   721 \nsigma                                         0.0  1.0  3567 \nSigma[cheese:backgroundrural,backgroundrural] 2.8  1.0  1958 \nSigma[cheese:backgroundurban,backgroundrural] 3.0  1.0  1140 \nSigma[cheese:backgroundurban,backgroundurban] 5.0  1.0  1077 \nmean_PPD                                      0.0  1.0  3749 \nlog-posterior                                 0.1  1.0  1105 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nVamos verificar o Posterior Predictive Check do modelo random slope na figura 4:\n\n\npp_check(random_slope)\n\n\n\n\nFigure 4: Posterior Preditive Check do modelo random slope\n\n\n\nRandom Intercept-Slope Model\nNo terceiro exemplo vamos usar um modelo que cada grupo de cheese recebe uma constante diferente e um coeficiente diferente para background:\n\n\nrandom_intercept_slope <- stan_glmer(\n  y ~ (1 + background | cheese),\n  data = cheese,\n  prior_intercept = normal(mean(cheese$y), 2.5 * sd(cheese$y)),\n  prior_covariance = decov(1)\n)\n\n\n\nAqui vemos que os queijos recebem a constantes diferentes e que cada queijo possui um coeficiente diferente para background do avaliador:\n\n\nsummary(random_intercept_slope)\n\n\n\nModel Info:\n function:     stan_glmer\n family:       gaussian [identity]\n formula:      y ~ (1 + background | cheese)\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 160\n groups:       cheese (4)\n\nEstimates:\n                                                mean   sd    10%\n(Intercept)                                    65.0    7.6  55.4\nb[(Intercept) cheese:A]                         5.8    7.6  -3.3\nb[backgroundurban cheese:A]                     7.8    2.2   5.0\nb[(Intercept) cheese:B]                       -10.5    7.9 -20.0\nb[backgroundurban cheese:B]                     4.6    2.3   1.6\nb[(Intercept) cheese:C]                        10.2    7.5   1.1\nb[backgroundurban cheese:C]                     8.4    2.2   5.5\nb[(Intercept) cheese:D]                         4.2    7.6  -4.8\nb[backgroundurban cheese:D]                     6.0    2.2   3.3\nsigma                                           7.1    0.4   6.6\nSigma[cheese:(Intercept),(Intercept)]         157.1  168.0  43.7\nSigma[cheese:backgroundurban,(Intercept)]      24.5   76.0 -46.8\nSigma[cheese:backgroundurban,backgroundurban]  84.9   81.0  25.2\n                                                50%   90%\n(Intercept)                                    65.2  74.0\nb[(Intercept) cheese:A]                         5.6  15.4\nb[backgroundurban cheese:A]                     7.8  10.6\nb[(Intercept) cheese:B]                       -10.5  -0.8\nb[backgroundurban cheese:B]                     4.6   7.6\nb[(Intercept) cheese:C]                        10.1  19.7\nb[backgroundurban cheese:C]                     8.4  11.2\nb[(Intercept) cheese:D]                         4.1  13.8\nb[backgroundurban cheese:D]                     6.1   8.8\nsigma                                           7.1   7.7\nSigma[cheese:(Intercept),(Intercept)]         111.1 308.9\nSigma[cheese:backgroundurban,(Intercept)]      17.0 102.5\nSigma[cheese:backgroundurban,backgroundurban]  60.7 165.7\n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 70.8    0.8 69.8  70.8  71.9 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n                                              mcse Rhat n_eff\n(Intercept)                                   0.3  1.0   788 \nb[(Intercept) cheese:A]                       0.3  1.0   810 \nb[backgroundurban cheese:A]                   0.0  1.0  4942 \nb[(Intercept) cheese:B]                       0.3  1.0   786 \nb[backgroundurban cheese:B]                   0.0  1.0  2615 \nb[(Intercept) cheese:C]                       0.3  1.0   804 \nb[backgroundurban cheese:C]                   0.0  1.0  4562 \nb[(Intercept) cheese:D]                       0.3  1.0   808 \nb[backgroundurban cheese:D]                   0.0  1.0  4895 \nsigma                                         0.0  1.0  3967 \nSigma[cheese:(Intercept),(Intercept)]         4.2  1.0  1595 \nSigma[cheese:backgroundurban,(Intercept)]     2.4  1.0   989 \nSigma[cheese:backgroundurban,backgroundurban] 1.9  1.0  1746 \nmean_PPD                                      0.0  1.0  3604 \nlog-posterior                                 0.1  1.0  1168 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nPor fim, vamos verificar o Posterior Predictive Check do modelo random intercept-slope na figura 5:\n\n\npp_check(random_intercept_slope)\n\n\n\n\nFigure 5: Posterior Preditive Check do modelo random intercept-slope\n\n\n\nModelos multiníveis no brms\nO brms tem uma pequena diferença no output do sumário do modelo. Aqui especificamos a priori da matriz de covariância um pouco diferente com prior(lkj_corr_cholesky(1), class = L) que é o mesmo que prior_covariance = decov(1) do rstanarm:\n\nOBS: 79 é a média de cheese$y e 21 é 2.5x o desvio padrão de cheese$y.\n\n\n\nlibrary(brms)\n\nbrms_random_intercept_slope <- brm(\n  y ~ (1 + background | cheese),\n  data = cheese,\n  prior = c(\n    prior(normal(71, 29), class = Intercept),\n    prior(lkj_corr_cholesky(1), class = L)\n  )\n)\n\n\n\nVeja o output do summary() para modelos multiníveis estimados pelo brms:\n\n\nsummary(brms_random_intercept_slope)\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: y ~ (1 + background | cheese) \n   Data: cheese (Number of observations: 160) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nGroup-Level Effects: \n~cheese (Number of levels: 4) \n                               Estimate Est.Error l-95% CI u-95% CI\nsd(Intercept)                     13.00      5.74     5.79    27.61\nsd(backgroundurban)                8.98      4.18     3.87    20.25\ncor(Intercept,backgroundurban)     0.18      0.53    -0.80     0.97\n                               Rhat Bulk_ESS Tail_ESS\nsd(Intercept)                  1.00     1426     1964\nsd(backgroundurban)            1.00     1328     1918\ncor(Intercept,backgroundurban) 1.00      678      970\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept    65.51      9.41    45.18    84.70 1.00      656     1042\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     7.11      0.41     6.36     7.96 1.00     2799     2530\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nNão há menção dos efeitos de grupo. Para isso precisamos usar a função ranef() (uma abreviação de random effects). Caso queira somente os efeitos populacionais pode usar a função fixef() (uma abreviação de fixed effects):\n\n\nranef(brms_random_intercept_slope)\n\n\n$cheese\n, , Intercept\n\n  Estimate Est.Error Q2.5 Q97.5\nA      5.3       9.5  -14  25.9\nB    -11.0       9.7  -31   9.8\nC      9.8       9.3   -9  30.0\nD      3.8       9.4  -15  24.0\n\n, , backgroundurban\n\n  Estimate Est.Error  Q2.5 Q97.5\nA      7.8       2.2 3.451  12.1\nB      4.8       2.3 0.066   9.3\nC      8.3       2.2 3.979  12.6\nD      6.0       2.1 1.896  10.1\n\nAtividade Prática\nPara atividade prática, temos o dataset rikz(Zuur, Ieno, & Smith, 2007) no diretório datasets/ (figura 6). Segue a descrição em inglês do dataset.\nFor each of 9 intertidal areas (denoted ‘Beaches’), the researchers sampled five sites (denoted ‘Sites’) and at each site they measured abiotic variables and the diversity of macro-fauna (e.g. aquatic invertebrates). Here, species richness refers to the total number of species found at a given site while NAP ( i.e. Normal Amsterdams Peil) refers to the height of the sampling location relative to the mean sea level and represents a measure of the amount of food available for birds, etc. For our purpose, the main question is:\nWhat is the influence of NAP on species richness?\n\n\n\nFigure 6: Dataset rikz\n\n\n\n\n\nrikz <- read_csv2(\"datasets/rikz.csv\", col_types = \"iidff\")\n\n\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.4 (2021-02-15)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n [1] brms_2.15.0     rstanarm_2.21.1 Rcpp_1.0.6      skimr_2.1.3    \n [5] readr_1.4.0     readxl_1.3.1    tibble_3.1.0    ggplot2_3.3.3  \n [9] patchwork_1.1.1 cowplot_1.1.1  \n\nloaded via a namespace (and not attached):\n  [1] backports_1.2.1      systemfonts_1.0.1    plyr_1.8.6          \n  [4] igraph_1.2.6         repr_1.1.3           splines_4.0.4       \n  [7] crosstalk_1.1.1      TH.data_1.0-10       rstantools_2.1.1    \n [10] inline_0.3.17        digest_0.6.27        htmltools_0.5.1.1   \n [13] magick_2.7.1         rsconnect_0.8.16     fansi_0.4.2         \n [16] magrittr_2.0.1       RcppParallel_5.0.3   matrixStats_0.58.0  \n [19] sandwich_3.0-0       xts_0.12.1           prettyunits_1.1.1   \n [22] jpeg_0.1-8.1         colorspace_2.0-0     textshaping_0.3.3   \n [25] xfun_0.22            dplyr_1.0.5          callr_3.6.0         \n [28] crayon_1.4.1         jsonlite_1.7.2       lme4_1.1-26         \n [31] survival_3.2-10      zoo_1.8-9            glue_1.4.2          \n [34] gtable_0.3.0         emmeans_1.5.5-1      V8_3.4.0            \n [37] pkgbuild_1.2.0       rstan_2.21.2         abind_1.4-5         \n [40] scales_1.1.1         mvtnorm_1.1-1        DBI_1.1.1           \n [43] miniUI_0.1.1.1       xtable_1.8-4         stats4_4.0.4        \n [46] StanHeaders_2.21.0-7 DT_0.17              htmlwidgets_1.5.3   \n [49] threejs_0.3.3        ellipsis_0.3.1       pkgconfig_2.0.3     \n [52] loo_2.4.1            farver_2.1.0         sass_0.3.1          \n [55] utf8_1.2.1           tidyselect_1.1.0     labeling_0.4.2      \n [58] rlang_0.4.10         reshape2_1.4.4       later_1.1.0.1       \n [61] munsell_0.5.0        cellranger_1.1.0     tools_4.0.4         \n [64] cli_2.3.1            generics_0.1.0       ggridges_0.5.3      \n [67] evaluate_0.14        stringr_1.4.0        fastmap_1.1.0       \n [70] yaml_2.2.1           ragg_1.1.2           processx_3.5.0      \n [73] knitr_1.31           purrr_0.3.4          nlme_3.1-152        \n [76] projpred_2.0.2       mime_0.10            xml2_1.3.2          \n [79] compiler_4.0.4       bayesplot_1.8.0      shinythemes_1.2.0   \n [82] rstudioapi_0.13      gamm4_0.2-6          curl_4.3            \n [85] png_0.1-7            statmod_1.4.35       bslib_0.2.4         \n [88] stringi_1.5.3        highr_0.8            ps_1.6.0            \n [91] Brobdingnag_1.2-6    lattice_0.20-41      Matrix_1.3-2        \n [94] nloptr_1.2.2.2       markdown_1.1         shinyjs_2.0.0       \n [97] vctrs_0.3.6          pillar_1.5.1         lifecycle_1.0.0     \n[100] jquerylib_0.1.3      bridgesampling_1.0-0 estimability_1.3    \n[103] httpuv_1.5.5         R6_2.5.0             bookdown_0.21       \n[106] promises_1.2.0.1     gridExtra_2.3        codetools_0.2-18    \n[109] distill_1.2          boot_1.3-27          colourpicker_1.1.0  \n[112] MASS_7.3-53.1        gtools_3.8.2         assertthat_0.2.1    \n[115] rprojroot_2.0.2      withr_2.4.1          shinystan_2.5.0     \n[118] multcomp_1.4-16      mgcv_1.8-34          parallel_4.0.4      \n[121] hms_1.0.0            grid_4.0.4           tidyr_1.1.3         \n[124] coda_0.19-4          minqa_1.2.4          rmarkdown_2.7       \n[127] downlit_0.2.1        shiny_1.6.0          lubridate_1.7.10    \n[130] base64enc_0.1-3      dygraphs_1.1.1.6    \n\n\n\n\nBates, D., Mächler, M., Bolker, B., & Walker, S. (2015). Fitting linear mixed-effects models using lme4. Journal of Statistical Software, 67(1), 1–48. https://doi.org/10.18637/jss.v067.i01\n\n\nBoatwright, P., McCulloch, R., & Rossi, P. (1999). Account-level modeling for trade promotion: An application of a constrained parameter hierarchical model. Journal of the American Statistical Association, 94(448), 1063–1073.\n\n\nde Finetti, B. (1974). Theory of Probability (Volume 1). New York: John Wiley & Sons.\n\n\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian Data Analysis. Chapman and Hall/CRC.\n\n\nLewandowski, D., Kurowicka, D., & Joe, H. (2009). Generating random correlation matrices based on vines and extended onion method. Journal of Multivariate Analysis, 100(9), 1989–2001.\n\n\nNau, R. F. (2001). De Finetti was Right: Probability Does Not Exist. Theory and Decision, 51(2), 89–124. https://doi.org/10.1023/A:1015525808214\n\n\nWaring, E., Quinn, M., McNamara, A., Arino de la Rubia, E., Zhu, H., & Ellis, S. (2021). Skimr: Compact and flexible summaries of data. Retrieved from https://CRAN.R-project.org/package=skimr\n\n\nZuur, A., Ieno, E. N., & Smith, G. M. (2007). Analyzing ecological data. Springer.\n\n\ndo inglês exchangeability.↩︎\npor isso que nas fórmulas do R o 1 é interpretado como a constante do modelo. Substitua-o por uma coluna de \\(0\\) de temos um modelo sem constante, por isso o 0 nas fórmulas é interpretado como um modelo ausente de constante.↩︎\ndecov(1) é basicamente uma priori uniforme.↩︎\n",
      "last_modified": "2021-03-29T16:46:14-03:00"
    },
    {
      "path": "2-Distribuicoes_Estatisticas.html",
      "title": "Distribuições Estatísticas",
      "description": "Os blocos fundamentais dos modelos Bayesianos",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 1, 2021",
      "contents": "\n\nContents\nDiscretas\nUniforme Discreta\nBernoulli\nBinomial\nPoisson\n\nBinomial Negativa\nContínuas\nNormal / Gaussiana\nLog-normal\nExponencial\nDistribuição \\(t\\) de Student\n\nDashboard de Distribuições\nAmbiente\n\n\nA estatística Bayesiana usa distribuições probabilísticas como o motor de sua inferência na elaboração dos valores dos parâmetros estimados e suas incertezas.\nImagine que distribuição probabilísticas são pequenas peças de “Lego.” Podemos construir o que quisermos com essas pequenas peças. Podemos fazer um castelo, uma casa, uma cidade; literalmente o que quisermos. O mesmo é valido para modelos probabilísticos em estatística Bayesiana. Podemos construir modelos dos mais simples aos mais complexo a partir de distribuições probabilísticas e suas relações entre si. Nesta aula vamos fazer um sobrevoo sobre as principais distribuições probabilísticas, sua notação matemática e seus principais usos em estatística Bayesiana.\nUma distribuição de probabilidade é a função matemática que fornece as probabilidades de ocorrência de diferentes resultados possíveis para um experimento. É uma descrição matemática de um fenômeno aleatório em termos de seu espaço amostral e as probabilidades de eventos (subconjuntos do espaço amostral).\nGeralmente usamos a notação X ~ Dist(par1, par2, ...). Onde X é a variável, Dist é o nome da distribuição, e par os parâmetros que definem como a distribuição se comporta. Toda distribuição probabilística pode ser “parameterizada” ao especificarmos parâmetros que permitem moldarmos alguns aspectos da distribuição para algum fim específico.\nComeçaremos pelas distribuições discretas e na sequência abordaremos as contínuas.\nDiscretas\nDistribuições de probabilidade discretas são aquelas que os resultados são números discretos (também chamados de números inteiros): \\(\\dots, -2, 1, 0,1,2,\\dots, N\\) e \\(N \\in \\mathbb{Z}\\). Em distribuições discretas chamamos a probabilidade de uma distribuição tomar certos valores como “massa.” A função massa de probabilidade \\(\\text{FMP}\\) é a função que especifica a probabilidade da variável aleatória \\(X\\) tomar o valor \\(x\\):\n\\[\n\\text{FMP}(x) = P(X = x)\n\\]\nUniforme Discreta\nA distribuição uniforme discreta é uma distribuição de probabilidade simétrica em que um número finito de valores são igualmente prováveis de serem observados. Cada um dos \\(n\\) valores tem probabilidade igual \\(\\frac{1}{n}\\). Outra maneira de dizer “distribuição uniforme discreta” seria “um número conhecido e finito de resultados igualmente prováveis de acontecer.”\nA distribuição uniforme discreta possui dois parâmetros e sua notação é \\(\\text{Unif}(a, b)\\):\nLimite Inferior (\\(a\\))\nLimite Superior (\\(b\\))\nExemplo: Um dado.\n\n\nggplot(data = tibble(\n  x = seq(1, 6),\n  y = dunif(x, min = 1, max = 6)),\n  aes(x, y)) +\n  geom_line(size = 2, col = \"red\") +\n  geom_point(size = 4, col = \"red\") +\n  labs(\n    title = \"Distribuição Uniforme Discreta\",\n    subtitle = expression(\"a =  1, b = 6\"),\n    x = expression(theta),\n    y = \"Massa\",\n    color = \"Parâmetros\"\n  ) +\n  scale_x_continuous(breaks = c(1:6))\n\n\n\n\nFigure 1: Distribuição Uniforme entre 1 e 6\n\n\n\nBernoulli\nA distribuição de Bernoulli descreve um evento binário de um sucesso de um experimento. Geralmente representamos \\(0\\) como falha e \\(1\\) como sucesso, então o resultado de uma distribuição de Bernoulli é uma variável binária \\(Y \\in \\{0, 1\\}\\).\nA distribuição de Bernoulli é muito usada para modelar resultados discretos binários no qual só há dois possíveis resultados.\nA distribuição de Bernoulli possui apenas um único paramêtro e sua notação é \\(\\text{Bernoulli} (p)\\):\nProbabilidade de Sucesso (\\(p\\))\nExemplo: Se o paciente sobreviveu ou morreu ou se o cliente conclui sua compra ou não.\nBinomial\nA distribuição binomial descreve um evento do número de sucessos em uma sequência de \\(n\\) experimentos independentes, cada um fazendo uma pergunta sim-não com probabilidade de sucesso \\(p\\). Note que a distribuição de Bernoulli é um caso especial da distribuição binomial no qual o número de experimentos é \\(1\\).\nA distribuição binomial é freqüentemente usada para modelar o número de sucessos em uma amostra de tamanho \\(n\\) desenhada com substituição de uma população de tamanho \\(N\\).\nA distribuição binomial possui dois parâmetros e sua notação é \\(\\text{Bin}(n, p)\\) ou \\(\\text{Binomial}(n, p)\\):\nNúmero de Experimentos (\\(n\\))\nProbabilidade de Sucessos (\\(p\\))\nExemplo: quantidade de caras em 5 lançamentos de uma moeda.\n\n\nggplot(data = tibble(x = seq(0, 5))) +\n  labs(\n    title = \"Comparativo de Distribuições Binomial\",\n    subtitle = expression(n == 5),\n    x = expression(theta),\n    y = \"Massa\",\n    color = \"Parâmetros\"\n  ) +\n  geom_line(aes(x, y = dbinom(x, size = 5, prob = 0.1), color = \"p ==  0.1\"), size = 2) +\n  geom_point(aes(x, y = dbinom(x, size = 5, prob = 0.1), color = \"p ==  0.1\"), size = 4) +\n  geom_line(aes(x, y = dbinom(x, size = 5, prob = 0.2), color = \"p ==  0.2\"), size = 2) +\n  geom_point(aes(x, y = dbinom(x, size = 5, prob = 0.2), color = \"p ==  0.2\"), size = 4) +\n  geom_line(aes(x, y = dbinom(x, size = 5, prob = 0.5), color = \"p ==  0.5\"), size = 2) +\n  geom_point(aes(x, y = dbinom(x, size = 5, prob = 0.5), color = \"p ==  0.5\"), size = 4) +\n  scale_color_brewer(palette = \"Set1\",\n    labels = scales::label_parse())\n\n\n\n\nFigure 2: Comparativo de Distribuições Binomial\n\n\n\nPoisson\nA distribuição Poisson expressa a probabilidade de um determinado número de eventos ocorrerem em um intervalo fixo de tempo ou espaço se esses eventos ocorrerem com uma taxa média constante conhecida e independentemente do tempo desde o último evento. A distribuição de Poisson também pode ser usada para o número de eventos em outros intervalos especificados, como distância, área ou volume.\nA distribuição Poisson possui um parâmetro e sua notação é \\(\\text{Poisson}(\\lambda)\\):\nTaxa (\\(\\lambda\\))\nExemplo: Quantidade de e-mails que você recebe diariamente. Quantidade de buracos que você encontra na rua.\n\n\nggplot(data = tibble(x = seq(0, 20))) +\n  labs(\n    title = \"Comparativo de Distribuições Poisson\",\n    x = expression(theta),\n    y = \"Massa\",\n    color = \"Parâmetros\"\n  ) +\n  geom_line(aes(x, y = dpois(x, lambda = 1), color = \"lambda ==  1\"), size = 2) +\n  geom_point(aes(x, y = dpois(x, lambda = 1), color = \"lambda ==  1\"), size = 4) +\n  geom_line(aes(x, y = dpois(x, lambda = 4), color = \"lambda ==  4\"), size = 2) +\n  geom_point(aes(x, y = dpois(x, lambda = 4), color = \"lambda ==  4\"), size = 4) +\n  geom_line(aes(x, y = dpois(x, lambda = 10), color = \"lambda ==  10\"), size = 2) +\n  geom_point(aes(x, y = dpois(x, lambda = 10), color = \"lambda ==  10\"), size = 4) +\n  scale_color_brewer(palette = \"Set1\",\n    labels = scales::label_parse())\n\n\n\n\nFigure 3: Comparativo de Distribuições Poisson\n\n\n\nBinomial Negativa\nA distribuição binomial negativa descreve um evento do número de sucessos em uma sequência de \\(n\\) experimentos independentes, cada um fazendo uma pergunta sim-não com probabilidade \\(p\\) até que se obtenha \\(k\\) sucessos. Note que ela se torna idêntica à distribuição de Poisson quando no limite de \\(k \\to \\infty\\). Isto faz com que seja uma opção robusta para substituir uma distribuição de Poisson para modelar fenômenos com uma superdispersão (variação nos dados excedente ao esperado).\nA distribuição negativa binomial possui dois parâmetros e sua notação é \\(\\text{NB}(k, p)\\) ou \\(\\text{Negative-Binomial}(k, p)\\):\nNúmero de Sucessos (\\(k\\))\nProbabilidade de Sucessos (\\(p\\))\nQualquer fenômeno que pode ser modelo com uma distribuição de Poisson, pode ser modelo com uma distribuição binomial negativa (Gelman et al., 2013; Gelman, Hill, & Vehtari, 2020).\nExemplo: Contagem anual de ciclones tropicais.\n\n\nggplot(data = tibble(x = seq(0, 5))) +\n  labs(\n    title = \"Comparativo de Distribuições Binomial Negativa\",\n    subtitle = expression(p == 0.5),\n    x = expression(theta),\n    y = \"Massa\",\n    color = \"Parâmetros\"\n  ) +\n  geom_line(aes(x, y = dnbinom(x, size = 1, prob = 0.5), color = \"k ==  1\"), size = 2) +\n  geom_point(aes(x, y = dnbinom(x, size = 1, prob = 0.5), color = \"k ==  1\"), size = 4) +\n  geom_line(aes(x, y = dnbinom(x, size = 2, prob = 0.5), color = \"k ==  2\"), size = 2) +\n  geom_point(aes(x, y = dnbinom(x, size = 2, prob = 0.5), color = \"k ==  2\"), size = 4) +\n  geom_line(aes(x, y = dnbinom(x, size = 5, prob = 0.5), color = \"k ==  5\"), size = 2) +\n  geom_point(aes(x, y = dnbinom(x, size = 5, prob = 0.5), color = \"k ==  5\"), size = 4) +\n  scale_color_brewer(palette = \"Set1\",\n    labels = scales::label_parse())\n\n\n\n\nFigure 4: Comparativo de Distribuições Binomial Negativa\n\n\n\nContínuas\nDistribuições de probabilidade contínuas são aquelas que os resultados são valores em uma faixa contínua (também chamados de número reais): \\([-\\infty, \\infty] \\in \\mathbb{R}\\). Em distribuições contínuas chamamos a probabilidade de uma distribuição tomar certos valores como “densidade.” Como estamos falando sobre números reais não conseguimos obter a probabilidade de uma variável aleatória \\(X\\) tomar o valor de \\(x\\). Isto sempre será \\(0\\), pois não há como especificar um valor exato de \\(x\\). \\(x\\) vive na linha dos números reais, portanto, precisamos especificar a probabilidade de \\(X\\) tomar valores em um intervalo \\([a.b]\\). A função densidade de probabilidade \\(\\text{FDP}\\) é definida como:\n\\[\n\\text{FDP}(x) = P(a \\leq X \\leq b) = \\int_a^b f(x) dx\n\\]\nNormal / Gaussiana\nEssa distribuição geralmente é usada nas ciências sociais e naturais para representar variáveis contínuas na qual as suas distribuições não são conhecidas. Esse pressuposto é por conta do teorema do limite central. O teorema do limite central afirma que, em algumas condições, a média de muitas amostras (observações) de uma variável aleatória com média e variância finitas é ela própria uma variável aleatória cuja distribuição converge para uma distribuição normal à medida que o número de amostras aumenta. Portanto, as quantidades físicas que se espera sejam a soma de muitos processos independentes (como erros de medição) muitas vezes têm distribuições que são quase normais.\nA distribuição normal possui dois parâmetros e sua notação é \\(\\text{Normal}(\\mu, \\sigma^2)\\) ou \\(\\text{N}(\\mu, \\sigma^2)\\):\nMédia (\\(\\mu\\)): média da distribuição e também a moda e a mediana\nDesvio Padrão (\\(\\sigma\\)): a variância da distribuição (\\(\\sigma^2\\)) é uma média de dispersão das observações em relação à média\nExemplo: Altura, Peso etc.\n\n\nggplot(data = tibble(x = seq(-4, 4, length = 100))) +\n  labs(\n    title = \"Comparativo de Distribuições Normais\",\n    subtitle = expression(mu == 0),\n    x = expression(theta),\n    y = \"Densidade\",\n    color = \"Parâmetros\"\n  ) +\n  geom_line(aes(x, y = dnorm(x, mean = 0, sd = 0.5), color = \"sigma ==  0.5\"), size = 2) +\n  geom_line(aes(x, y = dnorm(x, mean = 0, sd = 1), color = \"sigma ==  1.0\"), size = 2) +\n  geom_line(aes(x, y = dnorm(x, mean = 0, sd = 2), color = \"sigma ==  2.0\"), size = 2) +\n  geom_line(aes(x, y = dnorm(x, mean = 0, sd = 5), color = \"sigma ==  5.0\"), size = 2) +\n  scale_color_brewer(palette = \"Set1\",\n    labels = scales::label_parse())\n\n\n\n\nFigure 5: Comparativo de Distribuições Normais\n\n\n\nLog-normal\nA distribuição Log-normal é uma distribuição de probabilidade contínua de uma variável aleatória cujo logaritmo é normalmente distribuído. Assim, se a variável aleatória \\(X\\) for distribuída normalmente por log natural, então \\(Y = \\log (X)\\) terá uma distribuição normal.\nUma variável aleatória com distribuição logarítmica aceita apenas valores reais positivos. É um modelo conveniente e útil para medições em ciências exatas e de engenharia, bem como medicina, economia e outros campos, por ex. para energias, concentrações, comprimentos, retornos financeiros e outros valores.\nUm processo log-normal é a realização estatística do produto multiplicativo de muitas variáveis aleatórias independentes, cada uma das quais positiva.\nA distribuição log-normal possui dois parâmetros e sua notação é \\(\\text{Log-Normal}(\\mu, \\sigma^2)\\):\nMédia (\\(\\mu\\)): média do logaritmo natural da distribuição\nDesvio Padrão (\\(\\sigma\\)): a variância do logaritmo natural da distribuição (\\(\\sigma^2\\)) é uma média de dispersão das observações em relação à média\n\n\nggplot(data = tibble(x = seq(0, 3, length = 100))) +\n  labs(\n    title = \"Comparativo de Distribuições Log-Normais\",\n    subtitle = expression(mu == 0),\n    x = expression(theta),\n    y = \"Densidade\",\n    color = \"Parâmetros\"\n  ) +\n  geom_line(aes(x, y = dlnorm(x, mean = 0, sd = 0.25), color = \"sigma ==  0.25\"), size = 2) +\n  geom_line(aes(x, y = dlnorm(x, mean = 0, sd = 0.5), color = \"sigma ==  0.5\"), size = 2) +\n  geom_line(aes(x, y = dlnorm(x, mean = 0, sd = 1.0), color = \"sigma ==  1.0\"), size = 2) +\n  geom_line(aes(x, y = dlnorm(x, mean = 0, sd = 1.5), color = \"sigma ==  1.5\"), size = 2) +\n  scale_color_brewer(palette = \"Set1\",\n    labels = scales::label_parse())\n\n\n\n\nFigure 6: Comparativo de Distribuições Log-Normais\n\n\n\nExponencial\nA distribuição exponencial é a distribuição de probabilidade do tempo entre eventos que ocorrem de forma contínua e independente a uma taxa média constante.\nA distribuição exponencial possui um parâmetro e sua notação é \\(\\text{Exp} (\\lambda)\\):\nTaxa (\\(\\lambda\\))\nExemplo: Quanto tempo até o próximo terremoto. Quanto tempo até o próximo ônibus.\n\n\nggplot(data = tibble(x = seq(0, 5, length = 100))) +\n  labs(\n    title = \"Comparativo de Distribuições Exponenciais\",\n    x = expression(theta),\n    y = \"Densidade\",\n    color = \"Parâmetros\"\n  ) +\n  geom_line(aes(x, y = dexp(x, rate = 0.5), color = \"lambda ==  0.5\"), size = 2) +\n  geom_line(aes(x, y = dexp(x, rate = 1), color = \"lambda ==  1\"), size = 2) +\n  geom_line(aes(x, y = dexp(x, rate = 1.5), color = \"lambda ==  1.5\"), size = 2) +\n  geom_line(aes(x, y = dexp(x, rate = 2), color = \"lambda ==  2\"), size = 2) +\n  scale_color_brewer(palette = \"Set1\",\n    labels = scales::label_parse())\n\n\n\n\nFigure 7: Comparativo de Distribuições Exponenciais\n\n\n\nDistribuição \\(t\\) de Student\nA distribuição \\(t\\) de Student surge ao estimar a média de uma população normalmente distribuída em situações onde o tamanho da amostra é pequeno e o desvio padrão da população é desconhecido.\nSe tomarmos uma amostra de \\(n\\) observações de uma distribuição normal, então a distribuição \\(t\\) com \\(\\nu = n-1\\) graus de liberdade pode ser definida como a distribuição da localização da média da amostra em relação à média verdadeira, dividida pela desvio padrão da amostra, após multiplicar pelo termo padronizador \\(\\sqrt{n}\\).\nA distribuição \\(t\\) é simétrica e em forma de sino, como a distribuição normal, mas tem caudas mais longas, o que significa que é mais propensa a produzir valores que estão longe de sua média.\nA distribuição \\(t\\) de Student possui um parâmetro e sua notação é \\(\\text{Student} (\\nu)\\):\nGraus de Liberdade (\\(\\nu\\)): controla o quanto ela se assemelha com uma distribuição normal\nExemplo: Uma base de dados cheia de outliers.\n\n\nggplot(data = tibble(x = seq(-4, 4, length = 100))) +\n  labs(\n    title = \"Comparativo de Distribuições t de Student\",\n    x = expression(theta),\n    y = \"Densidade\",\n    color = \"Parâmetros\"\n  ) +\n  geom_line(aes(x, y = dt(x, df = 1), color = \"nu ==  1\"), size = 2) +\n  geom_line(aes(x, y = dt(x, df = 3), color = \"nu ==  3\"), size = 2) +\n  geom_line(aes(x, y = dt(x, df = 8), color = \"nu ==  8\"), size = 2) +\n  geom_line(aes(x, y = dt(x, df = 30), color = \"nu ==  30\"), size = 2) +\n  scale_color_brewer(palette = \"Set1\",\n    labels = scales::label_parse())\n\n\n\n\nFigure 8: Comparativo de Distribuições \\(t\\) de Student\n\n\n\nDashboard de Distribuições\nNão cobrimos todas as distribuições existentes. Há uma pletora de distribuições probabilísticas.\nPara acessar todo o zoológico de distribuições use essa ferramenta do Ben Lambert (estatístico do Imperial College of London): https://ben18785.shinyapps.io/distribution-zoo/\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.4 (2021-02-15)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n [1] brms_2.15.0     rstanarm_2.21.1 Rcpp_1.0.6      skimr_2.1.3    \n [5] readr_1.4.0     readxl_1.3.1    tibble_3.1.0    ggplot2_3.3.3  \n [9] patchwork_1.1.1 cowplot_1.1.1  \n\nloaded via a namespace (and not attached):\n  [1] backports_1.2.1      systemfonts_1.0.1    plyr_1.8.6          \n  [4] igraph_1.2.6         repr_1.1.3           splines_4.0.4       \n  [7] crosstalk_1.1.1      TH.data_1.0-10       rstantools_2.1.1    \n [10] inline_0.3.17        digest_0.6.27        htmltools_0.5.1.1   \n [13] magick_2.7.1         rsconnect_0.8.16     fansi_0.4.2         \n [16] magrittr_2.0.1       RcppParallel_5.0.3   matrixStats_0.58.0  \n [19] sandwich_3.0-0       xts_0.12.1           prettyunits_1.1.1   \n [22] jpeg_0.1-8.1         colorspace_2.0-0     textshaping_0.3.3   \n [25] xfun_0.22            dplyr_1.0.5          callr_3.6.0         \n [28] crayon_1.4.1         jsonlite_1.7.2       lme4_1.1-26         \n [31] survival_3.2-10      zoo_1.8-9            glue_1.4.2          \n [34] gtable_0.3.0         emmeans_1.5.5-1      V8_3.4.0            \n [37] pkgbuild_1.2.0       rstan_2.21.2         abind_1.4-5         \n [40] scales_1.1.1         mvtnorm_1.1-1        DBI_1.1.1           \n [43] miniUI_0.1.1.1       xtable_1.8-4         stats4_4.0.4        \n [46] StanHeaders_2.21.0-7 DT_0.17              htmlwidgets_1.5.3   \n [49] threejs_0.3.3        RColorBrewer_1.1-2   ellipsis_0.3.1      \n [52] pkgconfig_2.0.3      loo_2.4.1            farver_2.1.0        \n [55] sass_0.3.1           utf8_1.2.1           tidyselect_1.1.0    \n [58] labeling_0.4.2       rlang_0.4.10         reshape2_1.4.4      \n [61] later_1.1.0.1        munsell_0.5.0        cellranger_1.1.0    \n [64] tools_4.0.4          cli_2.3.1            generics_0.1.0      \n [67] ggridges_0.5.3       evaluate_0.14        stringr_1.4.0       \n [70] fastmap_1.1.0        yaml_2.2.1           ragg_1.1.2          \n [73] processx_3.5.0       knitr_1.31           purrr_0.3.4         \n [76] nlme_3.1-152         projpred_2.0.2       mime_0.10           \n [79] xml2_1.3.2           compiler_4.0.4       bayesplot_1.8.0     \n [82] shinythemes_1.2.0    rstudioapi_0.13      gamm4_0.2-6         \n [85] curl_4.3             png_0.1-7            statmod_1.4.35      \n [88] bslib_0.2.4          stringi_1.5.3        highr_0.8           \n [91] ps_1.6.0             Brobdingnag_1.2-6    lattice_0.20-41     \n [94] Matrix_1.3-2         nloptr_1.2.2.2       markdown_1.1        \n [97] shinyjs_2.0.0        vctrs_0.3.6          pillar_1.5.1        \n[100] lifecycle_1.0.0      jquerylib_0.1.3      bridgesampling_1.0-0\n[103] estimability_1.3     httpuv_1.5.5         R6_2.5.0            \n[106] bookdown_0.21        promises_1.2.0.1     gridExtra_2.3       \n[109] codetools_0.2-18     distill_1.2          boot_1.3-27         \n[112] colourpicker_1.1.0   MASS_7.3-53.1        gtools_3.8.2        \n[115] assertthat_0.2.1     rprojroot_2.0.2      withr_2.4.1         \n[118] shinystan_2.5.0      multcomp_1.4-16      mgcv_1.8-34         \n[121] parallel_4.0.4       hms_1.0.0            grid_4.0.4          \n[124] tidyr_1.1.3          coda_0.19-4          minqa_1.2.4         \n[127] rmarkdown_2.7        downlit_0.2.1        shiny_1.6.0         \n[130] lubridate_1.7.10     base64enc_0.1-3      dygraphs_1.1.1.6    \n\n\n\n\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian Data Analysis. Chapman and Hall/CRC.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2020). Regression and other stories. Cambridge University Press.\n\n\n\n\n",
      "last_modified": "2021-03-29T16:46:18-03:00"
    },
    {
      "path": "3-rstanarm.html",
      "title": "rstanarm e brms",
      "description": "As interfaces amigáveis do Stan",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 1, 2021",
      "contents": "\n\nContents\nFórmulas\nfamily\nrstanarm\nExemplo usando o mtcars\n\nbrms\nAmbiente\n\n\nA principal ferramenta para computação Bayesiana é a linguagem probabilística Stan (Carpenter et al., 2017). O problema do Stan é que ele é uma linguagem de programação e, portanto, possui um acesso dificultado a não-programadores. Abaixo um código que mostra como é um programa escrito em Stan1:\n\ndata {\n  int<lower=0> N;\n  vector<lower=0, upper=200>[N] kid_score;\n  vector<lower=0, upper=200>[N] mom_iq;\n}\nparameters {\n  vector[2] beta;\n  real<lower=0> sigma;\n}\nmodel {\n  sigma ~ cauchy(0, 2.5);\n  kid_score ~ normal(beta[1] + beta[2] * mom_iq, sigma);\n}\n\nPara remediar essa barreira de acesso ao Stan, temos interfaces abstratas que interpretam a intenção do usuário e lidam com a parte mais obral de codificação. As principais são rstanarm (Goodrich, Gabry, Ali, & Brilleman, 2020) e brms (Bürkner, 2017). Ambos usa a mesma síntaxe e as mesmas famílias de funções de verossimilhança, mas com algumas diferenças:\nrstanarm todos os modelos são pré-compilados e brms não possui os modelos pré-compilados então os modelos devem ser todos compilados antes de serem rodados. A diferença prática é que você irá esperar alguns instantes antes do R começar a amostrar do modelo.\nComo brms compila os modelos conforme a especificação do usuário (não possui modelos pré-compilados) ele pode criar modelos um pouco mais eficientes que o rstanarm. Caso o tempo de compilação dos modelos brms seja menor que ganho de velocidade em amostragem do modelo, é vantajoso especificar seu modelo com brms.\nbrms dá maior poder e flexibilidade ao usuário na especificação de funções de verossimilhança e também permite modelos mais complexos que o rstanarm (um exemplo notório é que rstanarm não permite usarmos distribuição \\(t\\) de Student como função de verossimilhança enquanto que isso é possível no brms. Portanto a Aula 9 - Regressão Robusta usará exclusivamente o brms).\nFórmulas\nTodos os modelos especificados pelo rstanarm e brms usam uma fórmula com a seguinte síntaxe:\ndependente ~ independente_1 + independente_2 + ...\nPara quem conhece R essa síntaxe é a mesma utilizada em regressões lineares frequentista com o lm() ou em modelos lineares generalizados frequentistas com glm().\nfamily\nTodo modelo especificado pelo rstanarm e brms devem especificar qual família da função de verossimilhança (family) respectivamente com a função de ligação (‘link’) que fará o mapeamento dos parâmetros condicionados nos dados para a variável dependente. Caso o usuário não designe nenhum valor para esses dois parâmetros, rstanarm e brms usarão a verossimilhança Gaussiana (family = gaussian) e a função de identidade como função de ligação (link = \"identity\").\nEstes argumentos family e link são conhecidos para quem usa R para estatística frequentista pois são os mesmos da função glm() de R para modelos lineares generalizados frequentistas. Algumas das principais famílias com suas funções de ligação padrões são:\nGaussiana – family = gaussian – link = \"identity\"\nLog-Normal – family = lognormal – link = \"log\"\nBinomial – family = binomial – link = \"logit\"\nPoisson – family = poisson – link = \"log\"\nBinomial Negativa – family = negbinomial – link = \"log\"\n\\(t\\) de Student – family = student – link = \"identity\"\nExponencial – family = exponential – link = \"log\"\nrstanarm\nO rstanarm é a porta de entrada para estatística Bayesiana com Stan. O nome rstanarm é:\nr: pacote para R\nstan: usa a linguagem probabilística Stan\narm: acrônimo para Applied Regression Modeling\nEle possui as seguintes funções para especificação de modelos Bayesianos:\nstan_glm() – modelos lineares generalizados (generalized linear model)\nstan_lm() – modelos lineares regularizados (linear model)\nstan_aov() – modelo ANOVA (analysis of variance)\nstan_glmer() – modelos linares generalizados multiníveis\nstan_lmer() – modelos linares regularizados multiníveis\nstan_jm() – modelos longitudinais e de sobrevivência\nstan_nlmer() – modelos não-lineares multiníveis (non-linear model)\nstan_polr() – modelos ordinais\nstan_gamm4() – modelos aditivos linares multiníveis\nNeste curso usaremos apenas stan_glm e stan_glmer, mas saiba que você possui uma vasta categoria de modelos bayesianos à disposição.\nExemplo usando o mtcars\nVamos estimar modelos Bayesianos usando o dataset já conhecido mtcars da Aula 1 - Comandos Básicos de R. A idéia é usarmos como variável dependente a autonomia do carro (milhas por galão – mpg) e como independentes o peso do carro (wt) e se o carro é automático ou manual (am). A fórmula então fica:\nmpg ~ wt + am\nNote que também devemos especificar a localização dos nossos dados com o argumento data. Para garantir que toda a funcionalidade do rstanarm esteja disponível para seu modelo, recomendo que especifique sempre o valor de data como um objeto data.frame ou tibble.\n\n\nlibrary(rstanarm)\nrstanarm_fit <- stan_glm(mpg ~ wt + am, data = mtcars)\n\n\n\nPodemos ver o sumário do modelo estimado2 com a função print() ou summary():\n\n\nprint(rstanarm_fit)\n\n\nstan_glm\n family:       gaussian [identity]\n formula:      mpg ~ wt + am\n observations: 32\n predictors:   3\n------\n            Median MAD_SD\n(Intercept) 37.3    3.2  \nwt          -5.3    0.8  \nam           0.0    1.5  \n\nAuxiliary parameter(s):\n      Median MAD_SD\nsigma 3.2    0.4   \n\n------\n* For help interpreting the printed output see ?print.stanreg\n* For info on the priors used see ?prior_summary.stanreg\n\n\n\nsummary(rstanarm_fit)\n\n\n\nModel Info:\n function:     stan_glm\n family:       gaussian [identity]\n formula:      mpg ~ wt + am\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 32\n predictors:   3\n\nEstimates:\n              mean   sd   10%   50%   90%\n(Intercept) 37.2    3.2 33.2  37.3  41.1 \nwt          -5.3    0.8 -6.3  -5.3  -4.3 \nam           0.0    1.6 -2.0   0.0   2.1 \nsigma        3.2    0.4  2.7   3.2   3.8 \n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 20.1    0.8 19.1  20.1  21.1 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.1  1.0  1945 \nwt            0.0  1.0  2085 \nam            0.0  1.0  1949 \nsigma         0.0  1.0  2793 \nmean_PPD      0.0  1.0  3434 \nlog-posterior 0.0  1.0  1394 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nA interpretação e significado da saída dos modelos rstanarm serão explicadas nas aulas seguintes. A função print() é mais concisa que a função summary(). Para quem já rodou modelos de regressão, o output da função print() mostra a mediana (Median) dos coeficientes e erro (sigma) do modelo junto com o desvio absoluto médio (mean absolute deviation – MAD_SD). No output da função summary(), a tabela Estimates é a tabela que mostra a média (mean) dos coeficientes e erro (sigma) do modelo junto com o desvio padrão (sd) e os percentis 10%, 50% (mediana) e 90% baseados na mediana e desvio absoluto médio.\nPodemos também especificar os percentis desejados no summary():\n\n\nsummary(rstanarm_fit, probs = c(0.025, 0.975))\n\n\n\nModel Info:\n function:     stan_glm\n family:       gaussian [identity]\n formula:      mpg ~ wt + am\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 32\n predictors:   3\n\nEstimates:\n              mean   sd   2.5%   98%\n(Intercept) 37.2    3.2 30.9   43.4 \nwt          -5.3    0.8 -6.9   -3.7 \nam           0.0    1.6 -3.1    3.3 \nsigma        3.2    0.4  2.5    4.2 \n\nFit Diagnostics:\n           mean   sd   2.5%   98%\nmean_PPD 20.1    0.8 18.5   21.6 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.1  1.0  1945 \nwt            0.0  1.0  2085 \nam            0.0  1.0  1949 \nsigma         0.0  1.0  2793 \nmean_PPD      0.0  1.0  3434 \nlog-posterior 0.0  1.0  1394 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nbrms\nO brms é a alia toda a comodidade do rstanarm com o poder e flexibilidade do Stan. O nome brms quer dizer:\nb: Bayesian\nr: regression\nm: models\ns: usando Stan\nAo invés de possuir diversas funções para diferentes tipos de modelo, brms tem apenas uma única função para especificar modelos: brm() – acrônimo para Bayesian Regression Model. O usuário consegue especificar qualquer modelo que quiser a partir da função brm() apenas mudando seus parâmetros internos. Os parâmetros da função brm() mais importantes são (como mencionado acima):\nfamily – especifica a família da função de verossimilhança do modelo (padrão gaussian)\nlink – especifica a função de ligação que fará o mapeamento dos parâmetros condicionados nos dados para a variável dependente do modelo (padrão varia conforme o family, mas para family = gaussian, a função identidade é a função de ligação padrão link = \"identity\")\nVamos usar o mesmo modelo que usamos para o rstanarm acima. Note que a fórmula não muda e usaremos a mesma:\nmpg ~ wt + am\nNote que também devemos especificar a localização dos nossos dados com o argumento data. Para garantir que toda a funcionalidade do brms esteja disponível para seu modelo, recomendo que especifique sempre o valor de data como um objeto data.frame ou tibble.\n\n\nlibrary(brms)\nbrms_fit <- brm(mpg ~ wt + am, data = mtcars)\n\n\n\nPodemos ver o sumário do modelo estimado3 com a função print() ou summary(). No caso do brms não há diferença entre elas e elas literalmente produzem o mesmo output:\n\n\nprint(brms_fit)\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: mpg ~ wt + am \n   Data: mtcars (Number of observations: 32) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept    37.25      3.21    30.93    43.48 1.00     2939     2678\nwt           -5.34      0.83    -7.01    -3.74 1.00     2972     2867\nam           -0.01      1.64    -3.28     3.20 1.00     3049     2824\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     3.21      0.43     2.49     4.17 1.00     3273     2946\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\nsummary(brms_fit)\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: mpg ~ wt + am \n   Data: mtcars (Number of observations: 32) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept    37.25      3.21    30.93    43.48 1.00     2939     2678\nwt           -5.34      0.83    -7.01    -3.74 1.00     2972     2867\nam           -0.01      1.64    -3.28     3.20 1.00     3049     2824\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     3.21      0.43     2.49     4.17 1.00     3273     2946\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nNote que temos quase que o mesmo output, sendo que brms por padrão mostra a média (Estimate) dos coeficientes e erro (sigma) do modelo junto com o desvio padrão (Est.Error) e os percentis 5% (l-95%) e 95% (u-95%) baseados na média e desvio padrão. Caso queira mediana e desvio absoluto médio, forneça o argumento robust = TRUE para a função print():\n\n\nsummary(brms_fit, robust = TRUE)\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: mpg ~ wt + am \n   Data: mtcars (Number of observations: 32) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept    37.27      3.15    30.93    43.48 1.00     2939     2678\nwt           -5.33      0.80    -7.01    -3.74 1.00     2972     2867\nam           -0.01      1.62    -3.28     3.20 1.00     3049     2824\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     3.17      0.40     2.49     4.17 1.00     3273     2946\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nNote que agora temos valores diferentes para o output de summary() com robust = TRUE, mas as colunas são as mesmas. Não se engane, agora temos a mediana (Estimate) dos coeficientes e erro (sigma) do modelo junto com o desvio absoluto médio (Est.Error) e os percentis 5% (l-95%) e 95% (u-95%) baseados na mediana e desvio absoluto médio.\nPodemos também especificar os percentis desejados no summary(). Aqui a síntaxe é um pouco diferente da síntaxe do rstanarm:\n\n\nsummary(brms_fit, prob = 0.9)\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: mpg ~ wt + am \n   Data: mtcars (Number of observations: 32) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-90% CI u-90% CI Rhat Bulk_ESS Tail_ESS\nIntercept    37.25      3.21    32.02    42.44 1.00     2939     2678\nwt           -5.34      0.83    -6.70    -4.01 1.00     2972     2867\nam           -0.01      1.64    -2.70     2.67 1.00     3049     2824\n\nFamily Specific Parameters: \n      Estimate Est.Error l-90% CI u-90% CI Rhat Bulk_ESS Tail_ESS\nsigma     3.21      0.43     2.59     3.97 1.00     3273     2946\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.4 (2021-02-15)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n [1] brms_2.15.0     rstanarm_2.21.1 Rcpp_1.0.6      skimr_2.1.3    \n [5] readr_1.4.0     readxl_1.3.1    tibble_3.1.0    ggplot2_3.3.3  \n [9] patchwork_1.1.1 cowplot_1.1.1  \n\nloaded via a namespace (and not attached):\n  [1] backports_1.2.1      systemfonts_1.0.1    plyr_1.8.6          \n  [4] igraph_1.2.6         repr_1.1.3           splines_4.0.4       \n  [7] crosstalk_1.1.1      TH.data_1.0-10       rstantools_2.1.1    \n [10] inline_0.3.17        digest_0.6.27        htmltools_0.5.1.1   \n [13] magick_2.7.1         rsconnect_0.8.16     fansi_0.4.2         \n [16] magrittr_2.0.1       RcppParallel_5.0.3   matrixStats_0.58.0  \n [19] sandwich_3.0-0       xts_0.12.1           prettyunits_1.1.1   \n [22] jpeg_0.1-8.1         colorspace_2.0-0     textshaping_0.3.3   \n [25] xfun_0.22            dplyr_1.0.5          callr_3.6.0         \n [28] crayon_1.4.1         jsonlite_1.7.2       lme4_1.1-26         \n [31] survival_3.2-10      zoo_1.8-9            glue_1.4.2          \n [34] gtable_0.3.0         emmeans_1.5.5-1      V8_3.4.0            \n [37] pkgbuild_1.2.0       rstan_2.21.2         abind_1.4-5         \n [40] scales_1.1.1         mvtnorm_1.1-1        DBI_1.1.1           \n [43] miniUI_0.1.1.1       xtable_1.8-4         stats4_4.0.4        \n [46] StanHeaders_2.21.0-7 DT_0.17              htmlwidgets_1.5.3   \n [49] threejs_0.3.3        RColorBrewer_1.1-2   ellipsis_0.3.1      \n [52] pkgconfig_2.0.3      loo_2.4.1            farver_2.1.0        \n [55] sass_0.3.1           utf8_1.2.1           tidyselect_1.1.0    \n [58] labeling_0.4.2       rlang_0.4.10         reshape2_1.4.4      \n [61] later_1.1.0.1        munsell_0.5.0        cellranger_1.1.0    \n [64] tools_4.0.4          cli_2.3.1            generics_0.1.0      \n [67] ggridges_0.5.3       evaluate_0.14        stringr_1.4.0       \n [70] fastmap_1.1.0        yaml_2.2.1           ragg_1.1.2          \n [73] processx_3.5.0       knitr_1.31           purrr_0.3.4         \n [76] nlme_3.1-152         projpred_2.0.2       mime_0.10           \n [79] xml2_1.3.2           compiler_4.0.4       bayesplot_1.8.0     \n [82] shinythemes_1.2.0    rstudioapi_0.13      gamm4_0.2-6         \n [85] curl_4.3             png_0.1-7            statmod_1.4.35      \n [88] bslib_0.2.4          stringi_1.5.3        highr_0.8           \n [91] ps_1.6.0             Brobdingnag_1.2-6    lattice_0.20-41     \n [94] Matrix_1.3-2         nloptr_1.2.2.2       markdown_1.1        \n [97] shinyjs_2.0.0        vctrs_0.3.6          pillar_1.5.1        \n[100] lifecycle_1.0.0      jquerylib_0.1.3      bridgesampling_1.0-0\n[103] estimability_1.3     httpuv_1.5.5         R6_2.5.0            \n[106] bookdown_0.21        promises_1.2.0.1     gridExtra_2.3       \n[109] codetools_0.2-18     distill_1.2          boot_1.3-27         \n[112] colourpicker_1.1.0   MASS_7.3-53.1        gtools_3.8.2        \n[115] assertthat_0.2.1     rprojroot_2.0.2      withr_2.4.1         \n[118] shinystan_2.5.0      multcomp_1.4-16      mgcv_1.8-34         \n[121] parallel_4.0.4       hms_1.0.0            grid_4.0.4          \n[124] tidyr_1.1.3          coda_0.19-4          minqa_1.2.4         \n[127] rmarkdown_2.7        downlit_0.2.1        shiny_1.6.0         \n[130] lubridate_1.7.10     base64enc_0.1-3      dygraphs_1.1.1.6    \n\n\n\n\nBürkner, P.-C. (2017). brms: An R package for Bayesian multilevel models using Stan. Journal of Statistical Software, 80(1), 1–28. https://doi.org/10.18637/jss.v080.i01\n\n\nCarpenter, B., Gelman, A., Hoffman, M. D., Lee, D., Goodrich, B., Betancourt, M., … Riddell, A. (2017). Stan : A Probabilistic Programming Language. Journal of Statistical Software, 76(1). https://doi.org/10.18637/jss.v076.i01\n\n\nGoodrich, B., Gabry, J., Ali, I., & Brilleman, S. (2020). Rstanarm: Bayesian applied regression modeling via Stan. Retrieved from https://mc-stan.org/rstanarm\n\n\nnotem que a síntaxe é bem similar à C++ com uma diferença notória que pontos flutuantes double são real e o ~ designa uma distribuição probabilística a uma variável↩︎\ngeralmente chamamos objetos stanreg que são oriundos das funções de modelos Bayesianos do rstanarm como fit.↩︎\ngeralmente chamamos objetos brmsfit que são oriundos das funções de modelos Bayesianos do brms como fit.↩︎\n",
      "last_modified": "2021-03-29T16:46:41-03:00"
    },
    {
      "path": "4-Priors.html",
      "title": "Priors",
      "description": "As famosas e controversas Priors",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 1, 2021",
      "contents": "\n\nContents\nSubjetividade da Priori\nTipos de Prioris\nPrioris para os Modelos rstanarm\nUniforme (flat)\nInformativas\nPadrões do rstanarm\nPadrões do brms\nExemplo usando o mtcars com rstanarm\nExemplo usando o mtcars com brms\n\nPor quê não é interessante usar prioris uniformes (flat priors)\nBayesian Workflow\nPrior Predictive Check\nExemplo rstanarm\nExemplo brms\n\nAtividade Prática\nAmbiente\n\n\nA Estatística Bayesiana é caracterizada pelo uso de informação prévia embutida como probabilidade prévia \\(P(\\theta)\\), chamada de a priori1:\n\\[\n\\underbrace{P(\\theta \\mid y)}_{\\textit{Posteriori}} = \\frac{\\overbrace{P(y \\mid  \\theta)}^{\\text{Verossimilhança}} \\cdot \\overbrace{P(\\theta)}^{\\textit{Priori}}}{\\underbrace{P(y)}_{\\text{Constante Normalizadora}}},\n\\]\nSubjetividade da Priori\nMuitas críticas à estatística Bayesiana, se dá pela subjetividade da elucidação da probabilidade a priori de certas hipóteses ou parâmetros de modelos. A subjetividade é algo indesejado na idealização do cientista e do método científico. Ambos devem ser imparciais e guiados pelas evidências. Isto faz com que a objetividade seja o “Santo Graal” da ciência e do cientista. Vou falar uma coisa que talvez não tenha sido assimilada pelo leitor: tudo que envolve ação humana nunca será 100% objetivo. Temos subjetividade em tudo, e ciência não é um exceção2.\nO próprio processo dedutivo e criativo de formulação de teoria e hipóteses não é algo objetivo. Há muita subjetividade incorporada em novas proposições teóricas. A estatística frequentista, que bane o uso de probabilidades a priori3 também é subjetiva, pois há MUITA subjetividade em especificar um modelo e uma função de verossimilhança (Jaynes, 2003; van de Schoot et al., 2021). Ao fazermos isso, estamos inserindo pressupostos bem fortes e opinados sobre o processo de geração dos dados que estamos analisando. Isto quer dizer que, mesmo usando estatística frequentista, ainda sim estamos sendo bem subjetivos ao escolhermos como analisar os dados, pois muitas técnicas frequentistas possuem fortes pressupostos sobre os dados. Ainda mais, quando acoplamos esses pressupostos da estatística frequentista com a inexistência da elucidação desses pressupostos4 faz com que a idealização da objetividade da ciência e da estatística caiam por água baixo. Isto é um problema sério pois não é só a falha da objetividade, mas sim uma falha silenciosa e sorrateira. O véu de objetividade científica se desfaz e continuamos a acreditar que ele ainda está lá.\nA estatística Bayesiana abraça a subjetividade enquanto a estatística frequentista a proíbe. Para a estatística Bayesiana, subjetividade guiam nossas inferências e nos levam a modelos mais robustos, confiáveis e que podem auxiliar à tomada de decisão. Já para a estatística frequentista, subjetividade é um tabu e todas inferências devem ser objetivas, mesmo que isso resulte em esconder pressupostos dos modelos embaixo dos panos. Consequentemente modelos oriundos da estatística frequentista, extremamente enviesados por pressupostos ocultos, não são robustos, podendo ser ilusórios e muitas vezes podem distorcer a realidade prejudicando o processo de tomada de decisão. Para concluir, estatística Bayesiana possui também pressupostos e subjetividade, mas estes são enunciados e formalizados. Ou seja, reconhecemos que a ação humana, mesmo em cenários científicos, é subjetiva e toda a subjetividade e os pressupostos do modelo são expostos de maneira transparente e auditável. Para mim isto faz toda diferença, uma vez que podemos desacoplar fatos de opinião e discutí-los separadamente ou de maneira conjunta.\nPortanto, caro leitor, abrace a incerteza e subjetividade, mas nunca esconda-a e sempre deixe-as à vista de maneira transparente e auditável.\nTipos de Prioris\nDe maneira geral, podemos ter 3 tipos de priori em uma abordagem Bayesiana (Gelman et al., 2013; McElreath, 2020; van de Schoot et al., 2021):\nuniforme (flat): não recomendada\nfracamente informativa (weakly informative): pequena restrição com um pouco de senso comum e baixo conhecimento de domínio incorporado\ninformativa (informative): conhecimento de domínio incorporado\nPara se aprofundar mais recomendo a vinheta do rstanarm sobre prioris.\nPrioris para os Modelos rstanarm\nO rstanarm possui as seguintes prioris incorporadas como padrão nos seus modelos. Recomendo fortemente que você use uma priori específica e não se atenha às prioris padrões do rstanarm. Apesar de refletirem as boas práticas e a fronteira do conhecimento científico sobre elucidação de prioris, elas podem mudar conforme são lançadas novas versões do rstanarm ou são incorporados novas diretrizes de elucidação de prioris. Isto pode prejudicar a robustez do seu modelo (e em especial do seu código), pois caso executado com versões diferentes do rstanarm, a opção de prioris padrão pode levar à diferentes elucidações de prioris.\nArgumento\nUsado em\nAplica-se à\nprior_intercept\nTodas funções de modelagem exceto stan_polr and stan_nlmer\nConstante (intercept) do modelo, após centralização dos preditores\nprior\nTodas funções de modelagem\nCoeficientes de Regressão, não inclui coeficientes que variam por grupo em modelos multiníveis (veja prior_covariance)\nprior_aux\nstan_glm, stan_glmer, stan_gamm4, stan_nlmer\nParâmetro auxiliar (ex: desvio padrão (standard error – DP), interpretação depende do modelo\nprior_covariance\nstan_glmer, stan_gamm4, stan_nlmer\nMatrizes de covariância em modelos multiníveis\nUniforme (flat)\nEspecifica-se colocando o valor NULL (nulo em R) nos argumentos prior_* dos modelos rstanarm. Exemplo:\nprior_intercept = NULL – constante possuirá priori uniforme sobre todos os números reais \\([-\\infty, +\\infty]\\)\nprior = NULL – parâmetros possuirão prioris uniformes sobre todo os números reais \\([-\\infty, +\\infty]\\)\nprior_aux = NULL – parâmetros auxiliares (geralmente o erro do modelo) possuirão prioris uniforme sobre todos os números reais \\([-\\infty, +\\infty]\\). No caso de erro do modelo, isto se restringe aos numeros reais positivos: \\((0, +\\infty]\\)\nColocando na função de modelo ficaria:\n\n\nfit <- stan_glm(y ~ ...,\n  prior = NULL,\n  prior_intercept = NULL,\n  prior_aux = NULL)\n\n\n\nInformativas\nColoca-se qualquer distribuição nos argumentos. Exemplo:\nprior = normal(0, 5) – \\(\\text{Normal}(0, 5)\\)\nprior_intercept = student_t(4, 0, 10) – \\(\\text{Student}(\\nu = 4, 0, 10)\\)\nprior_aux = cauchy(0, 3) – \\(\\text{Cauchy}^+(0, 3)\\)5\nColocando na função de modelo ficaria:\n\n\nfit <- stan_glm(y ~ ...,\n  prior = normal(0, 5),\n  prior_intercept = student_t(4, 0, 10),\n  prior_aux = cauchy(0, 3))\n\n\n\nPadrões do rstanarm\nAcontece se você não especifica nada nos argumentos prior* do rstanarm, os comportamentos diferem conforme o modelo. Aqui divido em modelos gaussianos (família de função verossimilhança Gaussiana ou normal) e outros (famílias de funções de verossimilhança binomial, poisson, etc…)\nModelos Gaussianos\nConstante (Intercept): Normal centralizada com média \\(\\mu_y\\) e desvio padrão de \\(2.5 \\sigma_y\\) - prior_intercept = normal(mean_y, 2.5 * sd_y)\nCoeficientes: Normal para cada coeficiente média \\(\\mu = 0\\) e desvio padrão de \\(2.5\\times\\frac{\\sigma_y}{\\sigma_{x_k}}\\) - prior = normal(0, 2.5 * sd_y/sd_xk)\nEm notação matemática:\n\\[\n\\begin{aligned}\n\\alpha &\\sim \\text{Normal}(\\mu_y, 2.5 \\cdot \\sigma_y)\\\\\n\\beta_k &\\sim \\text{Normal}\\left( 0, 2.5 \\cdot \\frac{\\sigma_y}{\\sigma_{x_k}} \\right) \\\\\n\\sigma &\\sim \\text{Exponential}\\left( \\frac{1}{\\sigma_y} \\right)\n\\end{aligned}\n\\]\nOutros Modelos (Binomial, Poisson etc.)\nConstante (Intercept): Normal centralizada com média \\(\\mu = 0\\) e desvio padrão de \\(2.5 \\sigma_y\\) - prior_intercept = normal(0, 2.5 * sd_y)\nCoeficientes: Normal para cada coeficiente média \\(\\mu = 0\\) e desvio padrão de \\(2.5\\times\\frac{1}{\\sigma_{x_k}}\\) - prior = normal(0, 2.5 * 1/sd_xk)\n\nOBS: em todos os modelos prior_aux, o desvio padrão do erro do modelo, a priori padrão é uma distribuição exponencial com taxa \\(\\frac{1}{\\sigma_y}\\): prior_aux = exponential(1/sd_y).\n\nEm notação matemática:\n\\[\n\\begin{aligned}\n\\alpha &\\sim \\text{Normal}(0, 2.5 \\cdot \\sigma_y)\\\\\n\\beta_k &\\sim \\text{Normal}\\left( 0, 2.5 \\cdot \\frac{1}{\\sigma_{x_k}} \\right) \\\\\n\\sigma &\\sim \\text{Exponential}\\left( \\frac{1}{\\sigma_y} \\right)\n\\end{aligned}\n\\]\nPadrões do brms\nComo o brms dá muito mais autonomia, poder e flexibilidade ao usuário, todas as prioris padrões dos coeficientes dos modelos são literalmente prioris uniformes sobre todo os números reais \\([-\\infty, +\\infty]\\). brms apenas ajusta de maneira robusta a priori para:\nConstante (Intercept): \\(t\\) de Student média \\(\\mu = \\text{mediana}(y)\\) e desvio padrão de \\(\\text{MAD}(y)\\)\nErro (sigma): \\(t\\) de Student média \\(\\mu = 0\\) e desvio padrão de \\(\\text{MAD}(y)\\)\n\nOBS: \\(\\text{MAD}\\) quer dizer Mean Absolute Deviation – Desvio Absoluto Médio.\n\nEm notação matemática:\n\\[\n\\begin{aligned}\n\\alpha &\\sim \\text{Student}(\\nu = 3, \\text{mediana}(y), \\text{MAD}(y) )\\\\\n\\beta_k &\\sim \\text{Unif}(- \\infty, + \\infty) \\\\\n\\sigma &\\sim \\text{Student}(\\nu = 3, 0, \\text{MAD}(y) )\n\\end{aligned}\n\\]\nPor isso recomendo fortemente você especificar suas próprias prioris em todos os modelos brms. Para especificar uma priori no brms, use o argumento prior com o valor prior(). Exemplo de uma priori especificada como \\(\\text{Normal}(0, 10)\\) para todos os coeficientes \\(\\beta\\) do modelo (b):\n\n\nbrms_fit <- brm(y ~ ..., prior = prior(normal(0, 10), class = b))\n\n\n\nExemplo usando o mtcars com rstanarm\nVamos estimar modelos Bayesianos usando o dataset já conhecido mtcars da Aula 1 - Comandos Básicos de R. A idéia é usarmos como variável dependente a autonomia do carro (milhas por galão – mpg) e como independentes o peso do carro (wt) e se o carro é automático ou manual (am). A fórmula então fica:\nmpg ~ wt + am\nPara constar, calcularemos alguns valores antes de ver o sumário das prioris:\n\\(\\mu_y\\): média do mpg - 20.09\n\\(2.5 \\sigma_y\\): 2.5 * sd(mtcars$mpg) - 15.07\n\\(2.5 \\times \\frac{\\sigma_y}{\\sigma_{x_{\\text{wt}}}}\\): 2.5 * (sd(mtcars$mpg) / sd(mtcars$wt)) - 15.4\n\\(2.5\\ times \\frac{\\sigma_y}{\\sigma_{x_{\\text{am}}}}\\): 2.5 * (sd(mtcars$mpg) / sd(mtcars$am)) - 30.2\n\\(\\frac{1}{\\sigma_y}\\): 1 / sd(mtcars$mpg) - 0.17\nA função prior_summary() do rstanarm resulta um sumário conciso das prioris utilizadas em um modelo. Coloque como argumento o modelo estimado:\n\n\nlibrary(rstanarm)\nrstanarm_default_prior <- stan_glm(mpg ~ wt + am, data = mtcars, chains = 1)\n\n\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 6.4e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.64 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.043319 seconds (Warm-up)\nChain 1:                0.043732 seconds (Sampling)\nChain 1:                0.087051 seconds (Total)\nChain 1: \n\nprior_summary(rstanarm_default_prior)\n\n\nPriors for model 'rstanarm_default_prior' \n------\nIntercept (after predictors centered)\n  Specified prior:\n    ~ normal(location = 20, scale = 2.5)\n  Adjusted prior:\n    ~ normal(location = 20, scale = 15)\n\nCoefficients\n  Specified prior:\n    ~ normal(location = [0,0], scale = [2.5,2.5])\n  Adjusted prior:\n    ~ normal(location = [0,0], scale = [15.40,30.20])\n\nAuxiliary (sigma)\n  Specified prior:\n    ~ exponential(rate = 1)\n  Adjusted prior:\n    ~ exponential(rate = 0.17)\n------\nSee help('prior_summary.stanreg') for more details\n\nAgora com prioris especificadas:\nComo há dois coeficientes eu especifico médias iguais (\\(0\\)), porém desvios padrões diferentes (\\(5\\) para wt e \\(6\\) para am) usando a função de combinar do R (combine) - c():\n\n\nrstanarm_custom_prior <- stan_glm(mpg ~ wt + am, data = mtcars, chains = 1,\n         prior = normal(c(0, 0), c(5, 6)),\n         prior_intercept = student_t(4, 0, 10),\n         prior_aux = cauchy(0, 3))\n\n\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 1.9e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.038111 seconds (Warm-up)\nChain 1:                0.03882 seconds (Sampling)\nChain 1:                0.076931 seconds (Total)\nChain 1: \n\nprior_summary(rstanarm_custom_prior)\n\n\nPriors for model 'rstanarm_custom_prior' \n------\nIntercept (after predictors centered)\n ~ student_t(df = 4, location = 0, scale = 10)\n\nCoefficients\n ~ normal(location = [0,0], scale = [5,6])\n\nAuxiliary (sigma)\n ~ half-cauchy(location = 0, scale = 3)\n------\nSee help('prior_summary.stanreg') for more details\n\nExemplo usando o mtcars com brms\nVamos usar o mesmo modelo que usamos para o rstanarm acima. Note que a fórmula não muda e usaremos a mesma:\nmpg ~ wt + am\nA função prior_summary() do brms resulta um sumário conciso das prioris utilizadas em um modelo. Coloque como argumento o modelo estimado:\n\n\nlibrary(brms)\nbrms_default_prior <- brm(mpg ~ wt + am, data = mtcars, chains = 1)\n\n\n\nSAMPLING FOR MODEL '5c829c9ee139a11d74ba6f4816e16620' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 1.9e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.020331 seconds (Warm-up)\nChain 1:                0.015705 seconds (Sampling)\nChain 1:                0.036036 seconds (Total)\nChain 1: \n\nprior_summary(brms_default_prior)\n\n\n                   prior     class coef group resp dpar nlpar bound\n                  (flat)         b                                 \n                  (flat)         b   am                            \n                  (flat)         b   wt                            \n student_t(3, 19.2, 5.4) Intercept                                 \n    student_t(3, 0, 5.4)     sigma                                 \n       source\n      default\n (vectorized)\n (vectorized)\n      default\n      default\n\nAgora com prioris especificadas:\nAqui nos agrupamos todas as prioris com o argumento prior e usando a função de combinar do R (combine) - c():\n\n\nbrms_custom_prior <- brm(mpg ~ wt + am, data = mtcars, chains = 1,\n         prior = c(\n           prior(normal(0, 5), class = b, coef = wt),\n           prior(normal(0, 6), class = b, coef = am),\n           prior(student_t(4, 0, 10), class = Intercept),\n           prior(cauchy(0, 3), class = sigma)\n         ))\n\n\n\nSAMPLING FOR MODEL 'f73c349d97a4380ebf93fa375a214f2e' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 1.8e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.020314 seconds (Warm-up)\nChain 1:                0.014533 seconds (Sampling)\nChain 1:                0.034847 seconds (Total)\nChain 1: \n\nprior_summary(brms_custom_prior)\n\n\n               prior     class coef group resp dpar nlpar bound\n              (flat)         b                                 \n        normal(0, 6)         b   am                            \n        normal(0, 5)         b   wt                            \n student_t(4, 0, 10) Intercept                                 \n        cauchy(0, 3)     sigma                                 \n  source\n default\n    user\n    user\n    user\n    user\n\nPor quê não é interessante usar prioris uniformes (flat priors)\nUma priori totalmente uniforme ou chapada (flat) é algo que devemos evitar (Gelman et al., 2013; van de Schoot et al., 2021) pelo simples motivo que ela parte da premissa de que “tudo é possível.” Não há limites na crença de que tamanho o valor deve ser ou quaisquer restrições.\nPrioris chapadas e super-vagas geralmente não são recomendadas e algum esforço deve ser incluído para ter, pelo menos, prioris um pouco informativas. Por exemplo, é comum esperar que os tamanhos de efeito realistas sejam da ordem de magnitude \\(0.1\\) em uma escala padronizada (por exemplo, uma inovação educacional que pode melhorar as pontuações dos testes em \\(0.1\\) desvios padrão). Nesse caso, uma priori de \\(\\text{Normal} (0,1)\\) poderia ser considerado muito informativo, de uma maneira ruim, pois coloca a maior parte de sua massa em valores de parâmetro que são irrealisticamente grandes em valor absoluto. O ponto geral aqui é que se considerarmos uma priori como “fraca” ou “forte,” isso é uma propriedade não apenas da priori, mas também da pergunta que está sendo feita.\nQuando dizemos que a priori é “pouco informativa,” o que queremos dizer é que, se houver uma quantidade razoavelmente grande de dados, a likelihood dominará e a priori não será importante. Se os dados forem fracos, porém, esta “priori fracamente informativo” influenciará fortemente a inferência posterior.\nUm outro exemplo interessante vem de uma aula do Ben Goodrich6 professor de Columbia e membro do grupo de pesquisa de Stan. Aqui ele fala sobre um dos maiores efeitos observados nas ciências sociais. Nas pesquisas de intenção de voto à eleição presidencial dos EUA de 2008 (Obama vs McCain), se você trocasse a raça de um respondente de race_black = 0 para race_black = 1 isso gerava um aumento de aproximadamente 60% (0.6) na probabilidade do respondente votar no Obama. Em escala logit esses 60% se traduziriam em um modelo binomial como um coeficiente \\(\\beta_{\\text{Race Black}} = 4.5\\). Esse tamanho de efeito (um dos maiores observados na história das ciências sociais) seria facilmente inferido com a prior padrão do rstanarm para modelos binomiais: \\(\\beta_{\\text{Race Black}} \\sim \\text{Normal}\\left( 0, 2.5 \\cdot \\frac{1}{\\sigma_{\\text{Race Black}}} \\right)\\).\n\n\nPor fim, não se esqueça que muitas distribuições, como por exemplo a distribuição normal, possuem suporte \\(\\mathbb{R}\\), ou seja pode acontecer qualquer número entre \\(-\\infty\\) até \\(\\infty\\) independente da média \\(\\mu\\) ou desvio padrão \\(\\sigma\\). É claro que moralmente a probabilidade \\(P(X = 100)\\) para \\(X \\sim \\text{Normal}(0, 0.01)\\) é zero, mesmo que matematicamente seja uma quantidade muito pequena \\(\\epsilon\\).\nBayesian Workflow\nO fluxo de trabalho que fazemos quando especificamos e executamos amostragem de modelos Bayesianos não é linear ou acíclico (Gelman et al., 2020). Isto quer dizer que precisamos iterar (ir e voltar) diversas vezes entre as diferentes etapas. A figura 1 demonstra o fluxo de trabalho7:\n\n\n\n{\"x\":{\"diagram\":\"\\ndigraph bayesian_workflow {\\n  forcelabels = true;\\n  graph [overlap = false,\\n         fontsize = 10,\\n         rankdir = LR]\\n  node [shape = oval,\\n        fontname = Helvetica]\\n  A [label = \\\"Especificação\\ndoModelo\\\"]\\n  B [label = \\\"Elicitação\\ndas Prioris\\\"]\\n  C [label = \\\"Inferência\\nda Posterior\\\"]\\n  A -> B\\n  B -> A [label = \\\"Prior\\nPredictive\\nCheck\\\"]\\n  B -> C\\n  C -> B [label = \\\"Posterior\\nPredictive\\nCheck\\\"]\\n}\\n\",\"config\":{\"engine\":\"dot\",\"options\":null}},\"evals\":[],\"jsHooks\":[]}\nFigure 1: Bayesian Workflow. Baseado em Gelman et al. (2020)\n\n\n\nPrior Predictive Check\nEm especial, antes de começar a alimentar o modelo com dados precisamos fazer uma checagem de todas as nossas prioris. Isso é chamado de Prior Predictive Check. De maneira muito simples, consiste em simular parâmetros com base nas suas distribuições especificadas a priori no modelo sem qualquer condicionamento aos dados e sem envolvimento nenhum da função de verossimilhança. Independentemente do nível de informação especificada na priori, é sempre importante realizar uma análise de sensibilidade prévia para entender completamente a influência que as prioris têm na posterior.\nIsso pode ser feito tanto no rstanarm quando no brms:\nrstanarm: em qualquer função stan_*() usar o argumento prior_PD = TRUE\nbrms: na função brm() usar o argumento sample_prior = \"only\"\nExemplo rstanarm\nContinuando no nosso exemplo mtcars da Aula 1 - Comandos Básicos de R:\n\n\nrstanarm_custom_prior <- stan_glm(mpg ~ wt + am, data = mtcars, chains = 1,\n         prior = normal(c(0, 0), c(5, 6)),\n         prior_intercept = student_t(4, 0, 10),\n         prior_aux = cauchy(0, 3),\n         prior_PD = TRUE)\n\n\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 1.3e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.13 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.023807 seconds (Warm-up)\nChain 1:                0.02106 seconds (Sampling)\nChain 1:                0.044867 seconds (Total)\nChain 1: \n\nsummary(rstanarm_custom_prior)\n\n\n\nModel Info:\n function:     stan_glm\n family:       gaussian [identity]\n formula:      mpg ~ wt + am\n algorithm:    sampling\n sample:       1000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 32\n predictors:   3\n\nEstimates:\n              mean   sd    10%   50%   90%\n(Intercept)   0.9   21.2 -24.7   0.3  27.2\nwt           -0.1    4.9  -6.2   0.2   6.2\nam            0.0    6.1  -7.6  -0.1   7.7\nsigma        15.4   82.2   0.5   3.1  20.5\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.7  1.0   830 \nwt            0.2  1.0   839 \nam            0.2  1.0  1013 \nsigma         2.9  1.0   799 \nlog-posterior 0.1  1.0   367 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nO foco é verificar se os valores dos parâmetros de interesse amostrados apenas das prioris fazem sentido. Por exemplo uma constante (intercept) com 90% de densidade entre -24.5 e 26.0 não faz sentido. Talvez seja melhor especificarmos uma priori um pouco mais informada.\nExemplo brms\nContinuando no nosso exemplo mtcars da Aula 1 - Comandos Básicos de R:\n\n\nbrms_custom_prior <- brm(mpg ~ wt + am, data = mtcars, chains = 1,\n         prior = c(\n           prior(normal(0, 5), class = b, coef = wt),\n           prior(normal(0, 6), class = b, coef = am),\n           prior(student_t(4, 0, 10), class = Intercept),\n           prior(cauchy(0, 3), class = sigma)\n         ),\n         sample_prior = \"only\")\n\n\n\nSAMPLING FOR MODEL 'f73c349d97a4380ebf93fa375a214f2e' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 1.4e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.14 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.013963 seconds (Warm-up)\nChain 1:                0.010303 seconds (Sampling)\nChain 1:                0.024266 seconds (Total)\nChain 1: \n\nsummary(brms_custom_prior)\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: mpg ~ wt + am \n   Data: mtcars (Number of observations: 32) \nSamples: 1 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 1000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     1.51     20.52   -38.60    42.09 1.00      717      656\nwt           -0.36      4.91    -9.78     9.06 1.00      735      633\nam            0.10      6.08   -11.30    11.68 1.00      961      685\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma    13.87     91.04     0.07    72.66 1.00     1052      490\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nO interessante do brms é que conseguimos naturalmente visualizar hipóteses sobre os valores do parâmetros de modelos estimados pela função brm(). Veja um exemplo na figura 2 com o método plot() da função hypothesis():\n\n\nplot(hypothesis(brms_custom_prior, \"Intercept = 0\"))\n\n\n\n\nFigure 2: Função hypothesis() do brms\n\n\n\nAtividade Prática\nRegressão linear especificando prioris fracamente informativas. Usar o dataset do pacote carData chamado Salaries\n\n\nlibrary(carData)\ndata(\"Salaries\")\n?Salaries\n\n\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.4 (2021-02-15)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n [1] carData_3.0-4      DiagrammeR_1.0.6.1 brms_2.15.0       \n [4] rstanarm_2.21.1    Rcpp_1.0.6         skimr_2.1.3       \n [7] readr_1.4.0        readxl_1.3.1       tibble_3.1.0      \n[10] ggplot2_3.3.3      patchwork_1.1.1    cowplot_1.1.1     \n\nloaded via a namespace (and not attached):\n  [1] backports_1.2.1      systemfonts_1.0.1    plyr_1.8.6          \n  [4] igraph_1.2.6         repr_1.1.3           splines_4.0.4       \n  [7] crosstalk_1.1.1      TH.data_1.0-10       rstantools_2.1.1    \n [10] inline_0.3.17        digest_0.6.27        htmltools_0.5.1.1   \n [13] magick_2.7.1         rsconnect_0.8.16     fansi_0.4.2         \n [16] magrittr_2.0.1       RcppParallel_5.0.3   matrixStats_0.58.0  \n [19] sandwich_3.0-0       xts_0.12.1           prettyunits_1.1.1   \n [22] jpeg_0.1-8.1         colorspace_2.0-0     textshaping_0.3.3   \n [25] xfun_0.22            dplyr_1.0.5          callr_3.6.0         \n [28] crayon_1.4.1         jsonlite_1.7.2       lme4_1.1-26         \n [31] survival_3.2-10      zoo_1.8-9            glue_1.4.2          \n [34] gtable_0.3.0         emmeans_1.5.5-1      V8_3.4.0            \n [37] pkgbuild_1.2.0       rstan_2.21.2         abind_1.4-5         \n [40] scales_1.1.1         mvtnorm_1.1-1        DBI_1.1.1           \n [43] miniUI_0.1.1.1       xtable_1.8-4         stats4_4.0.4        \n [46] StanHeaders_2.21.0-7 DT_0.17              htmlwidgets_1.5.3   \n [49] threejs_0.3.3        RColorBrewer_1.1-2   ellipsis_0.3.1      \n [52] pkgconfig_2.0.3      loo_2.4.1            farver_2.1.0        \n [55] sass_0.3.1           utf8_1.2.1           tidyselect_1.1.0    \n [58] labeling_0.4.2       rlang_0.4.10         reshape2_1.4.4      \n [61] later_1.1.0.1        visNetwork_2.0.9     munsell_0.5.0       \n [64] cellranger_1.1.0     tools_4.0.4          cli_2.3.1           \n [67] generics_0.1.0       ggridges_0.5.3       evaluate_0.14       \n [70] stringr_1.4.0        fastmap_1.1.0        yaml_2.2.1          \n [73] ragg_1.1.2           processx_3.5.0       knitr_1.31          \n [76] purrr_0.3.4          nlme_3.1-152         projpred_2.0.2      \n [79] mime_0.10            xml2_1.3.2           compiler_4.0.4      \n [82] bayesplot_1.8.0      shinythemes_1.2.0    rstudioapi_0.13     \n [85] gamm4_0.2-6          curl_4.3             png_0.1-7           \n [88] statmod_1.4.35       bslib_0.2.4          stringi_1.5.3       \n [91] highr_0.8            ps_1.6.0             Brobdingnag_1.2-6   \n [94] lattice_0.20-41      Matrix_1.3-2         nloptr_1.2.2.2      \n [97] markdown_1.1         shinyjs_2.0.0        vctrs_0.3.6         \n[100] pillar_1.5.1         lifecycle_1.0.0      jquerylib_0.1.3     \n[103] bridgesampling_1.0-0 estimability_1.3     httpuv_1.5.5        \n[106] R6_2.5.0             bookdown_0.21        promises_1.2.0.1    \n[109] gridExtra_2.3        codetools_0.2-18     distill_1.2         \n[112] boot_1.3-27          colourpicker_1.1.0   MASS_7.3-53.1       \n[115] gtools_3.8.2         assertthat_0.2.1     rprojroot_2.0.2     \n[118] withr_2.4.1          shinystan_2.5.0      multcomp_1.4-16     \n[121] mgcv_1.8-34          parallel_4.0.4       hms_1.0.0           \n[124] grid_4.0.4           tidyr_1.1.3          coda_0.19-4         \n[127] minqa_1.2.4          rmarkdown_2.7        downlit_0.2.1       \n[130] shiny_1.6.0          lubridate_1.7.10     base64enc_0.1-3     \n[133] dygraphs_1.1.1.6    \n\n\n\n\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian Data Analysis. Chapman and Hall/CRC.\n\n\nGelman, A., Vehtari, A., Simpson, D., Margossian, C. C., Carpenter, B., Yao, Y., … Modr’ak, M. (2020, November 3). Bayesian Workflow. Retrieved February 4, 2021, from http://arxiv.org/abs/2011.01808\n\n\nJaynes, E. T. (2003). Probability theory: The logic of science. Cambridge university press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan. CRC press.\n\n\nvan de Schoot, R., Depaoli, S., King, R., Kramer, B., Märtens, K., Tadesse, M. G., … Yau, C. (2021). Bayesian statistics and modelling. Nature Reviews Methods Primers, 1(1, 1), 1–26. https://doi.org/10.1038/s43586-020-00001-2\n\n\ntambém há o termo em inglês: prior.↩︎\ncaso discorde, dê uma estudada no rico campo da economia comportamental que provém uma montanha de evidências que os seres humanos são extremamente suscetíveis à vieses e, de maneira geral, não são bons tomadores de decisão.↩︎\nlembrando que sob a tutela da estatística frequentista, estamos proibidos de conjecturar probabilidade de parâmetros, pois eles são fixos e dependem apenas dos dados que temos. O que é conjecturado probabilisticamente são os dados em sí: a inferência é sempre elaborada a partir de um processo de frequência na qual há o pressuposto de “amostragem de \\(N\\) amostras de uma mesma população” no limite de \\(N \\to \\infty\\).↩︎\nveja que muitas disciplinas de estatística nem mencionam pressupostos das diferentes técnicas frequentistas.↩︎\nA distribuição Cauchy é o caso especial de uma distribuição \\(t\\) de Student com 1 grau de liberdade \\(( \\eta = 1)\\). Note que como ela é especificada como uma priori de um parâmetro auxiliar (no caso o erro do modelo), ela somente tomará valores positivos por isso o \\(\\text{Cauchy}^+\\).↩︎\ncaso queira ver o vídeo na íntegra, a parte que nos interessa de prioris começa a partir do minuto 40↩︎\nnote que o fluxo está extremamente simplificado do fluxo original no qual foi baseado. Sugiro o leitor consultar o fluxo original de Gelman et al. (2020).↩︎\n",
      "last_modified": "2021-03-29T16:47:20-03:00"
    },
    {
      "path": "5-MCMC.html",
      "title": "Markov Chain Monte Carlo -- MCMC",
      "description": "O motor por trás da Estatística Bayesiana",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 1, 2021",
      "contents": "\n\nContents\nPara quê serve o denominador \\(P(\\text{data})\\)?\nSe removermos o denominador de Bayes o que temos?\nSimulação Montecarlo com correntes Markov – (MCMC)\nMétodo Monte Carlo\nSimulações – Setup\nMetropolis e Metropolis-Hastings\nGibbs\nO que acontece quando rodamos correntes Markov em paralelo?\n\nHamiltonian Monte Carlo – HMC\nDistribuição dos Momentos – \\(P(\\phi)\\)\nAlgoritmo de HMC\nHMC – Implementação\nHMC – Geometrias Complexas\n\n“Não entendi nada…”\nImplementação com o rstanarm\nMétricas da simulação MCMC\nO que fazer se não obtermos convergência?\n\nGráficos de Diagnósticos do MCMC\nTraceplot\nPosterior Predictive Check\n\nO quê fazer para convergir suas correntes Markov\nAmbiente\n\n\nA principal barreira computacional para estatística Bayesiana é o denominador \\(P(\\text{data})\\) da fórmula de Bayes:\n\\[P(\\theta | \\text{data})=\\frac{P(\\theta) \\cdot P(\\text{data} | \\theta)}{P(\\text{data})}\\]\nEm casos discretos podemos fazer o denominador virar a soma de todos os parâmetros usando a regra da cadeia de probabilidade:\n\\[P(A,B|C)=P(A|B,C) \\times P(B|C)\\]\nIsto também é chamado de marginalização:\n\\[P(\\text{data})=\\sum_{\\theta} P(\\text{data} | \\theta) \\times P(\\theta)\\]\nPorém no caso de valores contínuos o denominador \\(P(\\text{data})\\) vira uma integral bem grande e complicada de calcular:\n\\[P(\\text{data})=\\int_{\\theta} P(\\text{data} | \\theta) \\times P(\\theta)d \\theta\\]\nEm muitos casos essa integral vira intratável (incalculável) e portanto devemos achar outras maneiras de calcular a probabilidade posterior \\(P(\\theta | \\text{data})\\) de Bayes sem usar o denominador \\(P(\\text{data})\\).\nPara quê serve o denominador \\(P(\\text{data})\\)?\nPara normalizar a posterior com o intuito de torná-la uma distribuição probabilística válida. Isto quer dizer que a soma de todas as probabilidades dos eventos possíveis da distribuição probabilística devem ser iguais a 1:\nno caso de distribuição probabilística discreta: \\(\\sum_{\\theta} P(\\theta | \\text{data}) = 1\\)\nno caso de distribuição probabilística contínua: \\(\\int_{\\theta} P(\\theta | \\text{data})d \\theta = 1\\)\nSe removermos o denominador de Bayes o que temos?\nAo removermos o denominador \\((\\text{data})\\) temos que a posterior \\(P(\\theta | \\text{data})\\) é proporcional à prior multiplicada pela verossimilhança \\(P(\\theta) \\cdot P(\\text{data} | \\theta)\\)1.\n\\[P(\\theta | \\text{data}) \\propto P(\\theta) \\cdot P(\\text{data} | \\theta)\\]\nEste vídeo do YouTube explica muito bem o problema do denominador.\n\n\nPlease use a browser that supports iframe embedding. If you are seeing this message Google “browser iframe embedding not rendering.”\n\n\nSimulação Montecarlo com correntes Markov – (MCMC)\nAí que entra simulação Montecarlo com correntes Markov (do inglês Markov Chain Monte Carlo – MCMC). MCMC é uma classe ampla de ferramentas computacionais para aproximação de integrais e geração de amostras de uma probabilidade posterior (S. Brooks, Gelman, Jones, & Meng, 2011). MCMC é usada quando não é possível coletar amostras de \\(\\theta\\) direto da distribuição probabilística posterior \\(P(\\theta | \\text{data})\\). Ao invés disso, nos coletamos amostras de maneira iterativa que a cada passo do processo nós esperamos que a distribuição da qual amostramos \\(P^*(\\theta^* | \\text{data})\\) (aqui \\(*\\) quer dizer simulado) se torna cada vez mais similar à posterior \\(P(\\theta | \\text{data})\\). Tudo isso é para eliminar o cálculo (muitas vezes impossível) do denominador \\(P(\\text{data})\\).\nA ideia é definir uma corrente Markov ergódica (quer dizer que há uma distribuição estacionária única) dos quais o conjunto de estados possíveis é o espaço amostral e a distribuição estacionária é a distribuição a ser aproximada (ou amostrada). Seja \\(X_0, X_1, \\dots, X_n\\) uma simulação da corrente. A corrente Markov converge à distribuição estacionária de qualquer estado inicial \\(X_0\\) após um número suficiente grande de iterações \\(r\\), a distribuição do estado \\(X_r\\) estará similar à distribuição estacionária, então podemos usá-la com amostra. As correntes Markov possuem uma propriedade que a distribuição de probabilidade do próximo estado depende apenas do estado atual e não na sequência de eventos que precederam: \\(P(X_{n+1}=x|X_{0},X_{1},X_{2},\\ldots ,X_{n}) = P(X_{n+1}=x|X_{n})\\). Essa propriedade é chamada de Markoviana, em homenagem ao matemático Andrei Andreyevich Markov (figura 1). Similarmente, repetindo esse argumento com \\(X_r\\) como o ponto inicial, podemos usar \\(X_{2r}\\) como amostra, e assim por diante. Podemos então usar a sequência de estados \\(X_r, X_{2r}, X_{3r}, \\dots\\) como quase amostras independentes da distribuição estacionária da corrente Markov.\n\n\n\nFigure 1: Andrei Andreyevich Markov. Figura de https://www.wikipedia.org\n\n\n\nA eficácia dessa abordagem depende em:\no quão grande \\(r\\) deve ser para garantir uma amostra adequadamente boa; e\npoder computacional requerido para cada iteração da corrente Markov.\nAlém disso, é costumeiro descartarmos as primeiras iterações do algoritmo pois elas costumam não ser representativas da distribuição a ser aproximada. Nas iterações iniciais de algoritmos MCMC geralmente a corrente Markov está em um processo de aquecimento2 (warm-up) e seu estado está bem distante do ideal para começarmos uma amostragem fidedigna. Geralmente, recomenda-se que se descarte metade das iterações (Gelman et al., 2013a). Por exemplo: se a corrente Markov possui 4.000 iterações, descartamos as 2.000 primeiras como warm-up.\nMétodo Monte Carlo\nStanislaw Ulam (figura 2), que participou do projeto Manhattan e ao tentar calcular o processo de difusão de neutrons para a bomba de hidrogênio acabou criando uma classe de métodos chamada Monte Carlo.\n\n\n\nFigure 2: Stanislaw Ulam. Figura de https://www.wikipedia.org\n\n\n\nMétodos de Monte Carlo possuem como conceito subjacente o uso a aleatoriedade para resolver problemas que podem ser determinísticos em princípio. Eles são freqüentemente usados em problemas físicos e matemáticos e são mais úteis quando é difícil ou impossível usar outras abordagens. Os métodos de Monte Carlo são usados principalmente em três classes de problemas: otimização, integração numérica e geração de sorteios a partir de uma distribuição de probabilidade.\nA ideia do método veio enquanto jogava paciência durante sua recuperação de uma cirurgia, Ulam pensou em jogar centenas de jogos para estimar estatisticamente a probabilidade de um resultado bem-sucedido. Conforme ele mesmo menciona em Eckhardt (1987):\n\nOs primeiros pensamentos e tentativas que fiz para praticar [o Método de Monte Carlo] foram sugeridos por uma pergunta que me ocorreu em 1946 quando eu estava convalescendo de uma doença e jogando paciência. A questão era quais são as chances de que um jogo de paciência com 52 cartas obtivesse sucesso? Depois de passar muito tempo tentando estimá-los por meio de cálculos combinatórios puros, me perguntei se um método mais prático do que o “pensamento abstrato” não seria expô-lo, digamos, cem vezes e simplesmente observar e contar o número de jogadas bem-sucedidas. Isso já era possível imaginar com o início da nova era de computadores rápidos, e eu imediatamente pensei em problemas de difusão de nêutrons e outras questões de física matemática e, de forma mais geral, como mudar os processos descritos por certas equações diferenciais em uma forma equivalente interpretável como uma sucessão de operações aleatórias. Mais tarde [em 1946], descrevi a ideia para John von Neumann e começamos a planejar cálculos reais.\n\nPor ser secreto, o trabalho de von Neumann e Ulam exigia um codinome. Um colega de von Neumann e Ulam, Nicholas Metropolis (figura 5), sugeriu usar o nome Monte Carlo, que se refere ao Casino Monte Carlo em Mônaco, onde o tio de Ulam (Michał Ulam) pedia dinheiro emprestado a parentes para jogar.\nAs aplicações do método de Monte Carlo são inúmeras: ciências físicas, engenharia, mudança climática, biologia computacional, computação gráfica, estatística aplicada, inteligência artificial, design e recursos visuais, busca e resgate, finanças e negócios e direito. No escopo desta aula focaremos em estatística aplicada e especificamente no contexto de inferência Bayesiana: fornecer uma amostra aleatória da distribuição posterior.\nSimulações – Setup\nEstou usando diversos pacotes:\nggplot2, plotly e ggforce para gráficos.\ngganimate para animações (GIFs).\nMASS para simulações aleatórias de distribuições multivariadas.\nrstan para funções de sumário e métricas de convergência e desempenho de simulações MCMC.\n\n\nlibrary(ggplot2)\ntheme_set(theme_minimal())\nlibrary(plotly)\nlibrary(gganimate)\nlibrary(ggforce)\nlibrary(MASS)\nlibrary(rstan)\n\n\n\nVamos começar com um problema didático de uma distribuição normal multivariada de \\(X\\) e \\(Y\\), onde\n\\[\n\\begin{bmatrix}\nX \\\\\nY\n\\end{bmatrix} \\sim \\text{Normal Multivariada} \\left(\n\\begin{bmatrix}\n\\mu_X \\\\\n\\mu_Y\n\\end{bmatrix}, \\mathbf{\\Sigma}\n\\right) \\\\\n\\mathbf{\\Sigma} \\sim\n\\begin{pmatrix}\n\\sigma^2_{X} & \\sigma_{X}\\sigma_{Y} \\rho \\\\\n\\sigma_{X}\\sigma_{Y} \\rho & \\sigma^2_{Y}\n\\end{pmatrix}\n\\]\nSe designarmos \\(\\mu_X = \\mu_Y = 0\\) e \\(\\sigma_X = \\sigma_Y = 1\\) (média 0 e desvio padrão 1 para ambos \\(X\\) e \\(Y\\)), temos a seguinte formulação:\n\\[\n\\begin{bmatrix}\nX \\\\\nY\n\\end{bmatrix} \\sim \\text{Normal Multivariada} \\left(\n\\begin{bmatrix}\n0 \\\\\n0\n\\end{bmatrix}, \\mathbf{\\Sigma}\n\\right), \\\\\n\\mathbf{\\Sigma} \\sim\n\\begin{pmatrix}\n1 & \\rho \\\\\n\\rho & 1\n\\end{pmatrix}.\n\\]\nSó faltando designar um valor de \\(\\rho\\) para a correlação entre \\(X\\) e \\(Y\\). Para o nosso exemplo vamos usar correlação de 0.8 (\\(\\rho = 0.8\\)):\n\\[\n\\mathbf{\\Sigma} \\sim\n\\begin{pmatrix}\n1 & 0.8 \\\\\n0.8 & 1\n\\end{pmatrix}.\n\\]\n\n\nN <- 1e5\nmus  <- c(0, 0)\nsigmas <- c(1, 1)\nr <- 0.8\nSigma <- diag(sigmas)\nSigma[1, 2] <- r\nSigma[2, 1] <- r\ndft <- data.frame(mvrnorm(N, mus, Sigma))\n\n\n\nNa figura 3 é possível ver um gráfico de densidade de uma distribuição multivariada normal de duas variáveis normais \\(X\\) e \\(Y\\), ambas com média 0 e desvio padrão 1. Sendo que a correlação entre elas é 0.8. E na figura 4 é possível ver uma imagem 3-D interativa da mesma distribuição, fique a vontade em usar seu mouse (dedo ou caneta, dependendo do dispositivo) para movimentar a imagem.\n\n\nggplot(dft, aes(X1, X2)) +\n  geom_density2d_filled() +\n  coord_cartesian(xlim = c(-3, 3), ylim = c(-3, 3)) +\n  labs(title = \"Multivariada Normal\",\n       subtitle = expression(list(mu == 0, sigma == 1, rho == 0.8)),\n       caption = \"10.000 simulações\",\n       x = expression(X), y = expression(Y)) +\n  theme(legend.position = \"NULL\")\n\n\n\n\nFigure 3: Gráfico de Densidade de uma distribuição Multivariada Normal\n\n\n\n\n\ndens <- kde2d(dft$X1, dft$X2)\nplot_ly(x = dens$x,\n        y = dens$y,\n        z = dens$z) %>% add_surface()\n\n\n\n\n{\"x\":{\"visdat\":{\"8c1067314a34\":[\"function () \",\"plotlyVisDat\"]},\"cur_data\":\"8c1067314a34\",\"attrs\":{\"8c1067314a34\":{\"x\":[-4.11222323909044,-3.76275945114626,-3.41329566320208,-3.0638318752579,-2.71436808731372,-2.36490429936954,-2.01544051142536,-1.66597672348118,-1.316512935537,-0.967049147592815,-0.617585359648634,-0.268121571704453,0.0813422162397277,0.430806004183909,0.780269792128089,1.12973358007227,1.47919736801645,1.82866115596063,2.17812494390481,2.52758873184899,2.87705251979317,3.22651630773736,3.57598009568154,3.92544388362572,4.2749076715699],\"y\":[-4.32381413035071,-3.95784855910568,-3.59188298786066,-3.22591741661563,-2.85995184537061,-2.49398627412558,-2.12802070288055,-1.76205513163553,-1.3960895603905,-1.03012398914547,-0.664158417900448,-0.298192846655422,0.0677727245896049,0.433738295834631,0.799703867079657,1.16566943832468,1.53163500956971,1.89760058081474,2.26356615205976,2.62953172330479,2.99549729454982,3.36146286579484,3.72742843703987,4.09339400828489,4.45935957952992],\"z\":[[3.40651108352134e-09,1.41934533126133e-08,8.54786240302624e-08,0.000130831863209747,1.94776526567504e-06,1.49783603255103e-06,1.1170089576991e-08,6.01986954373106e-12,1.16817732135535e-10,1.50245544102462e-14,4.62944974810078e-23,4.83295093316628e-35,2.28048400569722e-45,8.78734985512727e-51,2.21962779786052e-61,3.67504668072926e-77,3.98846726370328e-98,2.83738455537123e-124,1.16702068177763e-153,1.56588648116791e-183,5.9460095882168e-217,3.04648237511363e-242,1.0476778777822e-272,2.36166828733039e-308,0],[4.39462560522794e-05,6.94943900679841e-05,1.04291502349634e-05,5.75970473307081e-05,0.000176906604268204,0.000370540209494104,1.55421446807263e-05,8.30475843056959e-07,1.53069632670964e-05,7.14342142452053e-09,1.13543480848847e-15,2.9038893623358e-25,2.64561847471716e-28,1.01950388004498e-33,2.57520093025581e-44,4.26377054766638e-60,4.6281649856682e-81,2.42118913413043e-104,5.00622985414094e-129,7.25515626339583e-159,3.68875889960785e-180,1.93530271945878e-205,6.65546074071442e-236,5.25171440440826e-271,5.21884573812369e-305],[9.55774448047614e-05,0.000177213516750328,0.000316039775630404,0.000475626271585416,0.000761122825446468,0.000814816903847166,0.000578652080468251,0.000157642005236617,0.000152603615623742,3.79131793396399e-06,7.51171055499296e-11,3.17899382836251e-15,5.96544729558909e-16,2.29881835031841e-21,5.80666661659396e-32,9.62751627134557e-48,6.45601148716749e-65,2.03894997743999e-84,4.22210611955478e-109,5.68993288800346e-128,4.55423370733433e-148,2.3893730364403e-173,9.74271181456202e-204,3.23808866743861e-233,4.50467722508192e-267],[1.98596665642571e-07,4.68000995544877e-05,0.000509090380019503,0.000931319298108951,0.0012891264719117,0.00255519224543074,0.00194691180666576,0.00139812985945186,0.000387322200480871,0.000138389622336007,1.12962183753118e-05,4.51541808458966e-08,2.61431851364547e-08,1.00740783248176e-13,2.57450769746435e-24,2.19535111827777e-35,1.05790746618256e-49,3.3419444921475e-69,1.11809791229766e-85,1.36529655130866e-100,1.09278610207721e-120,5.81233702380819e-146,2.55947654424468e-171,5.43203463930242e-200,7.55679638075802e-234],[2.0971717790889e-11,2.45146152673218e-05,0.00101641626246237,0.0012023963529308,0.00431348854715178,0.00596725675304324,0.00681722538407796,0.00633846543983796,0.00269032102983323,0.00186745629509051,0.000257016293377211,6.68099172102812e-05,2.23554936688109e-05,9.43773499495428e-11,9.51160167439667e-16,6.99272785694416e-25,3.37970089697892e-39,2.8443677530022e-53,5.21415549375954e-63,6.36695308508056e-78,5.10133947007011e-98,2.57749276005559e-119,8.34462177624758e-143,1.77101149161936e-171,2.46374961111803e-205],[2.18739954530607e-13,8.27469962250889e-07,0.00068247158549802,0.00129956984621859,0.00404868380339934,0.0102606158585002,0.0148087501034371,0.0152333593380476,0.0125919827053159,0.00699472312030991,0.00241781085109058,0.000326864762138592,1.64609783322298e-05,5.34463376690191e-06,5.93226571697135e-10,5.36558733277978e-19,1.90647639364607e-28,2.53683060667389e-35,4.72578158624974e-45,5.77104072981931e-60,3.31061440322712e-77,1.63303711875425e-95,5.28749916069209e-119,1.12218648450566e-147,1.56113414734455e-181],[2.95266849169562e-16,2.85416661335113e-08,8.90740945415943e-05,0.00122580118110615,0.0046414034091961,0.0107569609558745,0.0239117407486324,0.0345320261172182,0.034266290423328,0.025908337162062,0.0111683859733492,0.00396670124627087,0.00103938025934649,0.000215424763750705,2.74471340647353e-07,1.04918685044655e-11,1.59258336217706e-17,4.46886513511614e-22,8.32438239306983e-32,5.50420318373213e-45,4.07127773250312e-58,2.01105763346145e-76,6.51146592352183e-100,1.38195370474173e-128,2.93245589422197e-157],[5.39964840899981e-19,5.73783566121195e-10,4.95237822889483e-06,0.000356036530448518,0.00364161528795007,0.0112329442468965,0.0252826501600385,0.0504539247890418,0.0644047045560643,0.0565147591080807,0.0365725560107204,0.0168018818177516,0.00511766159567819,0.00114102783214639,0.000134221597433633,3.14802960871893e-07,5.45629826051782e-09,1.53072361775968e-13,1.41245242401531e-22,1.29303645153607e-30,9.74415078109988e-44,4.81324295289534e-62,1.55844700619099e-85,4.43400824553211e-109,2.84966144455127e-127],[8.08171755432348e-23,9.9520282620662e-12,8.72151014566793e-06,0.000237656044981198,0.00242087074777216,0.0074732039291603,0.022384642393563,0.0557037311872487,0.0912557128673284,0.111817977555221,0.0876421013472796,0.0510910440320731,0.0211567749509494,0.00631968870616185,0.00125306808856439,0.000249914243381994,3.94877458670163e-05,1.74347212052722e-09,5.23218109941235e-13,6.0146277187387e-21,4.53254441838339e-34,2.23890921563308e-52,8.54657858913127e-71,8.37418644669075e-84,5.38198765821467e-102],[1.77556608338451e-26,4.68244714950935e-15,5.72836682532587e-08,5.26618049520792e-05,0.000520971666093416,0.00358304354991811,0.0146024372316178,0.0418007880446392,0.0937576081086299,0.158070989476187,0.157995985258691,0.117472705761148,0.068309234060372,0.0258290121813925,0.00614303473251792,0.00140371367897623,0.000338744362715045,2.87186516456263e-05,4.72966243885067e-08,5.43755630957161e-16,4.12176724282202e-29,8.46961929462488e-42,3.13499804301411e-50,3.07380889542921e-63,1.97549954784854e-81],[3.73881979289422e-28,4.1820126805177e-15,3.42658639075899e-07,0.000213096739325229,4.3973222484619e-05,0.00128105280915237,0.00620857351658763,0.0236609682820968,0.0673959425125629,0.142023226278179,0.202085537513268,0.206177388365867,0.142910430049431,0.0718865969637724,0.0247087506133945,0.0047660988724505,0.0012606718949474,0.000106045234620241,1.61011212783354e-07,3.22788996902712e-14,9.2123618335293e-20,1.49536811118862e-26,2.23643511113796e-34,2.19278426565827e-47,1.4092757463806e-65],[3.96017717925257e-29,3.86645225973798e-16,2.47948115467607e-08,1.04690276048912e-05,9.33739859692154e-08,0.000133111110976272,0.001505336639134,0.0100449990636382,0.0356202331310127,0.105081641208442,0.19439947445164,0.245025075795557,0.223771691425712,0.143465906225543,0.0646419650813796,0.0193175819154857,0.00436838485724641,0.000892066964783552,3.18041827586292e-05,1.69881000386951e-07,1.59463339843398e-12,2.07291272771527e-15,3.10070286927428e-23,3.04018320512746e-36,1.95388872614587e-54],[9.27339116358244e-35,9.03850964769535e-22,5.77463739774986e-14,2.41842863581794e-11,3.88926919292566e-09,0.000100098427596149,0.00050944399843051,0.00360939499961912,0.0136893590316382,0.0543814561636372,0.125589050531115,0.214168898320003,0.252702330848491,0.212680258807483,0.12368371559332,0.0571604244308721,0.0148492657453032,0.00428301746930206,0.000533538675367115,2.75095327364781e-05,2.44919907449026e-06,5.58559793676326e-09,8.35504525271334e-17,8.19197108729206e-30,5.26488017941314e-48],[4.22630081869033e-45,4.11918272416941e-32,2.63161451387286e-24,3.34109926960455e-18,4.16151119979132e-09,3.41162097549106e-05,8.99545384914694e-05,0.000537014515485226,0.00565794795375072,0.0201673293936082,0.0650968150283119,0.13459457027411,0.216709166154952,0.233737316709245,0.179942550046156,0.0954030715862073,0.0358967231160644,0.00978785209447172,0.00200550639931911,0.000394946604594165,0.000128582191560498,2.92511773464097e-07,4.37544553451306e-15,4.29280429019131e-28,6.30606127729647e-38],[3.74346108554796e-60,3.64858019840399e-47,6.70536258912719e-37,1.26938304068891e-22,1.58065154101849e-13,1.29158993030982e-09,1.61465392359957e-06,9.08018401722032e-05,0.000992221126994708,0.00512632101729583,0.0213674249325609,0.0609771333181536,0.127073954333846,0.182795988224094,0.182286136161845,0.128019925458391,0.0639035259991266,0.0214065384771248,0.00490871234422249,0.000973054976315337,4.01022180114187e-05,5.72791275188721e-09,9.59043068097496e-17,2.97039793505775e-18,6.78914545169897e-25],[6.44423115594109e-80,1.76612292089083e-65,4.93647515191911e-46,9.37777211109363e-32,1.1698365693386e-22,1.41425275871238e-13,6.22698386517161e-07,2.62951805516803e-05,0.000279527597873221,0.00157860429446793,0.00602574560623074,0.018752616701671,0.0543021443993639,0.103895733283513,0.132977779790837,0.128374603771506,0.0753939336135714,0.0355212183761688,0.0120559569069517,0.00206194514165532,0.000441096970059341,2.73484240954569e-07,1.78469373193845e-08,6.21521805008958e-10,1.42055105743125e-16],[7.68729358424888e-104,2.44560642444526e-79,7.08775698856484e-60,1.3645720073284e-45,1.85668279000812e-30,1.24717099176323e-18,5.51514928616487e-12,3.59878422919363e-08,7.11836377827706e-06,0.000206159016212575,0.000677559737625132,0.00454096610629842,0.0184411701444843,0.0423810497069583,0.0716411419156444,0.0888352172498334,0.0766481090433616,0.0426458883542985,0.0175314894554273,0.00410447707852974,0.00104229547613349,0.000236141437094331,7.29387726175071e-05,2.52746047466519e-06,5.77674769488895e-13],[1.54348158058503e-122,6.82438055278491e-98,2.1764367130903e-78,3.10524776593914e-57,3.18217737427384e-40,2.1376226328524e-28,2.96521296109842e-21,3.35038012197265e-15,1.97523298476773e-08,0.000133046448270912,0.000137471144441657,0.000903339786529172,0.00339562223667828,0.0128631814378422,0.0284907613212608,0.0459004645516009,0.0504343969800885,0.0368454386741711,0.020295131275482,0.00834622530427719,0.0025276260264015,0.000264485978452582,7.42808296982338e-05,2.97754176124738e-07,5.54723640489585e-14],[8.37072222983159e-146,6.47496277221125e-121,6.61607426510692e-94,1.03435132478381e-71,1.05997695834429e-54,7.26629325820164e-43,3.44825400430606e-33,1.16750358152517e-20,8.87833074222978e-12,6.03705086913571e-08,3.0979146677307e-07,0.000111121155685573,0.000546159808841194,0.00234731614653475,0.00811613899679378,0.01524872508983,0.0224969610775458,0.0222048655285225,0.0165153003974538,0.00796127257796058,0.00238983759119942,0.000568475706754498,0.000111703499381798,1.37762505288305e-06,7.78323799691101e-13],[5.8174658995359e-173,1.79576621930351e-140,4.28308842051526e-113,6.69614350285288e-91,6.86338053828388e-74,5.70790798535558e-61,9.45947538521377e-43,1.05207977853767e-28,8.00037164310086e-20,5.43819520219381e-16,1.1447107087918e-12,7.6069411229749e-08,1.88824406030061e-05,0.000282589139759991,0.0013566840600888,0.0043332775154336,0.00841566316788047,0.0115467512308974,0.00989353732973917,0.00702460127430449,0.00248407446365753,0.000835282652146337,0.00019689042809369,3.98684425041365e-05,1.13279935581737e-06],[6.20932658184517e-197,2.25939039635564e-164,5.3888801122331e-137,8.42494444063686e-115,9.85285809081692e-98,9.81016236238191e-75,1.65677535778078e-55,1.84264779117487e-41,1.40112690321962e-32,9.7734482363793e-29,8.84275975640076e-21,5.42678565856387e-14,3.55725848792818e-09,2.50688031203498e-05,0.00037257061396806,0.000652072224755515,0.00220596575329706,0.00390824530472625,0.00383520710782124,0.00356746514374532,0.00198660746096792,0.000847086231459706,0.000420124430561813,0.000206161951735914,0.000139297549047621],[1.51834614100114e-225,5.52481278783358e-193,1.31772509679596e-165,2.06533081524484e-143,1.29673322046541e-116,3.33931942363595e-92,5.63955821152384e-73,6.27221302516466e-59,4.76902554018659e-50,2.05571003722159e-43,6.4564082722214e-32,9.97509200941749e-22,2.50203874102328e-11,5.38184636508631e-06,2.28640215213753e-05,5.21287951737725e-05,0.000417456509937771,0.000641775046044822,0.00116730324640233,0.00158181795727826,0.00100667520344559,0.00068510033767778,0.000277599060128235,4.61300248449355e-05,4.35426880886139e-05],[7.215756742882e-259,2.6256005832423e-226,6.26274913779807e-199,2.18370540673512e-168,8.57861654858231e-139,2.20914667283235e-114,3.73088057671666e-95,4.14938831485597e-81,3.15554639168223e-72,1.05662622923261e-59,1.43227275358807e-42,5.4931932302565e-27,1.4524397658288e-16,3.79389505892861e-11,2.20909001199427e-10,3.05546580679959e-09,4.35913186858356e-06,3.31707747133925e-05,0.000430542207310076,0.000586742208506192,0.000307810148878761,0.000253683181760847,0.000409041984564786,7.35977011753656e-06,5.00851432147429e-07],[6.66465670367594e-297,2.42507689762034e-264,4.68473831753259e-230,2.80766623244054e-195,1.10298265871409e-165,2.84037672197857e-141,4.79691936622069e-122,5.33497231006159e-108,2.51418740546229e-97,2.69430717937953e-73,1.56978231833671e-52,6.05179120216435e-37,1.68469487817489e-26,5.83767588635578e-21,4.46168128161558e-20,1.47718573329587e-15,3.03760156043252e-12,1.11175862458942e-08,4.77448480759622e-07,1.37527946349091e-05,3.27369657863926e-05,4.5069603918654e-05,2.18665863961594e-05,2.45790160940866e-07,2.16743981653795e-12],[0,1.28033478220917e-301,1.17063504610327e-261,7.01587297133337e-227,2.75616313180305e-197,7.09761020470235e-173,1.1986662995098e-153,1.33312158277165e-139,6.45923897222376e-114,5.73686958901279e-88,3.34560845825795e-67,1.30290708566137e-51,3.98283248267262e-41,1.95445068709012e-35,2.5163612212255e-34,2.13073194576148e-26,2.2103622973781e-22,1.36299881951402e-16,5.4223823620928e-13,9.64890337003241e-07,4.75103088380026e-05,1.74076683148872e-08,2.3982844765835e-05,4.12736376796499e-05,4.65593304437425e-10]],\"alpha_stroke\":1,\"sizes\":[10,100],\"spans\":[1,20],\"type\":\"surface\",\"inherit\":true}},\"layout\":{\"margin\":{\"b\":40,\"l\":60,\"t\":25,\"r\":10},\"scene\":{\"xaxis\":{\"title\":[]},\"yaxis\":{\"title\":[]},\"zaxis\":{\"title\":[]}},\"hovermode\":\"closest\",\"showlegend\":false,\"legend\":{\"yanchor\":\"top\",\"y\":0.5}},\"source\":\"A\",\"config\":{\"showSendToCloud\":false},\"data\":[{\"colorbar\":{\"title\":\"\",\"ticklen\":2,\"len\":0.5,\"lenmode\":\"fraction\",\"y\":1,\"yanchor\":\"top\"},\"colorscale\":[[\"0\",\"rgba(68,1,84,1)\"],[\"0.0416666666666667\",\"rgba(70,19,97,1)\"],[\"0.0833333333333333\",\"rgba(72,32,111,1)\"],[\"0.125\",\"rgba(71,45,122,1)\"],[\"0.166666666666667\",\"rgba(68,58,128,1)\"],[\"0.208333333333333\",\"rgba(64,70,135,1)\"],[\"0.25\",\"rgba(60,82,138,1)\"],[\"0.291666666666667\",\"rgba(56,93,140,1)\"],[\"0.333333333333333\",\"rgba(49,104,142,1)\"],[\"0.375\",\"rgba(46,114,142,1)\"],[\"0.416666666666667\",\"rgba(42,123,142,1)\"],[\"0.458333333333333\",\"rgba(38,133,141,1)\"],[\"0.5\",\"rgba(37,144,140,1)\"],[\"0.541666666666667\",\"rgba(33,154,138,1)\"],[\"0.583333333333333\",\"rgba(39,164,133,1)\"],[\"0.625\",\"rgba(47,174,127,1)\"],[\"0.666666666666667\",\"rgba(53,183,121,1)\"],[\"0.708333333333333\",\"rgba(79,191,110,1)\"],[\"0.75\",\"rgba(98,199,98,1)\"],[\"0.791666666666667\",\"rgba(119,207,85,1)\"],[\"0.833333333333333\",\"rgba(147,214,70,1)\"],[\"0.875\",\"rgba(172,220,52,1)\"],[\"0.916666666666667\",\"rgba(199,225,42,1)\"],[\"0.958333333333333\",\"rgba(226,228,40,1)\"],[\"1\",\"rgba(253,231,37,1)\"]],\"showscale\":true,\"x\":[-4.11222323909044,-3.76275945114626,-3.41329566320208,-3.0638318752579,-2.71436808731372,-2.36490429936954,-2.01544051142536,-1.66597672348118,-1.316512935537,-0.967049147592815,-0.617585359648634,-0.268121571704453,0.0813422162397277,0.430806004183909,0.780269792128089,1.12973358007227,1.47919736801645,1.82866115596063,2.17812494390481,2.52758873184899,2.87705251979317,3.22651630773736,3.57598009568154,3.92544388362572,4.2749076715699],\"y\":[-4.32381413035071,-3.95784855910568,-3.59188298786066,-3.22591741661563,-2.85995184537061,-2.49398627412558,-2.12802070288055,-1.76205513163553,-1.3960895603905,-1.03012398914547,-0.664158417900448,-0.298192846655422,0.0677727245896049,0.433738295834631,0.799703867079657,1.16566943832468,1.53163500956971,1.89760058081474,2.26356615205976,2.62953172330479,2.99549729454982,3.36146286579484,3.72742843703987,4.09339400828489,4.45935957952992],\"z\":[[3.40651108352134e-09,1.41934533126133e-08,8.54786240302624e-08,0.000130831863209747,1.94776526567504e-06,1.49783603255103e-06,1.1170089576991e-08,6.01986954373106e-12,1.16817732135535e-10,1.50245544102462e-14,4.62944974810078e-23,4.83295093316628e-35,2.28048400569722e-45,8.78734985512727e-51,2.21962779786052e-61,3.67504668072926e-77,3.98846726370328e-98,2.83738455537123e-124,1.16702068177763e-153,1.56588648116791e-183,5.9460095882168e-217,3.04648237511363e-242,1.0476778777822e-272,2.36166828733039e-308,0],[4.39462560522794e-05,6.94943900679841e-05,1.04291502349634e-05,5.75970473307081e-05,0.000176906604268204,0.000370540209494104,1.55421446807263e-05,8.30475843056959e-07,1.53069632670964e-05,7.14342142452053e-09,1.13543480848847e-15,2.9038893623358e-25,2.64561847471716e-28,1.01950388004498e-33,2.57520093025581e-44,4.26377054766638e-60,4.6281649856682e-81,2.42118913413043e-104,5.00622985414094e-129,7.25515626339583e-159,3.68875889960785e-180,1.93530271945878e-205,6.65546074071442e-236,5.25171440440826e-271,5.21884573812369e-305],[9.55774448047614e-05,0.000177213516750328,0.000316039775630404,0.000475626271585416,0.000761122825446468,0.000814816903847166,0.000578652080468251,0.000157642005236617,0.000152603615623742,3.79131793396399e-06,7.51171055499296e-11,3.17899382836251e-15,5.96544729558909e-16,2.29881835031841e-21,5.80666661659396e-32,9.62751627134557e-48,6.45601148716749e-65,2.03894997743999e-84,4.22210611955478e-109,5.68993288800346e-128,4.55423370733433e-148,2.3893730364403e-173,9.74271181456202e-204,3.23808866743861e-233,4.50467722508192e-267],[1.98596665642571e-07,4.68000995544877e-05,0.000509090380019503,0.000931319298108951,0.0012891264719117,0.00255519224543074,0.00194691180666576,0.00139812985945186,0.000387322200480871,0.000138389622336007,1.12962183753118e-05,4.51541808458966e-08,2.61431851364547e-08,1.00740783248176e-13,2.57450769746435e-24,2.19535111827777e-35,1.05790746618256e-49,3.3419444921475e-69,1.11809791229766e-85,1.36529655130866e-100,1.09278610207721e-120,5.81233702380819e-146,2.55947654424468e-171,5.43203463930242e-200,7.55679638075802e-234],[2.0971717790889e-11,2.45146152673218e-05,0.00101641626246237,0.0012023963529308,0.00431348854715178,0.00596725675304324,0.00681722538407796,0.00633846543983796,0.00269032102983323,0.00186745629509051,0.000257016293377211,6.68099172102812e-05,2.23554936688109e-05,9.43773499495428e-11,9.51160167439667e-16,6.99272785694416e-25,3.37970089697892e-39,2.8443677530022e-53,5.21415549375954e-63,6.36695308508056e-78,5.10133947007011e-98,2.57749276005559e-119,8.34462177624758e-143,1.77101149161936e-171,2.46374961111803e-205],[2.18739954530607e-13,8.27469962250889e-07,0.00068247158549802,0.00129956984621859,0.00404868380339934,0.0102606158585002,0.0148087501034371,0.0152333593380476,0.0125919827053159,0.00699472312030991,0.00241781085109058,0.000326864762138592,1.64609783322298e-05,5.34463376690191e-06,5.93226571697135e-10,5.36558733277978e-19,1.90647639364607e-28,2.53683060667389e-35,4.72578158624974e-45,5.77104072981931e-60,3.31061440322712e-77,1.63303711875425e-95,5.28749916069209e-119,1.12218648450566e-147,1.56113414734455e-181],[2.95266849169562e-16,2.85416661335113e-08,8.90740945415943e-05,0.00122580118110615,0.0046414034091961,0.0107569609558745,0.0239117407486324,0.0345320261172182,0.034266290423328,0.025908337162062,0.0111683859733492,0.00396670124627087,0.00103938025934649,0.000215424763750705,2.74471340647353e-07,1.04918685044655e-11,1.59258336217706e-17,4.46886513511614e-22,8.32438239306983e-32,5.50420318373213e-45,4.07127773250312e-58,2.01105763346145e-76,6.51146592352183e-100,1.38195370474173e-128,2.93245589422197e-157],[5.39964840899981e-19,5.73783566121195e-10,4.95237822889483e-06,0.000356036530448518,0.00364161528795007,0.0112329442468965,0.0252826501600385,0.0504539247890418,0.0644047045560643,0.0565147591080807,0.0365725560107204,0.0168018818177516,0.00511766159567819,0.00114102783214639,0.000134221597433633,3.14802960871893e-07,5.45629826051782e-09,1.53072361775968e-13,1.41245242401531e-22,1.29303645153607e-30,9.74415078109988e-44,4.81324295289534e-62,1.55844700619099e-85,4.43400824553211e-109,2.84966144455127e-127],[8.08171755432348e-23,9.9520282620662e-12,8.72151014566793e-06,0.000237656044981198,0.00242087074777216,0.0074732039291603,0.022384642393563,0.0557037311872487,0.0912557128673284,0.111817977555221,0.0876421013472796,0.0510910440320731,0.0211567749509494,0.00631968870616185,0.00125306808856439,0.000249914243381994,3.94877458670163e-05,1.74347212052722e-09,5.23218109941235e-13,6.0146277187387e-21,4.53254441838339e-34,2.23890921563308e-52,8.54657858913127e-71,8.37418644669075e-84,5.38198765821467e-102],[1.77556608338451e-26,4.68244714950935e-15,5.72836682532587e-08,5.26618049520792e-05,0.000520971666093416,0.00358304354991811,0.0146024372316178,0.0418007880446392,0.0937576081086299,0.158070989476187,0.157995985258691,0.117472705761148,0.068309234060372,0.0258290121813925,0.00614303473251792,0.00140371367897623,0.000338744362715045,2.87186516456263e-05,4.72966243885067e-08,5.43755630957161e-16,4.12176724282202e-29,8.46961929462488e-42,3.13499804301411e-50,3.07380889542921e-63,1.97549954784854e-81],[3.73881979289422e-28,4.1820126805177e-15,3.42658639075899e-07,0.000213096739325229,4.3973222484619e-05,0.00128105280915237,0.00620857351658763,0.0236609682820968,0.0673959425125629,0.142023226278179,0.202085537513268,0.206177388365867,0.142910430049431,0.0718865969637724,0.0247087506133945,0.0047660988724505,0.0012606718949474,0.000106045234620241,1.61011212783354e-07,3.22788996902712e-14,9.2123618335293e-20,1.49536811118862e-26,2.23643511113796e-34,2.19278426565827e-47,1.4092757463806e-65],[3.96017717925257e-29,3.86645225973798e-16,2.47948115467607e-08,1.04690276048912e-05,9.33739859692154e-08,0.000133111110976272,0.001505336639134,0.0100449990636382,0.0356202331310127,0.105081641208442,0.19439947445164,0.245025075795557,0.223771691425712,0.143465906225543,0.0646419650813796,0.0193175819154857,0.00436838485724641,0.000892066964783552,3.18041827586292e-05,1.69881000386951e-07,1.59463339843398e-12,2.07291272771527e-15,3.10070286927428e-23,3.04018320512746e-36,1.95388872614587e-54],[9.27339116358244e-35,9.03850964769535e-22,5.77463739774986e-14,2.41842863581794e-11,3.88926919292566e-09,0.000100098427596149,0.00050944399843051,0.00360939499961912,0.0136893590316382,0.0543814561636372,0.125589050531115,0.214168898320003,0.252702330848491,0.212680258807483,0.12368371559332,0.0571604244308721,0.0148492657453032,0.00428301746930206,0.000533538675367115,2.75095327364781e-05,2.44919907449026e-06,5.58559793676326e-09,8.35504525271334e-17,8.19197108729206e-30,5.26488017941314e-48],[4.22630081869033e-45,4.11918272416941e-32,2.63161451387286e-24,3.34109926960455e-18,4.16151119979132e-09,3.41162097549106e-05,8.99545384914694e-05,0.000537014515485226,0.00565794795375072,0.0201673293936082,0.0650968150283119,0.13459457027411,0.216709166154952,0.233737316709245,0.179942550046156,0.0954030715862073,0.0358967231160644,0.00978785209447172,0.00200550639931911,0.000394946604594165,0.000128582191560498,2.92511773464097e-07,4.37544553451306e-15,4.29280429019131e-28,6.30606127729647e-38],[3.74346108554796e-60,3.64858019840399e-47,6.70536258912719e-37,1.26938304068891e-22,1.58065154101849e-13,1.29158993030982e-09,1.61465392359957e-06,9.08018401722032e-05,0.000992221126994708,0.00512632101729583,0.0213674249325609,0.0609771333181536,0.127073954333846,0.182795988224094,0.182286136161845,0.128019925458391,0.0639035259991266,0.0214065384771248,0.00490871234422249,0.000973054976315337,4.01022180114187e-05,5.72791275188721e-09,9.59043068097496e-17,2.97039793505775e-18,6.78914545169897e-25],[6.44423115594109e-80,1.76612292089083e-65,4.93647515191911e-46,9.37777211109363e-32,1.1698365693386e-22,1.41425275871238e-13,6.22698386517161e-07,2.62951805516803e-05,0.000279527597873221,0.00157860429446793,0.00602574560623074,0.018752616701671,0.0543021443993639,0.103895733283513,0.132977779790837,0.128374603771506,0.0753939336135714,0.0355212183761688,0.0120559569069517,0.00206194514165532,0.000441096970059341,2.73484240954569e-07,1.78469373193845e-08,6.21521805008958e-10,1.42055105743125e-16],[7.68729358424888e-104,2.44560642444526e-79,7.08775698856484e-60,1.3645720073284e-45,1.85668279000812e-30,1.24717099176323e-18,5.51514928616487e-12,3.59878422919363e-08,7.11836377827706e-06,0.000206159016212575,0.000677559737625132,0.00454096610629842,0.0184411701444843,0.0423810497069583,0.0716411419156444,0.0888352172498334,0.0766481090433616,0.0426458883542985,0.0175314894554273,0.00410447707852974,0.00104229547613349,0.000236141437094331,7.29387726175071e-05,2.52746047466519e-06,5.77674769488895e-13],[1.54348158058503e-122,6.82438055278491e-98,2.1764367130903e-78,3.10524776593914e-57,3.18217737427384e-40,2.1376226328524e-28,2.96521296109842e-21,3.35038012197265e-15,1.97523298476773e-08,0.000133046448270912,0.000137471144441657,0.000903339786529172,0.00339562223667828,0.0128631814378422,0.0284907613212608,0.0459004645516009,0.0504343969800885,0.0368454386741711,0.020295131275482,0.00834622530427719,0.0025276260264015,0.000264485978452582,7.42808296982338e-05,2.97754176124738e-07,5.54723640489585e-14],[8.37072222983159e-146,6.47496277221125e-121,6.61607426510692e-94,1.03435132478381e-71,1.05997695834429e-54,7.26629325820164e-43,3.44825400430606e-33,1.16750358152517e-20,8.87833074222978e-12,6.03705086913571e-08,3.0979146677307e-07,0.000111121155685573,0.000546159808841194,0.00234731614653475,0.00811613899679378,0.01524872508983,0.0224969610775458,0.0222048655285225,0.0165153003974538,0.00796127257796058,0.00238983759119942,0.000568475706754498,0.000111703499381798,1.37762505288305e-06,7.78323799691101e-13],[5.8174658995359e-173,1.79576621930351e-140,4.28308842051526e-113,6.69614350285288e-91,6.86338053828388e-74,5.70790798535558e-61,9.45947538521377e-43,1.05207977853767e-28,8.00037164310086e-20,5.43819520219381e-16,1.1447107087918e-12,7.6069411229749e-08,1.88824406030061e-05,0.000282589139759991,0.0013566840600888,0.0043332775154336,0.00841566316788047,0.0115467512308974,0.00989353732973917,0.00702460127430449,0.00248407446365753,0.000835282652146337,0.00019689042809369,3.98684425041365e-05,1.13279935581737e-06],[6.20932658184517e-197,2.25939039635564e-164,5.3888801122331e-137,8.42494444063686e-115,9.85285809081692e-98,9.81016236238191e-75,1.65677535778078e-55,1.84264779117487e-41,1.40112690321962e-32,9.7734482363793e-29,8.84275975640076e-21,5.42678565856387e-14,3.55725848792818e-09,2.50688031203498e-05,0.00037257061396806,0.000652072224755515,0.00220596575329706,0.00390824530472625,0.00383520710782124,0.00356746514374532,0.00198660746096792,0.000847086231459706,0.000420124430561813,0.000206161951735914,0.000139297549047621],[1.51834614100114e-225,5.52481278783358e-193,1.31772509679596e-165,2.06533081524484e-143,1.29673322046541e-116,3.33931942363595e-92,5.63955821152384e-73,6.27221302516466e-59,4.76902554018659e-50,2.05571003722159e-43,6.4564082722214e-32,9.97509200941749e-22,2.50203874102328e-11,5.38184636508631e-06,2.28640215213753e-05,5.21287951737725e-05,0.000417456509937771,0.000641775046044822,0.00116730324640233,0.00158181795727826,0.00100667520344559,0.00068510033767778,0.000277599060128235,4.61300248449355e-05,4.35426880886139e-05],[7.215756742882e-259,2.6256005832423e-226,6.26274913779807e-199,2.18370540673512e-168,8.57861654858231e-139,2.20914667283235e-114,3.73088057671666e-95,4.14938831485597e-81,3.15554639168223e-72,1.05662622923261e-59,1.43227275358807e-42,5.4931932302565e-27,1.4524397658288e-16,3.79389505892861e-11,2.20909001199427e-10,3.05546580679959e-09,4.35913186858356e-06,3.31707747133925e-05,0.000430542207310076,0.000586742208506192,0.000307810148878761,0.000253683181760847,0.000409041984564786,7.35977011753656e-06,5.00851432147429e-07],[6.66465670367594e-297,2.42507689762034e-264,4.68473831753259e-230,2.80766623244054e-195,1.10298265871409e-165,2.84037672197857e-141,4.79691936622069e-122,5.33497231006159e-108,2.51418740546229e-97,2.69430717937953e-73,1.56978231833671e-52,6.05179120216435e-37,1.68469487817489e-26,5.83767588635578e-21,4.46168128161558e-20,1.47718573329587e-15,3.03760156043252e-12,1.11175862458942e-08,4.77448480759622e-07,1.37527946349091e-05,3.27369657863926e-05,4.5069603918654e-05,2.18665863961594e-05,2.45790160940866e-07,2.16743981653795e-12],[0,1.28033478220917e-301,1.17063504610327e-261,7.01587297133337e-227,2.75616313180305e-197,7.09761020470235e-173,1.1986662995098e-153,1.33312158277165e-139,6.45923897222376e-114,5.73686958901279e-88,3.34560845825795e-67,1.30290708566137e-51,3.98283248267262e-41,1.95445068709012e-35,2.5163612212255e-34,2.13073194576148e-26,2.2103622973781e-22,1.36299881951402e-16,5.4223823620928e-13,9.64890337003241e-07,4.75103088380026e-05,1.74076683148872e-08,2.3982844765835e-05,4.12736376796499e-05,4.65593304437425e-10]],\"type\":\"surface\",\"frame\":null}],\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.2,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}\nFigure 4: Imagem 3-D Interativa de uma distribuição Multivariada Normal\n\n\n\nMetropolis e Metropolis-Hastings\nO primeiro algoritmo MCMC amplamente utilizado para gerar amostras de correntes Markov foi originário na física na década de 1950 (inclusive uma relação muito próxima com a bomba atômica no projeto Manhattan) e chama-se Metropolis (Metropolis, Rosenbluth, Rosenbluth, Teller, & Teller, 1953) em homenagem ao primeiro autor Nicholas Metropolis (figura 5). Em síntese, o algoritmo de Metropolis é uma adaptação de um passeio aleatório (random walk) com uma regra de aceitação/rejeição para convergir à distribuição-alvo.\nO algorimo de Metropolis usa uma distribuição de propostas \\(J_t(\\theta^*)\\) (\\(J\\) quer dizer jumping distribution e \\(t\\) indica em qual estado da corrente Markov estamos) para definir próximos valores da distribuição \\(P^*(\\theta^* | \\text{data})\\). Essa distribuição deve ser simétrica:\n\\[\nJ_t (\\theta^* | \\theta^{t-1}) = J_t(\\theta^{t-1}|\\theta^*).\n\\]\nNa década de 1970, surgiu um generalização do algoritmo de Metropolis que não necessita que as distribuições de proposta sejam simétricas. A generalização foi proposta por Wilfred Keith Hastings (Hastings, 1970) (figura 5) e chama-se algoritmo de Metropolis-Hastings.\n\n\n\nFigure 5: Da esquerda para direita: Nicholas Metropolis e Wilfred Hastings – Figuras de https://www.wikipedia.org\n\n\n\nAlgoritmo de Metropolis\nA essência do algoritmo é um passeio aleatório (random walk) pelo espaço amostral dos parâmetros, onde a probabilidade da corrente Markov mudar de estado é definida como:\n\\[\nP_{\\text{mudar}} = \\min\\left({\\frac{P (\\theta_{\\text{proposto}})}{P (\\theta_{\\text{atual}})}},1\\right).\n\\]\nIsso quer dizer a corrente Markov somente mudará para um novo estado em duas condições:\nQuando a probabilidade dos parâmetros propostos pelo passeio aleatório \\(P(\\theta_{\\text{proposto}})\\) é maior que a probabilidade dos parâmetros do estado atual \\(P(\\theta_{\\text{atual}})\\), mudamos com 100% de probabilidade. Vejam que se \\(P(\\theta_{\\text{proposto}}) > P(\\theta_{\\text{atual}})\\) então a função \\(\\min\\) escolhe o valor 1 que quer dizer 100%.\nQuando a probabilidade dos parâmetros propostos pelo passeio aleatório \\(P(\\theta_{\\text{proposto}})\\) é menor que a probabilidade dos parâmetros do estado atual \\(P(\\theta_{\\text{atual}})\\), mudamos com probabilidade igual a proporção dessa diferença. Vejam que se \\(P(\\theta_{\\text{proposto}}) < P(\\theta_{\\text{atual}})\\) então a função \\(\\min\\) não escolhe o valor 1, mas sim o valor \\(\\frac{P (\\theta_{\\text{proposto}})}{P (\\theta_{\\text{atual}})}\\) que equivale a proporção da probabilidade dos parâmetros propostos pela probabilidade dos parâmetros do estado atual.\nDe qualquer maneira, a cada iteração do algoritmo de Metropolis, mesmo que a corrente muda de estado ou não, amostramos o parâmetro \\(\\theta\\) de qualquer maneira. Ou seja, se a corrente não mudar em um certo estado \\(\\theta\\) será amostrado duas vezes (ou mais caso a corrente fique estacionária no mesmo estado).\nO algoritmo de Metropolis-Hastings pode ser descrito na seguinte maneira3 (\\(\\theta\\) é o parâmetro, ou conjunto de parâmetros, de interesse e \\(y\\) são os dados):\nDefina um ponto inicial \\(\\theta^0\\) do qual \\(p(\\theta^0|y) > 0\\), ou amostre-o de uma distribuição inicial \\(p_0 (\\theta)\\). \\(p_0(\\theta)\\) pode ser uma distribuição normal ou uma distribuição prévia de \\(\\theta\\) (\\(p(\\theta)\\)).\nPara \\(t = 1, 2, \\dots\\):\nAmostra uma proposta \\(\\theta^*\\) de uma distribuição de propostas no tempo \\(t\\), \\(J_t (\\theta^* | \\theta^{t-1})\\).\nCalcule a proporção das probabilidades:\nMetropolis: \\(r = \\frac{p(\\theta^* | y)}{p(\\theta^{t-1} | y)}\\)\nMetropolis-Hastings: \\(r = \\frac{\\frac{p(\\theta^* | y)}{J_t(\\theta^*|\\theta^{t-1})}}{\\frac{p(\\theta^{t-1} | y)}{J_t(\\theta^{t-1}|\\theta^*)}}\\)\n\nDesigne:\n\\[\\theta^t =\n  \\begin{cases}\n  \\theta^* & \\text{com probabilidade $\\min(r,1)$}\\\\\n  \\theta^{t-1} & \\text{caso contrário}\n  \\end{cases}\\]\n\nLimitações do Algoritmo de Metropolis\nAs limitações do algoritmo de Metropolis-Hastings são principalmente computacionais. Com propostas geradas aleatoriamente, geralmente leva um grande número de iterações para entrar em áreas de densidade posterior mais alta (mais provável). Mesmo algoritmos de Metropolis-Hastings eficientes às vezes aceitam menos de 25% das propostas (Roberts, Gelman, & Gilks, 1997). Em situações dimensionais mais baixas, o poder computacional aumentado pode compensar a eficiência mais baixa até certo ponto. Mas em situações de modelagem de dimensões mais altas e mais complexas, computadores maiores e mais rápidos sozinhos raramente são suficientes para superar o desafio.\nMetropolis – Implementação\nNo nosso exemplo didático vamos partir do pressuposto que \\(J_t(\\theta^* | \\theta^{t-1})\\) é simétrico à \\(J_t (\\theta^* | \\theta^{t-1}) = J_t(\\theta^{t-1}|\\theta^*)\\), portanto vamos apenas demonstrar o algoritmo de Metropolis (e não o algoritmo de Metropolis-Hastings).\nO Stan (Carpenter et al., 2017) (e consequentemente seu ecossistema inteiro de pacotes) não tem implementações de outros algoritmos a não ser o HMC (Hamiltonean Monte Carlo), portanto abaixo criei um amostrador Metropolis para o nosso exemplo didático. No fim ele imprime a porcentagem total de aceitação das propostas. Aqui estamos usando a mesma distribuição de propostas para tanto \\(X\\) e \\(Y\\): uma distribuição uniforme parameterizada com um parâmetro largura width:\n\\[\nX \\sim \\text{Uniforme} \\left( X - \\frac{\\text{largura}}{2}, X + \\frac{\\text{largura}}{2} \\right) \\\\\nY \\sim \\text{Uniforme} \\left( Y - \\frac{\\text{largura}}{2}, Y + \\frac{\\text{largura}}{2} \\right)\n\\] O pacote mnormt possui algumas funcionalidades para lidar com distribuições multivariadas, a função dmnorm() em especial calcula a função densidade de probabilidade (FDP)4 de uma distribuição normal multivariada, que é usada no cálculo proporção das probabilidades \\(r\\):\n\\[\n\\begin{aligned}\nr &= \\frac{\n\\operatorname{FDP}\\left(\n\\text{Normal Multivariada} \\left(\n\\begin{bmatrix}\nx_{\\text{proposto}} \\\\\ny_{\\text{proposto}}\n\\end{bmatrix}\n\\right)\n\\Bigg|\n\\text{Normal Multivariada} \\left(\n\\begin{bmatrix}\n\\mu_X \\\\\n\\mu_Y\n\\end{bmatrix}, \\mathbf{\\Sigma}\n\\right)\n\\right)}\n{\n\\operatorname{FDP}\\left(\n\\text{Normal Multivariada} \\left(\n\\begin{bmatrix}\nx_{\\text{atual}} \\\\\ny_{\\text{atual}}\n\\end{bmatrix}\n\\right)\n\\Bigg|\n\\text{Normal Multivariada} \\left(\n\\begin{bmatrix}\n\\mu_X \\\\\n\\mu_Y\n\\end{bmatrix}, \\mathbf{\\Sigma}\n\\right)\n\\right)}\\\\\n&=\\frac{\\operatorname{FDP}_{\\text{proposto}}}{\\operatorname{FDP}_{\\text{atual}}}\\\\\n&= \\exp\\Big(\n\\log\\left(\\operatorname{FDP}_{\\text{proposto}}\\right)\n-\n\\log\\left(\\operatorname{FDP}_{\\text{atual}}\\right)\n\\Big)\n\\end{aligned}\n\\]\n\n\nmetropolis <- function(S, half_width,\n                       mu_X = 0, mu_Y = 0,\n                       sigma_X = 1, sigma_Y = 1,\n                       rho,\n                       start_x, start_y,\n                       seed = 123) {\n   set.seed(seed)\n   Sigma <- diag(2)\n   Sigma[1, 2] <- rho\n   Sigma[2, 1] <- rho\n   draws <- matrix(nrow = S, ncol = 2)\n   x <- start_x\n   y <- start_y\n   accepted <- 0\n   draws[1, 1] <- x\n   draws[1, 2] <- y\n   for (s in 2:S) {\n      x_ <- runif(1, x - half_width, x + half_width)\n      y_ <- runif(1, y - half_width, y + half_width)\n      r <- exp(mnormt::dmnorm(c(x_, y_), mean = c(mu_X, mu_Y), varcov = Sigma, log = TRUE) -\n                        mnormt::dmnorm(c(x, y), mean = c(mu_X, mu_Y), varcov = Sigma, log = TRUE))\n      if (r > runif(1, 0, 1)) {\n        x <- x_\n        y <- y_\n        accepted <- accepted + 1\n      }\n      draws[s, 1] <- x\n      draws[s, 2] <- y\n   }\n   print(paste0(\"Taxa de aceitação \", accepted / S))\n   return(draws)\n}\n\n\n\n\n\nn_sim <- 1e4\n\n\n\nVamos executar nosso algoritmo Metropolis com 10,000 iterações.\n\n\nX_met <- metropolis(\n  S = n_sim, half_width = 2.75,\n  mu_X = 0, mu_Y = 0,\n  sigma_X = 1, sigma_Y = 1,\n  rho = r,\n  start_x = -2.5, start_y = 2.5\n)\n\n\n[1] \"Taxa de aceitação 0.2076\"\n\nhead(X_met, 7)\n\n\n      [,1] [,2]\n[1,] -2.50  2.5\n[2,] -2.50  2.5\n[3,] -2.50  2.5\n[4,] -2.50  2.5\n[5,] -2.50  2.5\n[6,] -1.52  2.9\n[7,]  0.68  1.5\n\nNa nossa primeira execução do algoritmo Metropolis temos como resultado uma matriz X_met com 10,000 linhas e 2 colunas (uma para cada valor de \\(X\\) e \\(Y\\), que passarei a chamar de \\(\\theta_1\\) e \\(\\theta_2\\), respectivamente). Vejam que a aceitação das propostas ficou em 20.8%, o esperado para algoritmos Metropolis (em torno de 20-25%) (Roberts et al., 1997).\nPara métricas de convergência e desempenho vamos usar a função rstan::monitor() que simula um print(stanfit)5mas para matrizes.\n\n\nres <- monitor(X_met, digits_summary = 1)\n\n\nInference for the input samples (2 chains: each with iter = 10000; warmup = 5000):\n\n     Q5 Q50 Q95 Mean SD  Rhat Bulk_ESS Tail_ESS\nV1 -1.6   0 1.7    0  1     1      952      909\n\nFor each parameter, Bulk_ESS and Tail_ESS are crude measures of \neffective sample size for bulk and tail quantities respectively (an ESS > 100 \nper chain is considered good), and Rhat is the potential scale reduction \nfactor on rank normalized split chains (at convergence, Rhat <= 1.05).\n\nneff <- res[, \"n_eff\"]\nreff <- mean(neff / (nrow(X_met))) #  9.5%\n\n\n\nVejam que o número de amostras eficientes em relação ao número total de iterações reff é 9,5% para todas as iterações incluindo warm-up.\nMetropolis – Intuição Visual\nEu acredito que uma boa intuição visual, mesmo que você não tenha entendido nenhuma fórmula matemática, é a chave para você começar a jornada de aprendizagem. Portanto fiz algumas animações com GIFs.\nA animação na figura 6 mostra as 100 primeiras simulações do algoritmo Metropolis usado para gerar X_met. Vejam que em diversas iterações a proposta é recusada e o algoritmo amostra os parâmetros \\(\\theta_1\\) e \\(\\theta_2\\) do estado anterior (que se torna o atual, pois a proposta é recusada).\nObservação: HPD é a sigla para Highest Probability Density (que é o intervalo de 90% de probabilidade da posterior).\n\n\ndf100 <- data.frame(\n    id = rep(1, 100),\n    iter = 1:100,\n    th1 = X_met[1:100, 1],\n    th2 = X_met[1:100, 2],\n    th1l = c(X_met[1, 1], X_met[1:(100 - 1), 1]),\n    th2l = c(X_met[1, 2], X_met[1:(100 - 1), 2])\n)\n\nlabs1 <- c(\"Amostras\", \"Iterações do Algoritmo\", \"90% HPD\")\n\np1 <- ggplot() +\n  geom_jitter(data = df100, width = 0.05, height = 0.05,\n             aes(th1, th2, group = id, color = \"1\"), alpha = 0.3) +\n  geom_segment(data = df100, aes(x = th1, xend = th1l, color = \"2\",\n                                 y = th2, yend = th2l)) +\n  stat_ellipse(data = dft, aes(x = X1, y = X2, color = \"3\"), level = 0.9) +\n  coord_cartesian(xlim = c(-3, 3), ylim = c(-3, 3)) +\n  labs(\n    title = \"Metropolis\", subtitle = \"100 Amostragens Iniciais\",\n    x = expression(theta[1]), y = expression(theta[2])) +\n  scale_color_manual(values = c(\"red\", \"forestgreen\", \"blue\"), labels = labs1) +\n  guides(color = guide_legend(override.aes = list(\n    shape = c(16, NA, NA), linetype = c(0, 1, 1)))) +\n  theme(legend.position = \"bottom\", legend.title = element_blank())\n\nanimate(p1 +\n  transition_reveal(along = iter) +\n  shadow_trail(0.01),\n  # animation options\n  height = 7, width = 7, units = \"in\", res = 300\n)\n\n\n\n\nFigure 6: Animação Metropolis\n\n\n\nNa figura 7 é possível ver como ficaram as primeiras 1.000 simulações excluindo 1.000 iterações iniciais como warmup.\n\n\n# Take all the 10,000 observations after warmup of 1,000\nwarm <- 1e3\ndfs <- data.frame(\n  th1 = X_met[(warm + 1):nrow(X_met), 1],\n  th2 = X_met[(warm + 1):nrow(X_met), 2]\n)\n\nlabs2 <- c(\"Amostras\", \"90% HPD\")\n\nggplot() +\n  geom_point(data = dfs[1:1000, ],\n             aes(th1, th2, color = \"1\"), alpha = 0.3) +\n  stat_ellipse(data = dft, aes(x = X1, y = X2, color = \"2\"), level = 0.9) +\n  coord_cartesian(xlim = c(-3, 3), ylim = c(-3, 3)) +\n  labs(\n    title = \"Metropolis\", subtitle = \"1.000 Amostragens Iniciais\",\n    x = expression(theta[1]), y = expression(theta[2])) +\n  scale_color_manual(values = c(\"steelblue\", \"blue\"), labels = labs2) +\n  guides(color = guide_legend(override.aes = list(\n    shape = c(16, NA), linetype = c(0, 1), alpha = c(1, 1)))) +\n  theme(legend.position = \"bottom\", legend.title = element_blank())\n\n\n\n\nFigure 7: Primeiras 1.000 simulações Metropolis após descarte de 1.000 iterações como warmup\n\n\n\nE na figura 8 é possível ver as restantes 9.000 simulações excluindo 1.000 iterações iniciais como warmup.\n\n\n# Show all 10,000 samples\nggplot() +\n  geom_point(data = dfs,\n             aes(th1, th2, color = \"1\"), alpha = 0.3) +\n  stat_ellipse(data = dft, aes(x = X1, y = X2, color = \"2\"), level = 0.9) +\n  coord_cartesian(xlim = c(-3, 3), ylim = c(-3, 3)) +\n  labs(\n    title = \"Metropolis\", subtitle = \"10.000 Amostragens\",\n    x = expression(theta[1]), y = expression(theta[2])) +\n  scale_color_manual(values = c(\"steelblue\", \"blue\"), labels = labs2) +\n  guides(color = guide_legend(override.aes = list(\n    shape = c(16, NA), linetype = c(0, 1), alpha = c(1, 1)))) +\n  theme(legend.position = \"bottom\", legend.title = element_blank())\n\n\n\n\nFigure 8: 9.000 simulações Metropolis após descarte de 1.000 iterações como warmup\n\n\n\nGibbs\nPara contornar o problema de baixa taxa de aceitação do algoritmo de Metropolis (e Metropolis-Hastings) foi desenvolvido o algoritmo de Gibbs que não possui uma regra de aceitação/rejeição para a mudança de estado da corrente Markov. Todas as propostas são aceitas.\nO algoritmo de Gibbs teve ideia original concebida pelo físico Josiah Willard Gibbs (figura 9), em referência a uma analogia entre um algoritmo de amostragem e a física estatística (statistical physics um ramo da física que tem sua base em mecânica estatística statistical mechanics). O algoritmo foi descrito pelos irmãos Stuart e Donald Geman (figura 9) em 1984 (Geman & Geman, 1984), cerca de oito décadas após a morte de Gibbs.\n\n\n\nFigure 9: Da esquerda para direita: Josiah Gibbs,Stuart Geman e Donald Geman – Figuras de https://www.wikipedia.org\n\n\n\nO algoritmo de Gibbs é muito útil em espaços amostrais multidimensionais (no qual há bem mais que 2 parâmetros a serem amostrados da probabilidade posterior). Também é conhecido como amostragem condicional alternativa (alternating conditional sampling), pois amostramos sempre um parâmetro condicionado à probabilidade dos outros parâmetros do modelo.\nO algoritmo de Gibbs pode ser visto como um caso especial do algoritmo de Metropolis-Hastings porque todas as propostas são aceitas (Gelman, 1992).\nAlgoritmo de Gibbs\nA essência do algoritmo de Gibbs é a amostragem de parâmetros condicionada à outros parâmetros \\(P(\\theta_1 | \\theta_2, \\dots \\theta_n)\\).\nO algoritmo de Gibbs pode ser descrito na seguinte maneira6 (\\(\\theta\\) é o parâmetro, ou conjunto de parâmetros, de interesse e \\(y\\) são os dados):\nDefina \\(p(\\theta_1), p(\\theta_2), \\dots, p(\\theta_n)\\): a probabilidade prévia (prior) de cada um dos parâmetros \\(\\theta_n\\).\nAmostre um ponto inicial \\(\\theta^0_1, \\theta^0_2, \\dots, \\theta^0_n\\). Geralmente amostramos de uma distribuição normal ou de uma distribuição especificada como a distribuição prévia (prior) de \\(\\theta_n\\).\nPara \\(t = 1,2,\\dots\\):\n\\[\\begin{aligned}\n \\theta^t_1 &\\sim p(\\theta_1 | \\theta^0_2, \\dots, \\theta^0_n) \\\\\n \\theta^t_2 &\\sim p(\\theta_2 | \\theta^{t-1}_1, \\dots, \\theta^0_n) \\\\\n &\\vdots \\\\\n \\theta^t_n &\\sim p(\\theta_n | \\theta^{t-1}_1, \\dots, \\theta^{t-1}_{n-1})\n \\end{aligned}\\]\nLimitações do Algoritmo de Gibbs\nA principal limitação do algoritmo de Gibbs é com relação a amostragem condicional alternativa.\nSe compararmos com o algoritmo Metropolis (e consequentemente Metropolis-Hastings) temos propostas aleatórias de uma distribuição de propostas na qual amostramos cada parâmetro incondicionalmente à outros parâmetros. Para que as propostas nos levem a locais corretos da probabilidade posterior para amostrarmos temos uma regra de aceitação/rejeição dessas propostas, se não as amostras do algoritmo de Metropolis não se aproximariam à distribuição-alvo de interesse. As mudanças de estado da corrente Markov são então executadas multidimensionalmente7. Como você viu nas figuras 6, 7 e 8 de intuição visual do algoritmo de Metropolis, em um espaço 2-D (como é o nosso exemplo didático bivariado normal), quando há uma mudança de estado na corrente Markov, o novo local de proposta considera tanto \\(\\theta_1\\) quanto \\(\\theta_2\\), provocando uma movimentação na diagonal no espaço amostral 2-D.\nNo caso do algoritmo de Gibbs, no nosso exemplo, essa movimentação se dá apenas em um único parâmetro, pois amostramos sequencialmente e condicionalmente à outros parâmetros. Isto provoca movimentos horizontais (no caso de \\(\\theta_1\\)) e movimentos verticais (no caso de \\(\\theta_2\\)), mas nunca movimentos diagonais como o que vemos no algoritmo de Metropolis.\nGibbs – Implementação\nO Stan (Carpenter et al., 2017) (e consequentemente seu ecossistema inteiro de pacotes) não tem implementações de outros algoritmos a não ser o HMC (Hamiltonian Monte Carlo), portanto abaixo criei um amostrador Gibbs para o nosso exemplo didático.\nAqui temos algumas coisas novas comparando com a implementação do amostrador Metropolis. Primeiro para amostrar condicionalmente os parâmetros \\(P(\\theta_1 | \\theta_2)\\) e \\(P(\\theta_2 | \\theta_1)\\), precisamos criar duas variáveis novas beta (\\(\\beta\\)) e lambda (\\(\\lambda\\)). Essas variáveis representam a correlação entre \\(X\\) e \\(Y\\) (\\(\\theta_1\\) e \\(\\theta_2\\) respectivamente). E então usamos essas variáveis na amostragem de \\(\\theta_1\\) e \\(\\theta_2\\):\n\\[\n\\begin{aligned}\n\\beta &= \\rho \\cdot \\frac{\\sigma_Y}{\\sigma_X} = \\rho \\\\\n\\lambda &= \\rho \\cdot \\frac{\\sigma_X}{\\sigma_Y} = \\rho \\\\\n\\sigma_{YX} &= 1 - \\rho^2\\\\\n\\sigma_{XY} &= 1 - \\rho^2\\\\\n\\theta_1 &\\sim \\text{Normal} \\bigg( \\mu_X + \\lambda \\cdot (y^* - \\mu_Y), \\sigma_{XY} \\bigg) \\\\\n\\theta_2 &\\sim \\text{Normal} \\bigg( \\mu_y + \\beta \\cdot (x^* - \\mu_X), \\sigma_{YX} \\bigg).\n\\end{aligned}\n\\]\n\n\ngibbs <- function(S,\n                  mu_X = 0, mu_Y = 0,\n                  sigma_X = 1, sigma_Y = 1,\n                  rho,\n                  start_x, start_y,\n                  seed = 123) {\n   set.seed(seed)\n   Sigma <- diag(2)\n   Sigma[1, 2] <- rho\n   Sigma[2, 1] <- rho\n   draws <- matrix(nrow = S, ncol = 2)\n   x <- start_x\n   y <- start_y\n   beta <- rho * sigma_Y / sigma_X\n   lambda <- rho * sigma_X / sigma_Y\n   sqrt1mrho2 <- sqrt(1 - rho^2)\n   sigma_YX <- sigma_Y * sqrt1mrho2\n   sigma_XY <- sigma_X * sqrt1mrho2\n   draws[1, 1] <- x\n   draws[1, 2] <- y\n   for (s in 2:S) {\n     if (s %% 2 == 0) {\n        y <- rnorm(1, mu_Y + beta * (x - mu_X), sigma_YX)\n     }\n     else {\n        x <- rnorm(1, mu_X + lambda * (y - mu_Y), sigma_XY)\n     }\n     draws[s, 1] <- x\n     draws[s, 2] <- y\n   }\n   return(draws)\n}\n\n\n\nVamos executar nosso algoritmo Gibbs com 10,000 iterações.\n\n\nX_gibbs <- gibbs(\n  S = n_sim,\n  mu_X = 0, mu_Y = 0,\n  sigma_X = 1, sigma_Y = 1,\n  rho = r,\n  start_x = -2.5, start_y = 2.5\n)\nhead(X_gibbs, 7)\n\n\n      [,1]  [,2]\n[1,] -2.50  2.50\n[2,] -2.50 -2.34\n[3,] -2.01 -2.34\n[4,] -2.01 -0.67\n[5,] -0.49 -0.67\n[6,] -0.49 -0.32\n[7,]  0.77 -0.32\n\nNa nossa primeira execução do algoritmo Gibbs temos como resultado uma matriz X_gibbs com 10,000 linhas e 2 colunas (as mesmas condições já mostradas no exemplo anterior com algoritmo Metropolis).\n\n\nres <- monitor(X_gibbs, digits_summary = 1)\n\n\nInference for the input samples (2 chains: each with iter = 10000; warmup = 5000):\n\n     Q5 Q50 Q95 Mean SD  Rhat Bulk_ESS Tail_ESS\nV1 -1.7   0 1.6    0  1     1     1156     1972\n\nFor each parameter, Bulk_ESS and Tail_ESS are crude measures of \neffective sample size for bulk and tail quantities respectively (an ESS > 100 \nper chain is considered good), and Rhat is the potential scale reduction \nfactor on rank normalized split chains (at convergence, Rhat <= 1.05).\n\nneff <- res[, \"n_eff\"]\nreff <- mean(neff / (nrow(X_gibbs) / 2)) #  23.2%\n\n\n\nVejam que o número de amostras eficientes em relação ao número total de iterações reff8 é 23% para todas as iterações incluindo warm-up. A eficiência do algoritmo Gibbs, no nosso exemplo didático, é o mais que dobro da eficiência do algoritmo de Metropolis (9,5% vs 23%).\nGibbs – Intuição Visual\nA animação na figura 10 mostra as 100 primeiras simulações do algoritmo Gibbs usado para gerar X_gibbs. Vejam que aqui não há movimentação na diagonal no espaço amostral devido à amostragem condicional alternativa dos parâmetros \\(\\theta_1\\) e \\(\\theta_2\\). A movimentação do algoritmo Gibbs no espaço amostral está condicionada a apenas um movimento por dimensão de parâmetro (que no nosso exemplo didático 2-D são as dimensões horizontais \\(\\theta_1\\) e verticais \\(\\theta_2\\)).\n\n\ndf100 <- data.frame(\n    id = rep(1, 100),\n    iter = 1:100,\n    th1 = X_gibbs[1:100, 1],\n    th2 = X_gibbs[1:100, 2],\n    th1l = c(X_gibbs[1, 1], X_gibbs[1:(100 - 1), 1]),\n    th2l = c(X_gibbs[1, 2], X_gibbs[1:(100 - 1), 2])\n)\n\nlabs1 <- c(\"Amostras\", \"Iterações do Algoritmo\", \"90% HPD\")\n\nind1 <- (1:50) * 2 - 1\ndf100s <- df100\ndf100s[ind1 + 1, 3:4] <- df100s[ind1, 3:4]\np1 <- ggplot() +\n  geom_point(data = df100s,\n             aes(th1, th2, group = id, color = \"1\")) +\n  geom_segment(data = df100, aes(x = th1, xend = th1l, color = \"2\",\n                                 y = th2, yend = th2l)) +\n  stat_ellipse(data = dft, aes(x = X1, y = X2, color = \"3\"), level = 0.9) +\n  coord_cartesian(xlim = c(-3, 3), ylim = c(-3, 3)) +\n  labs(\n    title = \"Gibbs\", subtitle = \"100 Amostragens Iniciais\",\n    x = expression(theta[1]), y = expression(theta[2])) +\n  scale_color_manual(values = c(\"red\", \"forestgreen\", \"blue\"), labels = labs1) +\n  guides(color = guide_legend(override.aes = list(\n    shape = c(16, NA, NA), linetype = c(0, 1, 1)))) +\n  theme(legend.position = \"bottom\", legend.title = element_blank())\n\nanimate(p1 +\n  transition_reveal(along = iter) +\n  shadow_trail(0.01),\n  # animation options\n  height = 7, width = 7, units = \"in\", res = 300\n)\n\n\n\n\nFigure 10: Animação Gibbs\n\n\n\nNa figura 11 é possível ver como ficaram as primeiras 1.000 simulações excluindo 1.000 iterações iniciais como warmup.\n\n\n# Take all the 10,000 observations after warmup of 1,000\nwarm <- 1e3\ndfs <- data.frame(\n  th1 = X_gibbs[(warm + 1):nrow(X_gibbs), 1],\n  th2 = X_gibbs[(warm + 1):nrow(X_gibbs), 2]\n)\n\nlabs2 <- c(\"Amostras\", \"90% HPD\")\n\nggplot() +\n  geom_point(data = dfs[1:1000, ],\n             aes(th1, th2, color = \"1\"), alpha = 0.3) +\n  stat_ellipse(data = dft, aes(x = X1, y = X2, color = \"2\"), level = 0.9) +\n  coord_cartesian(xlim = c(-3, 3), ylim = c(-3, 3)) +\n  labs(\n    title = \"Gibbs\", subtitle = \"1.000 Amostragens Iniciais\",\n    x = expression(theta[1]), y = expression(theta[2])) +\n  scale_color_manual(values = c(\"steelblue\", \"blue\"), labels = labs2) +\n  guides(color = guide_legend(override.aes = list(\n    shape = c(16, NA), linetype = c(0, 1), alpha = c(1, 1)))) +\n  theme(legend.position = \"bottom\", legend.title = element_blank())\n\n\n\n\nFigure 11: Primeiras 1.000 simulações Gibbs após descarte de 1.000 iterações como warmup\n\n\n\nE na figura 12 é possível ver as restantes 9.000 simulações excluindo 1.000 iterações iniciais como warmup.\n\n\n# Show all 10,000 samples\nggplot() +\n  geom_point(data = dfs,\n             aes(th1, th2, color = \"1\"), alpha = 0.3) +\n  stat_ellipse(data = dft, aes(x = X1, y = X2, color = \"2\"), level = 0.9) +\n  coord_cartesian(xlim = c(-3, 3), ylim = c(-3, 3)) +\n  labs(\n    title = \"Gibbs\", subtitle = \"10.000 Amostragens\",\n    x = expression(theta[1]), y = expression(theta[2])) +\n  scale_color_manual(values = c(\"steelblue\", \"blue\"), labels = labs2) +\n  guides(color = guide_legend(override.aes = list(\n    shape = c(16, NA), linetype = c(0, 1), alpha = c(1, 1)))) +\n  theme(legend.position = \"bottom\", legend.title = element_blank())\n\n\n\n\nFigure 12: 9.000 simulações Gibbs após descarte de 1.000 iterações como warmup\n\n\n\nO que acontece quando rodamos correntes Markov em paralelo?\nComo as correntes Markov são independentes, podemos executá-las em paralelo no computador. A chave para isso é definir pontos iniciais diferentes de cada corrente Markov (caso você use como ponto inicial uma amostra de uma distribuição prévia dos parâmetros isto não é um problema). Vamos usar o mesmo exemplo didático de uma distribuição normal bivariada \\(X\\) e \\(Y\\) que usamos nos exemplos anteriores, mas agora com 4 correntes Markov com diferentes pontos de início.\n\n\nstarts <- list(c(-2.5, 2.5),\n               c(2.5, -2.5),\n               c(-2.5, -2.5),\n               c(2.5, 2.5)\n               )\n\n\n\nCorrentes Markov em Paralelo – Metropolis\nPara criar 4 correntes Markov com pontos diferentes de início dos parâmetros, usamos 4 vezes o amostrador Metropolis que codificamos anterior, mas agora passamos diferentes argumentos start_x e start_y, além de diferentes seed do pseudogerador de número aleatórios para termos diferentes comportamentos das correntes Markov. Todo o resultado é combinado em um dataframe com uma coluna id representando o número de cada corrente (de 1 a 4).\n\n\nlibrary(dplyr)\nn_sim <- 100\nXs_met <- bind_rows(\n  as_tibble(metropolis(S = n_sim, half_width = 2.75,\n                       mu_X = 0, mu_Y = 0,\n                       sigma_X = 1, sigma_Y = 1,\n                       rho = r,\n                       start_x = -2.5, start_y = 2.5,\n                       seed = 1)),\n  as_tibble(metropolis(S = n_sim, half_width = 2.75,\n                       mu_X = 0, mu_Y = 0,\n                       sigma_X = 1, sigma_Y = 1,\n                       rho = r,\n                       start_x = 2.5, start_y = -2.5,\n                       seed = 2)),\n  as_tibble(metropolis(S = n_sim, half_width = 2.75,\n                       mu_X = 0, mu_Y = 0,\n                       sigma_X = 1, sigma_Y = 1,\n                       rho = r,\n                       start_x = -2.5, start_y = -2.5,\n                       seed = 3)),\n  as_tibble(metropolis(S = n_sim, half_width = 2.75,\n                       mu_X = 0, mu_Y = 0,\n                       sigma_X = 1, sigma_Y = 1,\n                       rho = r,\n                       start_x = 2.5, start_y = 2.5,\n                       seed = 4)),\n  .id = \"chain\")\n\n\n[1] \"Taxa de aceitação 0.28\"\n[1] \"Taxa de aceitação 0.19\"\n[1] \"Taxa de aceitação 0.29\"\n[1] \"Taxa de aceitação 0.15\"\n\nVejam que aqui não estamos interessados em muitas iterações, portanto cada corrente Markov amostrará 100 amostras dando um total de 400 amostras.\nHouveram algumas mudanças significativas na taxa de aprovação das propostas Metropolis. Todas ficaram em torno de 15%-29%, isso é por conta do baixo número de amostras (100), caso as amostras fosse maiores veremos esses valores convergirem para próximo de 20% conforme o exemplo anterior de 10.000 amostras com uma única corrente. errores Na figura 13 é possível ver as 4 correntes Markov do algoritmo de Metropolis explorando o espaço amostral.\n\n\ndfs100_met <- Xs_met %>%\n  group_by(chain) %>%\n  transmute(\n    chain,\n    iter = 1:n_sim,\n    th1 = V1,\n    th2 = V2,\n    th1l = dplyr::lag(V1, default = V1[1]),\n    th2l = dplyr::lag(V2, default = V2[1])\n  ) %>%\n  ungroup()\np1 <- ggplot(dfs100_met) +\n  geom_jitter(width = 0.05, height = 0.05,\n              aes(th1, th2, group = chain, color = chain), alpha = 0.3) +\n  geom_segment(aes(x = th1, xend = th1l, y = th2, yend = th2l,\n                   color = chain)) +\n  #geom_point(aes(x = th1, y = th2, color = chain)) +\n  stat_ellipse(data = dft, aes(x = X1, y = X2), color = \"black\", level = 0.9) +\n  coord_cartesian(xlim = c(-3, 3), ylim = c(-3, 3)) +\n  labs(\n    title = \"Metropolis\",subtitle = \"100 Amostragens Iniciais\",\n    x = expression(theta[1]), y = expression(theta[2])) +\n  scale_color_brewer(palette = \"Set1\") +\n  theme(legend.position = \"NULL\")\n\nanimate(p1 +\n          transition_reveal(along = iter) +\n          shadow_trail(0.01),\n        # animation options\n        height = 7, width = 7, units = \"in\", res = 300\n)\n\n\n\n\nFigure 13: Animação Metropolis – 4 correntes Markov em Paralelo\n\n\n\nCorrentes Markov em Paralelo – Gibbs\nSimilar ao exemplo das correntes Markov em paralelo com o algoritmo Metropoli, para criarmos 4 correntes Markov com pontos diferentes de início dos parâmetros, usamos 4 vezes o amostrador Gibbs que codificamos anterior, mas agora passamos diferentes argumentos start_x e start_y, além de diferentes seed do pseudogerador de número aleatórios para termos diferentes comportamentos das correntes Markov. Todo o resultado é combinado em um dataframe com uma coluna id representando o número de cada corrente (de 1 a 4).\n\n\nXs_gibbs <- bind_rows(\n  as_tibble(gibbs(S = n_sim,\n                       mu_X = 0, mu_Y = 0,\n                       sigma_X = 1, sigma_Y = 1,\n                       rho = r,\n                       start_x = -2.5, start_y = 2.5,\n                       seed = 1)),\n  as_tibble(gibbs(S = n_sim,\n                       mu_X = 0, mu_Y = 0,\n                       sigma_X = 1, sigma_Y = 1,\n                       rho = r,\n                       start_x = 2.5, start_y = -2.5,\n                       seed = 2)),\n  as_tibble(gibbs(S = n_sim,\n                       mu_X = 0, mu_Y = 0,\n                       sigma_X = 1, sigma_Y = 1,\n                       rho = r,\n                       start_x = -2.5, start_y = -2.5,\n                       seed = 3)),\n  as_tibble(gibbs(S = n_sim,\n                       mu_X = 0, mu_Y = 0,\n                       sigma_X = 1, sigma_Y = 1,\n                       rho = r,\n                       start_x = 2.5, start_y = 2.5,\n                       seed = 4)),\n  .id = \"chain\")\n\n\n\nVejam que aqui não estamos interessados em muitas iterações, portanto cada corrente Markov amostrará 100 amostras dando um total de 400 amostras.\nNa figura 14 é possível ver as 4 correntes Markov do algoritmo de Gibbs explorando o espaço amostral.\n\n\ndfs100_gibbs <- Xs_gibbs %>%\n  group_by(chain) %>%\n  transmute(\n    chain,\n    iter = 1:n_sim,\n    th1 = V1,\n    th2 = V2,\n    th1l = dplyr::lag(V1, default = V1[1]),\n    th2l = dplyr::lag(V2, default = V2[1])\n  ) %>%\n  ungroup()\np1 <- ggplot(dfs100_gibbs) +\n  geom_point(aes(x = th1, y = th2, group = chain, color = chain)) +\n  geom_segment(aes(x = th1, xend = th1l, y = th2, yend = th2l,\n                   color = chain)) +\n  stat_ellipse(data = dft, aes(x = X1, y = X2), color = \"black\", level = 0.9) +\n  coord_cartesian(xlim = c(-3, 3), ylim = c(-3, 3)) +\n  labs(\n    title = \"Gibbs\", subtitle = \"100 Amostragens Iniciais\",\n    x = expression(theta[1]), y = expression(theta[2])) +\n  scale_color_brewer(palette = \"Set1\") +\n  theme(legend.position = \"NULL\")\n\nanimate(p1 +\n  transition_reveal(along = iter) +\n  shadow_trail(0.01),\n  # animation options\n  height = 7, width = 7, units = \"in\", res = 300\n)\n\n\n\n\nFigure 14: Animação Gibbs – 4 correntes Markov em Paralelo\n\n\n\nHamiltonian Monte Carlo – HMC\nOs problemas de baixas taxas de aceitação de propostas das técnicas de Metropolis e do desempenho baixo do algoritmo de Gibbs em problemas multidimensionais nas quais a topologia da posterior é complexa fizeram com que surgisse uma nova técnica MCMC usando dinâmica Hamiltoniana (em homenagem ao físico irlandês William Rowan Hamilton (1805-1865) figura 15). O nome em inglês dessa técnica é Hamiltonean Monte Carlo – HMC.\n\n\n\nFigure 15: William Rowan Hamilton. Figura de https://www.wikipedia.org\n\n\n\nO HMC é uma adaptação da técnica de Metropolis e emprega um esquema guiado de geração de novas proposta: isso melhora a taxa de aceitação de propostas e, consequentemente, a eficiência. Mais especificamente, o HMC usa o gradiente do log posterior para direcionar a cadeia de Markov para regiões de maior densidade posterior, onde a maioria das amostras são coletadas. Como resultado, uma corrente Markov com o algoritmo HMC bem ajustada aceitará propostas em uma taxa muito mais alta do que o algoritmo Metropolis tradicional (Roberts et al., 1997).\nHMC foi inicialmente descrito na literatura de física Duane, Kennedy, Pendleton, & Roweth (1987) (que chamaram de “hybrid” Monte Carlo – HMC). Logo depois, HMC foi aplicado a problemas estatísticos por Radford M. Neal (1994) (que chamou de Hamiltonean Monte Carlo – HMC). Para uma discussão aprofundada (que não é o foco deste conteúdo) de HMC eu recomendo Radford M. Neal (2011) e Betancourt (2017).\nHMC usa dinâmica Hamiltoniana aplicada para partículas explorando a topologia de uma probabilidade posterior. Em algumas simulações Metropolis possui taxa de aceitação de aproximadamente 23%, enquanto HMC 65% (Gelman et al., 2013b). Além de explorar melhor a topologia da posterior e tolerar topologias complexas, HMC é muito mais eficiente que Metropolis e não sofre do problema de correlação dos parâmetros que Gibbs.\nPara cada componente \\(\\theta_j\\), o HMC adiciona uma variável de momento \\(\\phi_j\\). A densidade posterior \\(P(\\theta | y)\\) é incrementada por uma distribuição independente \\(P(\\phi)\\) dos momentos, definindo assim uma distribuição conjunta:\n\\[\nP(\\theta, \\phi | y) = P(\\phi) \\cdot P(\\theta|y)\n\\]\nO HMC usa uma distribuição de propostas que muda dependendo do estado atual na corrente Markov. O HMC descobre a direção em que a distribuição posterior aumenta, chamada de gradiente, e distorce a distribuição de propostas em direção ao gradiente. No algoritmo de Metropolis, a distribuição das propostas seria uma distribuição Normal (geralmente) centrada na posição atual, de modo que saltos acima ou abaixo da posição atual teriam a mesma probabilidade de serem propostos. Mas o HMC gera propostas de maneira bem diferente.\nVocê pode imaginar que para distribuições posteriores de alta dimensão que têm vales diagonais estreitos e até mesmo vales curvos, a dinâmica do HMC encontrará posições propostas que são muito mais promissoras do que uma distribuição de proposta simétrica ingênua, e mais promissoras do que a amostragem de Gibbs, que pode obter preso em paredes diagonais.\nA probabilidade da corrente Markov mudar de estado no algoritmo HMC é definida como:\n\\[\nP_{\\text{mudar}} = \\min\\left({\\frac{P(\\theta_{\\text{proposto}}) \\cdot P(\\phi_{\\text{proposto}})}{P(\\theta_{\\text{atual}})\\cdot P(\\phi_{\\text{atual}})}}, 1\\right),\n\\]\nonde \\(\\phi\\) é o momento.\nDistribuição dos Momentos – \\(P(\\phi)\\)\nNormalmente damos a \\(\\phi\\) uma distribuição normal multivariada com média 0 e covariância de \\(\\mathbf{M}\\), uma “matriz de massa.” Para mantêr as coisas um pouco mais simples, usamos uma matriz de massa diagonal \\(\\mathbf{M}\\). Isso faz com que os componentes de \\(\\phi\\) sejam independentes com \\(\\phi_j \\sim \\text{Normal}(0, M_{jj})\\)\nAlgoritmo de HMC\nO algoritmo de HM é bem similar ao algoritmo Metropolis mas com a inclusão do momento \\(\\phi\\) como uma maneira de quantificar o gradiente da posterior.\nAmostre \\(\\phi\\) de uma \\(\\text{Normal}(0,\\mathbf{M})\\)\nSimultaneamente amostre \\(\\theta\\) e \\(\\phi\\) com \\(L\\) leapfrog steps (não sei como traduzir isso, talvez múltiplos passos) cada um reduzido por um fator \\(\\epsilon\\). Em um leapfrog step, tanto \\(\\theta\\) quanto \\(\\phi\\) são alterados, um em relação ao outro. Repita os seguintes passos \\(L\\) vezes:\nUse o gradiente do log da posterior9 de \\(\\theta\\) para produzir um meio-salto(half-step) de \\(\\phi\\):\n\\[\\phi \\leftarrow \\phi + \\frac{1}{2} \\epsilon \\frac{d \\log p(\\theta | y)}{d \\theta}\\]\nUse o vetor de momentos \\(\\phi\\) para atualizar o vetor de parâmetros \\(\\theta\\):\n\\[\\theta \\leftarrow \\theta + \\epsilon \\mathbf{M}^{-1} \\phi\\]\nNovamente use o gradiente de \\(\\theta\\) para produzir um meio-salto(half-step) de \\(\\phi\\):\n\\[\\phi \\leftarrow \\phi + \\frac{1}{2} \\epsilon \\frac{d \\log p(\\theta | y)}{d \\theta}\\]\n\nDesigne \\(\\theta^{t-1}\\) e \\(\\phi^{t-1}\\) como os valores do vetor de parâmetros e do vetor de momentos, respectivamente, no início do processo de leapfrog (etapa 2) e \\(\\theta^*\\) e \\(\\phi^*\\) como os valores após \\(L\\) passos. Como regra de aceitação/rejeição calcule:\n\\[r = \\frac{p(\\theta^* | y) p(\\phi^*)}{p(\\theta^{t-1} | y) p(\\phi^{-1})}\\]\nDesigne:\n\\[\\theta^t\n \\begin{cases}\n \\theta^* & \\text{with probability min($r$,1)} \\\\\n \\theta^{t-1} & \\text{caso contrário}\n \\end{cases}\\]\nHMC – Implementação\nPara HMC, não vou codificar o algoritmo na mão, pois envolve derivadas que não vai ser muito eficiente no R. Para isso temos o Stan. O arquivo hmc.rds possui 1.000 amostragens com um leapfrog \\(L = 40\\), então no total são 40.001 iterações10. O exemplo é o mesmo que usamos para Metropolis e Gibbs, uma distribuição normal multivariada de \\(X\\) e \\(Y\\) (ambos com média 0 e desvio padrão 1), com correlação 0.8 (\\(\\rho = 0.8\\)):\n\\[\n\\begin{bmatrix}\nX \\\\\nY\n\\end{bmatrix} \\sim \\text{Normal Multivariada} \\left(\n\\begin{bmatrix}\n0 \\\\\n0\n\\end{bmatrix}, \\mathbf{\\Sigma}\n\\right) \\\\\n\\mathbf{\\Sigma} \\sim\n\\begin{pmatrix}\n1 & 0.8 \\\\\n0.8 & 1\n\\end{pmatrix}\n\\]\n\n\nload(here::here(\"R\", \"hmc.RData\"))\ndf <- tibble(id = rep(1, 40000),\n                 iter = rep(1:1000, each = 40),\n                 th1 = tt[1:40000, 1],\n                 th2 = tt[1:40000, 2],\n                 th1l = c(tt[1, 1], tt[1:(40000 - 1), 1]),\n                 th2l = c(tt[1, 2], tt[1:(40000 - 1), 2]))\n\n\n\n\n\nX_hmc <- tt[seq(2, 40001, by = 40), ]\nres <- monitor(X_hmc, digits_summary = 1)\n\n\nInference for the input samples (2 chains: each with iter = 1000; warmup = 500):\n\n     Q5  Q50 Q95 Mean  SD  Rhat Bulk_ESS Tail_ESS\nV1 -1.6 -0.1 1.4 -0.1 0.9     1      604      655\n\nFor each parameter, Bulk_ESS and Tail_ESS are crude measures of \neffective sample size for bulk and tail quantities respectively (an ESS > 100 \nper chain is considered good), and Rhat is the potential scale reduction \nfactor on rank normalized split chains (at convergence, Rhat <= 1.05).\n\nneff <- res[, \"n_eff\"]\nreff <- mean(neff / (nrow(X_hmc))) #  61%!!!\n\n\n\nNa nossa execução do algoritmo HMC temos como resultado uma matriz X_hmc com 100 linhas e 2 colunas (as mesmas condições já mostradas nos exemplos anteriores com algoritmo Metropolis e Gibbs, porém agora somente com 1.000 amostras).\nVejam que o número de amostras eficientes em relação ao número total de iterações reff é 61% para todas as iterações incluindo warm-up (no caso 1 leapfrog step \\(L = 1\\)). A eficiência do algoritmo HMC, no nosso exemplo didático, é o mais que 6x a eficiência do algoritmo de Metropolis (9,5% vs 61%) e quase 3x a eficiência do Gibbs (23% vs 61%).\nHMC – Intuição Visual\nA animação na figura 16 mostra as 50 primeiras simulações do algoritmo HMC usado para gerar X_hmc. Vejam que aqui temos em amarelo temos os leapfrog steps moldandos e distorcendo a distribuição de propostas em direção ao gradiente da posterior (conduzindo-as para áreas de maior probabilidade da posterior) e em vermelho temos as amostras após os 40 leapfrog step \\(L = 40\\) de cada interação. Notem como a exploração da posterior é muito mais eficiente e focada em locais onde realmente a distribuição de interesse possui maior probabilidade.\n\n\nlabs3 <- c(\"Amostras\", \"Iterações do Algoritmo\", \"90% HPD\", \"Leapfrog\")\n# base plot\np0 <- ggplot() +\n  stat_ellipse(data = dft, aes(x = X1, y = X2, color = \"3\"), level = 0.9) +\n  coord_cartesian(xlim = c(-3, 3), ylim = c(-3, 3)) +\n  labs(\n    title = \"HMC\", subtitle = \"50 Amostragens Iniciais\",\n    x = expression(theta[1]), y = expression(theta[2])) +\n  scale_color_manual(values = c(\"red\", \"forestgreen\", \"blue\", \"yellow\"), labels = labs3) +\n  guides(color = guide_legend(override.aes = list(\n    shape = c(16, NA, NA, 16), linetype = c(0, 1, 1, 0)))) +\n  theme(legend.position = \"bottom\", legend.title = element_blank())\n\n# first 100 iterations\ndf50 <- df %>% filter(iter <= 50)\npp <- p0 + geom_point(data = df50,\n                      aes(th1, th2, color = \"4\"), alpha = 0.3, size = 1) +\n  geom_segment(data = df50,\n               aes(x = th1, xend = th1l, color = \"2\", y = th2, yend = th2l),\n               alpha = 0.5) +\n        geom_point(data = df50[seq(1, nrow(df50), by = 40), ],\n                   aes(th1, th2, color = \"1\"), size = 2)\n\nanimate(pp +\n  transition_manual(iter, cumulative = TRUE) +\n  shadow_trail(0.05),\n  # animation options\n  height = 7, width = 7, units = \"in\", res = 300\n)\n\n\n\n\nFigure 16: Animação HMC\n\n\n\nNa figura 17 é possível ver como ficaram as 1.000 simulações excluindo o primeiro leapfrog step \\(L = 1\\) como warmup.\n\n\n# Take all the 1,000 observations after warmup of 1,000\nwarm <- 1\ndfs <- data.frame(\n  th1 = tt[(warm + 1):nrow(tt), 1],\n  th2 = tt[(warm + 1):nrow(tt), 2]\n)\n\nggplot() +\n  geom_point(data = dfs[seq(1, nrow(dfs), by = 40), ],\n             aes(th1, th2, color = \"1\"), alpha = 0.3) +\n  stat_ellipse(data = dft, aes(x = X1, y = X2, color = \"2\"), level = 0.9) +\n  coord_cartesian(xlim = c(-3, 3), ylim = c(-3, 3)) +\n  labs(\n    title = \"HMC\", subtitle = \"1.000 Amostragens\",\n    x = expression(theta[1]), y = expression(theta[2])) +\n  scale_color_manual(values = c(\"steelblue\", \"blue\"), labels = labs2) +\n  guides(color = guide_legend(override.aes = list(\n    shape = c(16, NA), linetype = c(0, 1), alpha = c(1, 1)))) +\n  theme(legend.position = \"bottom\", legend.title = element_blank())\n\n\n\n\nFigure 17: 1.000 simulações HMC após descarte da primeira iteração como warmup\n\n\n\nHMC – Geometrias Complexas\nHá casos que HMC será muito melhor que Metropolis ou Gibbs. Em especial, esses casos se concentram em geometrias complicadas e de difícil exploração. Nesses contextos um algoritmo que consiga guiar as propostas para regiões de maior densidade (como é o caso do HMC) consegue explorar de maneira muito mais eficiente (menos iterações para convergência) e eficaz (maior taxa de aceitação das propostas).\nVeja na figura 18 um exemplo de uma posterior bimodal (destaque para o histograma marginal de \\(X\\) e \\(Y\\)):\n\\[\nX = \\text{Normal} \\left(\n\\begin{bmatrix}\n10 \\\\\n2\n\\end{bmatrix},\n\\begin{bmatrix}\n1 & 0 \\\\\n0 & 1\n\\end{bmatrix}\n\\right), \\quad\nY = \\text{Normal} \\left(\n\\begin{bmatrix}\n0 \\\\\n0\n\\end{bmatrix},\n\\begin{bmatrix}\n8.4 & 2.0 \\\\\n2.0 & 1.7\n\\end{bmatrix}\n\\right).\n\\]\n\n\nlibrary(ggExtra)\ncomponents <- sample(1:2, prob = c(0.5, 0.5), size = N, replace = TRUE)\n\nmus_1 <- c(10, 2)\nsds_1 <- sqrt(c(1, 1))\nsamples_1 <- rnorm(n = N, mean = mus_1[components], sd = sds_1[components])\n\n\nmus_2 <- c(0, 0)\nsds_2 <- sqrt(c(8.4, 1.7))\nsamples_2 <- rnorm(n = N, mean = mus_2[components], sd = sds_2[components])\n\ndft_bimodal <- data.frame(samples_1, samples_2)\n\np4 <- ggplot(dft_bimodal, aes(samples_1, samples_2)) +\n  geom_point() +\n  labs(title = \"Multivariada Normal\",\n           subtitle = \"Mistura de uma Normal Bimodal com uma Normal com cauda longa\",\n           caption = \"10.000 simulações\",\n           x = expression(X), y = expression(Y)) +\n      theme(legend.position = \"NULL\")\nggMarginal(p4, type = \"density\")\n\n\n\n\nFigure 18: Gráfico de Densidade de uma distribuição Multivariada Normal com Multimodalidade\n\n\n\nE para finalizar um exemplo do funil de Neal (Radford M. Neal, 2003) na figura 19. Essa é uma posterior bem difícil de ser amostrada até mesmo para HMC, pois ela varia de geometria nas dimensões \\(X\\) e \\(Y\\). Isso faz com que o amostrador HMC tenha que toda hora trocar o leapfrog steps \\(L\\) e o fator \\(\\epsilon\\), pois na parte superior da imagem (o topo do funil) são necessários um valor de \\(L\\) grande e \\(\\epsilon\\) um valor pequeno; e na parte de baixo (no fundo do funil) o contrário: \\(L\\) pequeno e \\(\\epsilon\\) grande.\n\n\ny <- rnorm(N, 0, 3)\nx <- rnorm(N, 0, exp(y / 2))\ndft_funnel <- data.frame(x, y)\n\nggplot(dft_funnel, aes(x, y)) +\n  geom_point() +\n  labs(title = \"Funil de Neal\",\n           caption = \"10.000 simulações\",\n           x = expression(X), y = expression(Y)) +\n      theme(legend.position = \"NULL\")\n\n\n\n\nFigure 19: Gráfico de Densidade do Funil de Neal\n\n\n\n“Não entendi nada…”\nSe você não entendeu nada até agora, não se desespere. Pule todas as fórmulas e pegue a intuição visual dos algoritmos. Veja as limitações de Metropolis e Gibbs e compare as animações e figuras com as do HMC. A superioridade de eficiência (mais amostras com baixa autocorrelação) e eficácia (mais amostras próximas das áreas de maior probabilidade da distribuição-alvo) é autoexplicativa pelas imagens.\nAlém disso, você provavelmente nunca terá que codificar o seu algoritmo HMC (Gibbs, Metropolis ou qualquer outro MCMC) na mão. Para isso há pacotes como Stan (e seu ecossistema de pacotes: rstan, PyStan, brms, rstanarm, Stan.jl etc.). Além disso, Stan implementa um HMC modificado com uma técnica chamada No-U-Turn Sampling (NUTS)11 (Hoffman & Gelman, 2011) que seleciona automaticamente os valores de \\(\\epsilon\\) (fator de redução) e \\(L\\) (quantidade de leapfrog steps).12 O desempenho do HMC é altamente sensível à esses dois “hiperparâmetros” (parâmetros que devem ser especificados pelo usuário). Em particular, se \\(L\\) for muito pequeno, o algoritmo exibe comportamento indesejável de um passeio aleatório, enquanto se \\(L\\) for muito grande, o algoritmo desperdiça eficiência computacional. NUTS usa um algoritmo recursivo para construir um conjunto de pontos candidatos prováveis que abrangem uma ampla faixa da distribuição de propostas, parando automaticamente quando começa a voltar e refazer seus passos (por isso que ele não dá meia-volta – No U-turn), adicionalmente NUTS também calibra automaticamente (e de maneira simultânea) \\(L\\) e \\(\\epsilon\\).\nImplementação com o rstanarm\nComo configuração padrão, o pacote rstanarm utiliza HMC com NUTS. Além disso, os argumentos padrões do HMC no rstanarm são:\n4 correntes Markov de amostragem (chains = 4); e\n2.000 iterações de cada corrente (iter = 2000)13.\nRelembrando o exemplo da aula de regressão linear, vamos usar o mesmo dataset kidiq. São dados de uma survey de mulheres adultas norte-americanas e seus respectivos filhos. Datado de 2007 possui 434 observações e 4 variáveis:\nkid_score: QI da criança;\nmom_hs: binária (0 ou 1) se a mãe possui diploma de ensino médio;\nmom_iq: QI da mãe; e\nmom_age: idade da mãe.\nVamos estimar um modelo de regressão linear Bayesiano na qual a variável dependente é kid_score e as independentes são mom_hs e mom_iq.\nO modelo é o especificado da seguinte maneira:\n\\[\n\\begin{aligned}\n\\alpha &\\sim \\text{Normal}(\\mu_y, s_y) \\\\\n\\beta_k &\\sim \\text{Normal}(0, 2.5 \\cdot \\frac{s_y}{s_x}) \\\\\n\\sigma &\\sim \\text{Exponencial}(\\frac{1}{s_y})\\\\\ny &\\sim \\text{Normal}(\\alpha + \\beta_1 x_1 + \\dots + \\beta_K x_K, \\sigma),\n\\end{aligned}\n\\]\nonde \\(s_x = \\tt{sd(x)}\\), \\[\ns_y =\n\\begin{cases}\n\\tt{sd(y)} & \\text{se } \\tt{family = gaussian}, \\\\\n1 & \\text{caso contrário}.\n\\end{cases}\n\\] e \\[\n\\mu_y =\n\\begin{cases}\n\\tt{mean(y)} & \\text{se } \\tt{family = gaussian}, \\\\\n0 & \\text{caso contrário}.\n\\end{cases}\n\\]\nNo caso temos apenas duas variáveis independentes, então \\(K=2\\) e \\(\\beta_1 = \\tt{mom\\_hs}\\) e \\(\\beta_2 = \\tt{mom\\_iq}\\); variável dependente \\(y = \\tt{kid\\_score}\\) e o erro do modelo \\(\\sigma = \\tt{sigma}\\). A fórmula do modelo para o rstnarm é kid_score ~ mom_hs + mom_iq.\n\n\noptions(mc.cores = parallel::detectCores())\noptions(Ncpus = parallel::detectCores())\n\nlibrary(rstanarm)\nmodel <- stan_glm(\n  kid_score ~ mom_hs + mom_iq,\n  data = kidiq\n)\n\n\n\nMétricas da simulação MCMC\nUm modelo estimado pelo rstanarm pode ser inspecionado em relação ao desempenho da amostragem MCMC. Ao chamarmos a função summary() no modelo estimado há uma parte chamada MCMC diagnostics.\n\n\nsummary(model)\n\n\n\nModel Info:\n function:     stan_glm\n family:       gaussian [identity]\n formula:      kid_score ~ mom_hs + mom_iq\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 434\n predictors:   3\n\nEstimates:\n              mean   sd   10%   50%   90%\n(Intercept) 25.7    5.9 18.2  25.7  33.3 \nmom_hs       6.0    2.2  3.1   6.0   8.9 \nmom_iq       0.6    0.1  0.5   0.6   0.6 \nsigma       18.2    0.6 17.4  18.2  19.0 \n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 86.8    1.2 85.2  86.8  88.4 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.1  1.0  5120 \nmom_hs        0.0  1.0  4168 \nmom_iq        0.0  1.0  4811 \nsigma         0.0  1.0  4747 \nmean_PPD      0.0  1.0  4306 \nlog-posterior 0.0  1.0  1778 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nA seção MCMC diagnostics possui três colunas de valores para cada parâmetro estimado do modelo.\nNo nosso caso, temos três parâmetros importantes:\nvalor do coeficiente da variável mom_hs;\nvalor do coeficiente da variável mom_iq; e\nvalor do erro residual do modelo linear sigma. As três métricas são:\nmcse: Monte Carlo Standard Error, o erro de mensuração da amostragem Monte Carlo do parâmetro;\nn_eff: uma aproximação crua do número de amostras efetivas amostradas pelo MCMC estimada pelo valor de Rhat; e\nRhat: uma métrica de convergência e estabilidade da corrente Markov.\nA métrica mais importante para levarmos em consideração é a Rhat que é uma métrica que mensura se as correntes Markov são estáveis e convergiram para um valor durante o progresso total das simulações. Ela é basicamente a proporção de variação ao compararmos duas metades das correntes após o descarte dos warmups. Valor de 1 implica em convergência e estabilidade. Como padrão o Rhat deve ser menor que 1.01 para que a estimação Bayesiana seja válida (S. P. Brooks & Gelman, 1998; Gelman & Rubin, 1992).\nO que fazer se não obtermos convergência?\nDependendo do modelo e dos dados é possível que HMC (mesmo com NUTS) não atinja convergência. Nesse caso, ao rodar o modelo rstanarm dará diversos avisos de divergências. Aqui vou restringir o amostrador HMC do rstanarm para apenas 200 iterações com warmup padrão de metade das iterações (100) com duas correntes em paralelo (chains). Portanto, teremos \\(2 \\cdot (200 - 100) = 200\\) amostras de MCMC. Se atente as mensagens de erro.\n\n\nbad_model <- stan_glm(\n  kid_score ~ mom_hs + mom_iq,\n  data = kidiq,\n  chains = 2,\n  iter = 200\n  )\n\n\nWarning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.\nRunning the chains for more iterations may help. See\nhttp://mc-stan.org/misc/warnings.html#bulk-ess\nWarning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.\nRunning the chains for more iterations may help. See\nhttp://mc-stan.org/misc/warnings.html#tail-ess\n\n\n\n\nEsta é uma vantagem dos pacotes do ecossistema do Stan (incluindo rstanarm e brms). Quando o amostrador MCMC mostra problemas ele falha de uma maneira bem escandalosa com diversos avisos. Nunca ignore esses avisos, eles estão lá para te ajudar e indicar que seu modelo possui problemas sérios que devem ser inspecionados e sanados.\nE vemos que o Rhat dos parâmetros estimados do modelo estão bem acima do limiar de \\(1.01\\).\n\n\nsummary(bad_model)\n\n\n\nModel Info:\n function:     stan_glm\n family:       gaussian [identity]\n formula:      kid_score ~ mom_hs + mom_iq\n algorithm:    sampling\n sample:       200 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 434\n predictors:   3\n\nEstimates:\n              mean   sd   10%   50%   90%\n(Intercept) 25.8    6.3 17.8  25.7  33.7 \nmom_hs       5.9    2.2  3.0   5.8   8.8 \nmom_iq       0.6    0.1  0.5   0.6   0.6 \nsigma       18.3    0.6 17.5  18.2  19.1 \n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 86.9    1.3 85.2  86.9  88.2 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.4  1.0  245  \nmom_hs        0.1  1.0  231  \nmom_iq        0.0  1.0  234  \nsigma         0.1  1.0  112  \nmean_PPD      0.1  1.0   78  \nlog-posterior 0.2  1.0   59  \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nGráficos de Diagnósticos do MCMC\nO pacote rstanarm e brms tem diversos gráficos interessantes de diagnósticos de convergência das simulações MCMC. Eu recomendo o fluxo de visualizações de modelos Bayesianos de Gabry, Simpson, Vehtari, Betancourt, & Gelman (2019).\nTraceplot\nA primeira coisa que devemos ver quando há mensagens de avisos sobre divergências ou valores indesejáveis de Rhat é inspecionar as correntes Markov para ver se elas estão estacionárias ou se divergiram durante a amostragem do MCMC. Fazemos isso com a função plot(stanreg, \"trace\"). Objetos stanreg são modelos oriundos do rstanarm. No nosso caso temos dois objetos stanreg: o model e o bad_model.\nO traceplot é a sobreposição das amostragens MCMC das correntes para cada parâmetro estimado (eixo vertical). A ideia é que as correntes se misturam e que não haja nenhuma inclinação ao longo das iterações (eixo horizontal). Isso demonstra que elas convergiram para um certo valor do parâmetro e se mantiveram nessa região durante boa parte (ou toda) da(a) amostragem das correntes Markov.\nDetalhe: o traceplot usa somente as iterações válidas, após a remoção das iterações de warmup.\nVejam na figura 20 o traceplot do modelo que as correntes Markov convergiram e ficaram estacionárias durante a amostragem do MCMC (afinal esse é o modelo model que designamos iter = 2.000 e chains = 4, ambos padrões do rstanarm e brms). O ideal é sempre esse padrão no qual as correntes não apresentam uma tendência específica, ou seja, elas ficam geralmente “planas” na horizontal e não há uma grande variação de valores no eixo vertical (valor dos parâmetros). Esse padrão é muito parecido com “taturana.”\n\n\nplot(model, \"trace\")\n\n\n\n\nFigure 20: Traceplot do model\n\n\n\nNa figura 21 temos o traceplot do modelo que as correntes Markov não convergiram, o bad_model (designamos iter = 200 e chains = 2). Aqui você vê que se aumentarmos o período de warmup e o número de iterações, provavelmente as correntes Markov convergiriam e ficariam estacionárias na região de maior probabilidade da posterior (e, consequentemente, dos parâmetros de interesse).\n\n\nplot(bad_model, \"trace\")\n\n\n\n\nFigure 21: Traceplot do bad_model\n\n\n\nPosterior Predictive Check\nUm bom gráfico de diagnóstico é o posterior predictive check (PPC) que compara o histograma da variável dependente \\(y\\) contra o histograma variáveis dependentes simuladas pelo modelo \\(y_{\\text{rep}}\\) após a estimação dos parâmetros. A ideia é que os histogramas reais e simulados se misturem e não haja divergências. Fazemos isso com a função pp_check(stanreg).\nVejam na figura 22 o PPC do modelo que as correntes Markov convergiram e ficaram estacionárias durante a amostragem do MCMC (model). Podemos ver que as simulações \\(y_{\\text{rep}}\\) realmente capturaram a natureza da variável dependente \\(y\\).\n\n\npp_check(model)\n\n\n\n\nFigure 22: Posterior Preditive Check do model\n\n\n\nJá na na figura 23 temos o PPC do modelo que as correntes Markov não convergiram, o bad_model. Aqui vemos que as simulações \\(y_{\\text{rep}}\\) falharam em capturar a natureza da variável dependente \\(y\\). O PPC do bad_model também indica que se mantivéssemos um periodo maior de warmup e mais iterações das correntes Markov, provavelmente conseguiríamos ter um modelo que representasse muito bem o processo de geração de dados da nossa variável dependente \\(y\\).\n\n\npp_check(bad_model)\n\n\n\n\nFigure 23: Posterior Preditive Check do bad_model\n\n\n\nO quê fazer para convergir suas correntes Markov\nPrimeiro: Antes de fazer ajustes finos no número de correntes chains ou no número de iterações iter (entre outros …) saiba que o amostrador HMC-NUTS do Stan e seu ecossistema de pacotes (rstanarm e brms inclusos) é muito eficiente e eficaz em explorar as mais diversas complexas e “malucas” topologias de distribuições-alvo posterior. Os argumentos padrões (iter = 2000, chains = 4 e warmup = floor(iter/2)) funcionam perfeitamente para 99% dos casos (mesmo em modelos complexos). Dito isto, na maioria das vezes quando você possui problemas de amostragem e computacionais no seu modelo Bayesiano, o problema está na especificação do modelo e não no algoritmo de amostragem MCMC. Esta frase foi dita por Andrew Gelman (o “pai” do Stan) e é conhecido como o Folk Theorem (Gelman, 2008): “When you have computational problems, often there’s a problem with your model”.\nSe o seu modelo Bayesiano está com problemas de convergência há alguns passos que podem ser tentados14. Aqui listados do mais simples para o mais complexo:\nAumentar o número de iterações e correntes: primeira opção é aumentar o número de iterações do MCMC com o argumento iter = XXX e também é possível aumentar o número de correntes com o argumento chains = X. Lembrando que o padrão é iter = 2000 e chains = 4.\nAlterar a rotina de adaptação do HMC: a segunda opção é fazer com que o algoritmo de amostragem HMC fique mais conservador (com proposições de pulos menores). Isto pode ser alterado com o argumento adapt_delta da lista de opções control. control=list(adapt_delta=0.9). O padrão do adapt_delta é control=list(adapt_delta=0.8). Então qualquer valor entre \\(0.8\\) e \\(1.0\\) o torna mais conservador.\nReparametrização do Modelo: a terceira opção é reparametrizar o modelo. Há duas maneiras de parametrizar o modelo: a primeira com parametrização centrada (centered parameterization) e a segunda com parametrização não-centrada (non-centered parameterization). Não são assuntos que vamos cobrir aqui no curso. Recomendo o material de um dos desenvolvedores da linguagem Stan, Michael Betancourt.\nColetar mais dados: às vezes o modelo é complexo demais e precisamos de uma amostragem maior para conseguirmos estimativas estáveis.\nRepensar o modelo: falha de convergência quando temos uma amostragem adequada geralmente é por conta de uma especificação de priors e verossimilhança que não são compatíveis com os dados. Nesse caso, é preciso repensar o processo generativo de dados no qual os pressupostos do modelo estão ancorados.\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.4 (2021-02-15)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n [1] rstanarm_2.21.1      Rcpp_1.0.6           ggExtra_0.9         \n [4] dplyr_1.0.5          patchwork_1.1.1      cowplot_1.1.1       \n [7] rstan_2.21.2         StanHeaders_2.21.0-7 MASS_7.3-53.1       \n[10] ggforce_0.3.3        gganimate_1.0.7      plotly_4.9.3        \n[13] ggplot2_3.3.3       \n\nloaded via a namespace (and not attached):\n  [1] minqa_1.2.4        colorspace_2.0-0   ellipsis_0.3.1    \n  [4] ggridges_0.5.3     rsconnect_0.8.16   rprojroot_2.0.2   \n  [7] markdown_1.1       base64enc_0.1-3    farver_2.1.0      \n [10] DT_0.17            fansi_0.4.2        splines_4.0.4     \n [13] codetools_0.2-18   downlit_0.2.1      mnormt_2.0.2      \n [16] knitr_1.31         shinythemes_1.2.0  polyclip_1.10-0   \n [19] bayesplot_1.8.0    jsonlite_1.7.2     nloptr_1.2.2.2    \n [22] png_0.1-7          shiny_1.6.0        compiler_4.0.4    \n [25] httr_1.4.2         Matrix_1.3-2       assertthat_0.2.1  \n [28] fastmap_1.1.0      lazyeval_0.2.2     cli_2.3.1         \n [31] later_1.1.0.1      tweenr_1.0.2       htmltools_0.5.1.1 \n [34] prettyunits_1.1.1  tools_4.0.4        igraph_1.2.6      \n [37] gtable_0.3.0       glue_1.4.2         reshape2_1.4.4    \n [40] V8_3.4.0           jquerylib_0.1.3    vctrs_0.3.7       \n [43] nlme_3.1-152       crosstalk_1.1.1    xfun_0.22         \n [46] stringr_1.4.0      ps_1.6.0           lme4_1.1-26       \n [49] mime_0.10          miniUI_0.1.1.1     lifecycle_1.0.0   \n [52] gtools_3.8.2       statmod_1.4.35     zoo_1.8-9         \n [55] scales_1.1.1       colourpicker_1.1.0 ragg_1.1.2        \n [58] hms_1.0.0          promises_1.2.0.1   parallel_4.0.4    \n [61] inline_0.3.17      shinystan_2.5.0    RColorBrewer_1.1-2\n [64] yaml_2.2.1         curl_4.3           gridExtra_2.3     \n [67] loo_2.4.1          sass_0.3.1         distill_1.2       \n [70] stringi_1.5.3      highr_0.8          dygraphs_1.1.1.6  \n [73] gifski_1.4.3       boot_1.3-27        pkgbuild_1.2.0    \n [76] rlang_0.4.10       pkgconfig_2.0.3    systemfonts_1.0.1 \n [79] matrixStats_0.58.0 evaluate_0.14      lattice_0.20-41   \n [82] purrr_0.3.4        rstantools_2.1.1   htmlwidgets_1.5.3 \n [85] labeling_0.4.2     processx_3.5.0     tidyselect_1.1.0  \n [88] here_1.0.1         plyr_1.8.6         magrittr_2.0.1    \n [91] R6_2.5.0           magick_2.7.1       generics_0.1.0    \n [94] DBI_1.1.1          pillar_1.5.1       withr_2.4.1       \n [97] xts_0.12.1         survival_3.2-10    tibble_3.1.0      \n[100] crayon_1.4.1       utf8_1.2.1         tmvnsim_1.0-2     \n[103] rmarkdown_2.7      jpeg_0.1-8.1       progress_1.2.2    \n[106] grid_4.0.4         isoband_0.2.4      data.table_1.14.0 \n[109] callr_3.6.0        threejs_0.3.3      digest_0.6.27     \n[112] xtable_1.8-4       tidyr_1.1.3        httpuv_1.5.5      \n[115] textshaping_0.3.3  RcppParallel_5.0.3 stats4_4.0.4      \n[118] munsell_0.5.0      viridisLite_0.3.0  bslib_0.2.4       \n[121] shinyjs_2.0.0     \n\n\n\n\nBetancourt, M. (2017, January 9). A Conceptual Introduction to Hamiltonian Monte Carlo. Retrieved November 6, 2019, from http://arxiv.org/abs/1701.02434\n\n\nBrooks, S., Gelman, A., Jones, G., & Meng, X.-L. (2011). Handbook of Markov Chain Monte Carlo. Retrieved from https://books.google.com?id=qfRsAIKZ4rIC\n\n\nBrooks, S. P., & Gelman, A. (1998). General Methods for Monitoring Convergence of Iterative Simulations. Journal of Computational and Graphical Statistics, 7(4), 434–455. https://doi.org/10.1080/10618600.1998.10474787\n\n\nCarpenter, B., Gelman, A., Hoffman, M. D., Lee, D., Goodrich, B., Betancourt, M., … Riddell, A. (2017). Stan : A Probabilistic Programming Language. Journal of Statistical Software, 76(1). https://doi.org/10.18637/jss.v076.i01\n\n\nCasella, G., & George, E. I. (1992). Explaining the gibbs sampler. The American Statistician, 46(3), 167–174. https://doi.org/10.1080/00031305.1992.10475878\n\n\nChib, S., & Greenberg, E. (1995). Understanding the Metropolis-Hastings Algorithm. The American Statistician, 49(4), 327–335. https://doi.org/10.1080/00031305.1995.10476177\n\n\nDuane, S., Kennedy, A. D., Pendleton, B. J., & Roweth, D. (1987). Hybrid Monte Carlo. Physics Letters B, 195(2), 216–222. https://doi.org/10.1016/0370-2693(87)91197-X\n\n\nEckhardt, R. (1987). Stan Ulam, John von Neumann, and the Monte Carlo Method. Los Alamos Science, 15(30), 131–136.\n\n\nGabry, J., Simpson, D., Vehtari, A., Betancourt, M., & Gelman, A. (2019). Visualization in Bayesian workflow. Journal of the Royal Statistical Society: Series A (Statistics in Society), 182(2), 389–402. https://doi.org/10.1111/rssa.12378\n\n\nGelman, A. (1992). Iterative and Non-Iterative Simulation Algorithms. Computing Science and Statistics (Interface Proceedings), 24, 457–511. PROCEEDINGS PUBLISHED BY VARIOUS PUBLISHERS.\n\n\nGelman, A. (2008). The folk theorem of statistical computing. Retrieved from https://statmodeling.stat.columbia.edu/2008/05/13/the_folk_theore/\n\n\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013a). Basics of Markov Chain Simulation. In Bayesian Data Analysis. Chapman and Hall/CRC.\n\n\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013b). Bayesian Data Analysis. Chapman and Hall/CRC.\n\n\nGelman, A., & Rubin, D. B. (1992). Inference from Iterative Simulation Using Multiple Sequences. Statistical Science, 7(4), 457–472. https://doi.org/10.1214/ss/1177011136\n\n\nGeman, S., & Geman, D. (1984). Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images. IEEE Transactions on Pattern Analysis and Machine Intelligence, PAMI-6(6), 721–741. https://doi.org/10.1109/TPAMI.1984.4767596\n\n\nHastings, W. K. (1970). Monte Carlo sampling methods using Markov chains and their applications. Biometrika, 57(1), 97–109. https://doi.org/10.1093/biomet/57.1.97\n\n\nHoffman, M. D., & Gelman, A. (2011). The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo. Journal of Machine Learning Research, 15(1), 1593–1623. Retrieved from http://arxiv.org/abs/1111.4246\n\n\nMetropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H., & Teller, E. (1953). Equation of State Calculations by Fast Computing Machines. The Journal of Chemical Physics, 21(6), 1087–1092. https://doi.org/10.1063/1.1699114\n\n\nNeal, Radford M. (1994). An Improved Acceptance Procedure for the Hybrid Monte Carlo Algorithm. Journal of Computational Physics, 111(1), 194–203. https://doi.org/10.1006/jcph.1994.1054\n\n\nNeal, Radford M. (2003). Slice Sampling. The Annals of Statistics, 31(3), 705–741. Retrieved from https://www.jstor.org/stable/3448413\n\n\nNeal, Radford M. (2011). MCMC using Hamiltonian dynamics. In S. Brooks, A. Gelman, G. L. Jones, & X.-L. Meng (Eds.), Handbook of markov chain monte carlo.\n\n\nRoberts, G. O., Gelman, A., & Gilks, W. R. (1997). Weak convergence and optimal scaling of random walk Metropolis algorithms. Annals of Applied Probability, 7(1), 110–120. https://doi.org/10.1214/aoap/1034625254\n\n\no símbolo \\(\\propto\\) (\\propto) deve ser lido como “proporcional à.”↩︎\nAlgumas referências chamam esse processo de burnin.↩︎\nCaso queira uma melhor explanação do algoritmo de Metropolis e Metropolis-Hastings sugiro ver Chib & Greenberg (1995)↩︎\ndo ingles probability density function (PDF).↩︎\nobjetos stanfit são objetos resultantes de modelos rstan ou rstanarm.↩︎\nCaso queira uma melhor explanação do algoritmo de Gibbs sugiro ver Casella & George (1992).↩︎\nisto ficará claro nas imagens e animações.↩︎\nVejam que aqui eu propositalmente dividi a neff por nrow(X_gibbs) / 2 (metade do número de iterações). Isso foi necessário, pois da maneira que eu codifiquei o algoritmo Gibbs ele amostra um parâmetro a cada interação e geralmente não se implementa um amostrador Gibbs dessa maneira (amostra-se todos os parâmetros por iteração). Eu fiz de propósito pois quero gerar nos GIFs animados na figura 10 a real trajetória do amostrador Gibbs no espaço amostral (vertical e horizontal, e não diagonal).↩︎\npor questões de transbordamento numérico (numeric overflow) sempre trabalhamos com log de probabilidades.↩︎\n1.000 * 40 = 40.000. Esse 1 a mais é que usei a primeira iteração com Leapfrog \\(L = 1\\) como warmup.↩︎\nNUTS é um algoritmo que usa o integrador simplético leapfrog e constrói uma árvore binária composta por nós de folha que são as simulações de dinâmicas Hamiltonianas usando \\(2^j\\) leapfrog steps nas direções para frente ou para trás no tempo no qual \\(j\\) é o número inteiro representando as iterações da construção da árvore binária. Uma vez que a particula simulada começa a retroceder sua trajetória a construção da árvore é interrompida e o numero ideal de \\(L\\) leapfrog steps é definido como \\(2^j\\) no tempo \\(j-1\\) do começo do retrocesso da trajetória. Então a partícula simulada nunca dá “meia-voltas” por isso No U-turn. Para mais detalhes sobre o algoritmo e como ele se relaciona com as dinâmicas Hamiltoninanas veja Hoffman & Gelman (2011).↩︎\nalém disso, todos os pacotes do ecossistema Stan aplicam uma decomposição QR na matriz \\(X\\) de dados, criando uma base ortogonal (não correlacionada) para amostragem. Isso faz com a distribuição-alvo (posterior) fique muito mais amigável do ponto de vista topológico/geométrico para o amostrador MCMC explorá-la de maneira mais eficiente e eficaz.↩︎\nSendo que, por padrão, Stan e rstanarm descartam a primeira metade (1.000) das iterações como aquecimento (warmup = floor(iter/2)).↩︎\nalém disso, vale a pena ativar a decomposição QR na matriz \\(X\\) de dados, criando uma base ortogonal (não correlacionada) para amostragem. Isso faz com a distribuição-alvo (posterior) fique muito mais amigável do ponto de vista topológico/geométrico para o amostrador MCMC explorá-la de maneira mais eficiente e eficaz. Só você especificar o argumento QR = TRUE dentro da funções do rstanarm, exemplo stan_glm(..., QR = TRUE). Ou, no brms você adicionar o argumento decomp = \"QR\" para qualquer fórmula dentro da função brm().↩︎\n",
      "last_modified": "2021-03-31T14:00:36-03:00"
    },
    {
      "path": "6-Regressao_Linear.html",
      "title": "Regressão Linear Bayesiana",
      "description": "Modelos Lineares Generalizados -- Gaussiano/Normal",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 1, 2021",
      "contents": "\n\nContents\nRegressão Linear\nPosterior Predictive Check\nExemplo - Score de QI de crianças\n\nVariáveis qualitativas\nAtividade Prática\nWHO Life Expectancy\nWine Quality Kaggle Dataset\n\nAmbiente\n\n\n\n“All models are wrong but some are useful”\nBox (1976)\n\nEsta aula começa com uma citação bem provocante do estatístico George Box (figura 1) sobre modelos estatísticos. Sim, todos os modelos de alguma maneira estão errados. Mas eles são muito úteis. A ideia é que a realidade é muito complexa para nós compreendermos ao analisarmos de maneira nua e crua. Precisamos de alguma maneira simplificá-la em componentes individuais e analisar as suas relações. Mas aqui há um perigo: qualquer simplificação da realidade promove perda de informação de alguma maneira. Portanto sempre temos um equilíbrio delicado entre simplificações da realidade por meio de modelos e a inerente perda de informação. Agora você me pergunta: como eles são úteis? Imagine que você está no escuro total e você possui uma lanterna muito potente mas com um foco de iluminação estreito. Você não vai jogar a lanterna fora porque ela não consegue iluminar tudo ao seu redor e ficar no escuro? Você deve usar a lanterna para apontar para locais interessantes da escuridão e iluminá-los. Você nunca achará uma lanterna que ilumine tudo com a clareza que você precisa para analisar todos os detalhes da realidade. Assim como você nunca achará um modelo único que explicará toda a realidade ao seu redor. Você precisa de diferentes lanternas assim como precisa de diferentes modelos. Sem eles você ficará no escuro.\n\n\n\nFigure 1: George Box. Figura de https://www.wikipedia.org\n\n\n\nRegressão Linear\nVamos falar de um classe de modelo conhecido como regressão linear. A ideia aqui é modelar uma variável dependente sendo a combinação linear de variáveis independentes.\n\\[\ny = \\alpha + \\boldsymbol{\\beta} \\mathbf{X} + \\epsilon\n\\]\nSendo que:\n\\(y\\) – variável dependente\n\\(\\alpha\\) – constante (também chamada de intercept)\n\\(\\boldsymbol{\\beta}\\) – vetor de coeficientes\n\\(\\mathbf{X}\\) – matriz de dados\n\\(\\epsilon\\) – erro do modelo\nPara estimar os coeficientes \\(\\boldsymbol{\\beta}\\) usamos uma função de verosimilhança Gaussiana/normal. Matematicamente o modelo de regressão Bayesiano é\n\\[\n\\begin{aligned}\ny &\\sim \\text{Normal}\\left( \\alpha + \\mathbf{X} \\cdot \\boldsymbol{\\beta}, \\sigma \\right) \\\\\n\\alpha &\\sim \\text{Normal}(\\mu_\\alpha, \\sigma_\\alpha) \\\\\n\\boldsymbol{\\beta} &\\sim \\text{Normal}(\\mu_{\\boldsymbol{\\beta}}, \\sigma_{\\boldsymbol{\\beta}}) \\\\\n\\sigma &\\sim \\text{Exponencial}(\\lambda_\\sigma)\n\\end{aligned}\n\\]\nAqui vemos que a função de verosimilhança \\(P(y \\mid \\theta)\\) é uma distribuição normal na qual \\(y\\) depende dos parâmetros do modelo \\(\\alpha\\) e \\(\\boldsymbol{\\beta}\\), além de termos um erro \\(\\sigma\\). Condicionamos \\(y\\) nos dados observados \\(\\mathbf{X}\\) ao inserimos \\(\\alpha + \\mathbf{X} \\cdot \\boldsymbol{\\beta}\\) como o preditor linear do modelo (a média \\(\\mu\\) da função de verosimilhança do modelo). O que falta é especificar quais são as prioris dos parâmetros do modelo:\nDistribuição priori de \\(\\alpha\\) – Conhecimento que temos da constante do modelo\nDistribuição priori de \\(\\boldsymbol{\\beta}\\) – Conhecimento que temos dos coeficientes das variáveis independentes do modelo\nDistribuição priori de \\(\\sigma\\) – Conhecimento que temos sobre o erro do modelo. Importante que o erro pode ser somente positivo. Além disso é intuitivo colocar uma distribuição que dê peso maior para valores próximos de zero, mas que permita também valores distantes de zero, portanto uma distribuição com cauda longa é bem-vinda. Distribuições candidatas são a \\(\\text{Exponencial}\\) que só tem suporte nos numeros reais positivos (então já resolve a questão de erros negativos) ou a \\(\\text{Cauchy}^+\\) truncada para apenas números positivos (lembrando que a distribuição Cauchy é a \\(t\\) de Student com graus de liberdade \\(\\nu = 1\\))\nStan instanciará um modelo bayesiano com os dados fornecidos (\\(y\\) e \\(\\mathbf{X}\\)) e encontrará a distribuição posterior dos parâmetros de interesse do modelo (\\(\\alpha\\) e \\(\\boldsymbol{\\beta}\\)) calculando a distribuição posterior completa de:\n\\[\nP(\\theta \\mid y) = P(\\alpha, \\boldsymbol{\\beta}, \\sigma \\mid y)\n\\]\nPosterior Predictive Check\nLembrando o fluxo de trabalho que discutimos na Aula - Priors ((fig:workflow))\n\n\n\n{\"x\":{\"diagram\":\"\\ndigraph bayesian_workflow {\\n  forcelabels = true;\\n  graph [overlap = false,\\n         fontsize = 10,\\n         rankdir = LR]\\n  node [shape = oval,\\n        fontname = Helvetica]\\n  A [label = \\\"Especificação\\ndoModelo\\\"]\\n  B [label = \\\"Elicitação\\ndas Prioris\\\"]\\n  C [label = \\\"Inferência\\nda Posterior\\\"]\\n  A -> B\\n  B -> A [label = \\\"Prior\\nPredictive\\nCheck\\\"]\\n  B -> C\\n  C -> B [label = \\\"Posterior\\nPredictive\\nCheck\\\"]\\n}\\n\",\"config\":{\"engine\":\"dot\",\"options\":null}},\"evals\":[],\"jsHooks\":[]}\nFigure 2: Bayesian Workflow. Baseado em Gelman et al. (2020)\n\n\n\nPrecisamos nos certificar que a nossa distribuição posterior de \\(y\\) consegue capturar todas as nuanças da densidade real de \\(y\\). Isto é um procedimento chamado de Posterior Predictive Check e é geralmente auferido com uma inspeção visual da densidade real de \\(y\\) contrastada com amostragens da densidade posterior de \\(y\\) estimada pelo modelo Bayesiano. O propósito é comparar o histograma da variável dependente \\(y\\) contra o histograma variáveis dependentes simuladas pelo modelo \\(y_{\\text{rep}}\\) após a estimação dos parâmetros. A ideia é que os histogramas reais e simulados se misturem e não haja divergências.\nIsso pode ser feito tanto no rstanarm quando no brms. Ambos usam o pacote bayesplot (Gabry & Mahr, 2021) para gerar as visualizações1:\nrstanarm: função pp_check() em qualquer modelo oriundo das funções stan_*()\nbrms: função pp_check() em qualquer modelo oriundo da função brm()\nExemplo - Score de QI de crianças\nPara o nosso exemplo, usarei um dataset famoso chamado kidiq (Gelman & Hill, 2007) que está incluído no rstanarm. São dados de uma survey de mulheres adultas norte-americanas e seus respectivos filhos. Datado de 2007 possui 434 observações e 4 variáveis:\nkid_score: QI da criança\nmom_hs: binária (0 ou 1) se a mãe possui diploma de ensino médio\nmom_iq: QI da mãe\nmom_age: idade da mãe\nAo todo serão 4 modelos para modelar QI da criança (kid_score). Os primeiros dois modelos terão apenas uma única variável independente (mom_hs ou mom_iq), o terceiro usará duas variáveis independentes (mom_hs + mom_iq) e o quarto incluirá uma interação entre essas duas variáveis independentes (mom_hs * mom_iq).\n\n\n# Detectar quantos cores/processadores\noptions(mc.cores = parallel::detectCores())\noptions(Ncpus = parallel::detectCores())\n\nlibrary(rstanarm)\ndata(kidiq)\n\n\n\nDescritivo das variáveis\nAntes de tudo, analise SEMPRE os dados em mãos. Graficamente e com tabelas. Isso pode ajudar a elucidar prioris além de embasar melhor conhecimento de domínio do fenômeno de interesse.\nPessoalmente uso o pacote skimr (Waring et al., 2021) com a função skim():\n\n\nlibrary(skimr)\n\nskim(kidiq)\n\n\nTable 1: Data summary\nName\nkidiq\nNumber of rows\n434\nNumber of columns\n4\n_______________________\n\nColumn type frequency:\n\nnumeric\n4\n________________________\n\nGroup variables\nNone\nVariable type: numeric\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\nkid_score\n0\n1\n86.80\n20.41\n20\n74\n90\n102\n144\n▁▃▇▇▁\nmom_hs\n0\n1\n0.79\n0.41\n0\n1\n1\n1\n1\n▂▁▁▁▇\nmom_iq\n0\n1\n100.00\n15.00\n71\n89\n98\n110\n139\n▃▇▆▃▂\nmom_age\n0\n1\n22.79\n2.70\n17\n21\n23\n25\n29\n▂▅▇▃▂\n\nModelo 1 - mom_hs\nPrimeiro modelo é apenas a variável mom_hs como variável independente Acredito que se a mãe da criança possui ensino médio isso pode impactar positivamente de 1 a 2 desvio padrões no QI da criança. O que resulta em prior = normal(0, sd(kidiq$kid_score))2. Vou colocar a priori da constante \\(\\alpha\\) como uma normal centrada na média do QI da criança e com um desvio padrão 2.5 maior que o desvio padrão do QI da criança. Isto resulta em prior_intercept = normal(mean(kidiq$kid_score), 2.5 * sd(kidiq$kid_score)). Sobre a priori do erro do modelo vou manter o padrão do rstanarm que é uma distribuição exponencial com \\(\\lambda\\) 1 / sd(kidiq$kid_score).\n\n\nmodel_1 <- stan_glm(\n  kid_score ~ mom_hs,\n  data = kidiq,\n  prior = normal(0, sd(kidiq$kid_score)),\n  prior_intercept = normal(mean(kidiq$kid_score), 2.5 * sd(kidiq$kid_score)),\n  prior_aux = rstanarm::exponential(1 / sd(kidiq$kid_score))\n  )\n\n\n\nVamos ver como ficaram as estimação dos parâmetros de interesse do modelo com summary():\n\n\nsummary(model_1)\n\n\n\nModel Info:\n function:     stan_glm\n family:       gaussian [identity]\n formula:      kid_score ~ mom_hs\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 434\n predictors:   2\n\nEstimates:\n              mean   sd   10%   50%   90%\n(Intercept) 77.6    2.0 75.0  77.6  80.2 \nmom_hs      11.7    2.3  8.7  11.6  14.7 \nsigma       19.9    0.7 19.0  19.9  20.8 \n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 86.8    1.3 85.1  86.8  88.5 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.0  1.0  3873 \nmom_hs        0.0  1.0  3804 \nsigma         0.0  1.0  3939 \nmean_PPD      0.0  1.0  4146 \nlog-posterior 0.0  1.0  1752 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nNão tivemos nenhum problema nas correntes Markov pois todos os Rhat estão bem abaixo de 1.01. Mas o modelo está com um erro alto, \\(\\sigma \\approx 20\\). Isto é esperado pois estamos usando apenas uma única variável independente para modelar kid_score.\nVamos verificar o Posterior Predictive Check do modelo 1 na figura 3:\n\n\npp_check(model_1)\n\n\n\n\nFigure 3: Posterior Preditive Check do modelo 1\n\n\n\nModelo 2 - mom_iq\nSegundo modelo é apenas a variável mom_iq como variável independente Vou manter as prioris de \\(\\alpha\\) e \\(\\lambda\\). Para a variável mom_iq acredito que a correlação entre QI da mãe e QI da criança seja positiva e acima de 0.5. Então a minha priori será uma normal centrada em 0.5 com 0.5 de desvio padrão. Isto resulta em prior = normal(0.5, 0.5):\n\n\nmodel_2 <- stan_glm(\n  kid_score ~ mom_iq,\n  data = kidiq,\n  prior = normal(0.5, 0.5),\n  prior_intercept = normal(mean(kidiq$kid_score), 2.5 * sd(kidiq$kid_score)),\n  prior_aux = rstanarm::exponential(1 / sd(kidiq$kid_score))\n  )\n\n\n\n\n\nsummary(model_2)\n\n\n\nModel Info:\n function:     stan_glm\n family:       gaussian [identity]\n formula:      kid_score ~ mom_iq\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 434\n predictors:   2\n\nEstimates:\n              mean   sd   10%   50%   90%\n(Intercept) 25.9    5.9 18.4  25.8  33.4 \nmom_iq       0.6    0.1  0.5   0.6   0.7 \nsigma       18.3    0.6 17.6  18.3  19.1 \n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 86.8    1.2 85.2  86.8  88.4 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.1  1.0  3585 \nmom_iq        0.0  1.0  3606 \nsigma         0.0  1.0  3297 \nmean_PPD      0.0  1.0  4060 \nlog-posterior 0.0  1.0  1884 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nMais uma vez nenhum problema com as correntes Markov (Rhat menor que 1.01) e o erro do modelo continua em níveis elevados (\\(\\sigma \\approx 18\\)). Vamos precisar incorporar mais variáveis no modelo.\nVamos verificar o Posterior Predictive Check do modelo 2 na figura 4:\n\n\npp_check(model_2)\n\n\n\n\nFigure 4: Posterior Preditive Check do modelo 2\n\n\n\nModelo 3 - mom_hs + mom_iq\nTerceiro modelo usa as duas variáveis mom_hs e mom_iq como variáveis independentes. Vou manter todas as prioris definidas nos modelos 1 e 2.\n\n\nmodel_3 <- stan_glm(\n  kid_score ~ mom_hs + mom_iq,\n  data = kidiq,\n  prior = normal(c(0.0, 0.5), c(sd(kidiq$kid_score), 0.5)),\n  prior_intercept = normal(mean(kidiq$kid_score), 2.5 * sd(kidiq$kid_score)),\n  prior_aux = rstanarm::exponential(1 / sd(kidiq$kid_score))\n  )\n\n\n\n\n\nsummary(model_3)\n\n\n\nModel Info:\n function:     stan_glm\n family:       gaussian [identity]\n formula:      kid_score ~ mom_hs + mom_iq\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 434\n predictors:   3\n\nEstimates:\n              mean   sd   10%   50%   90%\n(Intercept) 25.8    5.8 18.4  25.9  33.1 \nmom_hs       5.9    2.2  3.0   5.9   8.7 \nmom_iq       0.6    0.1  0.5   0.6   0.6 \nsigma       18.2    0.6 17.4  18.2  19.0 \n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 86.8    1.2 85.2  86.8  88.3 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.1  1.0  4628 \nmom_hs        0.0  1.0  4642 \nmom_iq        0.0  1.0  4492 \nsigma         0.0  1.0  4769 \nmean_PPD      0.0  1.0  4176 \nlog-posterior 0.0  1.0  1728 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nVamos verificar o Posterior Predictive Check do modelo 3 na figura 5:\n\n\npp_check(model_3)\n\n\n\n\nFigure 5: Posterior Preditive Check do modelo 3\n\n\n\nModelo 4 - mom_hs * mom_iq\nQuarto modelo usa as duas variáveis mom_hs e mom_iq como variáveis independentes e adiciona uma interação entre as duas. Vou manter as mesmas prioris dos modelos anteriores. Note que a formula agora é atualizada para:\nkid_score ~ mom_hs * mom_iq\nO operador * na fórmula especifica uma interação entre duas variáveis. O rstanarm (e boa parte as coisas de R que usam a síntaxe de fórmulas y ~ ...) criará uma interação entre as variáveis mom_hs e mom_iq computando matematicamente uma nova variável com o produto das duas e inserindo-a no modelo. Além disso, ao especificarmos uma interação com o * a fórmula se expande para:\nmom_hs + mom_iq + mom_hs:mom_iq\nAqui o operador : é também a interação entre as variáveis mom_hs e mom_iq. A diferença entre o operador * e : nas fórmulas é que o operador * aplica o princípio de hierarquia: qualquer efeitos de interação entre variáveis também deve ser inseridos os efeitos principais das variáveis. Se você usar apenas o operador : você está infringindo o princípio de hierarquia. Por isso recomendo em todas suas interações usar sempre o operador * que naturalmente respeita o princípio de hierarquia.\nA interação x_1 * x_2 faz o vetor de coeficientes \\(\\boldsymbol{\\beta}\\) se tornar:\n\\[\n\\boldsymbol{\\beta} =\n\\begin{bmatrix}\n\\beta_{x_1} \\\\\n\\beta_{x_2} \\\\\n\\beta_{x_1} \\cdot \\beta_{x_2}\n\\end{bmatrix}\n\\]\nNote que adicionamos mais uma priori normal ao modelo que é literalmente o produto das duas prioris normais dos coeficientes mom_hs e mom_iq, representando a priori de mom_hs:mom_iq3:\n\\[\n\\begin{aligned}\n\\beta_3 &\\sim \\text{Normal}(\\mu_{\\beta_1} \\cdot \\mu_{\\beta_2}, \\sigma_{\\beta_1} \\cdot \\sigma_{\\beta_2}) \\\\\n&\\sim \\text{Normal}(0 \\cdot 0.5, \\text{SD}(y) \\cdot 0.5) \\\\\n&\\sim \\text{Normal}\\left( 0, \\frac{\\text{SD}(y)}{2} \\right)\n\\end{aligned}\n\\]\n\n\nmodel_4 <- stan_glm(\n  kid_score ~ mom_hs * mom_iq,\n  data = kidiq,\n  prior = normal(c(0.0, 0.5, 0), c(sd(kidiq$kid_score), 0.5, sd(kidiq$kid_score) * 0.5)),\n  prior_intercept = normal(mean(kidiq$kid_score), 2.5 * sd(kidiq$kid_score)),\n  prior_aux = rstanarm::exponential(1 / sd(kidiq$kid_score))\n  )\n\n\n\n\n\nsummary(model_4)\n\n\n\nModel Info:\n function:     stan_glm\n family:       gaussian [identity]\n formula:      kid_score ~ mom_hs * mom_iq\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 434\n predictors:   4\n\nEstimates:\n                mean   sd   10%   50%   90%\n(Intercept)    5.2   11.1 -9.0   5.3  19.6 \nmom_hs        31.1   11.8 15.9  31.3  46.1 \nmom_iq         0.8    0.1  0.6   0.8   0.9 \nmom_hs:mom_iq -0.3    0.1 -0.4  -0.3  -0.1 \nsigma         18.0    0.6 17.3  18.0  18.8 \n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 86.8    1.2 85.2  86.8  88.4 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.3  1.0  1197 \nmom_hs        0.3  1.0  1169 \nmom_iq        0.0  1.0  1169 \nmom_hs:mom_iq 0.0  1.0  1092 \nsigma         0.0  1.0  2376 \nmean_PPD      0.0  1.0  2740 \nlog-posterior 0.0  1.0  1396 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nO erro do modelo ainda continua elevado, \\(\\sigma \\approx 18\\), mas acredito que com estas 2 variáveis é o melhor que podemos fazer com uma função de verosimilhança Gaussiana/Normal.\nVamos verificar o Posterior Predictive Check do modelo 4 na figura 6:\n\n\npp_check(model_4)\n\n\n\n\nFigure 6: Posterior Preditive Check do modelo 4\n\n\n\nDentre os 4 modelos que usamos os Posterior Predictive Check estão muito próximos. Acredito que há uma leve vantagem dos modelos 3 e 4 sobre os modelo 1 e 2 ao inspecionarmos visualmente os Posterior Predictive Check. Para aprofundar-se em comparação de modelos veja a Aula - Comparação de Modelos, na qual saímos de inspeções visuais (arbitrárias) para métricas de comparação (objetivas).\nVariáveis qualitativas\nPara as variáveis qualitativas, o R usa um tipo especial de variável chamado factor. A codificação é em números inteiros \\(1,2,\\dots,K\\) mas a relação é distinta/nominal. Ou seja 1 é distinto de 2 e não 1 é 2x menor que 2. Não há relação quantitativa entre os valores das variáveis factor.\nIsso resolve o problema de termos variáveis qualitativas (também chamadas de dummy) em modelos de regressão. Para um factor com \\(K\\) quantidade de classes distintas, temos a possibilidade de criar \\(K-1\\) coeficientes de regressão. Um para cada classe e usando uma como basal (baseline).\nVeja o exemplo usando o pacote gapminder (Bryan, 2017) que convenientemente traz os dados do site gapminder.org para usarmos no R. Temos 5 continentes codificados como uma variável factor chamada continent.\n\n\nlibrary(gapminder)\nlevels(gapminder$continent)\n\n\n[1] \"Africa\"   \"Americas\" \"Asia\"     \"Europe\"   \"Oceania\" \n\nmodel_5 <- stan_glm(lifeExp ~ gdpPercap + factor(continent), data = gapminder)\n\n\n\n\n\nprint(model_5)\n\n\nstan_glm\n family:       gaussian [identity]\n formula:      lifeExp ~ gdpPercap + factor(continent)\n observations: 1704\n predictors:   6\n------\n                          Median MAD_SD\n(Intercept)               47.9    0.4  \ngdpPercap                  0.0    0.0  \nfactor(continent)Americas 13.6    0.6  \nfactor(continent)Asia      8.6    0.6  \nfactor(continent)Europe   17.6    0.6  \nfactor(continent)Oceania  18.1    1.8  \n\nAuxiliary parameter(s):\n      Median MAD_SD\nsigma 8.4    0.1   \n\n------\n* For help interpreting the printed output see ?print.stanreg\n* For info on the priors used see ?prior_summary.stanreg\n\nVeja que temos 4 variáveis independentes no modelo rstanarm com dados do gapminder (exatamente \\(K-1\\) como mencionado acima). O R por padrão usa a ordenação alfabética na hora de ordenar os níveis das variáveis qualitativa. Portando o valor Africa da variável continent foi selecionado como nível basal de referência pois é o que aparecerá primeiro numa ordenação alfabética dos 5 valores de continent.\n\nOBS: para mudar o nível basal de referência de uma variável factor use a função relevel() do R ou fct_relevel() do pacote forcats do tidyverse.\n\nAtividade Prática\nDois datasets estão disponíveis no diretório datasets/:\nWHO Life Expectancy Kaggle Dataset: datasets/WHO_Life_Exp.csv\nWine Quality Kaggle Dataset: datasets/Wine_Quality.csv\nWHO Life Expectancy\nEsse dataset possui 193 países nos últimos 15 anos.\nVariáveis\ncountry\nyear\nstatus\nlife_expectancy\nadult_mortality\ninfant_deaths\nalcohol\npercentage_expenditure\nhepatitis_b\nmeasles\nbmi\nunder_five_deaths\npolio\ntotal_expenditure\ndiphtheria\nhiv_aids\ngdp\npopulation\nthinness_1_19_years\nthinness_5_9_years\nincome_composition_of_resources\nschooling\nWine Quality Kaggle Dataset\nEsse dataset possui 1599 vinhos e estão relacionados com variantes tintas do vinho “Vinho Verde” português. Para mais detalhes, consulte Cortez, Cerdeira, Almeida, Matos, & Reis (2009). Devido a questões de privacidade e logística, apenas variáveis físico-químicas (entradas) e sensoriais (a saída) estão disponíveis (por exemplo, não há dados sobre os tipos de uva, marca de vinho, preço de venda do vinho, etc.).\nVariáveis\nfixed_acidity\nvolatile_acidity\ncitric_acid\nresidual_sugar\nchlorides\nfree_sulfur_dioxide\ntotal_sulfur_dioxide\ndensity\np_h\nsulphates\nalcohol\nquality\n\n\n###\n\n\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.4 (2021-02-15)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n [1] gapminder_0.3.0      ggExtra_0.9          dplyr_1.0.5         \n [4] rstan_2.21.2         StanHeaders_2.21.0-7 MASS_7.3-53.1       \n [7] ggforce_0.3.3        gganimate_1.0.7      plotly_4.9.3        \n[10] carData_3.0-4        DiagrammeR_1.0.6.1   brms_2.15.0         \n[13] rstanarm_2.21.1      Rcpp_1.0.6           skimr_2.1.3         \n[16] readr_1.4.0          readxl_1.3.1         tibble_3.1.0        \n[19] ggplot2_3.3.3        patchwork_1.1.1      cowplot_1.1.1       \n\nloaded via a namespace (and not attached):\n  [1] backports_1.2.1      systemfonts_1.0.1    plyr_1.8.6          \n  [4] igraph_1.2.6         lazyeval_0.2.2       repr_1.1.3          \n  [7] splines_4.0.4        crosstalk_1.1.1      TH.data_1.0-10      \n [10] rstantools_2.1.1     inline_0.3.17        digest_0.6.27       \n [13] htmltools_0.5.1.1    magick_2.7.1         rsconnect_0.8.16    \n [16] fansi_0.4.2          magrittr_2.0.1       RcppParallel_5.0.3  \n [19] matrixStats_0.58.0   sandwich_3.0-0       xts_0.12.1          \n [22] prettyunits_1.1.1    jpeg_0.1-8.1         colorspace_2.0-0    \n [25] textshaping_0.3.3    xfun_0.22            callr_3.6.0         \n [28] crayon_1.4.1         jsonlite_1.7.2       lme4_1.1-26         \n [31] survival_3.2-10      zoo_1.8-9            glue_1.4.2          \n [34] polyclip_1.10-0      gtable_0.3.0         emmeans_1.5.5-1     \n [37] V8_3.4.0             pkgbuild_1.2.0       abind_1.4-5         \n [40] scales_1.1.1         mvtnorm_1.1-1        DBI_1.1.1           \n [43] miniUI_0.1.1.1       isoband_0.2.4        progress_1.2.2      \n [46] viridisLite_0.3.0    xtable_1.8-4         tmvnsim_1.0-2       \n [49] stats4_4.0.4         DT_0.17              httr_1.4.2          \n [52] htmlwidgets_1.5.3    threejs_0.3.3        RColorBrewer_1.1-2  \n [55] ellipsis_0.3.1       pkgconfig_2.0.3      loo_2.4.1           \n [58] farver_2.1.0         sass_0.3.1           here_1.0.1          \n [61] utf8_1.2.1           tidyselect_1.1.0     labeling_0.4.2      \n [64] rlang_0.4.10         reshape2_1.4.4       later_1.1.0.1       \n [67] visNetwork_2.0.9     munsell_0.5.0        cellranger_1.1.0    \n [70] tools_4.0.4          cli_2.3.1            generics_0.1.0      \n [73] gifski_1.4.3         ggridges_0.5.3       evaluate_0.14       \n [76] stringr_1.4.0        fastmap_1.1.0        yaml_2.2.1          \n [79] ragg_1.1.2           processx_3.5.0       knitr_1.31          \n [82] purrr_0.3.4          nlme_3.1-152         projpred_2.0.2      \n [85] mime_0.10            xml2_1.3.2           compiler_4.0.4      \n [88] bayesplot_1.8.0      shinythemes_1.2.0    rstudioapi_0.13     \n [91] gamm4_0.2-6          curl_4.3             png_0.1-7           \n [94] tweenr_1.0.2         statmod_1.4.35       bslib_0.2.4         \n [97] stringi_1.5.3        highr_0.8            ps_1.6.0            \n[100] Brobdingnag_1.2-6    lattice_0.20-41      Matrix_1.3-2        \n[103] nloptr_1.2.2.2       markdown_1.1         shinyjs_2.0.0       \n[106] vctrs_0.3.6          pillar_1.5.1         lifecycle_1.0.0     \n[109] jquerylib_0.1.3      bridgesampling_1.0-0 estimability_1.3    \n[112] data.table_1.14.0    httpuv_1.5.5         R6_2.5.0            \n[115] bookdown_0.21        promises_1.2.0.1     gridExtra_2.3       \n[118] codetools_0.2-18     distill_1.2          boot_1.3-27         \n[121] colourpicker_1.1.0   gtools_3.8.2         assertthat_0.2.1    \n[124] rprojroot_2.0.2      withr_2.4.1          mnormt_2.0.2        \n[127] shinystan_2.5.0      multcomp_1.4-16      mgcv_1.8-34         \n[130] parallel_4.0.4       hms_1.0.0            grid_4.0.4          \n[133] tidyr_1.1.3          coda_0.19-4          minqa_1.2.4         \n[136] rmarkdown_2.7        downlit_0.2.1        shiny_1.6.0         \n[139] lubridate_1.7.10     base64enc_0.1-3      dygraphs_1.1.1.6    \n\n\n\n\nBox, G. E. P. (1976). Science and Statistics. Journal of the American Statistical Association, 71(356), 791–799. https://doi.org/10.2307/2286841\n\n\nBryan, J. (2017). Gapminder: Data from gapminder. Retrieved from https://CRAN.R-project.org/package=gapminder\n\n\nCortez, P., Cerdeira, A., Almeida, F., Matos, T., & Reis, J. (2009). Modeling wine preferences by data mining from physicochemical properties. Decision Support Systems, 47(4), 547–553.\n\n\nGabry, J., & Mahr, T. (2021). Bayesplot: Plotting for bayesian models. Retrieved from https://mc-stan.org/bayesplot/\n\n\nGelman, A., & Hill, J. (2007). Data analysis using regression and multilevel/hierarchical models. Cambridge university press.\n\n\nGelman, A., Vehtari, A., Simpson, D., Margossian, C. C., Carpenter, B., Yao, Y., … Modr’ak, M. (2020, November 3). Bayesian Workflow. Retrieved February 4, 2021, from http://arxiv.org/abs/2011.01808\n\n\nWaring, E., Quinn, M., McNamara, A., Arino de la Rubia, E., Zhu, H., & Ellis, S. (2021). Skimr: Compact and flexible summaries of data. Retrieved from https://CRAN.R-project.org/package=skimr\n\n\no pacote bayesplot é automaticamente instalado como uma dependência do rstanarm ou brms então não se preocupe em instalá-lo. Ele será automaticamente instalado caso instale tanto rstanarm quanto brms.↩︎\nlembrando que uma priori normal centrada em 0 por conta da simetria da normal também dá a possibilidade de valores negativos.↩︎\nconseguimos fazer isso com distribuições normais por conta das diversas propriedades matemáticas destas distribuições. Note que isto não funciona para todas as diferentes distribuições.↩︎\n",
      "last_modified": "2021-03-29T16:56:25-03:00"
    },
    {
      "path": "7-Regressao_Logistica.html",
      "title": "Regressão Logística Bayesiana",
      "description": "Modelos Lineares Generalizados -- Binomial",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 1, 2021",
      "contents": "\n\nContents\nComparativo com a Regressão Linear\nRegressão Logística Bayesiana\n\nRegressão Logística com o rstanarm e brms\nExemplo - Propensão a mudar de poço de água contaminado\n\nInterpretação dos coeficientes\nAtividade Prática\nAmbiente\n\n\nSaindo do universo dos modelos lineares, começamos a nos aventurar nos modelos linares generalizados (generalized linear models – GLM). O primeiro deles é a regressão logística (também chamada de regressão binomial).\nUma regressão logística se comporta exatamente como um modelo linear: faz uma predição simplesmente computando uma soma ponderada das variáveis independentes, mais uma constante. Porém ao invés de retornar um valor contínuo, como a regressão linear, retorna a função logística desse valor:\n\\[\n\\text{Logística}(x) = \\frac{1}{1 + e^{(-x)}}\n\\]\nUsamos regressão logística quando a nossa variável dependente é binária. Ela possui apenas dois valores distintos, geralmente codificados como \\(0\\) ou \\(1\\). Veja a figura 1 para uma intuição gráfica da função logística:\n\n\nggplot(data = tibble(\n  x = seq(-10, 10, length.out = 100),\n  y =  1 / (1 + exp(-x))\n  ),\n  aes(x, y)) +\n  geom_line(size = 2, color = \"steelblue\") +\n  ylab(\"Logística(x)\")\n\n\n\n\nFigure 1: Função Logística\n\n\n\nComo podemos ver, a função logística é basicamente um mapeamento de qualquer número real para um número real no intervalo entre 0 e 1:\n\\[\n\\text{Logística}(x) = \\{ \\mathbb{R} \\in [- \\infty , + \\infty] \\} \\to \\{ \\mathbb{R} \\in (0, 1) \\}\n\\]\nOu seja, a função logística é a candidata ideal para quando precisamos converter algo contínuo sem restrições para algo contínuo restrito entre 0 e 1. Por isso ela é usada quando precisamos que um modelo tenha como variável dependente uma probabilidade (lembrando que qualquer numero real entre 0 e 1 é uma probabilidade válida). No caso de uma variável dependente binária, podemos usar essa probabilidade como a chance da variável dependente tomar valor de 0 ou de 1.\nComparativo com a Regressão Linear\nA regressão linear segue a seguinte formulação matemática:\n\\[\n\\text{Linear} = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\dots + \\theta_n x_n\n\\]\n\\(\\theta\\) - parâmetro do modelo\n\\(\\theta_0\\) - constante\n\\(\\theta_1, \\theta_2, \\dots\\) - coeficientes das variáveis independentes \\(x_1, x_2, \\dots\\)\n\n\\(n\\) - número de variáveis independentes\n\\(\\hat{p} = \\text{Logística}(\\text{Linear}) = \\frac{1}{1 + e^{-\\operatorname{Linear}}}\\) - probabilidade prevista da observação ser o valor 1\n\\(\\hat{y}=\\left\\{\\begin{array}{ll} 0 & \\text { se } \\hat{p} < 0.5 \\\\ 1 & \\text { se } \\hat{p} \\geq 0.5 \\end{array}\\right.\\) – previsão do valor discreto de \\(y\\)\nExemplo:\n\\[\\text{Previsão de Morte} = \\text{Logística} \\big(-10 + 10 \\cdot \\text{cancer} + 12 \\cdot \\text{diabetes} + 8 \\cdot \\text{obesidade} \\big)\\]\nRegressão Logística Bayesiana\nPodemos modelar regressão logística de duas maneiras. A primeira opção com uma função verossimilhança Bernoulli e a segunda opção com uma função verossimilhança binomial.\nCom a verossimilhança Bernoulli modelamos uma variável dependente binária \\(y\\) que é o resultado de um experimento de Bernoulli com uma certa probabilidade \\(p\\).\nJá na verossimilhança binomial modelamos uma variável dependente contínua \\(y\\) que é o número de sucessos de \\(n\\) experimentos Bernoulli independentes.\nUsando Verossimilhança Bernoulli\n\\[\n\\begin{aligned}\ny &\\sim \\text{Bernoulli}\\left( p\\right) \\\\\np &\\sim \\text{Logística}(\\alpha + \\mathbf{X} \\cdot \\boldsymbol{\\beta}) \\\\\n\\alpha &\\sim \\text{Normal}(\\mu_\\alpha, \\sigma_\\alpha) \\\\\n\\boldsymbol{\\beta} &\\sim \\text{Normal}(\\mu_{\\boldsymbol{\\beta}}, \\sigma_{\\boldsymbol{\\beta}})\n\\end{aligned}\n\\]\nSendo que:\n\\(y\\) – variável dependente (binária)\n\\(p\\) – probabilidade de \\(y\\) tomar o valor de \\(y\\) - sucesso de um experimento Bernoulli\n\\(\\text{Logística}\\) – função logística\n\\(\\alpha\\) – constante (também chamada de intercept)\n\\(\\boldsymbol{\\beta}\\) – vetor de coeficientes\n\\(\\mathbf{X}\\) – matriz de dados\nUsando Verossimilhança Binomial\n\\[\n\\begin{aligned}\ny &\\sim \\text{Binomial}\\left(n,  p\\right) \\\\\np &\\sim \\text{Logística}(\\alpha + \\mathbf{X} \\cdot \\boldsymbol{\\beta}) \\\\\n\\alpha &\\sim \\text{Normal}(\\mu_\\alpha, \\sigma_\\alpha) \\\\\n\\boldsymbol{\\beta} &\\sim \\text{Normal}(\\mu_{\\boldsymbol{\\beta}}, \\sigma_{\\boldsymbol{\\beta}})\n\\end{aligned}\n\\]\nSendo que:\n\\(y\\) – variável dependente contínua - sucessos de \\(n\\) experimentos Bernoulli independentes\n\\(n\\) – número de experimentos Bernoulli independentes\n\\(p\\) – probabilidade de \\(y\\) tomar o valor de \\(y\\) - sucesso de um experimento Bernoulli\n\\(\\text{Logística}\\) – função logística\n\\(\\alpha\\) – constante (também chamada de intercept)\n\\(\\boldsymbol{\\beta}\\) – vetor de coeficientes\n\\(\\mathbf{X}\\) – matriz de dados\nEm ambas famílias de verossimilhança, o que falta é especificar quais são as prioris dos parâmetros do modelo:\nDistribuição priori de \\(\\alpha\\) – Conhecimento que temos da constante do modelo\nDistribuição priori de \\(\\boldsymbol{\\beta}\\) – Conhecimento que temos dos coeficientes das variáveis independentes do modelo\nStan instanciará um modelo bayesiano com os dados fornecidos (\\(y\\) e \\(\\mathbf{X}\\)) e encontrará a distribuição posterior dos parâmetros de interesse do modelo (\\(\\alpha\\) e \\(\\boldsymbol{\\beta}\\)) calculando a distribuição posterior completa de:\n\\[\nP(\\theta \\mid y) = P(\\alpha, \\boldsymbol{\\beta} \\mid y)\n\\]\nRegressão Logística com o rstanarm e brms\nO rstanarm e brms podem tolerar qualquer modelo linear generalizado e regressão logística não é uma exceção. Não há função de verossimilhança Bernoulli em Stan (e, consequentemente, em nenhuma de suas interfaces) pois ela é apenas um caso especial da função de verossimilhança binomial com apenas um único experimento Bernoulli. Ou seja:\n\\[\n\\text{Bernouli}(p) = \\text{Binomial}(1, p)\n\\]\nPara designar um modelo binomial no rstanarm e brms é preciso simplesmente alterar o argumento family da função stan_glm() ou brm(). Isso faz com que a família da função de verossimilhança do modelo seja modificada. Você pode controlar também a função de ligação com argumento link mas acredito que para a vasta maioria dos casos não é necessário alterar o padrão que Stan usa para as diferentes famílias de funções de verossimilhança.\nExemplo - Propensão a mudar de poço de água contaminado\nPara exemplo, usaremos um dataset chamado wells (Gelman & Hill, 2007) que está incluído no rstanarm. É uma survey com 3.200 residentes de uma pequena área de Bangladesh na qual os lençóis freáticos estão contaminados por arsênico. Respondentes com altos níveis de arsênico nos seus poços foram encorajados para trocar a sua fonte de água para uma níveis seguros de arsênico.\nPossui as seguintes variáveis:\nswitch: dependente indicando se o respondente trocou ou não de poço\narsenic: nível de arsênico do poço do respondente\ndist: distância em metros da casa do respondente até o poço seguro mais próximo\nassociation: dummy se os membros da casa do respondente fazem parte de alguma organização da comunidade\neduc: quantidade de anos de educação que o chefe da família respondente possui\n\n\noptions(mc.cores = parallel::detectCores())\noptions(Ncpus = parallel::detectCores())\n\nlibrary(rstanarm)\ndata(wells)\n\n\n\nDescritivo das variáveis\nAntes de tudo, analise SEMPRE os dados em mãos. Graficamente e com tabelas. Isso pode ajudar a elucidar prioris além de embasar melhor conhecimento de domínio do fenômeno de interesse.\nPessoalmente uso o pacote skimr (Waring et al., 2021) com a função skim():\n\n\nlibrary(skimr)\n\nskim(wells)\n\n\nTable 1: Data summary\nName\nwells\nNumber of rows\n3020\nNumber of columns\n5\n_______________________\n\nColumn type frequency:\n\nnumeric\n5\n________________________\n\nGroup variables\nNone\nVariable type: numeric\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\nswitch\n0\n1\n0.58\n0.49\n0.00\n0.00\n1.0\n1.0\n1.0\n▆▁▁▁▇\narsenic\n0\n1\n1.66\n1.11\n0.51\n0.82\n1.3\n2.2\n9.7\n▇▂▁▁▁\ndist\n0\n1\n48.33\n38.48\n0.39\n21.12\n36.8\n64.0\n339.5\n▇▂▁▁▁\nassoc\n0\n1\n0.42\n0.49\n0.00\n0.00\n0.0\n1.0\n1.0\n▇▁▁▁▆\neduc\n0\n1\n4.83\n4.02\n0.00\n0.00\n5.0\n8.0\n17.0\n▇▇▅▁▁\n\nModelo Binomial\nO modelo possuirá as seguintes variáveis como independentes: dist,arsenic, assoc e educ. Para todas essas variáveis, como os coeficientes estarão em uma escala logit (que é o inverso da transformação logística), usarei uma priori de uma distribuição normal com média 0 e desvio padrão 2.5. O que resulta em prior = normal(0, 2.5). Vou colocar a priori da constante \\(\\alpha\\) como uma normal centrada em 0 e com um desvio padrão 2.5, basicamente traduzindo o que usamos como priori em modelos gaussianos (regressão linear). Isto resulta em prior_intercept = normal(0, 2.5). Notem que aqui não temos erro do modelo, pois a função de verossimilhança não faz pressupostos sobre desvios como era o caso na regressão linear com uma verossimilhança Gaussiana/Normal. Portanto não há o que se especificar para prior_aux.\n\n\nmodel_binomial <- stan_glm(\n  switch ~ dist + arsenic + assoc + educ,\n  data = wells,\n  family = binomial,\n  prior = normal(0, 2.5),\n  prior_intercept = normal(0, 2.5)\n)\n\n\n\nVamos ver como ficaram as estimação dos parâmetros de interesse do modelo com summary():\n\n\nsummary(model_binomial)\n\n\n\nModel Info:\n function:     stan_glm\n family:       binomial [logit]\n formula:      switch ~ dist + arsenic + assoc + educ\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 3020\n predictors:   5\n\nEstimates:\n              mean   sd   10%   50%   90%\n(Intercept) -0.2    0.1 -0.3  -0.2   0.0 \ndist         0.0    0.0  0.0   0.0   0.0 \narsenic      0.5    0.0  0.4   0.5   0.5 \nassoc       -0.1    0.1 -0.2  -0.1   0.0 \neduc         0.0    0.0  0.0   0.0   0.1 \n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 0.6    0.0  0.6   0.6   0.6  \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.0  1.0  3655 \ndist          0.0  1.0  3518 \narsenic       0.0  1.0  2853 \nassoc         0.0  1.0  3460 \neduc          0.0  1.0  3419 \nmean_PPD      0.0  1.0  3312 \nlog-posterior 0.0  1.0  1781 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nNão tivemos nenhum problema nas correntes Markov pois todos os Rhat estão bem abaixo de 1.01.\nVamos verificar o Posterior Predictive Check do modelo binomial na figura 2:\n\n\npp_check(model_binomial)\n\n\n\n\nFigure 2: Posterior Preditive Check do modelo binomial\n\n\n\nEste é um ótimo exemplo de um Posterior Predictive Check no qual não conseguimos identificar qualquer anomalia no modelo.\nInterpretação dos coeficientes\nAo vermos a fórmula de regressão binomial percebemos a interpretação dos coeficientes requer uma transformação. A transformação que precisamos fazer á a que inverte a função logística. Mas antes preciso falar sobre qual a diferença matemática entre probabilidade (em inglês probability) e chances (em inglês odds). Probabilidade já discutimos na Aula 0 - O que é Estatística Bayesiana?: um número real entre 0 e 1 que representa a certeza de que um evento irá acontecer por meio de frequências de longo-prazo (probabilidade frequentista) ou níveis de credibilidade (probabilidade Bayesiana). Chances é um número positivo real (\\(\\mathbb{R}^+\\)) que mensura também a certeza de um evento. Mas essa certeza não é expressa como uma probabilidade (algo entre 0 e 1), mas como uma razão entre a quantidade de resultados que produzem o evento desejado e a quantidade de resultados que não produzem o evento desejado:\n\\[\n\\text{Chances} = \\frac{p}{1-p}\n\\]\nonde \\(p\\) é a probabilidade. Chance com o valor de \\(1\\) é uma chance neutra, algo como uma moeda justa \\(p = \\frac{1}{2}\\). Chances abaixo de \\(1\\) decrescem a probabilidade de vermos um certo evento e chances acima de \\(1\\) aumentam a probabilidade do evento. É um sistema de quantificação de incerteza muito usado em casas de apostas. Chances 2:1 quer dizer que a casa de aposta pagará R$ 2 para cada R$ 1 apostado caso o evento apostado ocorra.\nSe você revisitar a função logística, verá que ela os coeficientes de \\(\\boldsymbol{\\beta}\\) são literalmente o logarítmo da chance (em inglês logodds):\n\\[\n\\begin{aligned}\np &\\sim \\text{Logística}(\\alpha + \\mathbf{X} \\cdot \\beta) \\\\\np &\\sim \\text{Logística}(\\alpha) + \\text{Logística}(\\mathbf{X} \\cdot \\boldsymbol{\\beta}) \\\\\n\\boldsymbol{\\beta} &= \\frac{1}{1 + e^{(-\\boldsymbol{\\beta})}}\\\\\n\\boldsymbol{\\beta} &= \\log(\\text{Chance})\n\\end{aligned}\n\\]\nPortanto, os coeficientes de um modelo binomial são expressados em logodds no qual \\(0\\) é o elemento neutro e qualquer numero acima ou abaixo aumenta ou diminui as chances de obtermos um “sucesso” de \\(y\\). Para termos uma interpretação mais intuitiva (igual a das casas de apostas) precisamos converter as logodds em chances revertendo a função \\(\\log\\). Para isso basta “exponenciar” os valores de \\(\\boldsymbol{\\beta}\\):\n\\[\n\\text{Chances} = e^{\\boldsymbol{\\beta}}\n\\]\nFazemos isso com a função exp() do R nos coeficientes do model_binomial:\n\n\ncoeff <- exp(model_binomial$coefficients)\ncoeff\n\n\n(Intercept)        dist     arsenic       assoc        educ \n       0.85        0.99        1.60        0.88        1.04 \n\n(Intercept): a chance basal de respondentes mudarem de poço (14% de não mudarem)\ndist: a cada metro de distância diminui a chance de troca de poço em 1%\narsenic: a cada incremento do nível de arsênico aumenta a chance de troca de poço em 60%\nassoc: residências com membros que fazem parte de alguma organização da comunidade diminui a chance de troca de poço em 12%\neduc: a cada incremento dos anos de estudo aumenta a chance de troca de poço em 4%\nAtividade Prática\nDois datasets estão disponíveis no diretório datasets/:\nTitanic Survival: datasets/Titanic_Survival.csv\nIBM HR Analytics Employee Attrition & Performance: datasets/IBM_HR_Attrition.csv\n\n\n###\n\n\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.4 (2021-02-15)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n [1] gapminder_0.3.0      ggExtra_0.9          dplyr_1.0.5         \n [4] rstan_2.21.2         StanHeaders_2.21.0-7 MASS_7.3-53.1       \n [7] ggforce_0.3.3        gganimate_1.0.7      plotly_4.9.3        \n[10] carData_3.0-4        DiagrammeR_1.0.6.1   brms_2.15.0         \n[13] rstanarm_2.21.1      Rcpp_1.0.6           skimr_2.1.3         \n[16] readr_1.4.0          readxl_1.3.1         tibble_3.1.0        \n[19] ggplot2_3.3.3        patchwork_1.1.1      cowplot_1.1.1       \n\nloaded via a namespace (and not attached):\n  [1] backports_1.2.1      systemfonts_1.0.1    plyr_1.8.6          \n  [4] igraph_1.2.6         lazyeval_0.2.2       repr_1.1.3          \n  [7] splines_4.0.4        crosstalk_1.1.1      TH.data_1.0-10      \n [10] rstantools_2.1.1     inline_0.3.17        digest_0.6.27       \n [13] htmltools_0.5.1.1    magick_2.7.1         rsconnect_0.8.16    \n [16] fansi_0.4.2          magrittr_2.0.1       RcppParallel_5.0.3  \n [19] matrixStats_0.58.0   sandwich_3.0-0       xts_0.12.1          \n [22] prettyunits_1.1.1    jpeg_0.1-8.1         colorspace_2.0-0    \n [25] textshaping_0.3.3    xfun_0.22            callr_3.6.0         \n [28] crayon_1.4.1         jsonlite_1.7.2       lme4_1.1-26         \n [31] survival_3.2-10      zoo_1.8-9            glue_1.4.2          \n [34] polyclip_1.10-0      gtable_0.3.0         emmeans_1.5.5-1     \n [37] V8_3.4.0             pkgbuild_1.2.0       abind_1.4-5         \n [40] scales_1.1.1         mvtnorm_1.1-1        DBI_1.1.1           \n [43] miniUI_0.1.1.1       isoband_0.2.4        progress_1.2.2      \n [46] viridisLite_0.3.0    xtable_1.8-4         tmvnsim_1.0-2       \n [49] stats4_4.0.4         DT_0.17              httr_1.4.2          \n [52] htmlwidgets_1.5.3    threejs_0.3.3        RColorBrewer_1.1-2  \n [55] ellipsis_0.3.1       pkgconfig_2.0.3      loo_2.4.1           \n [58] farver_2.1.0         sass_0.3.1           here_1.0.1          \n [61] utf8_1.2.1           tidyselect_1.1.0     labeling_0.4.2      \n [64] rlang_0.4.10         reshape2_1.4.4       later_1.1.0.1       \n [67] visNetwork_2.0.9     munsell_0.5.0        cellranger_1.1.0    \n [70] tools_4.0.4          cli_2.3.1            generics_0.1.0      \n [73] gifski_1.4.3         ggridges_0.5.3       evaluate_0.14       \n [76] stringr_1.4.0        fastmap_1.1.0        yaml_2.2.1          \n [79] ragg_1.1.2           processx_3.5.0       knitr_1.31          \n [82] purrr_0.3.4          nlme_3.1-152         projpred_2.0.2      \n [85] mime_0.10            xml2_1.3.2           compiler_4.0.4      \n [88] bayesplot_1.8.0      shinythemes_1.2.0    rstudioapi_0.13     \n [91] gamm4_0.2-6          curl_4.3             png_0.1-7           \n [94] tweenr_1.0.2         statmod_1.4.35       bslib_0.2.4         \n [97] stringi_1.5.3        highr_0.8            ps_1.6.0            \n[100] Brobdingnag_1.2-6    lattice_0.20-41      Matrix_1.3-2        \n[103] nloptr_1.2.2.2       markdown_1.1         shinyjs_2.0.0       \n[106] vctrs_0.3.6          pillar_1.5.1         lifecycle_1.0.0     \n[109] jquerylib_0.1.3      bridgesampling_1.0-0 estimability_1.3    \n[112] data.table_1.14.0    httpuv_1.5.5         R6_2.5.0            \n[115] bookdown_0.21        promises_1.2.0.1     gridExtra_2.3       \n[118] codetools_0.2-18     distill_1.2          boot_1.3-27         \n[121] colourpicker_1.1.0   gtools_3.8.2         assertthat_0.2.1    \n[124] rprojroot_2.0.2      withr_2.4.1          mnormt_2.0.2        \n[127] shinystan_2.5.0      multcomp_1.4-16      mgcv_1.8-34         \n[130] parallel_4.0.4       hms_1.0.0            grid_4.0.4          \n[133] tidyr_1.1.3          coda_0.19-4          minqa_1.2.4         \n[136] rmarkdown_2.7        downlit_0.2.1        shiny_1.6.0         \n[139] lubridate_1.7.10     base64enc_0.1-3      dygraphs_1.1.1.6    \n\n\n\n\nGelman, A., & Hill, J. (2007). Data analysis using regression and multilevel/hierarchical models. Cambridge university press.\n\n\nWaring, E., Quinn, M., McNamara, A., Arino de la Rubia, E., Zhu, H., & Ellis, S. (2021). Skimr: Compact and flexible summaries of data. Retrieved from https://CRAN.R-project.org/package=skimr\n\n\n\n\n",
      "last_modified": "2021-03-29T16:56:34-03:00"
    },
    {
      "path": "8-Regressao_Poisson.html",
      "title": "Regressão de Poisson Bayesiana",
      "description": "Modelos Lineares Generalizados -- Poisson",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 1, 2021",
      "contents": "\n\nContents\nRegressão de Poisson Bayesiana\nRegressão de Poisson com o rstanarm e brms\nExemplo Poisson - Exterminação de baratas\n\nInterpretação dos coeficientes\nInflação de Zeros - Modelo Binomial Negativo\nInflação de Zeros - Mistura Binomial Negativa\nExemplo Binomial Negativo - Revisitando a exterminação de baratas\nExemplo Mistura Binomial Negativo - \\(\\textbf{Revisitando}^2\\) a exterminação de baratas\n\nAtividade Prática\nAmbiente\n\n\nSaindo do universo dos modelos lineares, começamos a nos aventurar nos modelos linares generalizados (generalized linear models - GLM). O segundo deles é a regressão de Poisson.\nUma regressão de Poisson se comporta exatamente como um modelo linear: faz uma predição simplesmente computando uma soma ponderada das variáveis independentes \\(\\mathbf{X}\\) pelos coeficientes estimados \\(\\boldsymbol{\\beta}\\), mais uma constante \\(\\alpha\\). Porém ao invés de retornar um valor contínuo \\(y\\), como a regressão linear, retorna o logarítmo natural desse valor \\(\\log(y)\\).\n\\[\n\\log(y)= \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\dots + \\theta_n x_n\n\\]\nque é o mesmo que\n\\[\ny = e^{(\\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\dots + \\theta_n x_n)}\n\\]\n\\(\\theta\\) - parâmetros do modelo\n\\(\\theta_0\\) - constante\n\\(\\theta_1, \\theta_2, \\dots\\) - coeficientes das variáveis independentes \\(x_1, x_2, \\dots\\)\n\n\\(n\\) - número de variáveis independentes\nA função \\(e^x\\) é chamada de função exponencial. Veja a figura 1 para uma intuição gráfica da função exponencial:\n\n\nggplot(data = tibble(\n  x = seq(0, 10, length.out = 100),\n  y =  exp(x)\n  ),\n  aes(x, y)) +\n  geom_line(size = 2, color = \"steelblue\") +\n  ylab(\"Exponencial(x)\")\n\n\n\n\nFigure 1: Função Exponencial\n\n\n\nRegressão de Poisson é usada quando a nossa variável dependente só pode tomar valores positivos, geralmente em contextos de dados de contagem.\nRegressão de Poisson Bayesiana\nPodemos fazer uma regressão de Poisson se a variável dependente \\(y\\) for uma variável com dados de contagem, ou seja, \\(y\\) somente toma valores positivos. A função de verossimilhança de Poisson usa uma constante \\(\\alpha\\) e os coeficientes \\(\\boldsymbol{\\beta}\\) porém estes são exponenciados (\\(e^x\\)):\n\\[\n\\begin{aligned}\ny &\\sim \\text{Poisson}\\left( e^{(\\alpha + \\mathbf{X} \\cdot \\boldsymbol{\\beta})} \\right) \\\\\n\\alpha &\\sim \\text{Normal}(\\mu_\\alpha, \\sigma_\\alpha) \\\\\n\\boldsymbol{\\beta} &\\sim \\text{Normal}(\\mu_{\\boldsymbol{\\beta}}, \\sigma_{\\boldsymbol{\\beta}})\n\\end{aligned}\n\\]\nComo podemos ver, o preditor linear \\(\\alpha + \\mathbf{X} \\cdot \\boldsymbol{\\beta}\\) é o logaritmo do valor de \\(y\\). Portanto precisamos exponenciar os valores do preditor linear:\n\\[\n\\begin{aligned}\n\\log(y) &= \\alpha + \\mathbf{X} \\cdot \\boldsymbol{\\beta} \\\\\ny &= e^{\\alpha \\mathbf{X} \\cdot \\boldsymbol{\\beta}} \\\\\ny &= e^{\\alpha } + e^{\\mathbf{X} \\cdot \\boldsymbol{\\beta}}\n\\end{aligned}\n\\]\nA constante \\(\\alpha\\) e os coeficientes \\(\\boldsymbol{\\beta}\\) são apenas interpretados após a exponenciação.\nRegressão de Poisson com o rstanarm e brms\nO rstanarm e brms podem tolerar qualquer modelo linear generalizado e regressão de Poisson não é uma exceção. Para designar um modelo de Poisson no rstanarm e brms é preciso simplesmente alterar o argumento family da função stan_glm() ou brm(). Isso faz com que a família da função de verossimilhança do modelo seja modificada. Você pode controlar também a função de ligação com argumento link mas acredito que para a vasta maioria dos casos não é necessário alterar o padrão que Stan usa para as diferentes famílias de funções de verossimilhança.\nExemplo Poisson - Exterminação de baratas\nPara exemplo, usaremos um dataset chamado roaches (Gelman & Hill, 2007) que está incluído no rstanarm. É uma base de dados com 262 observações sobre a eficácia de um sistema de controle de pragas em reduzir o número de baratas (roaches) em apartamentos urbanos.\nPossui as seguintes variáveis:\ny: variável dependente - número de baratas mortas\nroach1: número de baratas antes da dedetização\ntreatment: dummy para indicar se o apartamento foi dedetizado ou não\nsenior: dummy para indicar se há apenas idosos no apartamento\nexposure2: número de dias que as armadilhas de baratas foram usadas\n\n\noptions(mc.cores = parallel::detectCores())\noptions(Ncpus = parallel::detectCores())\n\nlibrary(rstanarm)\ndata(roaches)\n\n\n\nDescritivo das variáveis\nAntes de tudo, analise SEMPRE os dados em mãos. Graficamente e com tabelas. Isso pode ajudar a elucidar prioris além de embasar melhor conhecimento de domínio do fenômeno de interesse.\nPessoalmente uso o pacote skimr (Waring et al., 2021) com a função skim():\n\n\nlibrary(skimr)\n\nskim(roaches)\n\n\nTable 1: Data summary\nName\nroaches\nNumber of rows\n262\nNumber of columns\n5\n_______________________\n\nColumn type frequency:\n\nnumeric\n5\n________________________\n\nGroup variables\nNone\nVariable type: numeric\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\ny\n0\n1\n25.65\n50.85\n0.0\n0\n3\n24\n357.0\n▇▁▁▁▁\nroach1\n0\n1\n42.19\n75.26\n0.0\n1\n7\n50\n450.0\n▇▁▁▁▁\ntreatment\n0\n1\n0.60\n0.49\n0.0\n0\n1\n1\n1.0\n▅▁▁▁▇\nsenior\n0\n1\n0.31\n0.46\n0.0\n0\n0\n1\n1.0\n▇▁▁▁▃\nexposure2\n0\n1\n1.02\n0.32\n0.2\n1\n1\n1\n4.3\n▇▂▁▁▁\n\nModelo de Poisson\nO modelo possuirá as seguintes variáveis como independentes: roach1, treatment e senior. Para todas essas variáveis, como os coeficientes estarão em um escala logarítma usarei uma priori de uma distribuição normal com média 0 e os respectivos desvios padrões de 0.1, 5 e 51. O que resulta em prior = normal(c(0, 0, 0), c(0.1, 5, 5)). Vou colocar a priori da constante \\(\\alpha\\) como uma normal centrada em 0 e com um desvio padrão 2.5, basicamente traduzindo o que usamos como priori em modelos gaussianos (regressão linear). Isto resulta em prior_intercept = normal(0, 2.5). Notem que aqui não temos erro do modelo, pois a função de verossimilhança não faz pressupostos sobre desvios como era o caso na regressão linear com uma verossimilhança Gaussiana/Normal. Portanto não há o que se especificar para prior_aux.\n\n\nmodel_poisson <- stan_glm(\n  y ~ roach1 + treatment + senior,\n  data = roaches,\n  family = poisson,\n  prior = normal(c(0, 0, 0), c(0.1, 5, 5)),\n  prior_intercept = normal(0, 2.5)\n)\n\n\n\nVamos ver como ficaram as estimação dos parâmetros de interesse do modelo com summary():\n\n\nsummary(model_poisson)\n\n\n\nModel Info:\n function:     stan_glm\n family:       poisson [log]\n formula:      y ~ roach1 + treatment + senior\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 262\n predictors:   4\n\nEstimates:\n              mean   sd   10%   50%   90%\n(Intercept)  3.1    0.0  3.1   3.1   3.2 \nroach1       0.0    0.0  0.0   0.0   0.0 \ntreatment   -0.5    0.0 -0.5  -0.5  -0.5 \nsenior      -0.4    0.0 -0.4  -0.4  -0.3 \n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 25.6    0.4 25.1  25.6  26.2 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.0  1.0  3177 \nroach1        0.0  1.0  3559 \ntreatment     0.0  1.0  2753 \nsenior        0.0  1.0  2636 \nmean_PPD      0.0  1.0  3230 \nlog-posterior 0.0  1.0  1559 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nNão tivemos nenhum problema nas correntes Markov pois todos os Rhat estão bem abaixo de 1.01.\nVamos verificar o Posterior Predictive Check do modelo de Poisson na figura 2:\n\n\npp_check(model_poisson)\n\n\n\n\nFigure 2: Posterior Preditive Check do modelo de Poisson\n\n\n\nEste é um bom exemplo de um Posterior Predictive Check no qual há algo errado com o modelo. Isto indica que devemos pensar melhor nas variáveis nas prioris, ou até incorporar mais variáveis no modelo. A função de verossimilhança faz um bom trabalho em se moldar à densidade da variável dependente \\(y\\) mas ainda é necessário alguns ajustes finos no modelo.\nInterpretação dos coeficientes\nAo vermos a fórmula de regressão de Poisson percebemos a interpretação dos coeficientes requer uma transformação. A transformação que precisamos fazer é a que inverte o logarítmo de \\(y\\), no caso a função de exponenciação:\n\\[\n\\begin{aligned}\n\\log(y) &= \\alpha + \\mathbf{X} \\cdot \\boldsymbol{\\beta} \\\\\ny &= e^{\\alpha \\mathbf{X} \\cdot \\boldsymbol{\\beta}} \\\\\ny &= e^{\\alpha } + e^{\\mathbf{X} \\cdot \\boldsymbol{\\beta}}\n\\end{aligned}\n\\]\nFazemos isso com a função exp() do R nos coeficientes do model_poisson:\n\n\ncoeff <- exp(model_poisson$coefficients)\ncoeff\n\n\n(Intercept)      roach1   treatment      senior \n      23.01        1.01        0.60        0.69 \n\n(Intercept): a taxa basal de exterminação das baratas \\(y\\), \\(23\\)\nroach1: a cada uma barata antes da exterminação há um aumento de \\(\\approx 1\\) barata exterminada a mais\ntreatment: se o apartamento foi dedetizado há um aumento de \\(0.6\\) barata exterminada a mais\nsenior: se o apartamento possui somente idoso há um aumento de \\(\\approx 0.7\\) barata exterminada a mais\nInflação de Zeros2 - Modelo Binomial Negativo\nÀs vezes temos dados de contagem na qual há uma super-inflação de zeros na variável dependente \\(y\\). Nestes casos os modelos de Poisson podem não ser a melhor opção. Para isso é melhor usar função de verossimilhança binomial negativa. Lembrando que a distribuição negativa binomial tem dois parâmetros:\nNúmero de Sucessos (\\(k\\))\nProbabilidade de Sucessos (\\(p\\))\nQualquer fenômeno que pode ser modelo com uma distribuição de Poisson, pode ser modelo com uma distribuição binomial negativa (Gelman et al., 2013; Gelman, Hill, & Vehtari, 2020).\nUsando a função de verossimilhança binomial negativa nosso modelo se torna:\n\\[\n\\begin{aligned}\ny &\\sim \\text{Binomial Negativa} \\left( e^{(\\alpha + \\mathbf{X} \\cdot \\boldsymbol{\\beta})}, \\phi \\right) \\\\\n\\phi &\\sim \\text{Gamma}(0.01, 0.01) \\\\\n\\alpha &\\sim \\text{Normal}(\\mu_\\alpha, \\sigma_\\alpha) \\\\\n\\boldsymbol{\\beta} &\\sim \\text{Normal}(\\mu_{\\boldsymbol{\\beta}}, \\sigma_{\\boldsymbol{\\beta}})\n\\end{aligned}\n\\]\nVeja que, quando comparamos com o modelo de Poisson, temos uma novo parâmetro \\(\\phi\\) que parametriza a distribuição a distribuição binomial negativa. Esse parâmetro é a probabilidade de sucessos \\(p\\) da distribuição binomial negativa e geralmente usamos uma distribuição Gamma como priori para que \\(\\phi\\) cumpra a função de uma parâmetro de “dispersão recíproca.”\nPara usar funções de verossimilhança binomial negativa basta adicionar:\nrstanarm: family = neg_binomial_2\nbrms: family = negbinomial\nInflação de Zeros - Mistura Binomial Negativa\nMesmo usando uma função de verossimilhança binomial negativa, caso a superdispersão seja muito acentuada, o seu modelo ainda pode resultar em patologias. Uma outra sugestão é usar uma mistura com uma função de verossimilhança binomial negativa. Precisa de apenas uma única mudança na especificação do modelo:\n\\[\ny \\begin{cases}\n= 0, &\\text{ se } S_i = 0 \\\\\n\\sim \\text{Binomial Negativa} \\left( e^{(\\alpha + \\mathbf{X} \\cdot \\boldsymbol{\\beta})}, \\phi \\right), &\\text{ se } S_i = 1\n\\end{cases}\n\\]\nAqui, \\(S_i\\) é uma variável binária (dummy) indicando se a observação \\(i\\) tem valor diferente de zero ou não. \\(S_i\\) pode ser modelado usando uma regressão logística:\n\\[\n\\begin{aligned}\nP(S_i = 1) &= \\operatorname{logit}^{-1}(\\mathbf{X} \\cdot \\boldsymbol{\\gamma}) \\\\\n\\boldsymbol{\\gamma} &\\sim \\text{Beta}(1, 1)\n\\end{aligned}\n\\]\nonde \\(\\boldsymbol{\\gamma}\\) é um novo conjunto de coeficientes para essa parte do modelo com priori uniforme de \\(\\text{Beta} (1, 1)\\). Esse modelo de duas etapas (two-stage) pode ser feito apenas especificando family = zero_inflated_negbinomial no brms ou codificando diretamente no Stan. rstanarm não possui suporte para esse tipo de modelo baseado em uma mistura.\nExemplo Binomial Negativo - Revisitando a exterminação de baratas\nVamos dar uma olhada melhor no histograma da variável dependente y (figura 3). Como vocês podem ver, temos muitos zeros como observações de y:\n\n\nggplot(roaches, aes(y)) +\n  geom_histogram(bins = 15, fill = \"steelblue\") +\n  labs(\n    title = \"Histograma da variável y\",\n    y = \"Frequência\"\n  )\n\n\n\n\nFigure 3: Histograma da variável y\n\n\n\nroaches é um bom candidato para um modelo binomial negativo. Vamos então estimá-lo com o rstanarm. Aqui vou usar as mesmas prioris do modelo de Poisson. rstanarm por padrão usa a distribuição \\(\\text{Exponencial} (1)\\) como priori de \\(\\phi\\)3. Caso queira mudar é só especificar a sua priori desejada como argumento do prior_aux:\n\n\nmodel_negbinomial <- stan_glm(\n  y ~ roach1 + treatment + senior,\n  data = roaches,\n  family = neg_binomial_2,\n  prior = normal(c(0, 0, 0), c(0.1, 5, 5)),\n  prior_intercept = normal(0, 2.5),\n  prior_aux = rstanarm::exponential(1)\n)\n\n\n\nVamos ver como ficaram as estimação dos parâmetros de interesse do modelo com summary():\n\n\nsummary(model_negbinomial)\n\n\n\nModel Info:\n function:     stan_glm\n family:       neg_binomial_2 [log]\n formula:      y ~ roach1 + treatment + senior\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 262\n predictors:   4\n\nEstimates:\n                        mean   sd   10%   50%   90%\n(Intercept)            2.8    0.2  2.6   2.8   3.1 \nroach1                 0.0    0.0  0.0   0.0   0.0 \ntreatment             -0.7    0.2 -1.1  -0.7  -0.4 \nsenior                -0.3    0.3 -0.7  -0.3   0.0 \nreciprocal_dispersion  0.3    0.0  0.2   0.3   0.3 \n\nFit Diagnostics:\n           mean   sd    10%   50%   90%\nmean_PPD  95.8  185.3  26.1  52.0 175.5\n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n                      mcse Rhat n_eff\n(Intercept)           0.0  1.0  5328 \nroach1                0.0  1.0  5114 \ntreatment             0.0  1.0  5261 \nsenior                0.0  1.0  4957 \nreciprocal_dispersion 0.0  1.0  5319 \nmean_PPD              3.1  1.0  3636 \nlog-posterior         0.0  1.0  1865 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nNão tivemos nenhum problema nas correntes Markov pois todos os Rhat estão bem abaixo de 1.01. Vejam que as inferências sobre os parâmetros estão diferentes do modelo de Poisson. Notem também que o número de amostras efetivas (Effective Sample Size - ESS) para todos os parâmetros do modelo negativo binomial estão bem mais elevadas que o modelo de Poisson, indicando que com a parametrização binomial negativa o amostrador MCMC de Stan conseguiu explorar muito melhor a posterior do que na parametrização de Poisson.\nVamos verificar o Posterior Predictive Check do modelo binomial negativo na figura 4:\n\n\npp_check(model_negbinomial)\n\n\n\n\nFigure 4: Posterior Preditive Check do modelo Binomial Negativo\n\n\n\nVemos também que Posterior Preditive Check do modelo binomial negativo possui um aspecto muito melhor que o modelo de Poisson.\nExemplo Mistura Binomial Negativo - \\(\\textbf{Revisitando}^2\\) a exterminação de baratas\nVamos tentar aprimorar o modelo binomial negativo incorporando a mistura sugerida acima. Para isso teremos que usar o brms já que o rstanarm não possui suporte à misturas. Vou manter todas as prioris dos modelos anteriores. Mas para \\(\\phi\\) usarei a distribuição \\(\\text{Gamma}(0.01, 0.01)\\) (prior(gamma(0.01, 0.01), class = shape)) que possui suporte no brms e para os coeficientes \\(\\boldsymbol{\\gamma}\\) da segunda etapa do modelo usarei a priori uniforme \\(\\text{Beta}(1, 1)\\) (prior(beta(1,1), class = zi)):\n\n\nlibrary(brms)\nmodel_zero_inflated <- brm(\n  y ~ roach1 + treatment + senior,\n  data = roaches,\n  family = zero_inflated_negbinomial,\n  prior = c(\n    prior(normal(0, 0.1), class = b, coef = roach1),\n    prior(normal(0, 5), class = b, coef = treatment),\n    prior(normal(0, 5), class = b, coef = senior),\n    prior(normal(0, 2.5), class = Intercept),\n    prior(gamma(0.01, 0.01), class = shape),\n    prior(beta(1, 1), class = zi)\n    )\n)\n\n\n\nVamos ver como ficaram as estimação dos parâmetros de interesse do modelo com summary():\n\n\nsummary(model_zero_inflated)\n\n\n Family: zero_inflated_negbinomial \n  Links: mu = log; shape = identity; zi = identity \nFormula: y ~ roach1 + treatment + senior \n   Data: roaches (Number of observations: 262) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     2.92      0.24     2.46     3.39 1.00     2433     2438\nroach1        0.01      0.00     0.01     0.02 1.00     2447     1794\ntreatment    -0.72      0.25    -1.22    -0.24 1.00     2164     1211\nsenior       -0.31      0.26    -0.80     0.20 1.00     2758     2299\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nshape     0.30      0.05     0.23     0.42 1.00     1187      582\nzi        0.06      0.05     0.00     0.19 1.00      873      700\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nNão tivemos nenhum problema nas correntes Markov pois todos os Rhat estão bem abaixo de 1.01. Vejam que as inferências sobre os parâmetros estão similares ao modelo negativo binomial, mas com menores erros (Est.Error no brms vs sd no rstanarm).\nVamos verificar o Posterior Predictive Check da mistura binomial negativa na figura 5:\n\n\npp_check(model_zero_inflated, nsamples = 40)\n\n\n\n\nFigure 5: Posterior Preditive Check da mistura Binomial Negativa\n\n\n\nAs mistura negativa binomial tem quase o mesmo Posterior Preditive Check do modelo binomial, porém com menores erros de mensuração dos parâmetros de interesse. Isto nos satisfaz que das três alternativas aqui apresentadas a mistura negativa binomial é a melhor candidata para modelar roaches.\nAtividade Prática\nVeja o dataset NYC_bicycle que está disponível no diretório datasets/:\nNew York City - East River Bicycle Crossings: datasets/NYC_bicycle.csv\n\n\n###\n\n\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.4 (2021-02-15)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n [1] gapminder_0.3.0      ggExtra_0.9          dplyr_1.0.5         \n [4] rstan_2.21.2         StanHeaders_2.21.0-7 MASS_7.3-53.1       \n [7] ggforce_0.3.3        gganimate_1.0.7      plotly_4.9.3        \n[10] carData_3.0-4        DiagrammeR_1.0.6.1   brms_2.15.0         \n[13] rstanarm_2.21.1      Rcpp_1.0.6           skimr_2.1.3         \n[16] readr_1.4.0          readxl_1.3.1         tibble_3.1.0        \n[19] ggplot2_3.3.3        patchwork_1.1.1      cowplot_1.1.1       \n\nloaded via a namespace (and not attached):\n  [1] backports_1.2.1      systemfonts_1.0.1    plyr_1.8.6          \n  [4] igraph_1.2.6         lazyeval_0.2.2       repr_1.1.3          \n  [7] splines_4.0.4        crosstalk_1.1.1      TH.data_1.0-10      \n [10] rstantools_2.1.1     inline_0.3.17        digest_0.6.27       \n [13] htmltools_0.5.1.1    magick_2.7.1         rsconnect_0.8.16    \n [16] fansi_0.4.2          magrittr_2.0.1       RcppParallel_5.0.3  \n [19] matrixStats_0.58.0   sandwich_3.0-0       xts_0.12.1          \n [22] prettyunits_1.1.1    jpeg_0.1-8.1         colorspace_2.0-0    \n [25] textshaping_0.3.3    xfun_0.22            callr_3.6.0         \n [28] crayon_1.4.1         jsonlite_1.7.2       lme4_1.1-26         \n [31] survival_3.2-10      zoo_1.8-9            glue_1.4.2          \n [34] polyclip_1.10-0      gtable_0.3.0         emmeans_1.5.5-1     \n [37] V8_3.4.0             pkgbuild_1.2.0       abind_1.4-5         \n [40] scales_1.1.1         mvtnorm_1.1-1        DBI_1.1.1           \n [43] miniUI_0.1.1.1       isoband_0.2.4        progress_1.2.2      \n [46] viridisLite_0.3.0    xtable_1.8-4         tmvnsim_1.0-2       \n [49] stats4_4.0.4         DT_0.17              httr_1.4.2          \n [52] htmlwidgets_1.5.3    threejs_0.3.3        RColorBrewer_1.1-2  \n [55] ellipsis_0.3.1       pkgconfig_2.0.3      loo_2.4.1           \n [58] farver_2.1.0         sass_0.3.1           here_1.0.1          \n [61] utf8_1.2.1           tidyselect_1.1.0     labeling_0.4.2      \n [64] rlang_0.4.10         reshape2_1.4.4       later_1.1.0.1       \n [67] visNetwork_2.0.9     munsell_0.5.0        cellranger_1.1.0    \n [70] tools_4.0.4          cli_2.3.1            generics_0.1.0      \n [73] gifski_1.4.3         ggridges_0.5.3       evaluate_0.14       \n [76] stringr_1.4.0        fastmap_1.1.0        yaml_2.2.1          \n [79] ragg_1.1.2           processx_3.5.0       knitr_1.31          \n [82] purrr_0.3.4          nlme_3.1-152         projpred_2.0.2      \n [85] mime_0.10            xml2_1.3.2           compiler_4.0.4      \n [88] bayesplot_1.8.0      shinythemes_1.2.0    rstudioapi_0.13     \n [91] gamm4_0.2-6          curl_4.3             png_0.1-7           \n [94] tweenr_1.0.2         statmod_1.4.35       bslib_0.2.4         \n [97] stringi_1.5.3        highr_0.8            ps_1.6.0            \n[100] Brobdingnag_1.2-6    lattice_0.20-41      Matrix_1.3-2        \n[103] nloptr_1.2.2.2       markdown_1.1         shinyjs_2.0.0       \n[106] vctrs_0.3.6          pillar_1.5.1         lifecycle_1.0.0     \n[109] jquerylib_0.1.3      bridgesampling_1.0-0 estimability_1.3    \n[112] data.table_1.14.0    httpuv_1.5.5         R6_2.5.0            \n[115] bookdown_0.21        promises_1.2.0.1     gridExtra_2.3       \n[118] codetools_0.2-18     distill_1.2          boot_1.3-27         \n[121] colourpicker_1.1.0   gtools_3.8.2         assertthat_0.2.1    \n[124] rprojroot_2.0.2      withr_2.4.1          mnormt_2.0.2        \n[127] shinystan_2.5.0      multcomp_1.4-16      mgcv_1.8-34         \n[130] parallel_4.0.4       hms_1.0.0            grid_4.0.4          \n[133] tidyr_1.1.3          coda_0.19-4          minqa_1.2.4         \n[136] rmarkdown_2.7        downlit_0.2.1        shiny_1.6.0         \n[139] lubridate_1.7.10     base64enc_0.1-3      dygraphs_1.1.1.6    \n\n\n\n\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian Data Analysis. Chapman and Hall/CRC.\n\n\nGelman, A., & Hill, J. (2007). Data analysis using regression and multilevel/hierarchical models. Cambridge university press.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2020). Regression and other stories. Cambridge University Press.\n\n\nWaring, E., Quinn, M., McNamara, A., Arino de la Rubia, E., Zhu, H., & Ellis, S. (2021). Skimr: Compact and flexible summaries of data. Retrieved from https://CRAN.R-project.org/package=skimr\n\n\ndepois de diversos prior predictive checks cheguei a essas prioris que não são tão diferentes das padrões do rstanarm para modelos de Poisson.↩︎\ntambém chamados de superdispersão.↩︎\nrstanarm não possui suporte para especificar prioris com distribuição Gamma.↩︎\n",
      "last_modified": "2021-03-29T16:57:06-03:00"
    },
    {
      "path": "9-Regressao_Robusta.html",
      "title": "Regressão Robusta Bayesiana",
      "description": "Modelos Lineares Generalizados -- $t$ de Student",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 1, 2021",
      "contents": "\n\nContents\nComparativo Normal vs Student\nRegressão Robusta Bayesiana\nModelos Lineares Robustos com o pacote brms\nExemplo - Prestígio de Duncan (1961)\n\nAtividade Prática\nAmbiente\n\n\nVamos lembrar da curva Gaussiana/Normal que possui um formato de sino (figura 1). Ela não é muito alongada nas “pontas.” Ou seja, as observações não fogem muito da média. Quando usamos essa distribuição como verossimilhança na inferência modelos Bayesianos, forçamos a que todas as estimativas sejam condicionadas à uma distribuição normal da variável dependente. Se nos dados houverem muitas observações com valores discrepantes (bem diferentes da média – outliers), isso faz com que as estimativas dos coeficientes das variáveis independentes fiquem instáveis. Isso ocorre porquê a distribuição normal não consegue contemplar observações muito divergentes da média sem ter que mudar a média de posição. Em outras palavras, ela precisa se “deslocar” para conseguir estimar observações com valores discrepantes causando instabilidade da inferência.\n\n\nggplot(data = tibble(x = seq(-4, 4, length = 100))) +\n  labs(\n    title = \"Distribuição Normais\",\n    subtitle = expression(list(mu == 0, sigma == 1)),\n    x = expression(theta),\n    y = \"Densidade\"\n  ) +\n  geom_line(aes(x, y = dnorm(x, mean = 0, sd = 1)), color = \"steelblue\", size = 2)\n\n\n\n\nFigure 1: Distribuição Normal\n\n\n\nEntão precisamos de uma distribuição mais “maleável” como verossimilhança. Uma distribuição que seja mais robusta à observações discrepantes (outliers). Uma distribuição similar à Normal mas que possua caudas mais longas para justamente contemplar observações muito longe da média sem ter que mudar a média de posição e ter que se “contorser” toda. Para isso temos a distribuição \\(t\\) de Student. Lembrando o formato dela na figura 2:\n\n\nggplot(data = tibble(x = seq(-4, 4, length = 100))) +\n  labs(\n    title = \"Distribuição t de Student\",\n    subtitle = expression(list(nu == 3, mu == 0, sigma == 1)),\n    x = expression(theta),\n    y = \"Densidade\"\n  ) +\n  geom_line(aes(x, y = dt(x, df = 3)), color = \"red\", size = 2)\n\n\n\n\nFigure 2: Distribuição \\(t\\) de Student\n\n\n\nComparativo Normal vs Student\nReparem nas caudas na figura 3:\n\n\nggplot(data = tibble(x = seq(-4, 4, length = 100))) +\n  labs(\n    title = \"Comparativo Distribuições Normal vs t de Student\",\n    subtitle = expression(list(nu == 3, mu == 0, sigma == 1)),\n    x = expression(theta),\n    y = \"Densidade\"\n  ) +\n  geom_line(aes(x, y = dnorm(x, mean = 0, sd = 1), color = \"Normal\"), size = 2) +\n  geom_line(aes(x, y = dt(x, df = 3), color = \"Student\"), size = 2) +\n  scale_color_manual(\n    name = \"Distribuições\",\n    values = c(\"steelblue\", \"red\")\n  )\n\n\n\n\nFigure 3: Comparativo Distribuições Normal vs \\(t\\) de Student\n\n\n\nRegressão Robusta Bayesiana\nA abordagem padrão para modelarmos uma variável dependente contínua é com um função de verossimilhança Gaussiana/Normal. Isto implica que o erro do modelo, \\(\\sigma\\) da função de verossimilhança Gaussiana/Normal seja distribuído como uma distribuição normal:\n\\[\n\\begin{aligned}\ny &\\sim \\text{Normal}\\left( \\alpha + \\mathbf{X} \\cdot \\boldsymbol{\\beta}, \\sigma \\right) \\\\\n\\alpha &\\sim \\text{Normal}(\\mu_\\alpha, \\sigma_\\alpha) \\\\\n\\boldsymbol{\\beta} &\\sim \\text{Normal}(\\mu_{\\boldsymbol{\\beta}}, \\sigma_{\\boldsymbol{\\beta}}) \\\\\n\\sigma &\\sim \\text{Exponencial}(\\lambda_\\sigma)\n\\end{aligned}\n\\]\nDo ponto de vista Bayesiano, não há nada especial na verossimilhança Gaussiana/Normal. É apenas uma distribuição probabilística especificada em um modelo. Podemos deixar o modelo mais robusto ao usarmos uma distribuição \\(t\\) de Student como função de verossimilhança. Isto implica que o erro do modelo, \\(\\sigma\\) não segue uma distribuição normal, mas sim uma distribuição \\(t\\) de Student:\n\\[\n\\begin{aligned}\ny &\\sim \\text{Student}\\left( \\nu, \\alpha + \\mathbf{X} \\cdot \\boldsymbol{\\beta}, \\sigma \\right) \\\\\n\\alpha &\\sim \\text{Normal}(\\mu_\\alpha, \\sigma_\\alpha) \\\\\n\\boldsymbol{\\beta} &\\sim \\text{Normal}(\\mu_{\\boldsymbol{\\beta}}, \\sigma_{\\boldsymbol{\\beta}}) \\\\\n\\nu &\\sim \\text{Log-Normal}(2, 1) \\\\\n\\sigma &\\sim \\text{Exponencial}(\\lambda_\\sigma)\n\\end{aligned}\n\\]\nAqui temos algumas diferenças:\nA função de verossimilhança \\(t\\) de Student requer 1 parâmetro adicional: \\(\\nu\\), os graus de liberdade. Esses controlam o quão “longas” serão as caudas. Valores \\(\\nu > 20\\) fazem a distribuição \\(t\\) de Student praticamente se tornar uma distribuição normal.\nNão há nada especial em \\(\\nu\\). É apenas mais um parâmetro para o modelo estimar. Então é só eluciar uma priori. No caso, estou usando uma Distribuição Log-Normal com média 2 e desvio padrão 1.\nVeja que não há nada de especial também nas prioris dos coeficientes \\(\\boldsymbol{\\beta}\\) ou da constante \\(\\alpha\\). Poderíamos muito bem também colocar outras distribuições ou até deixar o modelo mais robustos ainda à outliers colocando prioris \\(t\\) de Student:\n\\[\n\\begin{aligned}\n\\alpha &\\sim \\text{Student}(\\nu_\\alpha, \\mu_\\alpha, \\sigma_\\alpha) \\\\\n\\boldsymbol{\\beta} &\\sim \\text{Student}(\\nu_{\\boldsymbol{\\beta}}, \\mu_{\\boldsymbol{\\beta}}, \\sigma_{\\boldsymbol{\\beta}}) \\\\\n\\nu_\\alpha &\\sim \\text{Log-Normal}(1, 1) \\\\\n\\nu_{\\boldsymbol{\\beta}} &\\sim \\text{Log-Normal}(1, 1)\n\\end{aligned}\n\\]\nModelos Lineares Robustos com o pacote brms\nO rstanarm não nos dá a possibilidade de usar distribuições \\(t\\) de Student como função de verossimilhança de modelos Bayesiano. Para usarmos distribuições \\(t\\) de Student, precisamos usar o brms (Bürkner, 2017). O brms usa a mesma síntaxe que o rstanarm e possui as mesmas famílias de funções de verossimilhança, mas com algumas diferenças:\nrstanarm todos os modelos são pré-compilados e brms não possui os modelos pré-compilados então os modelos devem ser todos compilados antes de serem rodados. A diferença prática é que você irá esperar alguns instantes antes do R começar a amostrar do modelo.\nComo brms compila os modelos conforme a especificação do usuário (não possui modelos pré-compilados) ele pode criar modelos um pouco mais eficientes que o rstanarm. Caso o tempo de compilação dos modelos brms seja menor que ganho de velocidade em amostragem do modelo, é vantajoso especificar seu modelo com brms.\nbrms dá maior poder e flexibilidade ao usuário na especificação de funções de verossimilhança e também permite modelos mais complexos que o rstanarm.\nA função que usamose para designar modelos Bayesianos no brms é a brm():\n\n\nbrm(y ~ ...,\n    data = ...,\n    family = student)\n\n\n\nExemplo - Prestígio de Duncan (1961)\nPara exemplicar regressão robusta vamos usar um dataset que tem muitas observações discrepantes (outliers) chamado Duncan (Duncan, 1961). Ele possui 45 observações sobre ocupações nos EUA e 5 variáveis:\nprofession: Nome da profissão\ntype: Tipo de ocupação. Uma variável qualitativa:\nprof - profissional ou de gestão\nwc - white-collar (colarinho branco)\nbc - blue-collar (colarinho azul)\n\nincome: Porcentagem de pessoas da ocupação que ganham acima U$ 3.500 por ano em 1950 (mais ou menos U$36.000 em 2017);\neducation: Porcentagem de pessoas da ocupação que possuem diploma de ensino médio em 1949 (que, sendo cínicos, podemos dizer que é de certa maneira equivalente com diploma de Doutorado em 2017); e\nprestige: Porcentagem de respondentes na pesquisa que classificam a sua ocupação como no mínimo “boa” em respeito à prestígio.\nComo sempre eu gosto de usar o pacote skimr (Waring et al., 2021) com a função skim():\n\n\nlibrary(skimr)\nduncan <- read_csv2(\"datasets/Duncan.csv\", col_types = \"ffiii\")\nskim(duncan)\n\n\nTable 1: Data summary\nName\nduncan\nNumber of rows\n45\nNumber of columns\n5\n_______________________\n\nColumn type frequency:\n\nfactor\n2\nnumeric\n3\n________________________\n\nGroup variables\nNone\nVariable type: factor\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\nprofession\n0\n1\nFALSE\n45\nacc: 1, pil: 1, arc: 1, aut: 1\ntype\n0\n1\nFALSE\n3\nbc: 21, pro: 18, wc: 6\nVariable type: numeric\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\nincome\n0\n1\n42\n24\n7\n21\n42\n64\n81\n▇▂▅▃▅\neducation\n0\n1\n53\n30\n7\n26\n45\n84\n100\n▆▆▃▂▇\nprestige\n0\n1\n48\n32\n3\n16\n41\n81\n97\n▇▃▅▂▇\n\nEu acho que variável dependente prestige merece uma atenção maior, vejam o histograma dela na figura 4. Parece que temos uma multimodalidade rolando por aqui:\n\n\nggplot(duncan, aes(prestige)) +\n  geom_histogram(bins = 15, fill = \"steelblue\") +\n  labs(\n    title = \"Histograma da variável prestige\",\n    y = \"Frequência\"\n  )\n\n\n\n\nFigure 4: Histograma da variável prestige\n\n\n\nPrimeiro modelo: Regressão Linear\nVamos estimar primeiramente uma regressão linear usando a distribuição Normal como verossimilhança no rstanarm. Para exemplificação vou manter as prioris padrões do rstanarm:\n\n\n# Detectar quantos cores/processadores\noptions(mc.cores = parallel::detectCores())\noptions(Ncpus = parallel::detectCores())\n\nlibrary(rstanarm)\n\nmodel_1 <- stan_glm(\n  prestige ~ income + education,\n  data = duncan,\n  family = gaussian # nem precisaria pois é o argumento padrão\n)\n\n\n\nE na sequência o sumário das estimativas do modelo, assim como os diagnósticos da MCMC:\n\n\nsummary(model_1)\n\n\n\nModel Info:\n function:     stan_glm\n family:       gaussian [identity]\n formula:      prestige ~ income + education\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 45\n predictors:   3\n\nEstimates:\n              mean   sd    10%   50%   90%\n(Intercept)  -6.1    4.6 -12.0  -6.2  -0.2\nincome        0.6    0.1   0.4   0.6   0.8\neducation     0.5    0.1   0.4   0.5   0.7\nsigma        13.8    1.6  11.8  13.6  15.8\n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 47.6    2.9 43.9  47.7  51.3 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.1  1.0  4499 \nincome        0.0  1.0  2089 \neducation     0.0  1.0  2319 \nsigma         0.0  1.0  1977 \nmean_PPD      0.1  1.0  3023 \nlog-posterior 0.0  1.0  1343 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nAparentemente parece que o modelo possui boas métricas (todos Rhat menores que 1.01) mas quando olhamos o Posterior Predictive Check (figura 5), vemos uma bagunça:\n\n\npp_check(model_1, nreps = 40)\n\n\n\n\nFigure 5: Posterior Preditive Check do modelo Gaussiano/Normal\n\n\n\nSegundo modelo: Regressão Robusta\nPara rodar um modelo Bayesiano que usa como verossimilhança a distribuição \\(t\\) de Student basta somente usar a mesma síntaxe que o stan_glm mas colocando argumento family = student. Aqui vou usar as mesmas priors que o padrão do rstanarm (caso queira, é só verificá-las com o prior_summary(model_1)):\n\n\nlibrary(brms)\nmodel_2 <- brm(\n  prestige ~ income + education,\n  data = duncan,\n  family = student,\n  prior = c(\n    prior(normal(0, 3.22), class = b, coef = income),\n    prior(normal(0, 2.65), class = b, coef = education),\n    prior(normal(48, 79), class = Intercept),\n    prior(exponential(0.032), class = sigma),\n    prior(lognormal(2, 1), class = nu)\n  )\n)\n\n\n\nE na sequência o sumário das estimativas do modelo com verossimilhança \\(t\\) de Student (estou colocando o prob = 0.9 para que o sumário do modelo brms seja o mesmo que o sumário do rstanarm), assim como os diagnósticos da MCMC:\n\n\nsummary(model_2, prob =  0.9)\n\n\n Family: student \n  Links: mu = identity; sigma = identity; nu = identity \nFormula: prestige ~ income + education \n   Data: duncan (Number of observations: 45) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-90% CI u-90% CI Rhat Bulk_ESS Tail_ESS\nIntercept    -7.09      3.75   -13.11    -0.74 1.00     4446     2847\nincome        0.69      0.14     0.46     0.91 1.00     2095     2550\neducation     0.49      0.11     0.31     0.67 1.00     2157     2502\n\nFamily Specific Parameters: \n      Estimate Est.Error l-90% CI u-90% CI Rhat Bulk_ESS Tail_ESS\nsigma    11.19      2.15     7.65    14.65 1.00     1784     1256\nnu       10.37     12.90     2.03    31.86 1.00     1838     1874\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nVemos que o erro do modelo sigma reduziu de \\(\\approx 14\\) para \\(\\approx 11\\), o que implica em uma melhor inferência do modelo. Além disso, temos um novo parâmetro estimado pelo modelo que é o parâmetro nu (\\(\\nu\\)): os graus de liberdade da distribuição \\(t\\) de Student usada como verossimilhança.\nE para concluir, vejam que p Posterior Predictive Check (figura 6) ficou com um aspecto muito melhor que o modelo linear:\n\n\npp_check(model_2, nsamples = 40)\n\n\n\n\nFigure 6: Posterior Preditive Check do modelo \\(t\\) de Student\n\n\n\nAtividade Prática\nO dataset Boston Housing está disponível em datasets/Boston_Housing.csv. Possui 506 observações e possui 14 variáveis:\nCRIM - per capita crime rate by town\nZN - proportion of residential land zoned for lots over 25,000 sq.ft.\nINDUS - proportion of non-retail business acres per town.\nCHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\nNOX - nitric oxides concentration (parts per 10 million)\nRM - average number of rooms per dwelling\nAGE - proportion of owner-occupied units built prior to 1940\nDIS - weighted distances to five Boston employment centres\nRAD - index of accessibility to radial highways\nTAX - full-value property-tax rate per $10,000\nPTRATIO - pupil-teacher ratio by town\nB - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\nLSTAT - % lower status of the population\nMEDV - Median value of owner-occupied homes in $1000’s\n\n\n###\n\n\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.4 (2021-02-15)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n [1] gapminder_0.3.0      ggExtra_0.9          dplyr_1.0.5         \n [4] rstan_2.21.2         StanHeaders_2.21.0-7 MASS_7.3-53.1       \n [7] ggforce_0.3.3        gganimate_1.0.7      plotly_4.9.3        \n[10] carData_3.0-4        DiagrammeR_1.0.6.1   brms_2.15.0         \n[13] rstanarm_2.21.1      Rcpp_1.0.6           skimr_2.1.3         \n[16] readr_1.4.0          readxl_1.3.1         tibble_3.1.0        \n[19] ggplot2_3.3.3        patchwork_1.1.1      cowplot_1.1.1       \n\nloaded via a namespace (and not attached):\n  [1] backports_1.2.1      systemfonts_1.0.1    plyr_1.8.6          \n  [4] igraph_1.2.6         lazyeval_0.2.2       repr_1.1.3          \n  [7] splines_4.0.4        crosstalk_1.1.1      TH.data_1.0-10      \n [10] rstantools_2.1.1     inline_0.3.17        digest_0.6.27       \n [13] htmltools_0.5.1.1    magick_2.7.1         rsconnect_0.8.16    \n [16] fansi_0.4.2          magrittr_2.0.1       RcppParallel_5.0.3  \n [19] matrixStats_0.58.0   sandwich_3.0-0       xts_0.12.1          \n [22] prettyunits_1.1.1    jpeg_0.1-8.1         colorspace_2.0-0    \n [25] textshaping_0.3.3    xfun_0.22            callr_3.6.0         \n [28] crayon_1.4.1         jsonlite_1.7.2       lme4_1.1-26         \n [31] survival_3.2-10      zoo_1.8-9            glue_1.4.2          \n [34] polyclip_1.10-0      gtable_0.3.0         emmeans_1.5.5-1     \n [37] V8_3.4.0             pkgbuild_1.2.0       abind_1.4-5         \n [40] scales_1.1.1         mvtnorm_1.1-1        DBI_1.1.1           \n [43] miniUI_0.1.1.1       isoband_0.2.4        progress_1.2.2      \n [46] viridisLite_0.3.0    xtable_1.8-4         tmvnsim_1.0-2       \n [49] stats4_4.0.4         DT_0.17              httr_1.4.2          \n [52] htmlwidgets_1.5.3    threejs_0.3.3        RColorBrewer_1.1-2  \n [55] ellipsis_0.3.1       pkgconfig_2.0.3      loo_2.4.1           \n [58] farver_2.1.0         sass_0.3.1           here_1.0.1          \n [61] utf8_1.2.1           tidyselect_1.1.0     labeling_0.4.2      \n [64] rlang_0.4.10         reshape2_1.4.4       later_1.1.0.1       \n [67] visNetwork_2.0.9     munsell_0.5.0        cellranger_1.1.0    \n [70] tools_4.0.4          cli_2.3.1            generics_0.1.0      \n [73] gifski_1.4.3         ggridges_0.5.3       evaluate_0.14       \n [76] stringr_1.4.0        fastmap_1.1.0        yaml_2.2.1          \n [79] ragg_1.1.2           processx_3.5.0       knitr_1.31          \n [82] purrr_0.3.4          nlme_3.1-152         projpred_2.0.2      \n [85] mime_0.10            xml2_1.3.2           compiler_4.0.4      \n [88] bayesplot_1.8.0      shinythemes_1.2.0    rstudioapi_0.13     \n [91] gamm4_0.2-6          curl_4.3             png_0.1-7           \n [94] tweenr_1.0.2         statmod_1.4.35       bslib_0.2.4         \n [97] stringi_1.5.3        highr_0.8            ps_1.6.0            \n[100] Brobdingnag_1.2-6    lattice_0.20-41      Matrix_1.3-2        \n[103] nloptr_1.2.2.2       markdown_1.1         shinyjs_2.0.0       \n[106] vctrs_0.3.6          pillar_1.5.1         lifecycle_1.0.0     \n[109] jquerylib_0.1.3      bridgesampling_1.0-0 estimability_1.3    \n[112] data.table_1.14.0    httpuv_1.5.5         R6_2.5.0            \n[115] bookdown_0.21        promises_1.2.0.1     gridExtra_2.3       \n[118] codetools_0.2-18     distill_1.2          boot_1.3-27         \n[121] colourpicker_1.1.0   gtools_3.8.2         assertthat_0.2.1    \n[124] rprojroot_2.0.2      withr_2.4.1          mnormt_2.0.2        \n[127] shinystan_2.5.0      multcomp_1.4-16      mgcv_1.8-34         \n[130] parallel_4.0.4       hms_1.0.0            grid_4.0.4          \n[133] tidyr_1.1.3          coda_0.19-4          minqa_1.2.4         \n[136] rmarkdown_2.7        downlit_0.2.1        shiny_1.6.0         \n[139] lubridate_1.7.10     base64enc_0.1-3      dygraphs_1.1.1.6    \n\n\n\n\nBürkner, P.-C. (2017). brms: An R package for Bayesian multilevel models using Stan. Journal of Statistical Software, 80(1), 1–28. https://doi.org/10.18637/jss.v080.i01\n\n\nDuncan, O. D. (1961). A socioeconomic index for all occupations. Class: Critical Concepts, 1, 388–426.\n\n\nWaring, E., Quinn, M., McNamara, A., Arino de la Rubia, E., Zhu, H., & Ellis, S. (2021). Skimr: Compact and flexible summaries of data. Retrieved from https://CRAN.R-project.org/package=skimr\n\n\n\n\n",
      "last_modified": "2021-03-29T16:57:31-03:00"
    },
    {
      "path": "aux-Dados_Faltantes.html",
      "title": "Dados Faltantes",
      "description": "Como que Stan, rstanarm e brms lidam com dados faltantes",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 1, 2021",
      "contents": "\n\nContents\nRemover dados faltantes\nImputar valores nos dados faltantes\nImputar a média\nImputar a mediana\nImputar o último valor ocorrido\n\nComparação dos resultados\nAmbiente\n\n\nDados faltantes são um problema comum em qualquer análise de dados. Tanto Stan, quanto suas interfaces brms e rstanarm usam observações completas nas suas inferências. Então, toda observação que contiver qualquer dado faltante será removida por completa. Isto quer dizer que qualquer linha do seu dataset que tiver dados faltantes nas colunas que são usadas como variáveis do modelo será removida. Temos duas abordagens básicas para lidar com dados faltantes1:\nremover os dados faltantes\nimputar valores nos dados faltantes\nRemover dados faltantes\nA remoção de dados faltantes se divide em duas principais abordagens usando a função na.omit() do pacote base stats:\nremoção de observações com dados faltantes: aqui removemos as linhas com dados faltantes df <- na.omit(df)\nremoção de variáveis com dados faltantes: aqui removemos as colunas com dados faltantes df <- t(na.omit(t(df)))\nImputar valores nos dados faltantes\nDentre as diversas maneiras de imputar valores ao dados faltantes, as mais comuns são três:\nimputar a média\nimputar a mediana\nimputar o último valor ocorrido (muito usada em séries temporais)\nMas ainda há maneiras mais avançadas e que desempenham melhor em certas condições (não cobriremos essas técnicas nesse curso):\nk-nearest neighbors imputation\nrandom forest imputation\nHá um pacote de R chamado DescTools(Andri et mult. al., 2021): uma coleção de funções focadas especialmente na parte descritiva de análise de um dataset.\nPara mostrar as abordagens, geramos um dataset de uma série temporal de uma semana com dados faltantes. O dataset df contém duas colunas: dia com o dia da semana; e valor representando uma mensuração observada naquele dia. Aproveito para incluir dois dados faltantes na coluna valor de maneira aleatória:\n\n\nlibrary(DescTools)\nset.seed(123)\ndf <- tibble(\n  dia = c(\"seg\", \"ter\", \"qua\", \"qui\", \"sex\", \"sab\", \"dom\"),\n  valor = runif(7))\nindices_aleatorios <- sample(1:nrow(df), 2)\ndf[indices_aleatorios[1], 2] <- NA\ndf[indices_aleatorios[2], 2] <- NA\ndf\n\n\n# A tibble: 7 x 2\n  dia    valor\n  <chr>  <dbl>\n1 seg    0.288\n2 ter    0.788\n3 qua   NA    \n4 qui    0.883\n5 sex    0.940\n6 sab   NA    \n7 dom    0.528\n\nImputar a média\nPara imputar a média nos dados faltantes usamos a função Impute() com o argumento FUN = mean():\n\n\ndf$media <- Impute(df$valor, FUN = mean(df$valor, na.rm = TRUE))\n\n\n\nImputar a mediana\nPara imputar a mediana nos dados faltantes usamos a função Impute() com o argumento FUN = median():\n\n\ndf$mediana <- Impute(df$valor, FUN = median(df$valor, na.rm = TRUE))\n\n\n\nImputar o último valor ocorrido\nPara imputar a média nos dados faltantes usamos a função LOC() (um acrônimo para Last Observation Carried Forward):\n\n\ndf$ultimo <- LOCF(df$valor)\n\n\n\nComparação dos resultados\nVeja a comparação dos resultados.\n\n\ndf\n\n\n# A tibble: 7 x 5\n  dia    valor media mediana ultimo\n  <chr>  <dbl> <dbl>   <dbl>  <dbl>\n1 seg    0.288 0.288   0.288  0.288\n2 ter    0.788 0.788   0.788  0.788\n3 qua   NA     0.685   0.788  0.788\n4 qui    0.883 0.883   0.883  0.883\n5 sex    0.940 0.940   0.940  0.940\n6 sab   NA     0.685   0.788  0.940\n7 dom    0.528 0.528   0.528  0.528\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.4 (2021-02-15)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 20.10\n\nMatrix products: default\nBLAS/LAPACK: /usr/lib/x86_64-linux-gnu/libmkl_rt.so\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] DescTools_0.99.40 tibble_3.1.0     \n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.6        pillar_1.5.1      bslib_0.2.4      \n [4] compiler_4.0.4    jquerylib_0.1.3   class_7.3-18     \n [7] tools_4.0.4       boot_1.3-27       digest_0.6.27    \n[10] downlit_0.2.1     rootSolve_1.8.2.1 lattice_0.20-41  \n[13] jsonlite_1.7.2    evaluate_0.14     lifecycle_1.0.0  \n[16] debugme_1.1.0     pkgconfig_2.0.3   rlang_0.4.10     \n[19] Matrix_1.3-2      cli_2.3.1         rstudioapi_0.13  \n[22] distill_1.2       yaml_2.2.1        parallel_4.0.4   \n[25] expm_0.999-6      mvtnorm_1.1-1     xfun_0.22        \n[28] e1071_1.7-6       stringr_1.4.0     knitr_1.31       \n[31] sass_0.3.1        vctrs_0.3.7       systemfonts_1.0.1\n[34] grid_4.0.4        gld_2.6.2         glue_1.4.2       \n[37] R6_2.5.0          textshaping_0.3.3 fansi_0.4.2      \n[40] lmom_2.8          rmarkdown_2.7     magrittr_2.0.1   \n[43] MASS_7.3-53.1     ellipsis_0.3.1    htmltools_0.5.1.1\n[46] assertthat_0.2.1  Exact_2.1         ragg_1.1.2       \n[49] utf8_1.2.1        proxy_0.4-25      stringi_1.5.3    \n[52] crayon_1.4.1     \n\n\n\n\nAndri et mult. al., S. (2021). DescTools: Tools for descriptive statistics. Retrieved from https://cran.r-project.org/package=DescTools\n\n\nhá uma terceira que é modelar os dados faltantes, veja a vinheta do brms para mais detalhes↩︎\n",
      "last_modified": "2021-03-30T18:53:50-03:00"
    },
    {
      "path": "aux-Model_Comparison.html",
      "title": "Comparação de Modelos",
      "description": "Como comparar modelos Bayesianos usando métricas objetivas",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 1, 2021",
      "contents": "\n\nContents\nMétricas de Comparação de Modelos.\nComo mensuramos precisão preditiva?\nLeave-one-out Cross-Validation (LOO)\nWidely Applicable Information Criteria (WAIC)\n\\(K\\)-fold Cross-Validation\n\nImplementações em Stan, rstanarm e brms\nAmbiente\n\n\nDepois de estimarmos um modelo Bayesiano, muitas vezes queremos medir sua precisão preditiva, por si só ou para fins de comparação, seleção ou cálculo de média do modelo (Geisser & Eddy, 1979).\nNas aulas desta disciplina nos debruçamos sobre diferentes gráficos de Posterior Predictive Check de diferentes modelos. Esta é uma maneira subjetiva e arbitrária de analisarmos e compararmos modelos entre si usando sua precisão preditiva. Há uma maneira objetiva de compararmos modelos Bayesianos com uma métrica robusta que nos ajude a selecionar qual o melhor modelo dentre o rol de modelos candidatos. Ter uma maneira objetiva de comparar modelos e escolher o melhor dentre eles é muito importante pois no workflow Bayesiano geralmente temos diversas iterações entre prioris e funções de verossimilhança o que ocasiona na criação de diversos modelos diferentes (Gelman et al., 2020).\nMétricas de Comparação de Modelos.\nTemos diversas métricas de comparação de modelos que usam a precisão preditiva, sendo as principais:\nLeave-one-out cross-validation (LOO) (Vehtari, Gelman, & Gabry, 2015)\nDeviance Information Criterion (DIC) (Spiegelhalter, Best, Carlin, & Van Der Linde, 2002), mas sabe-se que tem alguns problemas, que surgem em parte por não ser totalmente bayesiano, pois se baseia em uma estimativa pontual (Van Der Linde, 2005)\nWidely Applicable Information Criteria (WAIC) (Watanabe & Opper, 2010), totalmente Bayesiano no sentido de que usa toda a distribuição posterior, e é assintoticamente igual ao LOO (Vehtari et al., 2015)\nDestes, já descartamos o DIC por termos problemas e ser baseado em uma estimativa pontual (afinal somos Bayesianos, se estivéssemos interessados em estimativas pontuais estaríamos ainda maximizando funções de verossimilhança e achando a moda como os frequentistas fazem).\nLOO é computacionalmente intensivo, afinal na validação cruzada (cross-validation) re-estimamos o modelo para cada partição dos dados. Leave-one-out quer dizer que para um dataset de tamanho \\(N\\) estimaremos \\(N-1\\) modelos para \\(N-1\\) partições do dataset. Ou seja, deixamos uma observação para fora e estimamos o modelo usando a partição de dados sem essa observações e repetimos para todas as observações do dataset. Para superar essa dificuldade, LOO pode ser aproximado por amostragem de importância (Gelfand, 1996). Mas tal estimativa pode ser imprecisa. Usando uma amostragem de importância com suavização de Pareto (Pareto smoothed importance sampling – PSIS) podemos aproximar uma estimativa confiável ajustando uma distribuição de Pareto à cauda superior da distribuição dos pesos de importância. PSIS nos permite calcular LOO usando pesos de importância que de outra forma seriam instáveis. Tal aproximação é cunhada de PSIS-LOO (Vehtari et al., 2015).\nWAIC pode ser visto como uma melhoria do DIC para modelos bayesianos. Apesar de WAIC ser assintoticamente igual ao LOO, PSIS-LOO é mais robusto no quando usamos prioris não-informativas ou na presença observações influentes (outliers).\nComo mensuramos precisão preditiva?\nBayesianos mensuram precisão preditiva usando simulações da distribuição posterior do modelo \\(\\tilde{y}\\). Para isso temos a distribuição preditiva posterior (predictive posterior distribution):\n\\[\np(\\tilde{y} \\mid y) = \\int p(\\tilde{y}_i \\mid \\theta) p(\\theta \\mid y) d \\theta\n\\]\nOnde \\(p(\\theta \\mid y)\\) é a distribuição posterior do modelo (aquela que o rstanarm e brms estima para nós). A fórmula acima significa que calculamos a integral de toda a probabilidade conjunta da distribuição posterior preditiva com a distribuição posterior do nosso modelo: \\(p(\\tilde{y}_i \\mid \\theta) p(\\theta \\mid y)\\). Quanto maior a distribuição preditiva posterior \\(p(\\tilde{y} \\mid y)\\) melhor será a precisão preditiva do modelo. Para mantermos comparabilidade com um dado dataset nos calculamos a esperança dessa medida (do inglês expectation que pode ser também interpretada como a média ponderada) para cada um dos \\(n \\in N\\) observações do dataset:\n\\[\n\\operatorname{elpd} = \\sum_i^N \\int p_t(\\tilde{y}_i) \\log p(\\tilde{y}_i \\mid y) d \\tilde{y}\n\\]\nonde \\(\\operatorname{elpd}\\) é esperança do log da densidade preditiva pontual (expected log pointwise predictive density) e \\(p_t(\\tilde{y}_i)\\) é a distribuição representando o verdadeiro processo generativo dos dados para \\(\\tilde{y}_i\\). Os \\(p_t(\\tilde{y}_i)\\) são desconhecidos e geralmente usamos validação cruzada ou WAIC para aproximar a estimação de \\(\\operatorname{elpd}\\).\nLeave-one-out Cross-Validation (LOO)\nPodemos calcular o \\(\\operatorname{elpd}\\) usando LOO:\n\\[\n\\operatorname{elpd}^{\\text{loo}} = sum_i^N \\log p(y_i \\mid y_{-i})\n\\]\nonde\n\\[\np(y_i \\mid y_{-i}) = \\int p(y_i \\mid \\theta) p(\\theta \\mid y_{-i}) d \\theta\n\\]\nque é a densidade preditiva com uma observação a menos condicionada nos dados sem a observação \\(i\\) (\\(i_{-i}\\)).\nWidely Applicable Information Criteria1 (WAIC)\nWAIC (Watanabe & Opper, 2010) também é uma abordagem alternativa para calcularmos o \\(\\operatorname{elpd}\\) e é definida como:\n\\[\n\\widehat{\\operatorname{elpd}}_{\\text{waic}} = \\widehat{\\operatorname{lpd}} - \\widehat{p}_{\\text{waic}}\n\\]\nonde \\(\\widehat{\\operatorname{lpd}}\\) é a estimação do do log da densidade preditiva pontual (log pointwise predictive density):\n\\[\n\\widehat{\\operatorname{lpd}} = \\sum_i^N \\log p(y_i \\mid y) = sum_i^N \\log \\int p(y_i \\mid \\theta) p(\\theta \\mid y) d \\theta\n\\]\ne \\(\\widehat{p}_{\\text{waic}}\\) é o número estimado efetivo de paramêtros e calculado com base em:\n\\[\n\\widehat{p}_{\\text{waic}} = \\sum_i^N \\operatorname{var}_{\\text{post}} (\\log p(y_i \\mid \\theta))\n\\]\nque conseguimos calcular using a variância posterior do log da densidade preditiva para cada observação \\(y_i\\):\n\\[\n\\widehat{p}_{\\text{waic}} = \\sum_i^N V^S_{s=1} (\\log p(y_i \\mid \\theta^s))\n\\]\nonde \\(V^S_{s=1}\\) representa a variância da amostra:\n\\[\nV^S_{s=1} a_s = \\frac{1}{S-1} \\sum^S_{s=1} (a_s - \\bar{a})^2\n\\]\n\\(K\\)-fold Cross-Validation\nDa mesma maneira que conseguimos cacular \\(\\operatorname{elpd}\\) usando LOO com \\(N-1\\) partições do dataset podemos também calcular com qualquer número de partições que quisermos. Tal abordagem é chamada de validação cruzada usando \\(K\\) partições (\\(K\\)-fold Cross-Validation). Ao contrário de WAIC e LOO, \\(K\\)-fold Cross-Validation não conseguimos aproximar \\(\\operatorname{elpd}\\) e precisamos fazer a computação atual do \\(\\operatorname{elpd}\\) que quase sempre envolve um alto custo computacional.\nImplementações em Stan, rstanarm e brms\nStan e suas interfaces (rstanarm e brms) conseguem com o pacote loo (Vehtari et al., 2020)\nRelembrar o exemplo da Aula 8. função loo() waic() e kfold() padrão K = 10.\nE loo_compare(x, ..., criterion = c(\"loo\", \"kfold\", \"waic\"), detail = FALSE)\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.4 (2021-02-15)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nloaded via a namespace (and not attached):\n [1] fansi_0.4.2       digest_0.6.27     R6_2.5.0         \n [4] jsonlite_1.7.2    magrittr_2.0.1    evaluate_0.14    \n [7] stringi_1.5.3     rlang_0.4.10      jquerylib_0.1.3  \n[10] bslib_0.2.4       vctrs_0.3.7       ragg_1.1.2       \n[13] rmarkdown_2.7     distill_1.2       textshaping_0.3.3\n[16] tools_4.0.4       stringr_1.4.0     xfun_0.22        \n[19] yaml_2.2.1        parallel_4.0.4    compiler_4.0.4   \n[22] systemfonts_1.0.1 htmltools_0.5.1.1 knitr_1.31       \n[25] downlit_0.2.1     sass_0.3.1       \n\n\n\n\nGeisser, S., & Eddy, W. F. (1979). A predictive approach to model selection. Journal of the American Statistical Association, 74(365), 153–160.\n\n\nGelfand, A. E. (1996). Model determination using sampling-based methods. Markov Chain Monte Carlo in Practice, 145–161.\n\n\nGelman, A., Vehtari, A., Simpson, D., Margossian, C. C., Carpenter, B., Yao, Y., … Modr’ak, M. (2020, November 3). Bayesian Workflow. Retrieved February 4, 2021, from http://arxiv.org/abs/2011.01808\n\n\nSpiegelhalter, D. J., Best, N. G., Carlin, B. P., & Van Der Linde, A. (2002). Bayesian measures of model complexity and fit. Journal of the Royal Statistical Society: Series b (Statistical Methodology), 64(4), 583–639.\n\n\nVan Der Linde, A. (2005). DIC in variable selection. Statistica Neerlandica, 59(1), 45–56.\n\n\nVehtari, A., Gabry, J., Magnusson, M., Yao, Y., Bürkner, P.-C., Paananen, T., & Gelman, A. (2020). Loo: Efficient leave-one-out cross-validation and WAIC for bayesian models. Retrieved from https://mc-stan.org/loo/\n\n\nVehtari, A., Gelman, A., & Gabry, J. (2015, July 16). Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC. https://doi.org/10.1007/s11222-016-9696-4\n\n\nWatanabe, S., & Opper, M. (2010). Asymptotic equivalence of bayes cross validation and widely applicable information criterion in singular learning theory. Journal of Machine Learning Research, 11(12).\n\n\ntambém chamado às vezes de Watanabe-Akaike Information Criteria.↩︎\n",
      "last_modified": "2021-03-31T17:58:44-03:00"
    },
    {
      "path": "aux-Regressao_Coeficientes.html",
      "title": "Coeficientes de uma Regressão",
      "description": "Diferenças entre Coeficientes Padronizados vs Brutos",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 1, 2021",
      "contents": "\n\nContents\nSimulação\nMédia e Desvio Padrões\nCoeficientes Brutos vs Padronizados\n\nAmbiente\n\n\nEm tabelas de regressão temos geralmente temos duas opções de como reportar os coeficientes:\nCoeficientes Brutos: não há transformações e as associações das variáveis independentes/controles (covariáveis) com a dependente são reportadas em suas medidas originais. Exemplo: A cada 1 unidades de aumento de \\(x\\), \\(y\\) aumenta 0.45.\nCoeficientes Padronizados: os coeficientes são transformados para expressarem as associações das variáveis independentes/controles (covariáveis) com a dependente em relação à variação dos seus desvios padrões. Exemplo: A cada 1 desvio padrão de variação positiva de \\(x\\), \\(y\\) possui variação de 0.1 desvio padrão.\nSimulação\nPara explicar melhor esses conceitos, simularemos alguns dados:\n\\(x\\): 1.000 observações amostradas de uma distribuição normal com média \\(1\\) e desvio padrão \\(0.1\\). \\(x \\sim \\text{Normal} (1, 0.1)\\)\n\\(y\\): uma combinação linear de \\(100x\\) com uma constante e um erro pequeno normalmente distribuído. \\(y = 10 + 100x + \\epsilon\\) e \\(\\epsilon \\sim \\mathcal{N} (0, 1)\\).\n\n\nN <- 1000\nx <- rnorm(N, 1, 0.1)\nerror <- rnorm(N, 0, 1)\ny <- rep(10, N) + (100 * x) + error\n\ndf <- data.frame(x, y)\n\n\n\nObservem os dados com o pacote skimr (Waring et al., 2021) usando a função skim():\n\n\nlibrary(skimr)\nskim(df)\n\n\nTable 1: Data summary\nName\ndf\nNumber of rows\n1000\nNumber of columns\n2\n_______________________\n\nColumn type frequency:\n\nnumeric\n2\n________________________\n\nGroup variables\nNone\nVariable type: numeric\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\nx\n0\n1\n1\n0.1\n0.64\n0.94\n1\n1.1\n1.3\n▁▂▇▇▂\ny\n0\n1\n110\n9.8\n73.99\n103.82\n110\n117.2\n138.1\n▁▂▇▆▁\n\nMédia e Desvio Padrões\nPrestem atenção:\n\\(x\\): média 1, desvio padrão 0.1\n\\(y\\): média 110.31, desvio padrão 9.76\nCoeficientes Brutos vs Padronizados\nAgora vamos executar uma regressão1 e mostrar coeficientes tanto como brutos, assim como padronizados:\n\n\nlibrary(lm.beta)\nmodel <- lm.beta(lm(y ~ x, df))\nsummary(model)\n\n\n\nCall:\nlm(formula = y ~ x, data = df)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-3.374 -0.651  0.019  0.681  3.284 \n\nCoefficients:\n            Estimate Standardized Std. Error t value\n(Intercept)    9.597        0.000      0.322    29.8\nx            100.360        0.995      0.320   313.9\n                       Pr(>|t|)    \n(Intercept) <0.0000000000000002 ***\nx           <0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.98 on 998 degrees of freedom\nMultiple R-squared:  0.99,  Adjusted R-squared:  0.99 \nF-statistic: 9.85e+04 on 1 and 998 DF,  p-value: <0.0000000000000002\n\nAmbas colunas o output de summary() mostram a mesma coisa:\nColuna não padronizada Estimate: a cada 1 unidade que \\(x\\) aumenta, \\(y\\) aumenta 100.36\nColuna padronizada Standardized: a cada 1 desvio padrão de \\(x\\) de incremento (dp = 0.1), há um aumento de 0.99 desvio padrão de \\(y\\) (9.71). Um total de 100.36. \\(\\big( \\frac{0.955 * \\operatorname{sd}_y}{\\operatorname{sd}_x}\\big)\\)\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.4 (2021-02-15)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 20.10\n\nMatrix products: default\nBLAS/LAPACK: /usr/lib/x86_64-linux-gnu/libmkl_rt.so\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] lm.beta_1.5-1 skimr_2.1.3  \n\nloaded via a namespace (and not attached):\n [1] highr_0.8         bslib_0.2.4       compiler_4.0.4   \n [4] pillar_1.5.1      jquerylib_0.1.3   base64enc_0.1-3  \n [7] tools_4.0.4       digest_0.6.27     downlit_0.2.1    \n[10] jsonlite_1.7.2    evaluate_0.14     lifecycle_1.0.0  \n[13] tibble_3.1.0      debugme_1.1.0     pkgconfig_2.0.3  \n[16] rlang_0.4.10      DBI_1.1.1         distill_1.2      \n[19] yaml_2.2.1        parallel_4.0.4    xfun_0.22        \n[22] repr_1.1.3        dplyr_1.0.5       stringr_1.4.0    \n[25] knitr_1.31        generics_0.1.0    vctrs_0.3.7      \n[28] sass_0.3.1        systemfonts_1.0.1 tidyselect_1.1.0 \n[31] glue_1.4.2        R6_2.5.0          textshaping_0.3.3\n[34] fansi_0.4.2       rmarkdown_2.7     tidyr_1.1.3      \n[37] purrr_0.3.4       magrittr_2.0.1    htmltools_0.5.1.1\n[40] ellipsis_0.3.1    assertthat_0.2.1  ragg_1.1.2       \n[43] utf8_1.2.1        stringi_1.5.3     crayon_1.4.1     \n\n\n\n\nWaring, E., Quinn, M., McNamara, A., Arino de la Rubia, E., Zhu, H., & Ellis, S. (2021). Skimr: Compact and flexible summaries of data. Retrieved from https://CRAN.R-project.org/package=skimr\n\n\nestou rodando uma regressão simples frequentista pois o foco não é a robustez da inferência mas apenas uma mera exemplificação de como interpretar coeficientes.↩︎\n",
      "last_modified": "2021-03-30T18:53:50-03:00"
    },
    {
      "path": "aux-Tabelas_para_Publicacao.html",
      "title": "Tabelas para Publicação",
      "description": "Como montar tabelas de modelos Bayesianos prontas para publicação",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 1, 2021",
      "contents": "\n\nContents\nTemas do gtsummary\nEstatísticas Descritivas com o tbl_summary\nModelos Bayesianos com o tbl_regression\nAmbiente\n\n\nAo invés de ser obrigado a passar horas a fio formatando tabelas em Excel softwares pagos, você pode usar pacotes gratuitos do R para formatar automaticamente suas tabelas. Em especial, eu gosto bastante do pacote gtsummary (Sjoberg et al., 2021) para preparar tabelas prontas para publicação. Inclusive eu fui um dos proponentes de incluir suporte do gtsummary para modelos Bayesianos do rstanarm e brms (veja detalhes nessa issue do GitHub)1. Geralmente uso duas funções do gtsummary no meu fluxo de trabalho:\nEstatísticas Descritivas: tbl_summary()\nModelos Bayesianos: tbl_regression()\nPara os modelos Bayesianos mostrarei como o gtsummary funciona para modelos brms neste tutorial.\nTemas do gtsummary\nO gtsummary tem diversos temas interessantes que podem ser definidos com as funções theme_gtsummary_*(). Basta colocar no ínicio do seu markdown. Consulte a documentação dos temas do gtsummary e veja alguns exemplos:\nTemas de Periódicos – theme_gtsummary_journal():\n\"jama\" - The Journal of the American Medical Association\n\"nejm\" - The New England Journal of Medicine\n\"lancet\" - The Lancet\n\nTemas de Idiomas (esse é o que eu sempre uso) – theme_gtsummary_language():\n\"pt\" - Português\n\nVou demonstrar as tabelas do gtsummary com o tema do idioma Português nesse tutoria:\n\n\ntheme_gtsummary_language(\"pt\")\n\n\n\nEstatísticas Descritivas com o tbl_summary\nA função tbl_summary() do gtsummary formata uma tabela de Estatística Descritiva de maneira bem conveniente. Geralmente uso duas opções para reportar os dados. Essas opção vão dentro do argumento statistics to tbl_summary:\nMediana com Q1 e Q3 (minha preferida):\nall_continuous() ~ c(\"{N_nonmiss}\",\n                     \"{median} ({p25}, {p75})\",\n                     \"{min}, {max}\")\nMédia com Desvio Padrão (caso algum editor/revisor/stakeholder prefira):\nall_continuous() ~ c(\"{N_nonmiss}\",\n                     \"{mean} ({sd})\",\n                     \"{min}, {max}\")\nComo exemplo, usarei o dataset kidiq (Gelman & Hill, 2007) da Aula 6 - Regressão Linear.\nVejam que aqui eu fiz diversas alterações que vocês podem ver na documentação da função tbl_summary() do gtsummary:\n\n\nkidiq <- rstanarm::kidiq\n\ntbl_summary(\n  kidiq %>% mutate(mom_hs = as.factor(mom_hs)),\n  by = mom_hs,\n  type = all_continuous() ~ \"continuous2\",\n  statistic = list(\n    all_continuous() ~ c(\"{N_nonmiss}\",\n                         \"{median} ({p25}, {p75})\",\n                         \"{min}, {max}\"),\n    all_categorical() ~ \"{n} ({p}%)\"),\n  missing = \"no\",\n  digits = all_continuous() ~ 2) %>%\n  add_overall() %>%\n  # bold variable labels, italicize levels\n  bold_labels() %>%\n  italicize_levels() %>%\n  # change stuff\n  modify_header(label ~ \"**Variable**\") %>%\n  modify_spanning_header(c(\"stat_1\", \"stat_2\") ~ \"**Ensino Médio da Mãe**\") %>%\n  add_n()\n\n\nhtml {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#gngfhykekf .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#gngfhykekf .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#gngfhykekf .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#gngfhykekf .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 4px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#gngfhykekf .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#gngfhykekf .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#gngfhykekf .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#gngfhykekf .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#gngfhykekf .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#gngfhykekf .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#gngfhykekf .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#gngfhykekf .gt_group_heading {\n  padding: 8px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#gngfhykekf .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#gngfhykekf .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#gngfhykekf .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#gngfhykekf .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#gngfhykekf .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 12px;\n}\n\n#gngfhykekf .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#gngfhykekf .gt_first_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n}\n\n#gngfhykekf .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#gngfhykekf .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#gngfhykekf .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#gngfhykekf .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#gngfhykekf .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#gngfhykekf .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding: 4px;\n}\n\n#gngfhykekf .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#gngfhykekf .gt_sourcenote {\n  font-size: 90%;\n  padding: 4px;\n}\n\n#gngfhykekf .gt_left {\n  text-align: left;\n}\n\n#gngfhykekf .gt_center {\n  text-align: center;\n}\n\n#gngfhykekf .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#gngfhykekf .gt_font_normal {\n  font-weight: normal;\n}\n\n#gngfhykekf .gt_font_bold {\n  font-weight: bold;\n}\n\n#gngfhykekf .gt_font_italic {\n  font-style: italic;\n}\n\n#gngfhykekf .gt_super {\n  font-size: 65%;\n}\n\n#gngfhykekf .gt_footnote_marks {\n  font-style: italic;\n  font-size: 65%;\n}\nVariable\n      N\n      Total, N = 4341\n      \n        Ensino Médio da Mãe\n      \n    0, N = 93\n      1, N = 341\n    kid_score\n      434.00\n      \n      \n      \n    N\n      \n      434.00\n      93.00\n      341.00\n    Mediana (IQR)\n      \n      90.00 (74.00, 102.00)\n      80.00 (58.00, 95.00)\n      92.00 (77.00, 103.00)\n    Intervalo\n      \n      20.00, 144.00\n      20.00, 136.00\n      38.00, 144.00\n    mom_iq\n      434.00\n      \n      \n      \n    N\n      \n      434.00\n      93.00\n      341.00\n    Mediana (IQR)\n      \n      97.92 (88.66, 110.27)\n      88.66 (81.83, 99.16)\n      100.24 (90.45, 113.17)\n    Intervalo\n      \n      71.04, 138.89\n      74.23, 127.54\n      71.04, 138.89\n    mom_age\n      434.00\n      \n      \n      \n    N\n      \n      434.00\n      93.00\n      341.00\n    Mediana (IQR)\n      \n      23.00 (21.00, 25.00)\n      21.00 (20.00, 24.00)\n      23.00 (21.00, 25.00)\n    Intervalo\n      \n      17.00, 29.00\n      17.00, 28.00\n      17.00, 29.00\n    \n        \n          1\n          \n           \n          c(\"N\", \"Mediana (IQR)\", \"Intervalo\")\n          \n      \n    \n\nModelos Bayesianos com o tbl_regression\nVou usar o “Modelo 3” da Aula 6 - Regressão Linear que usa o dataset kidiq (Gelman & Hill, 2007) como exemplo:\n\n\ngaussian_brms <- brm(\n  kid_score ~ mom_hs + mom_iq,\n  data = kidiq,\n  prior = c(\n           prior(normal(0, 20), class = b, coef = mom_hs),\n           prior(normal(0, 0.5), class = b, coef = mom_iq),\n           prior(normal(87, 51), class = Intercept),\n           prior(exponential(0.05), class = sigma)\n         )\n)\n\n\n\nPor padrão tbl_regression() somente mostrar os efeitos globais (fixed effects) do modelo brms. Caso queira os efeitos de grupo (random effects) você deve especificar effects = \"ran_pars\". Além disso, também por padrão é mostrado a média e o desvio padrão dos coeficientes do modelo. Caso queira mediana e desvio absoluto médio use robust = TRUE. Para controlar os percentis a serem reportados da posterior dos parâmetros use conf.level = X. Para concluir, a constante (intercept) não é reportada por padrão, caso queira adicione intercept = TRUE. Veja um exemplo:\n\n\ntbl_regression(gaussian_brms, robust = TRUE, conf.level = 0.9, intercept = TRUE)\n\n\nhtml {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#yqbehnxygd .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#yqbehnxygd .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#yqbehnxygd .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#yqbehnxygd .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 4px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#yqbehnxygd .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#yqbehnxygd .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#yqbehnxygd .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#yqbehnxygd .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#yqbehnxygd .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#yqbehnxygd .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#yqbehnxygd .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#yqbehnxygd .gt_group_heading {\n  padding: 8px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#yqbehnxygd .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#yqbehnxygd .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#yqbehnxygd .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#yqbehnxygd .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#yqbehnxygd .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 12px;\n}\n\n#yqbehnxygd .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#yqbehnxygd .gt_first_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n}\n\n#yqbehnxygd .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#yqbehnxygd .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#yqbehnxygd .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#yqbehnxygd .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#yqbehnxygd .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#yqbehnxygd .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding: 4px;\n}\n\n#yqbehnxygd .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#yqbehnxygd .gt_sourcenote {\n  font-size: 90%;\n  padding: 4px;\n}\n\n#yqbehnxygd .gt_left {\n  text-align: left;\n}\n\n#yqbehnxygd .gt_center {\n  text-align: center;\n}\n\n#yqbehnxygd .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#yqbehnxygd .gt_font_normal {\n  font-weight: normal;\n}\n\n#yqbehnxygd .gt_font_bold {\n  font-weight: bold;\n}\n\n#yqbehnxygd .gt_font_italic {\n  font-style: italic;\n}\n\n#yqbehnxygd .gt_super {\n  font-size: 65%;\n}\n\n#yqbehnxygd .gt_footnote_marks {\n  font-style: italic;\n  font-size: 65%;\n}\nCaracterísticas\n      Beta\n      90% CI1\n    (Intercept)\n      26\n      17, 36\n    mom_hs\n      6.0\n      2.4, 9.6\n    mom_iq\n      0.56\n      0.46, 0.66\n    \n        \n          1\n          \n           \n          CI = Intervalo de confiança\n          \n      \n    \n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.4 (2021-02-15)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 20.10\n\nMatrix products: default\nBLAS/LAPACK: /usr/lib/x86_64-linux-gnu/libmkl_rt.so\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] gtsummary_1.3.7.9014 brms_2.15.0          Rcpp_1.0.6          \n[4] dplyr_1.0.5         \n\nloaded via a namespace (and not attached):\n  [1] minqa_1.2.4          colorspace_2.0-0     ellipsis_0.3.1      \n  [4] ggridges_0.5.3       rsconnect_0.8.16     estimability_1.3    \n  [7] markdown_1.1         base64enc_0.1-3      rstan_2.21.2        \n [10] DT_0.17              fansi_0.4.2          mvtnorm_1.1-1       \n [13] codetools_0.2-18     bridgesampling_1.0-0 splines_4.0.4       \n [16] downlit_0.2.1        knitr_1.31           shinythemes_1.2.0   \n [19] bayesplot_1.8.0      projpred_2.0.2       jsonlite_1.7.2      \n [22] nloptr_1.2.2.2       gt_0.2.2             broom_0.7.5         \n [25] broom.mixed_0.2.6    shiny_1.6.0          compiler_4.0.4      \n [28] emmeans_1.5.5-1      backports_1.2.1      assertthat_0.2.1    \n [31] Matrix_1.3-2         fastmap_1.1.0        cli_2.3.1           \n [34] later_1.1.0.1        htmltools_0.5.1.1    prettyunits_1.1.1   \n [37] tools_4.0.4          igraph_1.2.6         coda_0.19-4         \n [40] gtable_0.3.0         glue_1.4.2           reshape2_1.4.4      \n [43] V8_3.4.0             jquerylib_0.1.3      vctrs_0.3.7         \n [46] debugme_1.1.0        nlme_3.1-152         broom.helpers_1.2.1 \n [49] crosstalk_1.1.1      xfun_0.22            stringr_1.4.0       \n [52] ps_1.6.0             lme4_1.1-26          mime_0.10           \n [55] miniUI_0.1.1.1       lifecycle_1.0.0      gtools_3.8.2        \n [58] statmod_1.4.35       MASS_7.3-53.1        zoo_1.8-9           \n [61] scales_1.1.1         rstanarm_2.21.1      colourpicker_1.1.0  \n [64] hms_1.0.0            ragg_1.1.2           promises_1.2.0.1    \n [67] Brobdingnag_1.2-6    parallel_4.0.4       inline_0.3.17       \n [70] TMB_1.7.19           shinystan_2.5.0      gamm4_0.2-6         \n [73] yaml_2.2.1           curl_4.3             gridExtra_2.3       \n [76] ggplot2_3.3.3        StanHeaders_2.21.0-7 loo_2.4.1           \n [79] sass_0.3.1           labelled_2.8.0       distill_1.2         \n [82] stringi_1.5.3        dygraphs_1.1.1.6     checkmate_2.0.0     \n [85] boot_1.3-27          pkgbuild_1.2.0       commonmark_1.7      \n [88] rlang_0.4.10         pkgconfig_2.0.3      systemfonts_1.0.1   \n [91] matrixStats_0.58.0   evaluate_0.14        lattice_0.20-41     \n [94] purrr_0.3.4          rstantools_2.1.1     htmlwidgets_1.5.3   \n [97] tidyselect_1.1.0     processx_3.5.0       plyr_1.8.6          \n[100] magrittr_2.0.1       R6_2.5.0             generics_0.1.0      \n[103] DBI_1.1.1            haven_2.3.1          pillar_1.5.1        \n[106] withr_2.4.1          mgcv_1.8-34          xts_0.12.1          \n[109] survival_3.2-10      abind_1.4-5          tibble_3.1.0        \n[112] crayon_1.4.1         utf8_1.2.1           rmarkdown_2.7       \n[115] grid_4.0.4           callr_3.6.0          forcats_0.5.1       \n[118] threejs_0.3.3        digest_0.6.27        xtable_1.8-4        \n[121] tidyr_1.1.3          httpuv_1.5.5         textshaping_0.3.3   \n[124] RcppParallel_5.0.3   stats4_4.0.4         munsell_0.5.0       \n[127] bslib_0.2.4          shinyjs_2.0.0       \n\n\n\n\nGelman, A., & Hill, J. (2007). Data analysis using regression and multilevel/hierarchical models. Cambridge university press.\n\n\nSjoberg, D. D., Curry, M., Hannum, M., Larmarange, J., Whiting, K., & Zabor, E. C. (2021). Gtsummary: Presentation-ready data summary and analytic result tables.\n\n\nse atentem que atualmente (Abril de 2021) suporte para modelos do rstanarm e brms só funcionam na versão de desenvolvimento do GitHub que pode ser instalada com remotes::install_github(\"ddsjoberg/gtsummary\")↩︎\n",
      "last_modified": "2021-03-30T18:53:50-03:00"
    },
    {
      "path": "index.html",
      "title": "Estatística Bayesiana com R e Stan",
      "description": "Companion para a disciplina de Estatística Bayesiana para alunos de Mestrado e Doutorado da UNINOVE",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 1, 2021",
      "contents": "\n\nContents\nStan\nComo usar esse conteúdo?\nAulas\nO que esta disciplina não é\nRStudio na Núvem Gratuito\nProfessor\nComo usar esse conteúdo?\nReferências\nLivros\nArtigos\n\nConteúdos Similares\nComo citar esse conteúdo\nLicença\n\n\n\n\n\n\nFigure 1: Bayesian for Everyone!\n\n\n\nA Estatística Bayesiana é uma abordagem de Estatística inferencial que não usa hipóteses nulas (\\(H_0\\)) e \\(p\\)-valores. Se você não sabe o que é um \\(p\\)-valor, recomendo olhar o tutorial sobre o que são \\(p\\)-valores. Muitos cientistas e pesquisadores acreditam que sabe o que é um \\(p\\)-valor, mas sua compreensão é falha e imperfeita, por isso, mesmo que você acredite que saiba o que é um \\(p\\)-valor, eu ainda recomendo que veja o tutorial sobre o que são \\(p\\)-valores.\nStan\nStan (Carpenter et al., 2017) é uma plataforma para modelagem e computação estatística de alto desempenho. Milhares de usuários contam com Stan para modelagem estatística, análise de dados e previsão nas ciências sociais, biológicas e físicas, engenharia e negócios. Stan tem mais de 3.600 citações no Google Scholar1. Além disso, Stan tem o suporte financeiro da NumFOCUS, uma fundação sem fins lucrativos que dá apoio financeiro à projetos de softwares opensource. Dentre os patrocinadores da NumFOCUS podemos citar AWS Amazon, Bloomberg, Microsoft, IBM, RStudio, Facebook, NVIDIA, Netflix, entre outras.\nOs modelos em Stan são especificados pela sua própria linguagem (similar à C++) e são compilados em um arquivo executável que gera inferências estatísticas Bayesiana com amostragem Monte Carlo de correntes Markov (Markov Chain Monte Carlo – MCMC) de alto desempenho. Stan possui interfaces para as seguintes linguagens de programação2:\nR: RStan e CmdStanR\nPython: PyStan e CmdStanPy\nShell (Linha de Comando): CmdStan\nJulia: Stan.jl\nScala: ScalaStan\nMatlab: MatlabStan\nStata: StataStan\nMathematica: MathematicaStan\nA linguagem Stan possui uma curva de aprendizagem bem desafiadora, por isso Stan possui um ecossistema de pacotes de interfaces que muitas vezes ajudam e simplificam a sua utilização:\nrstanarm: ajuda o usuário a especificar modelos usando a síntaxe familiar de fórmulas do R.\nbrms: similar ao rstanarm pois usa a síntaxe familiar de fórmulas do R, mas dá maior flexibilidade na especificação de modelos mais complexos3.\nStan4 usa um amostrador MCMC que utiliza dinâmica Hamiltoniana (Hamiltonian Monte Carlo – HMC) para guiar as propostas de amostragem de novos parâmetros no sentido do gradiente da densidade de probabilidade da posterior. Isto implica em um amostrador mais eficiente e que consegue explorar todo o espaço amostral da posterior com menos iterações; e também mais eficaz que consegue tolerar diferentes topologias de espaços amostrais da posterior. Em outras palavras, Stan usa técnicas de amostragem avançadas que permite com que modelos complexos Bayesianos atinjam convergência de maneira rápida. No Stan, raramente deve-se ajustar os parâmetros do algoritmo HMC, pois geralmente os parâmetros padrões (out-of-the-box) funcionam muito bem. Assim, o usuário foca no que é importante: a especificação dos componentes probabilísticos do seu modelo Bayesiano.\nComo usar esse conteúdo?\nEste conteúdo possui licença livre para uso (CC BY-SA). Caso queira utilizar o conteúdo para um curso ou estudos, por favor colabore nesse repositório quaisquer aprimorações que foram realizadas. O propósito do conteúdo não é o rigor matemático geralmente adotado em disciplinas e tutoriais de estatística Bayesiana, mas gerar uma forte intuição deixando de lado o rigor matemático e focar no ferramental (primariamente rstanarm e um pouco de brms).\nPara configurar um ambiente local:\nClone o repositório do GitHub: git clone https://github.com/storopoli/Estatistica-Bayesiana.git\nAcesse o diretório: cd Estatistica-Bayesiana\nInstale os pacotes necessários: Rscript .binder/install.R\nAulas\nO que é Estatística Bayesiana\nConteúdos Primários:\nComandos Básicos de R\nDistribuições Estatísticas\nrstanarm e brms\nPriors\nMarkov Chain Montecarlo (MCMC)\nRegressão Linear\nRegressão Logística Bayesiana\nRegressão de Poisson Bayesiana\nRegressão Robusta Bayesiana\nModelos Multiníveis\nConteúdos Auxiliares:\nComparação de Modelos\nDados Faltantes\nCoeficientes de uma Regressão\nTabelas para Publicação\nO que esta disciplina não é\nNão será coberto conteúdos sobre leitura, manipulação e exportação de dados com R. Para isso recomendo fortemente o livro R para Data Science (Figura 2) que pode ser encontrado gratuitamente aqui e possui uma versão impressa em português5.\n\n\n\nFigure 2: R for Data Science\n\n\n\nRStudio na Núvem Gratuito\nClique no ícone abaixo para abrir uma sessão do RStudio no Projeto Binder.\n\nProfessor\nProf. Dr. José Eduardo Storopoli    \nComo usar esse conteúdo?\nEste conteúdo possui licença livre para uso (CC BY-SA). Caso queira utilizar o conteúdo para um curso ou estudos, por favor colabore nesse repositório quaisquer aprimorações que foram realizadas.\nPara configurar um ambiente local:\nClone o repositório do GitHub: git clone https://github.com/storopoli/Estatistica-Bayesiana.git\nAcesse o diretório: cd Estatistica-Bayesiana\nInstale os pacotes necessários: Rscript .binder/install.R\nReferências\nLivros\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian Data Analysis. Chapman and Hall/CRC.\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan. CRC press.\nGelman, A., Hill, J., & Vehtari, A. (2020). Regression and other stories. Cambridge University Press.\nBrooks, S., Gelman, A., Jones, G., & Meng, X.-L. (2011). Handbook of Markov Chain Monte Carlo. CRC Press. https://books.google.com?id=qfRsAIKZ4rIC\nGeyer, C. J. (2011). Introduction to markov chain monte carlo. In S. Brooks, A. Gelman, G. L. Jones, & X.-L. Meng (Eds.), Handbook of markov chain monte carlo.\n\nArtigos\nBásicos\nvan de Schoot, R., Depaoli, S., King, R., Kramer, B., Märtens, K., Tadesse, M. G., Vannucci, M., Gelman, A., Veen, D., Willemsen, J., & Yau, C. (2021). Bayesian statistics and modelling. Nature Reviews Methods Primers, 1(1, 1), 1–26. https://doi.org/10.1038/s43586-020-00001-2\nGelman, A., Vehtari, A., Simpson, D., Margossian, C. C., Carpenter, B., Yao, Y., Kennedy, L., Gabry, J., Bürkner, P.-C., & Modr’ak, M. (2020, November 3). Bayesian Workflow. http://arxiv.org/abs/2011.01808\nGabry, J., Simpson, D., Vehtari, A., Betancourt, M., & Gelman, A. (2019). Visualization in Bayesian workflow. Journal of the Royal Statistical Society: Series A (Statistics in Society), 182(2), 389–402. https://doi.org/10.1111/rssa.12378\nBenjamin, D. J., Berger, J. O., Johannesson, M., Nosek, B. A., Wagenmakers, E.-J., Berk, R., Bollen, K. A., Brembs, B., Brown, L., Camerer, C., Cesarini, D., Chambers, C. D., Clyde, M., Cook, T. D., De Boeck, P., Dienes, Z., Dreber, A., Easwaran, K., Efferson, C., … Johnson, V. E. (2018). Redefine statistical significance. Nature Human Behaviour, 2(1), 6–10. https://doi.org/10.1038/s41562-017-0189-z\nCarpenter, B., Gelman, A., Hoffman, M. D., Lee, D., Goodrich, B., Betancourt, M., Brubaker, M., Guo, J., Li, P., & Riddell, A. (2017). Stan : A Probabilistic Programming Language. Journal of Statistical Software, 76(1). https://doi.org/10.18637/jss.v076.i01\nEtz, A. (2018). Introduction to the Concept of Likelihood and Its Applications. Advances in Methods and Practices in Psychological Science, 1(1), 60–69. https://doi.org/10.1177/2515245917744314\nEtz, A., Gronau, Q. F., Dablander, F., Edelsbrunner, P. A., & Baribault, B. (2018). How to become a Bayesian in eight easy steps: An annotated reading list. Psychonomic Bulletin & Review, 25(1), 219–234. https://doi.org/10.3758/s13423-017-1317-5\nMcShane, B. B., Gal, D., Gelman, A., Robert, C., & Tackett, J. L. (2019). Abandon Statistical Significance. American Statistician, 73, 235–245. https://doi.org/10.1080/00031305.2018.1527253\nAmrhein, V., Greenland, S., & McShane, B. (2019). Scientists rise up against statistical significance. Nature, 567(7748), 305–307. https://doi.org/10.1038/d41586-019-00857-9\nvan Ravenzwaaij, D., Cassey, P., & Brown, S. D. (2018). A simple introduction to Markov Chain Monte–Carlo sampling. Psychonomic Bulletin and Review, 25(1), 143–154. https://doi.org/10.3758/s13423-016-1015-8\nVandekerckhove, J., Matzke, D., Wagenmakers, E.-J., & others. (2015). Model comparison and the principle of parsimony. In J. R. Busemeyer, Z. Wang, J. T. Townsend, & A. Eidels (Eds.), Oxford handbook of computational and mathematical psychology (pp. 300–319). Oxford University Press Oxford.\nvan de Schoot, R., Kaplan, D., Denissen, J., Asendorpf, J. B., Neyer, F. J., & van Aken, M. A. G. (2014). A Gentle Introduction to Bayesian Analysis: Applications to Developmental Research. Child Development, 85(3), 842–860. https://doi.org/10.1111/cdev.12169_eprint: https://srcd.onlinelibrary.wiley.com/doi/pdf/10.1111/cdev.12169\nWagenmakers, E.-J. (2007). A practical solution to the pervasive problems of p values. Psychonomic Bulletin & Review, 14(5), 779–804. https://doi.org/10.3758/BF03194105\nComplementares\nCohen, J. (1994). The earth is round (p \\(<\\) .05). American Psychologist, 49(12), 997–1003. https://doi.org/10.1037/0003-066X.49.12.997\nDienes, Z. (2011). Bayesian Versus Orthodox Statistics: Which Side Are You On? Perspectives on Psychological Science, 6(3), 274–290. https://doi.org/10.1177/1745691611406920\nEtz, A., & Vandekerckhove, J. (2018). Introduction to Bayesian Inference for Psychology. Psychonomic Bulletin & Review, 25(1), 5–34. https://doi.org/10.3758/s13423-017-1262-3\nJ’unior, C. A. M. (2020). Quanto vale o valor-p? Arquivos de Ciências Do Esporte, 7(2).\nKerr, N. L. (1998). HARKing: Hypothesizing after the results are known. Personality and Social Psychology Review, 2(3), 196–217. https://doi.org/10.1207/s15327957pspr0203_4\nKruschke, J. K., & Vanpaemel, W. (2015). Bayesian estimation in hierarchical models. In J. R. Busemeyer, Z. Wang, J. T. Townsend, & A. Eidels (Eds.), The Oxford handbook of computational and mathematical psychology (pp. 279–299). Oxford University Press Oxford, UK.\nKruschke, J. K., & Liddell, T. M. (2018). Bayesian data analysis for newcomers. Psychonomic Bulletin & Review, 25(1), 155–177. https://doi.org/10.3758/s13423-017-1272-1\nKruschke, J. K., & Liddell, T. M. (2018). The Bayesian New Statistics: Hypothesis testing, estimation, meta-analysis, and power analysis from a Bayesian perspective. Psychonomic Bulletin & Review, 25(1), 178–206. https://doi.org/10.3758/s13423-016-1221-4\nLakens, D., Adolfi, F. G., Albers, C. J., Anvari, F., Apps, M. A. J., Argamon, S. E., Baguley, T., Becker, R. B., Benning, S. D., Bradford, D. E., Buchanan, E. M., Caldwell, A. R., Van Calster, B., Carlsson, R., Chen, S. C., Chung, B., Colling, L. J., Collins, G. S., Crook, Z., … Zwaan, R. A. (2018). Justify your alpha. Nature Human Behaviour, 2(3), 168–171. https://doi.org/10.1038/s41562-018-0311-x\nMorey, R. D., Hoekstra, R., Rouder, J. N., Lee, M. D., & Wagenmakers, E.-J. (2016). The fallacy of placing confidence in confidence intervals. Psychonomic Bulletin & Review, 23(1), 103–123. https://doi.org/10.3758/s13423-015-0947-8\nMurphy, K. R., & Aguinis, H. (2019). HARKing: How Badly Can Cherry-Picking and Question Trolling Produce Bias in Published Results? Journal of Business and Psychology, 34(1). https://doi.org/10.1007/s10869-017-9524-7\nStark, P. B., & Saltelli, A. (2018). Cargo-cult statistics and scientific crisis. Significance, 15(4), 40–43. https://doi.org/10.1111/j.1740-9713.2018.01174.x\nConteúdos Similares\nExistem alguns conteúdos em português similares que eu indico:\nMarco Inácio — Apostila de Stan\nUm dos desenvolvedores da equipe do Stan. A apostila está um pouco desatualizada (2018). O foco é o rigor matemático e a linguagem Stan. Muito bem escrita e com bons exemplos.\nRicardo Ehlers (USP) — Inferência Bayesiana (Notas de Aula)\nNotas de uma disciplina da USP pelo professor Ricardo Ehlers. O foco é o rigor matemática e as ferramentas utilizadas são desatualizadas (BUGS e JAGS). Também muito bem escrita e com bons exemplos.\nLuís Gustavo Esteves, Rafael Izbicki e Rafael Bassi Stern (UFSCar) — Inferência Bayesiana (Notas de Aula)\nNotas de uma disciplina da UFSCar pelos professores Luís Gustavo Esteves, Rafael Izbicki e Rafael Bassi Stern. O foco é o rigor matemático, mas o conteúdo é um pouco mais acessível com uma forte introdução à lógica Bayesiana. Fala um pouco da linguagem Stan e sua interface do R (rstan) no finalzinho.\nComo citar esse conteúdo\nPara citar o conteúdo use:\nStoropoli (2021). Estatística Bayesiana com R e Stan. Disponível em: https://storopoli.io/Estatistica-Bayesiana.\nOu em formato BibTeX para LaTeX:\n@misc{storopoli2021estatisticabayesianaR,\n  author = {Storopoli, Jose},\n  title = {Estatística Bayesiana com R e Stan},\n  url = {https://storopoli.io/Estatistica-Bayesiana},\n  year = {2021}\n}\nLicença\nEste obra está licenciado com uma Licença Creative Commons Atribuição-CompartilhaIgual 4.0 Internacional.\n\n\nconforme consulta em 14 de Março de 2021.↩︎\nestou riscando as linguagens que não são opensource por uma questão de princípios.↩︎\ne geralmente a amostragem é um pouco mais rápida que o rstanarm.↩︎\ne consequentemente todas suas interfaces com diversas linguagens de programação e todos os pacotes do seu ecossistema.↩︎\nNão temos nada a ver com a Amazon. Caso queira comprar em qualquer outra loja fique à vontade, ou algum sebo… Jeff Bezos nem sabe que eu existo…↩︎\n",
      "last_modified": "2021-03-29T16:57:48-03:00"
    }
  ],
  "collections": []
}
