{
  "articles": [
    {
      "path": "0-Estatistica-Bayesiana.html",
      "title": "O que é Estatística Bayesiana?",
      "description": "Noções de Probabilidade, Estatística Frequentista versus Estatística Bayesiana",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 2, 2021",
      "contents": "\n\nContents\nO que é probabilidade?\nDefinição Matemática\nProbabilidade Condicional\nProbabilidade Conjunta\nTeorema de Bayes\nParâmetros Discretos vs Contínuos\n\nEstatística Bayesiana\nEstatística Frequentista\n\\(p\\)-valores\nO que o \\(p\\)-valor não é\nIntervalos de Confiança\n\nEstatística Bayesiana vs Frequentista\nVantagens da Estatística Bayesiana\nStan\nHistória do Stan\n\nAmbiente\n\n\nA estatística Bayesiana1 é uma abordagem de análise de dados baseada no teorema de Bayes, onde o conhecimento disponível sobre os parâmetros em um modelo estatístico é atualizado com as informações dos dados observados (Gelman et al., 2013). O conhecimento prévio é expresso como uma distribuição a priori2 e combinado com os dados observados na forma de uma função de verossimilhança3 para determinar a distribuição a posteriori4 . A posteriori também pode ser usada para fazer previsões sobre eventos futuros.\nEstatística Bayesiana está revolucionando todos os campos das ciências baseadas em evidências5 (van de Schoot et al., 2021). A insatisfação com métodos tradicionais de inferência estatística (estatística frequentista) e o advento dos computadores com o crescimento exponencial de poder computacional6 proporcionaram a ascensão da estatística Bayesiana por ser uma abordagem alinhada com a intuição humana de incerteza, robusta à más-práticas científicas, porém computacionalmente intensiva.\nPorém antes de entrarmos em estatística Bayesiana, temos que falar de probabilidade: o motor da inferência Bayesiana.\nO que é probabilidade?\n\nProbabilidade não existe!\nde Finetti (1974)7\n\nEssas são as primeiras palavras no prefácio do célebre livro de Bruno de Finetti (figura 1), um dos mais importantes matemáticos e filósofos da probabilidade. Sim, a probabilidade não existe. Ou melhor, probabilidade como uma quantidade física, chance objetiva, NÃO existe. De Finetti mostrou que, em certo sentido preciso, se dispensarmos a questão da chance objetiva nada se perde. A matemática do raciocínio indutivo permanece exatamente a mesma.\n\n\n\nFigure 1: Bruno de Finetti. Figura de https://www.wikipedia.org\n\n\n\nConsidere jogar uma moeda de enviesada. As tentativas são consideradas independentes e, como resultado, exibem outra propriedade importante. A ordem não importa. Dizer que a ordem não importa é dizer que se você pegar qualquer sequência finita de cara e coroa e permutar os resultados da maneira que quiser, a sequência resultante terá a mesma probabilidade. Dizemos que essa probabilidade é invariante sob permutações.\nOu, dito de outra forma, a única coisa que importa é a frequência relativa. As sequências de resultados que têm as mesmas frequências de cara e coroa consequentemente possuem a mesma probabilidade. A frequência é considerada uma estatística suficiente8. Dizer que a ordem não importa ou dizer que a única coisa que importa é a frequência são duas maneiras de dizer exatamente a mesma coisa. Essa propriedade é chamada de permutabilidade por de Finetti. E é a mais importantes propriedade da probabilidade que faz com que possamos manipulá-la matematicamente (ou filosoficamente) mesmo que ela não exista como uma “coisa” física.\nAinda desenvolvendo o argumento: “O raciocínio probabilístico –sempre entendido como subjetivo– decorre apenas da incerteza de algo. Não faz diferença se a incerteza diz respeito a um futuro imprevisível9, ou a um passado despercebido, ou a um passado duvidosamente relatado ou esquecido10… A única coisa relevante é a incerteza – a extensão de nosso próprio conhecimento e ignorância. O fato real de se os eventos considerados são ou não determinados em algum sentido, ou conhecidos por outras pessoas, e assim por diante, é irrelevante” (tradução minha de de Finetti (1974)).\nConcluindo: não importa o que é probabilidade, você consegue usá-la de qualquer maneira, mesmo que ela seja um frequência absoluta (ex: probabilidade de eu plantar bananeira de sunga na Avenida Paulista é ZERO pois a probabilidade de um evento que nunca ocorreu ocorrer no futuro é ZERO) ou um palpite subjetivo (ex: talvez a probabilidade não seja ZERO, mas 0,00000000000001; bem improvável, mas não impossível).\nDefinição Matemática\nCom a intuição filosófica de probabilidade elaborada, vamos às intuições matemáticas. A probabilidade de um evento é um número real11 entre 0 e 1, onde, grosso modo, 0 indica a impossibilidade do evento e 1 indica a certeza do evento. Quanto maior a probabilidade de um evento, mais provável é que o evento ocorrerá. Um exemplo simples é o lançamento de uma moeda justa (imparcial). Como a moeda é justa, os dois resultados (“cara” e “coroa”) são igualmente prováveis; a probabilidade de “cara” é igual à probabilidade de “coroa”; e uma vez que nenhum outro resultado é possível, a probabilidade de “cara” ou “coroa” é \\(\\frac{1}{2}\\) (que também pode ser escrita como 0,5 ou 50%).\nSobre notação, definimos que \\(A\\) é um evento e \\(P(A)\\) a probabilidade do evento, logo:\n\\[\n\\{P(A) \\in \\mathbb{R} : 0 \\geq P(A) \\geq 1 \\}.\n\\]\nIsto quer dizer o “probabilidade do evento A ocorrer é o conjunto de todos os numeros reais entre 0 e 1; incluindo 0 e 1.” Além disso temos três axiomas12, oriundos de Kolmogorov (1933) (figura 2):\nNão-negatividade: Para todo \\(A\\), \\(P(A) \\geq 0\\). Toda probabilidade é positiva (maior ou igual a zero), independente do evento.\nAditividade: Para dois mutuamente exclusivos \\(A\\) e \\(B\\) (não podem ocorrer ao mesmo tempo13): \\(P(A) = 1 - P(B)\\) e \\(P(B) = 1 - P(A)\\).\nNormalização: A probabilidade de todos os eventos possíveis \\(A_1, A_2, \\dots\\) devem somar 1: \\(\\sum_{n \\in \\mathbb{N}} A_n = 1\\).\n\n\n\nFigure 2: Andrey Nikolaevich Kolmogorov. Figura de https://www.wikipedia.org\n\n\n\nCom esses três simples (e intuitivos) axiomas, conseguimos derivar e construir toda a matemática da probabilidade.\nProbabilidade Condicional\nUm conceito importante é a probabilidade condicional que podemos definir como “probabilidade de um evento ocorrer caso outro tenha ocorrido ou não.” A notação que usamos é \\(P( A \\mid B )\\), que lê-se como “a probabilidade de observamos \\(A\\) dado que já observamos \\(B\\).”\nUm bom exemplo é o jogo de Poker Texas Hold’em, onde o jogador recebe duas cartas e podem utilizar mais cinco cartas comunitárias para montar sua “mão.” A probabilidade de você receber um Rei (\\(K\\)) é \\(\\frac{4}{52}\\):\n\\[\nP(K) = \\left(\\frac{4}{52}\\right) = \\left(\\frac{1}{13}\\right).\n\\]\nE a probabilidade de você receber um Ás (\\(A\\)) também é \\(\\frac{4}{52}\\):\n\\[\nP(A) = \\left(\\frac{4}{52}\\right) = \\left(\\frac{1}{13}\\right).\n\\]\nPorém a probabilidade de você receber um Rei como segunda carta dado que você recebeu um Ás como primeira carta é:\n\\[\nP(K \\mid A) = \\left(\\frac{4}{51}\\right).\n\\]\nComo temos uma carta a menos (\\(52 - 1 = 51\\)) já que você recebeu o Ás (visto que \\(A\\) foi observado), temos 4 Reis ainda no baralho, logo \\(\\frac{4}{51}\\).\nProbabilidade Conjunta\nProbabilidade condicional nos leva à um outro conceito importante: probabilidade conjunta. Probabilidade conjunta é a “probabilidade de observados dois eventos ocorrem.” Continuando no nosso exemplo do Poker, a probabilidade de você receber como duas cartas iniciais um Ás (\\(A\\)) e um Rei (\\(K\\)) é:\n\\[\n\\begin{aligned}\nP(A,K) &= P(A) \\cdot P(K \\mid A) \\\\\n&= P \\left(\\frac{1}{13}\\right) \\cdot P \\left(\\frac{4}{51}\\right)\\\\\n&= P \\left(\\frac{4}{51 \\cdot 13}\\right) \\\\\n&\\approx 0.006.\n\\end{aligned}\n\\]\nNote que \\(P(A,K) = P(K,A)\\):\n\\[\n\\begin{aligned}\nP(K,A) &= P(K) \\cdot P(A \\mid K) \\\\\n&= P \\left(\\frac{1}{13}\\right) \\cdot P \\left(\\frac{4}{51}\\right)\\\\\n&= P \\left(\\frac{4}{51 \\cdot 13}\\right) \\\\\n&\\approx 0.006.\n\\end{aligned}\n\\]\nNo nosso exemplo de Poker temos uma certa simetria:\n\\[\nP(K \\mid A) = P(A \\mid K).\n\\]\nMas sem sempre essa simetria existe (na verdade muito raramente ela existe). A identidade que temos é a seguinte:\n\\[\nP(A) \\cdot P(K \\mid A) = P(K) \\cdot P(A \\mid K).\n\\]\nEntão essa simetria só existe quando as taxas basais dos eventos condicionais são iguais:\n\\[\nP(A) = P(K).\n\\]\nQue é o que ocorre no nosso exemplo.\nProbabilidade Condicional não é “comutativa”\n\\[P(A \\mid B) \\neq P(B \\mid A)\\]\nVeja um exemplo prático. Digamos que eu estou me sentindo bem e começo a tossir na fila do mercado. O que você acha que irá acontecer? Todo mundo vai achar que estou com COVID, o que é equivalente à pensar em \\(P(\\text{tosse} \\mid \\text{covid})\\). Vendo os sintomas mais comuns do COVID, caso você esteja com COVID, a chance de você tossir é muito alta. Mas na verdade tossimos muito mais frequentemente que temos COVID – \\(P(\\text{tosse}) \\neq P(\\text{COVID})\\), logo:\n\\[\nP(\\text{COVID} \\mid \\text{tosse}) \\neq P(\\text{tosse} \\mid \\text{COVID}).\n\\]\nTeorema de Bayes\nEste é o ultimo conceito de probabilidade que precisamos abordar antes de mergulhar na estatística Bayesiana14, mas é o mais importante. Note que não é coincidência semântica que estatística Bayesiana e teorema de Bayes possuem o mesmo prefixo.\nThomas Bayes (1701 - 1761, figura 3) foi um estatístico, filósofo e ministro presbiteriano inglês conhecido por formular um caso específico do teorema que leva seu nome: o teorema de Bayes. Bayes nunca publicou o que se tornaria sua realização mais famosa; suas notas foram editadas e publicadas após sua morte pelo seu amigo Richard Price15. Em seus últimos anos, Bayes se interessou profundamente por probabilidade. Alguns especulam que ele foi motivado a refutar o argumento de David Hume contra a crença em milagres com base nas evidências do testemunho em “An Inquiry Concerning Human Understanding.”\n\n\n\nFigure 3: Thomas Bayes. Figura de https://www.wikipedia.org\n\n\n\nVamos logo para o Teorema. Lembra que temos a seguinte identidade na probabilidade:\n\\[\n\\begin{aligned}\nP(A,B) &= P(B,A) \\\\\nP(A) \\cdot P(B \\mid A) &= P(B) \\cdot P(A \\mid B).\n\\end{aligned}\n\\]\nPois bem, agora passe o \\(P(B)\\) do lado direito para o lado esquerdo dividindo:\n\\[\n\\begin{aligned}\nP(A) \\cdot P(B \\mid A) &= \\overbrace{P(B)}^{\\text{isso vai para $\\leftarrow$}} \\cdot P(A \\mid B) \\\\\n&\\\\\n\\frac{P(A) \\cdot P(B \\mid A)}{P(B)} &= P(A \\mid B) \\\\\nP(A \\mid B) &= \\frac{P(A) \\cdot P(B \\mid A)}{P(B)}.\n\\end{aligned}\n\\]\nE esse é o resultado final:\n\\[\nP(A \\mid B) = \\frac{P(A) \\cdot P(B \\mid A)}{P(B)}.\n\\]\nA estatística Bayesiana usa esse teorema como motor de inferência dos parâmetros de um modelo condicionado aos dados observados.\nParâmetros Discretos vs Contínuos\nTudo o que foi exposto até agora partiu do pressuposto que os parâmetros são discretos. Isto foi feito com o intuito de prover uma melhor intuição do que é probabilidade. Nem sempre trabalhamos com parâmetros discretos. Os parâmetros podem ser contínuos, como por exemplo: idade, altura, peso etc. Mas não se desespere, todas as regras e axiomas da probabilidade são válidos também para parâmetros contínuos. A única coisa que temos que fazer é trocar todas as somas \\(\\sum\\) por integrais \\(\\int\\). Por exemplo o terceiro axioma de Normalização para variáveis aleatórias contínuas se torna:\n\\[\n\\int_{x \\in X} p(x) dx = 1.\n\\]\nEstatística Bayesiana\nAgora que você já sabe o que é probabilidade e o que é o teorema de Bayes, vou propor o seguinte modelo:\n\\[\n\\underbrace{P(\\theta \\mid y)}_{\\textit{Posteriori}} = \\frac{\\overbrace{P(y \\mid  \\theta)}^{\\text{Verossimilhança}} \\cdot \\overbrace{P(\\theta)}^{\\textit{Priori}}}{\\underbrace{P(y)}_{\\text{Constante Normalizadora}}},\n\\]\nonde:\n\\(\\theta\\) – parâmetro(s) de interesse\n\\(y\\) – dados observados\nPriori – probabilidade prévia do valor do(s) parâmetro(s)16\nVerossimilhança – probabilidade dos dados observados condicionados aos valores do(s) parâmetro(s)\nPosteriori – probabilidade posterior do valor do(s) parâmetros após observamos os dados \\(y\\)\nConstante Normalizadora – \\(P(y)\\) não faz sentido intuitivo. Essa probabilidade é transformada e pode ser interepretada como algo que existe apenas para que o resultado de \\(P(y \\mid \\theta) P(\\theta)\\) seja algo entre 0 e 1 – uma probabilidade válida. Vamos falar mais sobre essa constante na Aula 4 - Markov Chain Montecarlo – MCMC.\nA estatísica Bayesiana nos permite quantificar diretamente a incerteza relacionada ao valor de um ou mais parâmetros do nosso modelo condicionado ao dados observados. Isso é a característica principal da estatística Bayesiana. Pois estamos estimando diretamente \\(P(\\theta \\mid y)\\) por meio do teorema de Bayes. A estimativa resultante é totalmente intuitiva: simplesmente quantifica a intercerteza que temos sobre o valor de um ou mais parâmetro condicionado nos dados, nos pressupostos do nosso modelo (verossimilhança) e na probabilidade prévia que temos sobre tais valores.\nEstatística Frequentista\nPara contrastar com a estatística Bayesiana, vamos ver como a estatística clássica frequentista17. E já aviso, não é algo intuitivo que nem a estatística Bayesiana.\nPara a estatística frequentista o pesquisador está proibido de fazer conjecturas probabilísticas sobre parâmetros. Pois eles não são incertos, muito pelo contrário é uma quantidade determinada. A única questão é que não observamos diretamente os parâmetros, mas eles são determinísticos e não permitem qualquer margem de incerteza. Logo, para a abordagem frequentista, parâmetros são quantidades de interesse não observadas na qual não fazemos conjecturas probabilísticas.\nO que é então incerto na estatística frequentista? Resposta curta: os dados observados. Para a abordagem frequentista a sua amostra é incerta. É sobre ela que você pode fazer conjecturas probabilísticas. Portanto, a incerteza é expressa na probabilidade de eu obter dados similares aos que eu obtive se eu amostrasse de uma população de interesse infinitas amostras do mesmo tamanho que a minha amostra18. A incerteza é condicionada à uma abordagem frequentista, em outras palavras, a incerteza só existe se eu considerar um processo de amostragem infinito e extrair desse processo uma frequência. A probabilidade só existe se representar uma frequência. Mesmo se isso ocasionar em um “processo de amostragem infinito de uma população que eu nunca observei,” por mais estranho que isso soe19.\nPara a abordagem frequentista não existe probabilidade posteriori nem priori pois ambas envolvem parâmetros, e vimos que isso é proibido em solo frequentista. Tudo o que é necessário para a inferência estatística está contida na verossimilhança20.\nAlém disso, por razões de facilidade de computação, pois boa parte desses métodos foram inventados na primeira métade do século XX (sem a ajuda do computador), apenas é computado o valor dos parâmetros que maximizam a função da verossimilhança21. Desse processo de otimização extraímos a moda da verossimilhança. A estimativa de maximização da verossimilhança é o valor dos parâmetros de forma que a amostra de tamanho \\(N\\) amostrada de maneira aleatória de uma população (os dados que você tem) é a amostra de tamanho \\(N\\) mais provável da população. Todas as outras amostras potenciais que poderiam ser extraídos dessa população terão uma estimação pior do que a amostra que você realmente tem22.\nA moda funciona perfeitamente no mundo de conto de fadas que se pressupõe que tudo segue uma distribuição normal, pois a moda é igual a mediana e a média – \\(\\text{média} = \\text{mediana} = \\text{moda}\\). Só tem um problema, raramente esse pressuposto é verdadeiro (figura 4), ainda mais quando falamos de parâmetros num contexto de pluralidade de parâmetros e relações complexas entre parâmetros (modelos complexos).\n\n\n\nFigure 4: Pressupostos vs Realidade. Figura de Katherine Hoffman. Reprodução Autorizada.\n\n\n\nVale aqui uma breve explicação sociológica e computacional porque a estatística clássica proíbe conjecturas probabilísticas sobre parâmetros e trabalhamos com otimização (achar o valor máximo de uma função) do que aproximação ou estimação da densidade completa da verossimilhança (em outras palavras, “levantar a capivara toda” da verossimilhança ao invés de somente a moda).\nSobre a questão sociológica, a ciência no começo do século XX partia do princípio que ela é objetiva e toda subjetividade deve ser banida. Logo, como a estimação da probabilidade a posteriori de parâmetros envolve a elucidação de uma probabilidade a priori de parâmetros, tal método não deve ser permitido na ciência, pois traz subjetividade (sabemos hoje que nada no comportamento humano é puramente objetivo, e a subjetividade impregna todas as empreitadas humanas).\nSobre a questão computacional, na década de 1930s sem computadores era muito mais fácil usar pressupostos fortes sobre os dados para conseguir uma resposta de uma estimação estatística usando derivações matemáticas do que calcular na mão a estimação estatística sem depender de tais pressupostos. Por exemplo: o famoso teste \\(t\\) de Student é um teste que indica quando conseguimos rejeitar que a média de um certo parâmetro de interesse entre dois grupos é igual (famosa hipótese nula – \\(H_0\\)). Esse teste parte do pressuposto que se o parâmetro de interesse for distribuído conforme uma distribuição normal (pressuposto 1 – normalidade da variável dependente), se a variância do parâmetro de interesse varia de maneira homogênea dentre os grupos (pressuposto 2 – homogeneidade das variâncias) e se o número de observações nos dois grupos de interesse é similar (pressuposto 3 – homogeneidade do tamanho dos grupos) a diferença entre os grupos ponderada pela variância dos grupos segue uma distribuição \\(t\\) de Student (por isso o nome do teste).\nEntão a estimação estatística se resume a calcular a média de dois grupos, a variância de cada um deles para um parâmetro de interesse e buscar o tal do \\(p\\)-valor numa tabela e ver se conseguimos rejeitar a \\(H_0\\). Isto é válido quando tudo o que fazemos é calculado na mão, hoje com um computador 1 milhão de vezes mais potente que o computador da Apollo 11 (levou a humanidade à lua) no seu bolso23, não sei se ainda é valido.\n\\(p\\)-valores\n\n\\(p\\)-valores são de difícil entendimento, \\(p < 0.05\\).\n\n\n\n\nJá que mencionamos \\(p\\)-valor, vamos então explicar o que é o \\(p\\)-valor. Primeiramente a definição estatística:\n\n\\(p\\)-valor é a probabilidade de obter resultados no mínimo tão extremos quanto os que foram observados, dado que a hipótese nula \\(H_0\\) é verdadeira.\n\nSe você escrever essa definição em qualquer prova, livro ou artigo científico, você estará 100% preciso e correto na definição do que é um \\(p\\)-valor. Agora, a compreensão dessa definição é algo complicado. Para isso, vamos quebrar essa definição em algumas partes para melhor compreensão:\n“probabilidade de obter resultados…”: vejam que \\(p\\)-valores são uma característica dos seus dados e não da sua teoria ou hipótese.\n“…no mínimo tão extremos quanto os que foram observados…”: “no minimo tão” implica em definir um limiar para a caracterização de algum achado relevante, que é comumente chamado de \\(\\alpha\\). Geralmente estipulamos alpha em 5% (\\(\\alpha = 0.05\\)) e qualquer coisa mais extrema que alpha (ou seja menor que 5%) caracterizamos como significante.\n“..dado que a hipótese nula é verdadeira…”: Todo teste estatístico que possui um \\(p\\)-valor possui uma Hipótese Nula (geralmente escrita como \\(H_0\\)). Hipótese nula, sempre tem a ver com algum efeito nulo. Por exemplo, a hipótese nula do teste Shapiro-Wilk e Komolgorov-Smirnov é “os dados são distribuídos conforme uma distribuição Normal” e a do teste de Levene é “as variâncias dos dados são iguais.” Sempre que ver um \\(p\\)-valor, se pergunte: “Qual a hipótese nula que este teste presupõe correta?”\nPara entender o \\(p\\)-valor qualquer teste estatístico primeiro descubra qual é a hipótese nula por trás daquele teste. A definição do \\(p\\)-valor não mudará. Em todo teste ela é sempre a mesma. O que muda com o teste é a hipótese nula. Cada teste possui sua \\(H_0\\). Por exemplo, alguns testes estatísticos comuns:\nTeste t: \\(P(D \\mid \\text{efeito nulo})\\)\nANOVA: \\(P(D \\mid \\text{não há diferença entre os grupos})\\)\nRegressão: \\(P(D \\mid \\text{coeficiente é nulo})\\)\nShapiro-Wilk: \\(P(D \\mid \\text{amostra é normal})\\)\n\\(p\\)-valor é a probabilidade dos dados que você obteve dado que a hipótese nula é verdadeira. Para os que gostam do formalismo matemático: \\(p = P(D \\mid H_0)\\). Em português, essa expressão significa “a probabilidade de \\(D\\) condicionado à \\(H_0\\).” Antes de avançarmos para alguns exemplos e tentativas de formalizar uma intuição sobre os \\(p\\)-valores, é importante ressaltar que \\(p\\)-valores dizem algo à respeito dos dados e não de hipóteses. Para o \\(p\\)-valor, a hipótese nula é verdadeira, e estamos apenas avaliando se os dados se conformam à essa hipótese nula ou não. Se vocês saírem desse tutorial munidos com essa intuição, o mundo será agraciado com pesquisadores mais preparados para qualificar e interpretar evidências (\\(p < 0.05\\)).\nExemplo intuitivo:\n\nImagine que você tem uma moeda que suspeita ser enviesada para uma probabilidade maior de dar cara. (Sua hipótese nula é então que a moeda é justa.) Você joga a moeda 100 vezes e obtém mais cara do que coroa. O \\(p\\)-valor não dirá se a moeda é justa, mas dirá a probabilidade de você obter pelo menos tantas caras quanto se a moeda fosse justa. É isso - nada mais.\n\n\nApesar de mencionar anteriormente que definições intuitivas não são precisas, elas sem dúvida facilitam o entendimento do \\(p\\)-valor.\n\\(p\\)-valores – Algumas questões históricas\nNão tem como entendermos \\(p\\)-valores se não compreendermos as suas origens e trajetória histórica. A primeira menção do termo foi feita pelo estatístico Ronald Fisher[A controvérsia da personalidade e vida de Ronald Fisher merece uma nota de rodapé. Suas contribuições, sem dúvida, foram cruciais para o avanço da ciência e da estatística. Seu intelecto era brilhante e seu talento já floresceu jovem: antes de completar 33 anos de idade ele tinha proposto o método de estimação por máxima verossimilhança (maximum likelihood estimation) (Stigler & others, 2007) e também criou o conceito de graus de liberdade (degrees of freedom) ao propor uma correção no teste de chi-quadrado de Pearson (Baird, 1983). Também inventou a Análise de Variância (ANOVA) e foi o primeiro a propor randomização como uma maneira de realizar experimentos, sendo considerado o “pai” dos ensaios clínicos randomizados. Nem tudo é florido na vida de Fisher, ele foi um eugenista e possuía uma visão muito forte sobre etnia e raça preconizando a superioridade de certas etnias. Além disso, era extremamente invariante, perseguindo, prejudicando e debochando qualquer crítico à suas teorias e publicações. O que vemos hoje no monopólio do paradigma Neyman-Pearson (Neyman & Pearson, 1933) com \\(p\\)-valores e hipóteses nulas é resultado desse esforço Fisheriano em calar os críticos e deixar apenas sua voz ecoar.] em 1925 (Fisher, 1925) que define o \\(p\\)-valor como um “índice que mede a força da evidência contra a hipótese nula.” Para quantificar a força da evidência contra a hipótese nula, Fisher defendeu “\\(p<0.05\\) (5% de significância) como um nível padrão para concluir que há evidência contra a hipótese testada, embora não como uma regra absoluta.” Fisher não parou por aí mas classificou a força da evidência contra a hipótese nula. Ele propôs “se \\(p\\) está entre 0.1 e 0.9, certamente não há razão para suspeitar da hipótese testada. Se estiver abaixo de 0.02, é fortemente indicado que a hipótese falha em explicar o conjunto dos fatos. Não seremos frequentemente perdidos se traçarmos uma linha convencional de 0.05” Desde que Fisher fez esta declaração há quase 100 anos, o limiar de 0.05 foi usado por pesquisadores e cientistas em todo o mundo e tornou-se ritualístico usar 0.05 como limiar como se outros limiares não pudessem ser usados.\n\n\n\nFigure 5: Ronald Fisher. Figura de https://www.wikipedia.org\n\n\n\nApós isso, o limiar de 0.05 agora instaurado como inquestionável influenciou fortemente a estatística e a ciência. Mas não há nenhuma razão contra a adoção de outros limiares (\\(\\alpha\\)) como 0.1 ou 0.01. Se bem argumentados, a escolha de limiares diferentes de 0.05 pode ser bem-vista por editores, revisores e orientadores. Como o \\(p\\)-valor é uma probabilidade, ele não é um quantidade contínua. Não há razão para diferenciarmos um \\(p\\) de 0.049 contra um \\(p\\) de 0.051. Robert Rosenthal, um psicólogo já dizia “Deus ama \\(p\\) de 0.06 tanto quanto um \\(p\\) de 0.05” (Rosnow & Rosenthal, 1989).\nNo último ano de sua vida, Fisher publicou um artigo (Fisher, 1962) examinando as possibilidades dos métodos Bayesianos, mas com as probabilidades a priori a serem determinadas experimentalmente. Inclusive alguns autores especulam (Jaynes, 2003) que se Fisher estivesse vivo hoje, ele provavelmente seria um “Bayesiano.”\nO que o \\(p\\)-valor não é\nCom a definição e intuição do que é um \\(p\\)-valor bem ancoradas, podemos avançar para o que o \\(p\\)-valor não é!\n\n\n\n\\(p\\)-valor não é a probabilidade da Hipótese nula - Famosa confusão entre \\(P(D \\mid H_0)\\) e \\(P(H_0 \\mid D)\\). \\(p\\)-valor não é a probabilidade da hipótese nula, mas sim a probabilidade dos dados que você obteve. Para obter a $P(H_0 D) você precisa de estatística Bayesiana.\n\\(p\\)-valor não é a probabilidade dos dados serem produzidos pelo acaso - Não! Ninguém falou nada de acaso. Mais uma vez: \\(p\\)-valor é probabilidade de obter resultados no mínimo tão extremos quanto os que foram observados, dado que a hipótese nula é verdadeira.\n\\(p\\)-valor mensura o tamanho do efeito de um teste estatístico - Também não… \\(p\\)-valor não diz nada sobre o tamanho do efeito. Apenas sobre se o quanto os dados observados divergem do esperado sob a hipótese nula. É claro que efeitos grandes são mais prováveis de serem estatisticamente significantes que efeitos pequenos. Mas isto não é via de regra e nunca julguem um achado pelo seu \\(p\\)-valor, mas sim pelo seu tamanho de efeito. Além disso, \\(p\\)-valores podem ser “hackeados” de diversas maneiras (Head, Holman, Lanfear, Kahn, & Jennions, 2015) e muitas vezes seu valor é uma consequência direta do tamanho da amostra.\nIntervalos de Confiança\nPara concluir, vamos falar sobre os famosos intervalos de confiança, que não são uma medida que quantifica a incerteza do valor de um parâmetro (lembre-se conjecturas probabilísticas sobre parâmetros são proibidos em frequentist-land). Segure seu queixo, intervalos de confiança são:\n\nUm intervalo de confiança de X% para um parâmetro é um intervalo \\((a, b)\\) gerado por um procedimento que em amostragem repetida tem uma probabilidade de X% de conter o valor verdadeiro do parâmetro, para todos os valores possíveis do parâmetro\nNeyman (1937) (o “pai” dos intervalos de confiança, figura 6)\n\n\n\n\nFigure 6: Jerzy Neyman. Figura de https://www.wikipedia.org\n\n\n\nMais uma vez a ideia da amostragem repetida infinita vezes de uma população que você nunca viu. Por exemplo: digamos que você executou uma análise estatística para comparar eficácia de uma política pública em dois grupos e você obteve a diferença entre a média desses grupos. Você pode expressar essa diferença como um intervalo de confiança. Geralmente escolhemos a confiança de 95%. Você então escreve no seu artigo que a “diferença entre grupos observada é de 10.5 - 23.5 (95% IC).” Isso quer dizer que 95 estudos de 100, que usem o mesmo tamanho de amostra e população-alvo, aplicando o mesmo teste estatístico, esperarão encontrar um resultado de diferenças de média entre grupos entre 10.5 e 23.5. Aqui as unidades são arbitrárias, mas para continuar o exemplo vamos supor que sejam expectativa de vida.\nInfelizmente com estatística frequentista você tem que escolher uma das duas qualidades para explicações: intuitiva ou precisa24.\nIntervalos de Confiança (Frequentista) vs Intervalos de Credibilidade (Bayesiana)\nA estatística Bayesiana possui um conceito análogo ao de intervalos de confiança da estatística frequentista. Esse conceito se chama intervalo de credibilidade25 e, ao contrário do intervalo de confiança, a sua definição é intuitiva. Intervalo de credibilidade mensura um intervalo no qual temos certeza que o valor do parâmetro de interesse é, com base na verossimilhança condicionada aos dados observados – \\(P(y \\mid \\theta)\\); e na probabilidade priori do parâmetro – \\(P(\\theta)\\). Ele é basicamente uma “fatia” da probabilidade posteriori do parâmetro restrita a um certo nível de certeza. Por exemplo: um intervalo de credibilidade 95% mostra o intervalo que temos 95% de certeza que o valor do nosso parâmetro se encontra. Simples assim…\nPara exemplificar veja na figura 7 que mostra uma distribuição Log-Normal com média 0 e desvio padrão 2. O gráfico na parte superior mostra a estimativa da máxima verossimilhança26 do valor de \\(\\theta\\) que é a moda da distribuição. E no gráfico de baixo temos o intervalo de credibilidade 50% do valor de \\(\\theta\\) que é o intervalo entre o percentil 25% e o percentil 75%. Nesse exemplo, estimação por máxima verossimilhança nos leva à valores estimados que não são condizentes com a real densidade probabilística do valor de \\(\\theta\\).\n\n\n\nFigure 7: De baixo para cima: Estimação de Máxima Verossimilhança e Intervalo de Credibilidade\n\n\n\nAgora um exemplo de uma distribuição multimodal27. A figura 8 mostra uma distribuição bimodal com duas modas 2 e 1028. O gráfico na parte superior mostra a estimativa da máxima verossimilhança do valor de \\(\\theta\\) que é a moda da distribuição. Vejam que mesmo com 2 modas, maxima verossimilhança se “agarra” na maior moda. E no gráfico de baixo temos o intervalo de credibilidade 50% do valor de \\(\\theta\\) que é o intervalo entre o percentil 25% e o percentil 75%. Nesse exemplo, estimação por máxima verossimilhança de novo nos leva à valores estimados que não são condizentes com a real densidade probabilística do valor de \\(\\theta\\).\n\n\n\nFigure 8: De baixo para cima: Estimação de Máxima Verossimilhança e Intervalo de Credibilidade\n\n\n\nEstatística Bayesiana vs Frequentista\nO que discutimos acima de resume nessa tabela abaixo:\n\nEstatística Bayesiana\nEstatística Frequentista\nDados\nFixos – Não Aleatórios\nIncertos – Aleatórios\nParâmetros\nIncertos – Aleatorios\nFixos – Não Aleatórios\nInferência\nIncerteza sobre o valor do parâmetro\nIncerteza sobre um processo de amostragem de uma população infinita\nProbabilidade\nSubjetiva\nObjetiva (mas com diversos pressupostos dos modelos)\nIncerteza\nIntervalo de Credibilidade – \\(P(\\theta \\mid y)\\)\nIntervalo de Confiança – \\(P(y \\mid \\theta)\\)\nVantagens da Estatística Bayesiana\nPor fim, eu sumarizo as principais vantagens da estatística Bayesiana:\nAbordagem Natural para expressar incerteza\nHabilidade de incorporar informações prévia\nMaior flexibilidade do modelo\nDistribuição posterior completa dos parâmetros\nIntervalos de Confiança vs Intervalos de Credibilidade\n\nPropagação natural da incerteza\nE eu acredito que preciso também mostrar a principal desvantagem:\nVelocidade lenta de estimativa do modelo (30 segundos ao invés de 3 segundos na abordagem frequentista)\nStan\nStan (Carpenter et al., 2017) é uma plataforma para modelagem e computação estatística de alto desempenho. Milhares de usuários contam com Stan para modelagem estatística, análise de dados e previsão nas ciências sociais, biológicas e físicas, engenharia e negócios. Stan tem mais de 3.600 citações no Google Scholar29. Além disso, Stan tem o suporte financeiro da NumFOCUS, uma fundação sem fins lucrativos que dá apoio financeiro à projetos de softwares opensource. Dentre os patrocinadores da NumFOCUS podemos citar AWS Amazon, Bloomberg, Microsoft, IBM, RStudio, Facebook, NVIDIA, Netflix, entre outras.\nOs modelos em Stan são especificados pela sua própria linguagem (similar à C++) e são compilados em um arquivo executável que gera inferências estatísticas Bayesiana com amostragem Monte Carlo de correntes Markov (Markov Chain Monte Carlo – MCMC) de alto desempenho. Stan possui interfaces para as seguintes linguagens de programação30:\nR: RStan e CmdStanR\nPython: PyStan e CmdStanPy\nShell (Linha de Comando): CmdStan\nJulia: Stan.jl\nScala: ScalaStan\nMatlab: MatlabStan\nStata: StataStan\nMathematica: MathematicaStan\nPara instalar Stan o usuário deve possuir um compilador C++ no seu sistema operacional31. Essa é a principal dependência do Stan, uma vez que todas suas outras dependências (Boost e Eigen) são bibliotecas header-only e não precisam de configurações adicionais a não ser um compilador C++ funcional.\nA linguagem Stan possui uma curva de aprendizagem bem desafiadora, por isso Stan possui um ecossistema de pacotes de interfaces que muitas vezes ajudam e simplificam a sua utilização:\nrstanarm: ajuda o usuário a especificar modelos usando a síntaxe familiar de fórmulas do R.\nbrms: similar ao rstanarm pois usa a síntaxe familiar de fórmulas do R, mas dá maior flexibilidade na especificação de modelos mais complexos32.\nStan33 usa um amostrador MCMC que utiliza dinâmica Hamiltoniana (Hamiltonian Monte Carlo – HMC) para guiar as propostas de amostragem de novos parâmetros no sentido do gradiente da densidade de probabilidade da posterior. Isto implica em um amostrador mais eficiente e que consegue explorar todo o espaço amostral da posterior com menos iterações; e também mais eficaz que consegue tolerar diferentes topologias de espaços amostrais da posterior. Em outras palavras, Stan usa técnicas de amostragem avançadas que permite com que modelos complexos Bayesianos atinjam convergência de maneira rápida. No Stan, raramente deve-se ajustar os parâmetros do algoritmo HMC, pois geralmente os parâmetros padrões (out-of-the-box) funcionam muito bem. Assim, o usuário foca no que é importante: a especificação dos componentes probabilísticos do seu modelo Bayesiano.\nStan é a ferramenta mais popular e poderosa de inferência Bayesiana, veja abaixo um vídeo de uma série popular chamada Billions, temporada 3 episódio 9. Interessante aqui é que não se menciona outras ferramentas extremamente populares em análise de dados34 e coloca Stan no mesmo patamar que Python, Julia e C++.\n\n\nHistória do Stan\nStan é uma homenagem ao matemático Stanislaw Ulam (figura 9), que participou do projeto Manhattan e ao tentar calcular o processo de difusão de neutrons para a bomba de hidrogênio acabou criando uma classe de métodos chamada Monte Carlo.\n\n\n\nFigure 9: Stanislaw Ulam. Figura de https://www.wikipedia.org\n\n\n\nMétodos de Monte Carlo possuem como conceito subjacente o uso a aleatoriedade para resolver problemas que podem ser determinísticos em princípio. Eles são freqüentemente usados em problemas físicos e matemáticos e são mais úteis quando é difícil ou impossível usar outras abordagens. Os métodos de Monte Carlo são usados principalmente em três classes de problemas: otimização, integração numérica e geração de sorteios a partir de uma distribuição de probabilidade.\nA ideia do método veio enquanto jogava paciência durante sua recuperação de uma cirurgia, Ulam pensou em jogar centenas de jogos para estimar estatisticamente a probabilidade de um resultado bem-sucedido. Conforme ele mesmo menciona em Eckhardt (1987):\n\nOs primeiros pensamentos e tentativas que fiz para praticar [o Método de Monte Carlo] foram sugeridos por uma pergunta que me ocorreu em 1946 quando eu estava convalescendo de uma doença e jogando paciência. A questão era quais são as chances de que um jogo de paciência com 52 cartas obtivesse sucesso? Depois de passar muito tempo tentando estimá-los por meio de cálculos combinatórios puros, me perguntei se um método mais prático do que o “pensamento abstrato” não seria expô-lo, digamos, cem vezes e simplesmente observar e contar o número de jogadas bem-sucedidas. Isso já era possível imaginar com o início da nova era de computadores rápidos, e eu imediatamente pensei em problemas de difusão de nêutrons e outras questões de física matemática e, de forma mais geral, como mudar os processos descritos por certas equações diferenciais em uma forma equivalente interpretável como uma sucessão de operações aleatórias. Mais tarde [em 1946], descrevi a ideia para John von Neumann e começamos a planejar cálculos reais.\n\nPor ser secreto, o trabalho de von Neumann e Ulam exigia um codinome. Um colega de von Neumann e Ulam, Nicholas Metropolis35, sugeriu usar o nome Monte Carlo, que se refere ao Casino Monte Carlo em Mônaco, onde o tio de Ulam (Michał Ulam) pedia dinheiro emprestado a parentes para jogar.\nCaso o leitor se interesse na história por trás da criação do Stan veja esse vídeo abaixo do Youtube da StanCon 2018.\n\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.4 (2021-02-15)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 20.10\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.9.0\nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.9.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] tibble_3.1.0    ggplot2_3.3.3   patchwork_1.1.1 cowplot_1.1.1  \n\nloaded via a namespace (and not attached):\n [1] bslib_0.2.4       compiler_4.0.4    pillar_1.5.1     \n [4] jquerylib_0.1.3   highr_0.8         tools_4.0.4      \n [7] digest_0.6.27     downlit_0.2.1     debugme_1.1.0    \n[10] jsonlite_1.7.2    evaluate_0.14     lifecycle_1.0.0  \n[13] gtable_0.3.0      pkgconfig_2.0.3   rlang_0.4.10     \n[16] DBI_1.1.1         distill_1.2       yaml_2.2.1       \n[19] parallel_4.0.4    xfun_0.22         withr_2.4.1      \n[22] dplyr_1.0.5       stringr_1.4.0     knitr_1.31       \n[25] generics_0.1.0    vctrs_0.3.6       sass_0.3.1       \n[28] systemfonts_1.0.1 tidyselect_1.1.0  grid_4.0.4       \n[31] glue_1.4.2        R6_2.5.0          textshaping_0.3.2\n[34] jpeg_0.1-8.1      fansi_0.4.2       rmarkdown_2.7    \n[37] farver_2.1.0      purrr_0.3.4       magrittr_2.0.1   \n[40] scales_1.1.1      htmltools_0.5.1.1 ellipsis_0.3.1   \n[43] assertthat_0.2.1  colorspace_2.0-0  labeling_0.4.2   \n[46] ragg_1.1.1        utf8_1.1.4        stringi_1.5.3    \n[49] munsell_0.5.0     crayon_1.4.1     \n\n\n\n\nBaird, D. (1983). The fisher/pearson chi-squared controversy: A turning point for inductive inference. The British Journal for the Philosophy of Science, 34(2), 105–118. Retrieved from http://www.jstor.org/stable/687444\n\n\nBaird, D. (1983). The fisher/pearson chi-squared controversy: A turning point for inductive inference. The British Journal for the Philosophy of Science, 34(2), 105–118. Retrieved from http://www.jstor.org/stable/687444\n\n\nde Finetti, B. (1974). Theory of Probability (Volume 1). New York: John Wiley & Sons.\n\n\nEckhardt, R. (1987). Stan Ulam, John von Neumann, and the Monte Carlo Method. Los Alamos Science, 15(30), 131–136.\n\n\nFisher, R. A. (1925). Statistical methods for research workers. Oliver; Boyd.\n\n\nFisher, R. A. (1925). Statistical methods for research workers. Oliver; Boyd.\n\n\nFisher, R. A. (1962). Some Examples of Bayes’ Method of the Experimental Determination of Probabilities A Priori. Journal of the Royal Statistical Society. Series B (Methodological), 24(1), 118–124. Retrieved from http://www.jstor.org/stable/2983751\n\n\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian Data Analysis. Chapman and Hall/CRC.\n\n\nHead, M. L., Holman, L., Lanfear, R., Kahn, A. T., & Jennions, M. D. (2015). The extent and consequences of p-hacking in science. PLoS Biol, 13(3), e1002106.\n\n\nHead, M. L., Holman, L., Lanfear, R., Kahn, A. T., & Jennions, M. D. (2015). The extent and consequences of p-hacking in science. PLoS Biol, 13(3), e1002106.\n\n\nJaynes, E. T. (2003). Probability theory: The logic of science. Cambridge university press.\n\n\nKolmogorov, A. N. (1933). Foundations of the Theory of Probability. Berlin: Julius Springer.\n\n\nNau, R. F. (2001). De Finetti was Right: Probability Does Not Exist. Theory and Decision, 51(2), 89–124. https://doi.org/10.1023/A:1015525808214\n\n\nNeyman, J. (1937). Outline of a theory of statistical estimation based on the classical theory of probability. Philosophical Transactions of the Royal Society of London. Series A, Mathematical and Physical Sciences, 236(767), 333–380.\n\n\nNeyman, J. (1937). Outline of a theory of statistical estimation based on the classical theory of probability. Philosophical Transactions of the Royal Society of London. Series A, Mathematical and Physical Sciences, 236(767), 333–380.\n\n\nNeyman, J., & Pearson, E. S. (1933). On the problem of the most efficient tests of statistical hypotheses. Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character, 231(694-706), 289–337.\n\n\nNeyman, J., & Pearson, E. S. (1933). On the problem of the most efficient tests of statistical hypotheses. Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character, 231(694-706), 289–337.\n\n\nRosnow, R. L., & Rosenthal, R. (1989). Statistical procedures and the justification of knowledge in psychological science. American Psychologist, 44, 1276–1284.\n\n\nRosnow, R. L., & Rosenthal, R. (1989). Statistical procedures and the justification of knowledge in psychological science. American Psychologist, 44, 1276–1284.\n\n\nStigler, S. M., & others. (2007). The epic story of maximum likelihood. Statistical Science, 22(4), 598–620.\n\n\nStigler, S. M., & others. (2007). The epic story of maximum likelihood. Statistical Science, 22(4), 598–620.\n\n\nvan de Schoot, R., Depaoli, S., King, R., Kramer, B., Märtens, K., Tadesse, M. G., … Yau, C. (2021). Bayesian statistics and modelling. Nature Reviews Methods Primers, 1(1, 1), 1–26. https://doi.org/10.1038/s43586-020-00001-2\n\n\nmaiúsculo, pois se refere ao teorema de Bayes que é um sobrenome.↩︎\ndo inglês prior distribution.↩︎\ndo inglês likelihood function.↩︎\ndo inglês posterior distribution↩︎\npessoalmente, como um bom Popperiano, não acreditado que haja ciência sem ser baseada em evidências; o que não usa evidências pode ser considerado como filosofia ou práticas sociais (não menos ou mais importantes que a ciência, apenas uma demarcação do que é ciência e do que não é; ex: direito).↩︎\nseu smartphone (iPhone 12 - 4GB RAM) possui 1.000.000x (1 milhão) mais poder computacional que o computador de bordo da Apollo 11 (4kB RAM) que levou o homem à lua. Detalhe: esse computador de bordo era responsável pela navegação, rota e controles do módulo lunar.↩︎\ncaso o leitor queira uma discussão aprofundada veja Nau (2001).↩︎\ndo inglês sufficient statistic.↩︎\nobservação minha: relacionado à abordagem Bayesiana subjetiva.↩︎\nobservação minha: relacionado à abordagem frequentista objetiva.↩︎\num número que pode ser expressado como um ponto em uma linha contínua que se origina em menos infinito e termina e mais infinito \\((-\\infty, +\\infty)\\); para quem gosta de computação é um ponto flutuante float ou double.↩︎\nna matemática axiomas são afirmações pressupostas como verdadeiras que servem como premissas or pontos de partidas para elaboração de argumentos e teoremas. Muitas vezes os axiomas são questionáveis, por exemplo geometria não-Euclidiana refuta o quinto axioma de Euclides sobre linhas paralelas. Até agora não há nenhum questionamento que tenha suportado o escrutínio do tempo e da ciência sobre os três axiomas da probabilidade.↩︎\npor exemplo, o resultado de uma moeda dado é um dos 2 eventos mutualmente exclusivos: cara ou coroa.↩︎\npalavra de escoteiro.↩︎\no nome formal do teorema é Bayes-Price-Laplace, pois Thomas Bayes foi o primeiro a descobrir, Richard Price pegou seus rascunhos, formalizou em notação matemática e apresentou para a Royal Society of London, e Pierre Laplace redescobriu o teorema sem ter tido contato prévio no final do século XVIII na França ao usar probabilidade para inferência estatística com dados do Censo na era Napoleônica.↩︎\nvou cobrir probabilidades prévias –priori– no conteúdo da aula 3 - Priors↩︎\ntambém chamada de ortodoxa.↩︎\neu avisei que não era intuitivo…↩︎\nseu “sentido aranha” deve estar disparando agora…↩︎\nalgo que vale notar: a verossimilhança também carrega muita subjetividade.↩︎\npara os que gostam de matemática, calculamos em qual ponto de \\(\\theta\\) a derivada da verossimilhança é zero – \\(\\mathcal{L}^\\prime = 0\\).↩︎\neu já avisei que não é tão intuitivo?↩︎\nseu smartphone (iPhone 12 - 4GB RAM) possui 1.000.000x (1 milhão) mais poder computacional que o computador de bordo da Apollo 11 (4kB RAM) que levou o homem à lua. Detalhe: esse computador de bordo era responsável pela navegação, rota e controles do módulo lunar.↩︎\nisto foi copiado de Andrew Gelman – Estatístico Bayesiano.↩︎\ndo inglês credible interval.↩︎\ndo inglês: Maximum Likelihood Estimation – MLE.↩︎\no que não é muito raro de se ver no mundo real.↩︎\npara os curiosos é uma mistura de duas distribuições normais ambas com desvio padrão 1, mas com médias diferentes. Para completar atribui os pesos de 60% para a distribuição com média 2 e 40% para a distribuição com média 10.↩︎\nconforme consulta em 14 de Março de 2021.↩︎\nestou riscando as linguagens que não são opensource por uma questão de princípios.↩︎\no que ocasiona muitas frustações, mas quase todos os problemas são solucionados se o usuário seguir as instruções no repositório GitHub do Stan sobre compiladores C++.↩︎\ne geralmente a amostragem é um pouco mais rápida que o rstanarm.↩︎\ne consequentemente todas suas interfaces com diversas linguagens de programação e todos os pacotes do seu ecossistema.↩︎\nnada de TensorFlow, PyTorch, Pandas, Scikit-Learn, etc…↩︎\ntambém mencionado na Aula 4 - Markov Chain Montecarlo – MCMC.↩︎\n",
      "last_modified": "2021-03-14T09:30:29-03:00"
    },
    {
      "path": "1-Comandos_Basicos.html",
      "title": "Comandos Básicos de R",
      "description": "Introdução ao R e aos comandos básicos do R",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 2, 2021",
      "contents": "\n\nContents\nLendo Arquivos de Dados\nCSV\nExcel\n\nGráficos\nAmbiente\n\n\nEste arquivo é um documento R Markdown. Ele é uma proposta de prosa com código em R, além de ser o formato preferido nosso de comunicar nossas análises. Quando renderizamos o documento no formato desejado. Todo código que é inserido nele é executado e as saídas são incorporadas no documento final. Isto vale para tabelas e gráficos. Por exemplo, podemos pedir para o R imprimir algo com a função print() e o resultado será o código que foi executado e o seu resultado.\n\n\nprint(\"Você executou um código\")\n\n\n[1] \"Você executou um código\"\n\nO formato R Markdown é muito flexível. Podemos fazer relatórios (em PDF, Word e HTML), apresentações (em PDF, PowerPoint e HTML), artigos acadêmicos, livros, websites1, blogs, CVs, etc.\n\nO site do autor foi feito usando a biblioteca {postcards}(Kross, 2021) de R. O CV também foi feito em R usando a biblioteca {vitae} (O’Hara-Wild & Hyndman, 2021).\nLendo Arquivos de Dados\nCom o R conseguimos ler diversos tipo de arquivos de dados: CSV, texto, HTML, Excel, Stata, SPSS, Planilhas Google, Banco de Dados Relacionais, entre outros… Vamos demonstrar como ler arquivos de dados dos dois formatos mais comuns: CSV e Excel.\nCSV\nPara ler um arquivo CSV (.csv) no R execute a função read.csv() para arquivos CSV formato americano (vírgula como separador e decimais como ponto) ou a função read.csv2() para arquivos CSV formato europeu/brasileiro (ponto-e-vírgula como separador e decimais como vírgula). Não esqueça de designar a leitura para uma variável com o designador <-.\n\n\ndf <- read.csv2(\"datasets/mtcars.csv\", row.names = 1)\nhead(df)\n\n\n                  mpg cyl disp  hp drat  wt qsec vs am gear carb\nMazda RX4          21   6  160 110  3.9 2.6   16  0  1    4    4\nMazda RX4 Wag      21   6  160 110  3.9 2.9   17  0  1    4    4\nDatsun 710         23   4  108  93  3.9 2.3   19  1  1    4    1\nHornet 4 Drive     21   6  258 110  3.1 3.2   19  1  0    3    1\nHornet Sportabout  19   8  360 175  3.1 3.4   17  0  0    3    2\nValiant            18   6  225 105  2.8 3.5   20  1  0    3    1\n\nExcel\nPara ler um arquivo Excel (.xls ou .xlsx) no R é necessário importar um pacote chamado readxl que contem a função read_excel. Para importar um pacote no R executamos o comando library() com um argumento único sendo o nome do pacote. Caso não tenha o pacote instalado, deve instalar ele com o comando install.packages(). Não esqueça de colocar o nome do pacote entre aspas \"nome_do_pacote\" dentro do parênteses da função.\n\n\n# install.packages(\"readxl\")\nlibrary(readxl)\ndf <- read_excel(\"datasets/mtcars.xlsx\")\nhead(df)\n\n\n# A tibble: 6 x 12\n  ...1       mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear\n  <chr>    <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1 Mazda R…  21       6   160   110  3.9   2.62  16.5     0     1     4\n2 Mazda R…  21       6   160   110  3.9   2.88  17.0     0     1     4\n3 Datsun …  22.8     4   108    93  3.85  2.32  18.6     1     1     4\n4 Hornet …  21.4     6   258   110  3.08  3.22  19.4     1     0     3\n5 Hornet …  18.7     8   360   175  3.15  3.44  17.0     0     0     3\n6 Valiant   18.1     6   225   105  2.76  3.46  20.2     1     0     3\n# … with 1 more variable: carb <dbl>\n\nGráficos\nGeralmente no R você pode plotar mostrar graficamente diversos objetos com o comando plot(). Quando você plota um dataset (conjunto de dados lido de um aquivo), o R retorna um gráfico chamado Pair Plot:\nNa diagonal: nome da variável (coluna do dataset)\nFora da diagonal: um gráfico de dispersão entre a variável no eixo horizontal e a variável no eixo vertical\nExemplo: na figura 1 veja a relação entre disp (cilindrada) e hp (cavalos de potência). Ela é uma relação positiva. Quanto maior disp maior hp.\n\n\nplot(mtcars)\n\n\n\n\nFigure 1: Pair Plot do dataset mtcars\n\n\n\nAmbiente\nEm todos os arquivos dessa disciplina, mostrarei o ambiente computacional usado para replicação.\n\n\nsessionInfo()\n\n\nR version 4.0.4 (2021-02-15)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] readxl_1.3.1    tibble_3.1.0    ggplot2_3.3.3   patchwork_1.1.1\n[5] cowplot_1.1.1  \n\nloaded via a namespace (and not attached):\n [1] tidyselect_1.1.0  xfun_0.21         bslib_0.2.4      \n [4] purrr_0.3.4       colorspace_2.0-0  vctrs_0.3.6      \n [7] generics_0.1.0    htmltools_0.5.1.1 yaml_2.2.1       \n[10] utf8_1.1.4        rlang_0.4.10      jquerylib_0.1.3  \n[13] pillar_1.5.0      glue_1.4.2        withr_2.4.1      \n[16] DBI_1.1.1         jpeg_0.1-8.1      lifecycle_1.0.0  \n[19] stringr_1.4.0     cellranger_1.1.0  munsell_0.5.0    \n[22] gtable_0.3.0      ragg_1.1.1        evaluate_0.14    \n[25] labeling_0.4.2    knitr_1.31        parallel_4.0.4   \n[28] fansi_0.4.2       highr_0.8         Rcpp_1.0.6       \n[31] scales_1.1.1      jsonlite_1.7.2    farver_2.1.0     \n[34] systemfonts_1.0.1 textshaping_0.3.1 distill_1.2      \n[37] digest_0.6.27     stringi_1.5.3     bookdown_0.21    \n[40] dplyr_1.0.4       grid_4.0.4        rprojroot_2.0.2  \n[43] cli_2.3.1         tools_4.0.4       magrittr_2.0.1   \n[46] sass_0.3.1        crayon_1.4.1      pkgconfig_2.0.3  \n[49] downlit_0.2.1     ellipsis_0.3.1    xml2_1.3.2       \n[52] lubridate_1.7.10  assertthat_0.2.1  rmarkdown_2.7    \n[55] rstudioapi_0.13   R6_2.5.0          compiler_4.0.4   \n\n\n\n\nKross, S. (2021). Postcards: Create beautiful, simple personal websites. Retrieved from https://CRAN.R-project.org/package=postcards\n\n\nO’Hara-Wild, M., & Hyndman, R. (2021). Vitae: Curriculum vitae for r markdown. Retrieved from https://CRAN.R-project.org/package=vitae\n\n\nesse website foi todo feito com R↩︎\n",
      "last_modified": "2021-03-12T08:08:23-03:00"
    },
    {
      "path": "2-Distribuicoes_Estatisticas.html",
      "title": "Distribuições Estatísticas",
      "description": "Distribuições Estatísticas",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 2, 2021",
      "contents": "\n\nContents\nDiscretas\nUniforme Discreta\nBinomial\nPoisson\n\nContínuas\nNormal / Gaussiana\nLog-normal\nExponencial\nDistribuição t de Student\n\nDashboard de Distribuições\nAmbiente\n\n\nA estatística usa distribuições probabilísticas como o motor de sua inferência na elaboração dos valores dos parâmetros estimados e suas incertezas.\nUma distribuição de probabilidade é a função matemática que fornece as probabilidades de ocorrência de diferentes resultados possíveis para um experimento. É uma descrição matemática de um fenômeno aleatório em termos de seu espaço amostral e as probabilidades de eventos (subconjuntos do espaço amostral)\nGeralmente usamos a notação X ~ Dist(par1, par2, ...). Onde X é a variável Dist é a distribuição e par os parâmetros que definem como a distribuição se comporta.\nDiscretas\nDistribuições de probabilidade discretas são aquelas que os resultados são números discretos (também chamados de números inteiros): \\(\\dots, -2, 1, 0,1,2,\\dots, N\\) e \\(N \\in \\mathbb{Z}\\).\nUniforme Discreta\nA distribuição uniforme discreta é uma distribuição de probabilidade simétrica em que um número finito de valores são igualmente prováveis de serem observados. Cada um dos \\(n\\) valores tem probabilidade igual \\(\\frac{1}{n}\\). Outra maneira de dizer “distribuição uniforme discreta” seria “um número conhecido e finito de resultados igualmente prováveis de acontecer.”\nA distribuição uniforme discreta possui dois parâmetros e sua notação é \\(U(a, b)\\):\nLimite Inferior (\\(a\\))\nLimite Superior (\\(b\\))\nExemplo: Um dado.\n\n\nx <- seq(1, 6)\ny <- dunif(x, min = 1, max = 6)\n\nplot(x, y, xlab=\"valor de x\",\n  ylab=\"Densidade\",\n  main=\"Distribuição Uniforme Discreta\",\n  lwd=2, col=\"red\"\n)\n\n\n\n\nBinomial\nA distribuição binomial descreve um evento do número de sucessos em uma sequência de \\(n\\) experimentos independentes, cada um fazendo uma pergunta sim-não.\nA distribuição binomial é freqüentemente usada para modelar o número de sucessos em uma amostra de tamanho \\(n\\) desenhada com substituição de uma população de tamanho \\(N\\).\nA distribuição binomial possui dois parâmetros e sua notação é \\(Bin(n, p)\\):\nNúmero de Experimentos (\\(n\\))\nProbabiliade de Sucessos (\\(p\\))\nExemplo: quantidade de caras em 5 lançamentos de uma moeda.\n\n\nx <- seq(0, 5)\n\nprobs <- c(0.1, 0.2, 0.5)\ncolors <- c(\"red\", \"blue\", \"darkgreen\")\nlabels <- c(\"p=0.1\", \"p=0.2\", \"p=0.5\")\n\nplot(NA, xlab=\"valor de x\",\n  ylab=\"Densidade\",\n  main=\"Comparativo de Distribuições Binomiais\",\n  xlim = c(0, 5),\n  ylim = c(0, 1))\n\nfor (i in 1:4){\n  lines(x, dbinom(x, 5, prob = probs[i]), lwd=2, col=colors[i])\n}\n\nlegend(\"topright\", inset=.05, title=\"Desvio Padrões\",\n  labels, lwd=2, lty=c(1, 1, 1, 1, 2), col=colors)\n\n\n\n\nPoisson\nA distribuição Poisson expressa a probabilidade de um determinado número de eventos ocorrerem em um intervalo fixo de tempo ou espaço se esses eventos ocorrerem com uma taxa média constante conhecida e independentemente do tempo desde o último evento. A distribuição de Poisson também pode ser usada para o número de eventos em outros intervalos especificados, como distância, área ou volume.\nA distribuição Poisson possui um parâmetro e sua notação é \\(pois(\\lambda)\\):\nTaxa (\\(\\lambda\\))\nExemplo: Quantidade de e-mails que você recebe diariamente. Quantidade de buracos que você encontra na rua.\n\n\nx <- seq(0, 20)\n\nrates <- c(1, 4, 10)\ncolors <- c(\"red\", \"blue\", \"darkgreen\")\nlabels <- c(\"taxa=1\", \"taxa=4\", \"taxa=10\")\n\nplot(NA, xlab=\"valor de x\",\n  ylab=\"Densidade\",\n  main=\"Comparativo de Distribuições Poisson\",\n  xlim = c(0, 20),\n  ylim = c(0, 0.5))\n\nfor (i in 1:4){\n  lines(x, dpois(x, lambda = rates[i]), lwd=2, col=colors[i])\n}\n\nlegend(\"topright\", inset=.05, title=\"Taxas\",\n  labels, lwd=2, lty=c(1, 1, 1, 1, 2), col=colors)\n\n\n\n\nContínuas\nDistribuições de probabilidade contínuas são aquelas que os resultados são valores em uma faixa contínua (também chamados de número reais): \\([-\\infty, \\infty] \\in \\mathbb{R}\\).\nNormal / Gaussiana\nEssa distribuição geralmente é usada nas ciências sociais e naturais para representar variáveis contínuas na qual as suas distribuições não são conhecidas. Esse pressuposto é por conta do teorema do limite central. O teorema do limite central afirma que, em algumas condições, a média de muitas amostras (observações) de uma variável aleatória com média e variância finitas é ela própria uma variável aleatória cuja distribuição converge para uma distribuição normal à medida que o número de amostras aumenta. Portanto, as quantidades físicas que se espera sejam a soma de muitos processos independentes (como erros de medição) muitas vezes têm distribuições que são quase normais.\nA distribuição normal possui dois parâmetros e sua notação é \\(N(\\mu, \\sigma^2)\\):\nMédia (\\(\\mu\\)): média da distribuição e também a moda e a mediana\nDesvio Padrão (\\(\\sigma\\)): a variância da distribuição (\\(\\sigma^2\\)) é uma média de dispersão das observações em relação à média\nExemplo: Altura, Peso etc.\n\n\nx <- seq(-4, 4, length = 100)\n\ndps <- c(0.5, 1, 2, 5)\ncolors <- c(\"red\", \"blue\", \"darkgreen\", \"gold\")\nlabels <- c(\"dp=0.5\", \"dp=1\", \"dp=2\", \"dp=5\")\n\nplot(NA, xlab=\"valor de x\",\n  ylab=\"Densidade\",\n  main=\"Comparativo de Distribuições Normais\",\n  xlim = c(-4, 4),\n  ylim = c(0, 1))\n\nfor (i in 1:4){\n  lines(x, dnorm(x, mean = 0, sd = dps[i]), lwd=2, col=colors[i])\n}\n\nlegend(\"topright\", inset=.05, title=\"Desvio Padrões\",\n  labels, lwd=2, lty=c(1, 1, 1, 1, 2), col=colors)\n\n\n\n\nLog-normal\nA distribuição Log-normal é uma distribuição de probabilidade contínua de uma variável aleatória cujo logaritmo é normalmente distribuído. Assim, se a variável aleatória \\(X\\) for distribuída normalmente por log, então \\(Y = \\ln (X)\\) terá uma distribuição normal.\nUma variável aleatória com distribuição logarítmica aceita apenas valores reais positivos. É um modelo conveniente e útil para medições em ciências exatas e de engenharia, bem como medicina, economia e outros campos, por ex. para energias, concentrações, comprimentos, retornos financeiros e outros valores.\nUm processo log-normal é a realização estatística do produto multiplicativo de muitas variáveis aleatórias independentes, cada uma das quais positiva.\nA distribuição log-normal possui dois parâmetros e sua notação é \\(Lognormal(\\mu, \\sigma^2)\\):\nMédia (\\(\\mu\\)): média do logaritmo natural da distribuição\nDesvio Padrão (\\(\\sigma\\)): a variância do logaritmo natural da distribuição (\\(\\sigma^2\\)) é uma média de dispersão das observações em relação à média\n\n\nx <- seq(0, 3, length = 100)\n\ndps <- c(0.25, 0.5, 1, 1.5)\ncolors <- c(\"red\", \"blue\", \"darkgreen\", \"gold\")\nlabels <- c(\"dp=0.25\", \"dp=0.5\", \"dp=1\", \"dp=1.5\")\n\nplot(NA, xlab=\"valor de x\",\n  ylab=\"Densidade\",\n  main=\"Comparativo de Distribuições Log-Normais\",\n  xlim = c(0, 3),\n  ylim = c(0, 2))\n\nfor (i in 1:4){\n  lines(x, dlnorm(x, mean = 0, sd = dps[i]), lwd=2, col=colors[i])\n}\n\nlegend(\"topright\", inset=.05, title=\"Desvio Padrões\",\n  labels, lwd=2, lty=c(1, 1, 1, 1, 2), col=colors)\n\n\n\n\nExponencial\nA distribuição exponencial é a distribuição de probabilidade do tempo entre eventos que ocorrem de forma contínua e independente a uma taxa média constante.\nA distribuição exponencial possui um parâmetro e sua notação é \\(Exp (\\lambda)\\):\nTaxa (\\(\\lambda\\))\nExemplo: Quanto tempo até o próximo terremoto. Quanto tempo até o próximo ônibus.\n\n\nx <- seq(0, 5, length = 100)\n\nrates <- c(0.5, 1, 1.5, 2)\ncolors <- c(\"red\", \"blue\", \"darkgreen\", \"gold\")\nlabels <- c(\"taxa=0.5\", \"taxa=1.0\", \"taxa=1.5\", \"taxa=2.0\")\n\nplot(NA, xlab=\"valor de x\",\n  ylab=\"Densidade\",\n  main=\"Comparativo de Distribuições Exponenciais\",\n  xlim = c(0, 5),\n  ylim = c(0, 1.5))\n\nfor (i in 1:4){\n  lines(x, dexp(x,rate = rates[i]), lwd=2, col=colors[i])\n}\n\nlegend(\"topright\", inset=.05, title=\"Taxas\",\n  labels, lwd=2, lty=c(1, 1, 1, 1, 2), col=colors)\n\n\n\n\nDistribuição t de Student\nA distribuição t de Student surge ao estimar a média de uma população normalmente distribuída em situações onde o tamanho da amostra é pequeno e o desvio padrão da população é desconhecido.\nSe tomarmos uma amostra de \\(n\\) observações de uma distribuição normal, então a distribuição t com \\(\\nu = n-1\\) graus de liberdade pode ser definida como a distribuição da localização da média da amostra em relação à média verdadeira, dividida pela desvio padrão da amostra, após multiplicar pelo termo padronizador \\(\\sqrt{n}\\).\nA distribuição t é simétrica e em forma de sino, como a distribuição normal, mas tem caudas mais pesadas, o que significa que é mais propensa a produzir valores que estão longe de sua média.\nA distribuição t de Student possui um parâmetro e sua notação é \\(Student (\\nu)\\):\nGraus de Liberdade (\\(\\nu\\)): controla o quanto ela se assemelha com uma distribuição normal\nExemplo: Uma base de dados cheia de outliers.\n\n\nx <- seq(-4, 4, length = 100)\n\ndegfs <- c(1, 3, 8, 30)\ncolors <- c(\"red\", \"blue\", \"darkgreen\", \"gold\")\nlabels <- c(\"df=1\", \"df=3\", \"df=8\", \"df=30\")\n\nplot(NA, xlab=\"valor de x\",\n  ylab=\"Densidade\",\n  main=\"Comparativo de Distribuições t de Student\",\n  xlim = c(-4, 4),\n  ylim = c(0, 0.5))\n\nfor (i in 1:4){\n  lines(x, dt(x,df = degfs[i]), lwd=2, col=colors[i])\n}\n\nlegend(\"topright\", inset=.05, title=\"Graus de Liberdade\",\n  labels, lwd=2, lty=c(1, 1, 1, 1, 2), col=colors)\n\n\n\n\nDashboard de Distribuições\nPara acessar todo o zoológico de distribuições use essa ferramenta do Ben Lambert (estatístico do Imperial College of London): https://ben18785.shinyapps.io/distribution-zoo/\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.4 (2021-02-15)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] readxl_1.3.1    tibble_3.1.0    ggplot2_3.3.3   patchwork_1.1.1\n[5] cowplot_1.1.1  \n\nloaded via a namespace (and not attached):\n [1] tidyselect_1.1.0  xfun_0.21         bslib_0.2.4      \n [4] purrr_0.3.4       colorspace_2.0-0  vctrs_0.3.6      \n [7] generics_0.1.0    htmltools_0.5.1.1 yaml_2.2.1       \n[10] utf8_1.1.4        rlang_0.4.10      jquerylib_0.1.3  \n[13] pillar_1.5.0      glue_1.4.2        withr_2.4.1      \n[16] DBI_1.1.1         jpeg_0.1-8.1      lifecycle_1.0.0  \n[19] stringr_1.4.0     cellranger_1.1.0  munsell_0.5.0    \n[22] gtable_0.3.0      ragg_1.1.1        evaluate_0.14    \n[25] labeling_0.4.2    knitr_1.31        parallel_4.0.4   \n[28] fansi_0.4.2       highr_0.8         Rcpp_1.0.6       \n[31] scales_1.1.1      jsonlite_1.7.2    farver_2.1.0     \n[34] systemfonts_1.0.1 textshaping_0.3.1 distill_1.2      \n[37] digest_0.6.27     stringi_1.5.3     bookdown_0.21    \n[40] dplyr_1.0.4       grid_4.0.4        rprojroot_2.0.2  \n[43] cli_2.3.1         tools_4.0.4       magrittr_2.0.1   \n[46] sass_0.3.1        crayon_1.4.1      pkgconfig_2.0.3  \n[49] downlit_0.2.1     ellipsis_0.3.1    xml2_1.3.2       \n[52] lubridate_1.7.10  assertthat_0.2.1  rmarkdown_2.7    \n[55] rstudioapi_0.13   R6_2.5.0          compiler_4.0.4   \n\n\n\n\n",
      "last_modified": "2021-03-12T08:08:23-03:00"
    },
    {
      "path": "3-Priors.html",
      "title": "Priors",
      "description": "As famosas e controversas Priors",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 2, 2021",
      "contents": "\n\nContents\nTipos de Priors\nPriors para os Modelos\nUniforme (Flat Prior)\nInformativas\nPadrões do rstanarm\nExemplo usando o mtcars\n\nPor quê não é interessante usar priors uniformes (flat priors)\nAtividade\n\nAmbiente\n\n\nA Estatística Bayesiana é caracterizada pelo uso de informação prévia embutida como probabilidade prévia \\(P(H)\\)\n\\[P(H | D)=\\frac{P(H) \\cdot P(D | H)}{P(D)}\\]\nTipos de Priors\nDe maneira geral, podemos ter 3 tipos de priors em uma abordagem Bayesiana:\nuniforme (Flat Prior): não recomendada\nfracamente informativa (weakly informative): pequena restrição com um pouco de senso comum e baixo conhecimento de domínio incorporado\ninformativa (informative): conhecimento de domínio incorporado\nPara se aprofundar mais recomendo a vignette do rstanarm sobre priors\nPriors para os Modelos\nArgumento\nUsado em\nAplica-se à\nprior_intercept\nTodas funções de modelagem exceto stan_polr and stan_nlmer\nConstante (intercept) do modelo, após centralização dos preditores\nprior\nTodas funções de modelagem\nCoeficientes de Regressão, não inclui coeficientes que variam por grupo em modelos multiníveis (veja prior_covariance)\nprior_aux\nstan_glm, stan_glmer, stan_gamm4, stan_nlmer\nParâmetro auxiliar (ex: desvio padrão (standard error - DP), interpretação depende do modelo\nprior_covariance\nstan_glmer, stan_gamm4, stan_nlmer\nMatrizes de covariância em modelos multiníveis\nUniforme (Flat Prior)\nEspecifica-se colocando o valor NULL (nulo em R) no. Exemplo:\nprior_intercept = NULL\nprior = NULL\nprior_aux = NULL\nColocando na função de modelo ficaria stan_glm(y ~ x1 + x2, data = df, prior = NULL, prior_intercept = NULL, prior_aux = NULL)\nInformativas\nColoca-se qualquer distribuição nos argumentos. Exemplo:\nprior = normal(0, 5)\nprior_intercept = student_t(4, 0, 10)\nprior_aux = cauchy(0, 3)\nColocando na função de modelo ficaria stan_glm(y ~ x1 + x2, data = df, prior = normal(0, 5), prior_intercept = student_t(4, 0, 10), prior_aux = cauchy(0, 3))\nPadrões do rstanarm\nAcontece se você não especifica nada nos argumentos de priors. O comportamento difere conforme o modelo. Aqui divido em modelos gaussianos (segue uma likelihood gaussiana ou normal) e outros (binomial, poisson etc)\nModelos Gaussianos\nConstante(Intercept): centralizada com média \\(\\mu_y\\) e desvio padrão de \\(2.5 \\sigma_y\\) - prior_intercept = normal(mean_y, 2.5 * sd_y)\nCoeficientes: para cada coeficiente média \\(\\mu = 0\\) e desvio padrão de \\(2.5\\times\\frac{\\sigma_y}{\\sigma_{x_k}}\\) - prior = normal(0, 2.5 * sd_y/sd_xk)\nOutros Modelos (Binomial, Poisson etc.)\nConstante(Intercept): centralizada com média \\(\\mu = 0\\) e desvio padrão de \\(2.5 \\sigma_y\\) - prior_intercept = normal(0, 2.5 * sd_y)\nCoeficientes: para cada coeficiente média \\(\\mu = 0\\) e desvio padrão de \\(2.5\\times\\frac{1}{\\sigma_{x_k}}\\) - prior = normal(0, 2.5 * 1/sd_xk)\n\nOBS: em todos os modelos prior_aux, o desvio padrão do erro do modelo, a prior padrão é uma distribuição exponencial com taxa \\(\\frac{1}{\\sigma_y}\\): prior_aux = exponential(1/sd_y)\n\nExemplo usando o mtcars\nVamos estimar modelos Bayesianos usando o dataset já conhecido mtcars. Para constar, calcularemos alguns valores antes de ver o sumário das priors:\n\\(\\mu_y\\): média do mpg - 20.09\n\\(2.5 \\sigma_y\\): 2.5 * sd(mtcars$mpg) - 15.07\n\\(2.5\\times\\frac{\\sigma_y}{\\sigma_{x_{\\text{wt}}}}\\): 2.5 * (sd(mtcars$mpg)/sd(mtcars$wt)) - 15.4\n\\(2.5\\times\\frac{\\sigma_y}{\\sigma_{x_{\\text{am}}}}\\): 2.5 * (sd(mtcars$mpg)/sd(mtcars$am)) - 30.2\n\\(\\frac{1}{\\sigma_y}\\): 1/sd(mtcars$mpg) - 0.17\nA função prior_summary resulta um sumário conciso das priors utilizadas em um modelo. Coloque como argumento o modelo estimado:\n\n\nlibrary(rstanarm)\ndefault_prior_test <- stan_glm(mpg ~ wt + am, data = mtcars, chains = 1)\n\n\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 6.3e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.63 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.045595 seconds (Warm-up)\nChain 1:                0.041012 seconds (Sampling)\nChain 1:                0.086607 seconds (Total)\nChain 1: \n\nprior_summary(default_prior_test)\n\n\nPriors for model 'default_prior_test' \n------\nIntercept (after predictors centered)\n  Specified prior:\n    ~ normal(location = 20, scale = 2.5)\n  Adjusted prior:\n    ~ normal(location = 20, scale = 15)\n\nCoefficients\n  Specified prior:\n    ~ normal(location = [0,0], scale = [2.5,2.5])\n  Adjusted prior:\n    ~ normal(location = [0,0], scale = [15.40,30.20])\n\nAuxiliary (sigma)\n  Specified prior:\n    ~ exponential(rate = 1)\n  Adjusted prior:\n    ~ exponential(rate = 0.17)\n------\nSee help('prior_summary.stanreg') for more details\n\nAgora com priors especificadas:\nComo há dois coeficientes eu especifico médias iguais (\\(0\\)), porém desvios padrões diferentes (\\(5\\) para wt e \\(6\\) para am) usando a função de combinar do R (combine) - c()\n\n\ncustom_prior_test <- stan_glm(mpg ~ wt + am, data = mtcars, chains = 1,\n         prior = normal(c(0, 0), c(5, 6)),\n         prior_intercept = student_t(4, 0, 10),\n         prior_aux = cauchy(0, 3))\n\n\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 2.3e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.23 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.038477 seconds (Warm-up)\nChain 1:                0.038706 seconds (Sampling)\nChain 1:                0.077183 seconds (Total)\nChain 1: \n\nprior_summary(custom_prior_test)\n\n\nPriors for model 'custom_prior_test' \n------\nIntercept (after predictors centered)\n ~ student_t(df = 4, location = 0, scale = 10)\n\nCoefficients\n ~ normal(location = [0,0], scale = [5,6])\n\nAuxiliary (sigma)\n ~ half-cauchy(location = 0, scale = 3)\n------\nSee help('prior_summary.stanreg') for more details\n\nPor quê não é interessante usar priors uniformes (flat priors)\nUma prior totalmente uniforme ou chapada (flat) é algo que devemos evitar pelo simples motivo que ela parte da premissa de que “tudo é possível.” Não há limites na crença de que tamanho o valor deve ser.\nPriors chapadas e super-vagas geralmente não são recomendadas e algum esforço deve ser incluído para ter, pelo menos, priors um pouco informativa. Por exemplo, é comum esperar que os tamanhos de efeito realistas sejam da ordem de magnitude \\(0.1\\) em uma escala padronizada (por exemplo, uma inovação educacional que pode melhorar as pontuações dos testes em \\(0.1\\) desvios padrão). Nesse caso, um prior de \\(N \\sim (0,1)\\) poderia ser considerado muito informativo, de uma maneira ruim, pois coloca a maior parte de sua massa em valores de parâmetro que são irrealisticamente grandes em valor absoluto. O ponto geral aqui é que se considerarmos uma prior como “fraca” ou “forte,” isso é uma propriedade não apenas da prior, mas também da pergunta que está sendo feita.\nQuando dizemos que a prior é “pouco informativa,” o que queremos dizer é que, se houver uma quantidade razoavelmente grande de dados, a likelihood dominará e a prior não será importante. Se os dados forem fracos, porém, esta “prior fracamente informativo” influenciará fortemente a inferência posterior.\nNão se esqueça que distribuição normal tem suporte \\(\\mathbb{R}\\), ou seja pode acontecer qualquer número entre \\(-\\infty\\) até \\(\\infty\\) independente da média \\(\\mu\\) ou desvio padrão \\(\\sigma\\).\nAtividade\nRegressão linear pensando nas priors. Usar o dataset do pacote carData chamado Salaries\n\n\nlibrary(carData)\ndata(\"Salaries\")\n?Salaries\n\n\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.4 (2021-02-15)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] carData_3.0-4   rstanarm_2.21.1 Rcpp_1.0.6      readxl_1.3.1   \n[5] tibble_3.1.0    ggplot2_3.3.3   patchwork_1.1.1 cowplot_1.1.1  \n\nloaded via a namespace (and not attached):\n  [1] minqa_1.2.4          colorspace_2.0-0     ellipsis_0.3.1      \n  [4] ggridges_0.5.3       rsconnect_0.8.16     rprojroot_2.0.2     \n  [7] markdown_1.1         base64enc_0.1-3      rstudioapi_0.13     \n [10] farver_2.1.0         rstan_2.21.2         DT_0.17             \n [13] fansi_0.4.2          lubridate_1.7.10     xml2_1.3.2          \n [16] codetools_0.2-18     splines_4.0.4        downlit_0.2.1       \n [19] knitr_1.31           shinythemes_1.2.0    bayesplot_1.8.0     \n [22] jsonlite_1.7.2       nloptr_1.2.2.2       shiny_1.6.0         \n [25] compiler_4.0.4       assertthat_0.2.1     Matrix_1.3-2        \n [28] fastmap_1.1.0        cli_2.3.1            later_1.1.0.1       \n [31] htmltools_0.5.1.1    prettyunits_1.1.1    tools_4.0.4         \n [34] igraph_1.2.6         gtable_0.3.0         glue_1.4.2          \n [37] reshape2_1.4.4       dplyr_1.0.4          V8_3.4.0            \n [40] cellranger_1.1.0     jquerylib_0.1.3      vctrs_0.3.6         \n [43] nlme_3.1-152         crosstalk_1.1.1      xfun_0.21           \n [46] stringr_1.4.0        ps_1.6.0             lme4_1.1-26         \n [49] mime_0.10            miniUI_0.1.1.1       lifecycle_1.0.0     \n [52] gtools_3.8.2         statmod_1.4.35       MASS_7.3-53.1       \n [55] zoo_1.8-8            scales_1.1.1         colourpicker_1.1.0  \n [58] ragg_1.1.1           promises_1.2.0.1     parallel_4.0.4      \n [61] inline_0.3.17        shinystan_2.5.0      yaml_2.2.1          \n [64] curl_4.3             gridExtra_2.3        loo_2.4.1           \n [67] StanHeaders_2.21.0-7 sass_0.3.1           distill_1.2         \n [70] stringi_1.5.3        highr_0.8            dygraphs_1.1.1.6    \n [73] boot_1.3-27          pkgbuild_1.2.0       rlang_0.4.10        \n [76] pkgconfig_2.0.3      systemfonts_1.0.1    matrixStats_0.58.0  \n [79] evaluate_0.14        lattice_0.20-41      purrr_0.3.4         \n [82] rstantools_2.1.1     htmlwidgets_1.5.3    labeling_0.4.2      \n [85] tidyselect_1.1.0     processx_3.4.5       plyr_1.8.6          \n [88] magrittr_2.0.1       bookdown_0.21        R6_2.5.0            \n [91] generics_0.1.0       DBI_1.1.1            pillar_1.5.0        \n [94] withr_2.4.1          xts_0.12.1           survival_3.2-7      \n [97] crayon_1.4.1         utf8_1.1.4           rmarkdown_2.7       \n[100] jpeg_0.1-8.1         grid_4.0.4           callr_3.5.1         \n[103] threejs_0.3.3        digest_0.6.27        xtable_1.8-4        \n[106] httpuv_1.5.5         textshaping_0.3.1    RcppParallel_5.0.3  \n[109] stats4_4.0.4         munsell_0.5.0        bslib_0.2.4         \n[112] shinyjs_2.0.0       \n\n\n\n\n",
      "last_modified": "2021-03-12T08:08:23-03:00"
    },
    {
      "path": "4-MCMC.html",
      "title": "Markov Chain Monte Carlo -- MCMC",
      "description": "O motor por trás da Estatística Bayesiana",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 2, 2021",
      "contents": "\n\nContents\nPara quê serve o denominador \\(P(\\text{data})\\)?\nSe removermos o denominador de Bayes o que temos?\nSimulação Montecarlo com correntes Markov – (MCMC)\nMétodo Monte Carlo\nSimulações – Setup\nMetropolis e Metropolis-Hastings\nGibbs\nO que acontece quando rodamos correntes Markov em paralelo?\n\nHamiltonian Monte Carlo – HMC\nDistribuição dos Momentos – \\(P(\\phi)\\)\nAlgoritmo de HMC\nHMC – Implementação\n\n“Não entendi nada…”\nImplementação com o rstanarm\nMétricas da simulação MCMC\nO que fazer se não obtermos convergência?\n\nGráficos de Diagnósticos do MCMC\nTraceplot\nPosterior Predictive Check\n\nO quê fazer para convergir suas correntes Markov\nAmbiente\n\n\nA principal barreira computacional para estatística Bayesiana é o denominador \\(P(\\text{data})\\) da fórmula de Bayes:\n\\[P(\\theta | \\text{data})=\\frac{P(\\theta) \\cdot P(\\text{data} | \\theta)}{P(\\text{data})}\\]\nEm casos discretos podemos fazer o denominador virar a soma de todos os parâmetros usando a regra da cadeia de probabilidade:\n\\[P(A,B|C)=P(A|B,C) \\times P(B|C)\\]\nIsto também é chamado de marginalização:\n\\[P(\\text{data})=\\sum_{\\theta} P(\\text{data} | \\theta) \\times P(\\theta)\\]\nPorém no caso de valores contínuos o denominador \\(P(\\text{data})\\) vira uma integral bem grande e complicada de calcular:\n\\[P(\\text{data})=\\int_{\\theta} P(\\text{data} | \\theta) \\times P(\\theta)d \\theta\\]\nEm muitos casos essa integral vira intratável (incalculável) e portanto devemos achar outras maneiras de calcular a probabilidade posterior \\(P(\\theta | \\text{data})\\) de Bayes sem usar o denominador \\(P(\\text{data})\\).\nPara quê serve o denominador \\(P(\\text{data})\\)?\nPara normalizar a posterior com o intuito de torná-la uma distribuição probabilística válida. Isto quer dizer que a soma de todas as probabilidades dos eventos possíveis da distribuição probabilística devem ser iguais a 1:\nno caso de distribuição probabilística discreta: \\(\\sum_{\\theta} P(\\theta | \\text{data}) = 1\\)\nno caso de distribuição probabilística contínua: \\(\\int_{\\theta} P(\\theta | \\text{data})d \\theta = 1\\)\nSe removermos o denominador de Bayes o que temos?\nAo removermos o denominador \\((\\text{data})\\) temos que a posterior \\(P(\\theta | \\text{data})\\) é proporcional à prior multiplicada pela verossimilhança \\(P(\\theta) \\cdot P(\\text{data} | \\theta)\\)1.\n\\[P(\\theta | \\text{data}) \\propto P(\\theta) \\cdot P(\\text{data} | \\theta)\\]\nEste vídeo do YouTube explica muito bem o problema do denominador.\n\n\nPlease use a browser that supports iframe embedding. If you are seeing this message Google “browser iframe embedding not rendering.”\n\n\nSimulação Montecarlo com correntes Markov – (MCMC)\nAí que entra simulação Montecarlo com correntes Markov (do inglês Markov Chain Monte Carlo – MCMC). MCMC é uma classe ampla de ferramentas computacionais para aproximação de integrais e geração de amostras de uma probabilidade posterior (S. Brooks, Gelman, Jones, & Meng, 2011). MCMC é usada quando não é possível coletar amostras de \\(\\theta\\) direto da distribuição probabilística posterior \\(P(\\theta | \\text{data})\\). Ao invés disso, nos coletamos amostras de maneira iterativa que a cada passo do processo nós esperamos que a distribuição da qual amostramos \\(P^*(\\theta^* | \\text{data})\\) (aqui \\(*\\) quer dizer simulado) se torna cada vez mais similar à posterior \\(P(\\theta | \\text{data})\\). Tudo isso é para eliminar o cálculo (muitas vezes impossível) do denominador \\(P(\\text{data})\\).\nA ideia é definir uma corrente Markov ergódica (quer dizer que há uma distribuição estacionária única) dos quais o conjunto de estados possíveis é o espaço amostral e a distribuição estacionária é a distribuição a ser aproximada (ou amostrada). Seja \\(X_0, X_1, \\dots, X_n\\) uma simulação da corrente. A corrente Markov converge à distribuição estacionária de qualquer estado inicial \\(X_0\\) após um número suficiente grande de iterações \\(r\\), a distribuição do estado \\(X_r\\) estará similar à distribuição estacionária, então podemos usá-la com amostra. As correntes Markov possuem uma propriedade que a distribuição de probabilidade do próximo estado depende apenas do estado atual e não na sequência de eventos que precederam: \\(P(X_{n+1}=x|X_{0},X_{1},X_{2},\\ldots ,X_{n}) = P(X_{n+1}=x|X_{n})\\). Essa propriedade é chamada de Markoviana, em homenagem ao matemático Andrei Andreyevich Markov (figura 1). Similarmente, repetindo esse argumento com \\(X_r\\) como o ponto inicial, podemos usar \\(X_{2r}\\) como amostra, e assim por diante. Podemos então usar a sequência de estados \\(X_r, X_{2r}, X_{3r}, \\dots\\) como quase amostras independentes da distribuição estacionária da corrente Markov.\n\n\n\nFigure 1: Andrei Andreyevich Markov. Figura de https://www.wikipedia.org\n\n\n\nA eficácia dessa abordagem depende em:\no quão grande \\(r\\) deve ser para garantir uma amostra adequadamente boa; e\npoder computacional requerido para cada iteração da corrente Markov.\nAlém disso, é costumeiro descartarmos as primeiras iterações do algoritmo pois elas costumam não ser representativas da distribuição a ser aproximada. Nas iterações iniciais de algoritmos MCMC geralmente a corrente Markov está em um processo de aquecimento2 (warm-up) e seu estado está bem distante do ideal para começarmos uma amostragem fidedigna. Geralmente, recomenda-se que se descarte metade das iterações (Gelman et al., 2013a). Por exemplo: se a corrente Markov possui 4.000 iterações, descartamos as 2.000 primeiras como warm-up.\nMétodo Monte Carlo\nStanislaw Ulam (figura 2), que participou do projeto Manhattan e ao tentar calcular o processo de difusão de neutrons para a bomba de hidrogênio acabou criando uma classe de métodos chamada Monte Carlo.\n\n\n\nFigure 2: Stanislaw Ulam. Figura de https://www.wikipedia.org\n\n\n\nMétodos de Monte Carlo possuem como conceito subjacente o uso a aleatoriedade para resolver problemas que podem ser determinísticos em princípio. Eles são freqüentemente usados em problemas físicos e matemáticos e são mais úteis quando é difícil ou impossível usar outras abordagens. Os métodos de Monte Carlo são usados principalmente em três classes de problemas: otimização, integração numérica e geração de sorteios a partir de uma distribuição de probabilidade.\nA ideia do método veio enquanto jogava paciência durante sua recuperação de uma cirurgia, Ulam pensou em jogar centenas de jogos para estimar estatisticamente a probabilidade de um resultado bem-sucedido. Conforme ele mesmo menciona em Eckhardt (1987):\n\nOs primeiros pensamentos e tentativas que fiz para praticar [o Método de Monte Carlo] foram sugeridos por uma pergunta que me ocorreu em 1946 quando eu estava convalescendo de uma doença e jogando paciência. A questão era quais são as chances de que um jogo de paciência com 52 cartas obtivesse sucesso? Depois de passar muito tempo tentando estimá-los por meio de cálculos combinatórios puros, me perguntei se um método mais prático do que o “pensamento abstrato” não seria expô-lo, digamos, cem vezes e simplesmente observar e contar o número de jogadas bem-sucedidas. Isso já era possível imaginar com o início da nova era de computadores rápidos, e eu imediatamente pensei em problemas de difusão de nêutrons e outras questões de física matemática e, de forma mais geral, como mudar os processos descritos por certas equações diferenciais em uma forma equivalente interpretável como uma sucessão de operações aleatórias. Mais tarde [em 1946], descrevi a ideia para John von Neumann e começamos a planejar cálculos reais.\n\nPor ser secreto, o trabalho de von Neumann e Ulam exigia um codinome. Um colega de von Neumann e Ulam, Nicholas Metropolis (figura 5), sugeriu usar o nome Monte Carlo, que se refere ao Casino Monte Carlo em Mônaco, onde o tio de Ulam (Michał Ulam) pedia dinheiro emprestado a parentes para jogar.\nAs aplicações do método de Monte Carlo são inúmeras: ciências físicas, engenharia, mudança climática, biologia computacional, computação gráfica, estatística aplicada, inteligência artificial, design e recursos visuais, busca e resgate, finanças e negócios e direito. No escopo desta aula focaremos em estatística aplicada e especificamente no contexto de inferência Bayesiana: fornecer uma amostra aleatória da distribuição posterior.\nSimulações – Setup\nEstou usando diversos pacotes:\nggplot2, plotly e ggforce para gráficos.\ngganimate para animações (GIFs).\nMASS para simulações aleatórias de distribuições multivariadas.\nrstan para funções de sumário e métricas de convergência e desempenho de simulações MCMC.\n\n\nlibrary(ggplot2)\ntheme_set(theme_minimal())\nlibrary(plotly)\nlibrary(gganimate)\nlibrary(ggforce)\nlibrary(MASS)\nlibrary(rstan)\n\n\n\nVamos começar com um problema didático de uma distribuição normal multivariada de \\(X\\) e \\(Y\\), onde\n\\[\n\\begin{bmatrix}\nX \\\\\nY\n\\end{bmatrix} \\sim \\text{Normal Multivariada} \\left(\n\\begin{bmatrix}\n\\mu_X \\\\\n\\mu_Y\n\\end{bmatrix}, \\mathbf{\\Sigma}\n\\right) \\\\\n\\mathbf{\\Sigma} \\sim\n\\begin{pmatrix}\n\\sigma^2_{X} & \\sigma_{X}\\sigma_{Y} \\rho \\\\\n\\sigma_{X}\\sigma_{Y} \\rho & \\sigma^2_{Y}\n\\end{pmatrix}\n\\]\nSe designarmos \\(\\mu_X = \\mu_Y = 0\\) e \\(\\sigma_X = \\sigma_Y = 1\\) (média 0 e desvio padrão 1 para ambos \\(X\\) e \\(Y\\)), temos a seguinte formulação:\n\\[\n\\begin{bmatrix}\nX \\\\\nY\n\\end{bmatrix} \\sim \\text{Normal Multivariada} \\left(\n\\begin{bmatrix}\n0 \\\\\n0\n\\end{bmatrix}, \\mathbf{\\Sigma}\n\\right), \\\\\n\\mathbf{\\Sigma} \\sim\n\\begin{pmatrix}\n1 & \\rho \\\\\n\\rho & 1\n\\end{pmatrix}.\n\\]\nSó faltando designar um valor de \\(\\rho\\) para a correlação entre \\(X\\) e \\(Y\\). Para o nosso exemplo vamos usar correlação de 0.8 (\\(\\rho = 0.8\\)):\n\\[\n\\mathbf{\\Sigma} \\sim\n\\begin{pmatrix}\n1 & 0.8 \\\\\n0.8 & 1\n\\end{pmatrix}.\n\\]\n\n\nmus  <- c(0, 0)\nsigmas <- c(1, 1)\nr <- 0.8\nSigma <- diag(sigmas)\nSigma[1, 2] <- r\nSigma[2, 1] <- r\ndft <- data.frame(mvrnorm(1e5, mus, Sigma))\n\n\n\nNa figura 3 é possível ver um gráfico de densidade de uma distribuição multivariada normal de duas variáveis normais \\(X\\) e \\(Y\\), ambas com média 0 e desvio padrão 1. Sendo que a correlação entre elas é 0.8. E na figura 4 é possível ver uma imagem 3-D interativa da mesma distribuição, fique a vontade em usar seu mouse (dedo ou caneta, dependendo do dispositivo) para movimentar a imagem.\n\n\nggplot(dft, aes(X1, X2)) +\n  geom_density2d_filled() +\n  coord_cartesian(xlim = c(-3, 3), ylim = c(-3, 3)) +\n  labs(title = \"Multivariada Normal\",\n       subtitle = expression(list(mu == 0, sigma == 1, rho == 0.8)),\n       caption = \"10.000 simulações\",\n       x = expression(X), y = expression(Y)) +\n  theme(legend.position = \"NULL\")\n\n\n\n\nFigure 3: Gráfico de Densidade de uma distribuição Multivariada Normal\n\n\n\n\n\ndens <- kde2d(dft$X1, dft$X2)\nplot_ly(x = dens$x,\n        y = dens$y,\n        z = dens$z) %>% add_surface()\n\n\n\n\n{\"x\":{\"visdat\":{\"1426f45c3d53dc\":[\"function () \",\"plotlyVisDat\"]},\"cur_data\":\"1426f45c3d53dc\",\"attrs\":{\"1426f45c3d53dc\":{\"x\":[-4.11222323909044,-3.76275945114626,-3.41329566320208,-3.0638318752579,-2.71436808731372,-2.36490429936954,-2.01544051142536,-1.66597672348118,-1.316512935537,-0.967049147592815,-0.617585359648634,-0.268121571704453,0.0813422162397277,0.430806004183909,0.780269792128089,1.12973358007227,1.47919736801645,1.82866115596063,2.17812494390481,2.52758873184899,2.87705251979317,3.22651630773736,3.57598009568154,3.92544388362572,4.2749076715699],\"y\":[-4.32381413035071,-3.95784855910568,-3.59188298786066,-3.22591741661563,-2.85995184537061,-2.49398627412558,-2.12802070288055,-1.76205513163553,-1.3960895603905,-1.03012398914547,-0.664158417900448,-0.298192846655422,0.0677727245896049,0.433738295834631,0.799703867079657,1.16566943832468,1.53163500956971,1.89760058081474,2.26356615205976,2.62953172330479,2.99549729454982,3.36146286579484,3.72742843703987,4.09339400828489,4.45935957952992],\"z\":[[3.40651108352134e-09,1.41934533126133e-08,8.54786240302624e-08,0.000130831863209747,1.94776526567504e-06,1.49783603255103e-06,1.1170089576991e-08,6.01986954373106e-12,1.16817732135535e-10,1.50245544102462e-14,4.62944974810078e-23,4.83295093316628e-35,2.28048400569722e-45,8.78734985512727e-51,2.21962779786052e-61,3.67504668072926e-77,3.98846726370328e-98,2.83738455537123e-124,1.16702068177763e-153,1.56588648116791e-183,5.9460095882168e-217,3.04648237511363e-242,1.0476778777822e-272,2.36166828733039e-308,0],[4.39462560522794e-05,6.94943900679841e-05,1.04291502349634e-05,5.75970473307081e-05,0.000176906604268204,0.000370540209494104,1.55421446807263e-05,8.30475843056959e-07,1.53069632670964e-05,7.14342142452053e-09,1.13543480848847e-15,2.9038893623358e-25,2.64561847471716e-28,1.01950388004498e-33,2.57520093025581e-44,4.26377054766638e-60,4.6281649856682e-81,2.42118913413043e-104,5.00622985414094e-129,7.25515626339583e-159,3.68875889960785e-180,1.93530271945878e-205,6.65546074071442e-236,5.25171440440826e-271,5.21884573812369e-305],[9.55774448047614e-05,0.000177213516750328,0.000316039775630404,0.000475626271585416,0.000761122825446468,0.000814816903847166,0.000578652080468251,0.000157642005236617,0.000152603615623742,3.79131793396399e-06,7.51171055499296e-11,3.17899382836251e-15,5.96544729558909e-16,2.29881835031841e-21,5.80666661659396e-32,9.62751627134557e-48,6.45601148716749e-65,2.03894997743999e-84,4.22210611955478e-109,5.68993288800346e-128,4.55423370733433e-148,2.3893730364403e-173,9.74271181456202e-204,3.23808866743861e-233,4.50467722508192e-267],[1.98596665642571e-07,4.68000995544877e-05,0.000509090380019503,0.000931319298108951,0.0012891264719117,0.00255519224543074,0.00194691180666576,0.00139812985945186,0.000387322200480871,0.000138389622336007,1.12962183753118e-05,4.51541808458966e-08,2.61431851364547e-08,1.00740783248176e-13,2.57450769746435e-24,2.19535111827777e-35,1.05790746618256e-49,3.3419444921475e-69,1.11809791229766e-85,1.36529655130866e-100,1.09278610207721e-120,5.81233702380819e-146,2.55947654424468e-171,5.43203463930242e-200,7.55679638075802e-234],[2.0971717790889e-11,2.45146152673218e-05,0.00101641626246237,0.0012023963529308,0.00431348854715178,0.00596725675304324,0.00681722538407796,0.00633846543983796,0.00269032102983323,0.00186745629509051,0.000257016293377211,6.68099172102812e-05,2.23554936688109e-05,9.43773499495428e-11,9.51160167439667e-16,6.99272785694416e-25,3.37970089697892e-39,2.8443677530022e-53,5.21415549375954e-63,6.36695308508056e-78,5.10133947007011e-98,2.57749276005559e-119,8.34462177624758e-143,1.77101149161936e-171,2.46374961111803e-205],[2.18739954530607e-13,8.27469962250889e-07,0.00068247158549802,0.00129956984621859,0.00404868380339934,0.0102606158585002,0.0148087501034371,0.0152333593380476,0.0125919827053159,0.00699472312030991,0.00241781085109058,0.000326864762138592,1.64609783322298e-05,5.34463376690191e-06,5.93226571697135e-10,5.36558733277978e-19,1.90647639364607e-28,2.53683060667389e-35,4.72578158624974e-45,5.77104072981931e-60,3.31061440322712e-77,1.63303711875425e-95,5.28749916069209e-119,1.12218648450566e-147,1.56113414734455e-181],[2.95266849169562e-16,2.85416661335113e-08,8.90740945415943e-05,0.00122580118110615,0.0046414034091961,0.0107569609558745,0.0239117407486324,0.0345320261172182,0.034266290423328,0.025908337162062,0.0111683859733492,0.00396670124627087,0.00103938025934649,0.000215424763750705,2.74471340647353e-07,1.04918685044655e-11,1.59258336217706e-17,4.46886513511614e-22,8.32438239306983e-32,5.50420318373213e-45,4.07127773250312e-58,2.01105763346145e-76,6.51146592352183e-100,1.38195370474173e-128,2.93245589422197e-157],[5.39964840899981e-19,5.73783566121195e-10,4.95237822889483e-06,0.000356036530448518,0.00364161528795007,0.0112329442468965,0.0252826501600385,0.0504539247890418,0.0644047045560643,0.0565147591080807,0.0365725560107204,0.0168018818177516,0.00511766159567819,0.00114102783214639,0.000134221597433633,3.14802960871893e-07,5.45629826051782e-09,1.53072361775968e-13,1.41245242401531e-22,1.29303645153607e-30,9.74415078109988e-44,4.81324295289534e-62,1.55844700619099e-85,4.43400824553211e-109,2.84966144455127e-127],[8.08171755432348e-23,9.9520282620662e-12,8.72151014566793e-06,0.000237656044981198,0.00242087074777216,0.0074732039291603,0.022384642393563,0.0557037311872487,0.0912557128673284,0.111817977555221,0.0876421013472796,0.0510910440320731,0.0211567749509494,0.00631968870616185,0.00125306808856439,0.000249914243381994,3.94877458670163e-05,1.74347212052722e-09,5.23218109941235e-13,6.0146277187387e-21,4.53254441838339e-34,2.23890921563308e-52,8.54657858913127e-71,8.37418644669075e-84,5.38198765821467e-102],[1.77556608338451e-26,4.68244714950935e-15,5.72836682532587e-08,5.26618049520792e-05,0.000520971666093416,0.00358304354991811,0.0146024372316178,0.0418007880446392,0.0937576081086299,0.158070989476187,0.157995985258691,0.117472705761148,0.068309234060372,0.0258290121813925,0.00614303473251792,0.00140371367897623,0.000338744362715045,2.87186516456263e-05,4.72966243885067e-08,5.43755630957161e-16,4.12176724282202e-29,8.46961929462488e-42,3.13499804301411e-50,3.07380889542921e-63,1.97549954784854e-81],[3.73881979289422e-28,4.1820126805177e-15,3.42658639075899e-07,0.000213096739325229,4.3973222484619e-05,0.00128105280915237,0.00620857351658763,0.0236609682820968,0.0673959425125629,0.142023226278179,0.202085537513268,0.206177388365867,0.142910430049431,0.0718865969637724,0.0247087506133945,0.0047660988724505,0.0012606718949474,0.000106045234620241,1.61011212783354e-07,3.22788996902712e-14,9.2123618335293e-20,1.49536811118862e-26,2.23643511113796e-34,2.19278426565827e-47,1.4092757463806e-65],[3.96017717925257e-29,3.86645225973798e-16,2.47948115467607e-08,1.04690276048912e-05,9.33739859692154e-08,0.000133111110976272,0.001505336639134,0.0100449990636382,0.0356202331310127,0.105081641208442,0.19439947445164,0.245025075795557,0.223771691425712,0.143465906225543,0.0646419650813796,0.0193175819154857,0.00436838485724641,0.000892066964783552,3.18041827586292e-05,1.69881000386951e-07,1.59463339843398e-12,2.07291272771527e-15,3.10070286927428e-23,3.04018320512746e-36,1.95388872614587e-54],[9.27339116358244e-35,9.03850964769535e-22,5.77463739774986e-14,2.41842863581794e-11,3.88926919292566e-09,0.000100098427596149,0.00050944399843051,0.00360939499961912,0.0136893590316382,0.0543814561636372,0.125589050531115,0.214168898320003,0.252702330848491,0.212680258807483,0.12368371559332,0.0571604244308721,0.0148492657453032,0.00428301746930206,0.000533538675367115,2.75095327364781e-05,2.44919907449026e-06,5.58559793676326e-09,8.35504525271334e-17,8.19197108729206e-30,5.26488017941314e-48],[4.22630081869033e-45,4.11918272416941e-32,2.63161451387286e-24,3.34109926960455e-18,4.16151119979132e-09,3.41162097549106e-05,8.99545384914694e-05,0.000537014515485226,0.00565794795375072,0.0201673293936082,0.0650968150283119,0.13459457027411,0.216709166154952,0.233737316709245,0.179942550046156,0.0954030715862073,0.0358967231160644,0.00978785209447172,0.00200550639931911,0.000394946604594165,0.000128582191560498,2.92511773464097e-07,4.37544553451306e-15,4.29280429019131e-28,6.30606127729647e-38],[3.74346108554796e-60,3.64858019840399e-47,6.70536258912719e-37,1.26938304068891e-22,1.58065154101849e-13,1.29158993030982e-09,1.61465392359957e-06,9.08018401722032e-05,0.000992221126994708,0.00512632101729583,0.0213674249325609,0.0609771333181536,0.127073954333846,0.182795988224094,0.182286136161845,0.128019925458391,0.0639035259991266,0.0214065384771248,0.00490871234422249,0.000973054976315337,4.01022180114187e-05,5.72791275188721e-09,9.59043068097496e-17,2.97039793505775e-18,6.78914545169897e-25],[6.44423115594109e-80,1.76612292089083e-65,4.93647515191911e-46,9.37777211109363e-32,1.1698365693386e-22,1.41425275871238e-13,6.22698386517161e-07,2.62951805516803e-05,0.000279527597873221,0.00157860429446793,0.00602574560623074,0.018752616701671,0.0543021443993639,0.103895733283513,0.132977779790837,0.128374603771506,0.0753939336135714,0.0355212183761688,0.0120559569069517,0.00206194514165532,0.000441096970059341,2.73484240954569e-07,1.78469373193845e-08,6.21521805008958e-10,1.42055105743125e-16],[7.68729358424888e-104,2.44560642444526e-79,7.08775698856484e-60,1.3645720073284e-45,1.85668279000812e-30,1.24717099176323e-18,5.51514928616487e-12,3.59878422919363e-08,7.11836377827706e-06,0.000206159016212575,0.000677559737625132,0.00454096610629842,0.0184411701444843,0.0423810497069583,0.0716411419156444,0.0888352172498334,0.0766481090433616,0.0426458883542985,0.0175314894554273,0.00410447707852974,0.00104229547613349,0.000236141437094331,7.29387726175071e-05,2.52746047466519e-06,5.77674769488895e-13],[1.54348158058503e-122,6.82438055278491e-98,2.1764367130903e-78,3.10524776593914e-57,3.18217737427384e-40,2.1376226328524e-28,2.96521296109842e-21,3.35038012197265e-15,1.97523298476773e-08,0.000133046448270912,0.000137471144441657,0.000903339786529172,0.00339562223667828,0.0128631814378422,0.0284907613212608,0.0459004645516009,0.0504343969800885,0.0368454386741711,0.020295131275482,0.00834622530427719,0.0025276260264015,0.000264485978452582,7.42808296982338e-05,2.97754176124738e-07,5.54723640489585e-14],[8.37072222983159e-146,6.47496277221125e-121,6.61607426510692e-94,1.03435132478381e-71,1.05997695834429e-54,7.26629325820164e-43,3.44825400430606e-33,1.16750358152517e-20,8.87833074222978e-12,6.03705086913571e-08,3.0979146677307e-07,0.000111121155685573,0.000546159808841194,0.00234731614653475,0.00811613899679378,0.01524872508983,0.0224969610775458,0.0222048655285225,0.0165153003974538,0.00796127257796058,0.00238983759119942,0.000568475706754498,0.000111703499381798,1.37762505288305e-06,7.78323799691101e-13],[5.8174658995359e-173,1.79576621930351e-140,4.28308842051526e-113,6.69614350285288e-91,6.86338053828388e-74,5.70790798535558e-61,9.45947538521377e-43,1.05207977853767e-28,8.00037164310086e-20,5.43819520219381e-16,1.1447107087918e-12,7.6069411229749e-08,1.88824406030061e-05,0.000282589139759991,0.0013566840600888,0.0043332775154336,0.00841566316788047,0.0115467512308974,0.00989353732973917,0.00702460127430449,0.00248407446365753,0.000835282652146337,0.00019689042809369,3.98684425041365e-05,1.13279935581737e-06],[6.20932658184517e-197,2.25939039635564e-164,5.3888801122331e-137,8.42494444063686e-115,9.85285809081692e-98,9.81016236238191e-75,1.65677535778078e-55,1.84264779117487e-41,1.40112690321962e-32,9.7734482363793e-29,8.84275975640076e-21,5.42678565856387e-14,3.55725848792818e-09,2.50688031203498e-05,0.00037257061396806,0.000652072224755515,0.00220596575329706,0.00390824530472625,0.00383520710782124,0.00356746514374532,0.00198660746096792,0.000847086231459706,0.000420124430561813,0.000206161951735914,0.000139297549047621],[1.51834614100114e-225,5.52481278783358e-193,1.31772509679596e-165,2.06533081524484e-143,1.29673322046541e-116,3.33931942363595e-92,5.63955821152384e-73,6.27221302516466e-59,4.76902554018659e-50,2.05571003722159e-43,6.4564082722214e-32,9.97509200941749e-22,2.50203874102328e-11,5.38184636508631e-06,2.28640215213753e-05,5.21287951737725e-05,0.000417456509937771,0.000641775046044822,0.00116730324640233,0.00158181795727826,0.00100667520344559,0.00068510033767778,0.000277599060128235,4.61300248449355e-05,4.35426880886139e-05],[7.215756742882e-259,2.6256005832423e-226,6.26274913779807e-199,2.18370540673512e-168,8.57861654858231e-139,2.20914667283235e-114,3.73088057671666e-95,4.14938831485597e-81,3.15554639168223e-72,1.05662622923261e-59,1.43227275358807e-42,5.4931932302565e-27,1.4524397658288e-16,3.79389505892861e-11,2.20909001199427e-10,3.05546580679959e-09,4.35913186858356e-06,3.31707747133925e-05,0.000430542207310076,0.000586742208506192,0.000307810148878761,0.000253683181760847,0.000409041984564786,7.35977011753656e-06,5.00851432147429e-07],[6.66465670367594e-297,2.42507689762034e-264,4.68473831753259e-230,2.80766623244054e-195,1.10298265871409e-165,2.84037672197857e-141,4.79691936622069e-122,5.33497231006159e-108,2.51418740546229e-97,2.69430717937953e-73,1.56978231833671e-52,6.05179120216435e-37,1.68469487817489e-26,5.83767588635578e-21,4.46168128161558e-20,1.47718573329587e-15,3.03760156043252e-12,1.11175862458942e-08,4.77448480759622e-07,1.37527946349091e-05,3.27369657863926e-05,4.5069603918654e-05,2.18665863961594e-05,2.45790160940866e-07,2.16743981653795e-12],[0,1.28033478220917e-301,1.17063504610327e-261,7.01587297133337e-227,2.75616313180305e-197,7.09761020470235e-173,1.1986662995098e-153,1.33312158277165e-139,6.45923897222376e-114,5.73686958901279e-88,3.34560845825795e-67,1.30290708566137e-51,3.98283248267262e-41,1.95445068709012e-35,2.5163612212255e-34,2.13073194576148e-26,2.2103622973781e-22,1.36299881951402e-16,5.4223823620928e-13,9.64890337003241e-07,4.75103088380026e-05,1.74076683148872e-08,2.3982844765835e-05,4.12736376796499e-05,4.65593304437425e-10]],\"alpha_stroke\":1,\"sizes\":[10,100],\"spans\":[1,20],\"type\":\"surface\",\"inherit\":true}},\"layout\":{\"margin\":{\"b\":40,\"l\":60,\"t\":25,\"r\":10},\"scene\":{\"xaxis\":{\"title\":[]},\"yaxis\":{\"title\":[]},\"zaxis\":{\"title\":[]}},\"hovermode\":\"closest\",\"showlegend\":false,\"legend\":{\"yanchor\":\"top\",\"y\":0.5}},\"source\":\"A\",\"config\":{\"showSendToCloud\":false},\"data\":[{\"colorbar\":{\"title\":\"\",\"ticklen\":2,\"len\":0.5,\"lenmode\":\"fraction\",\"y\":1,\"yanchor\":\"top\"},\"colorscale\":[[\"0\",\"rgba(68,1,84,1)\"],[\"0.0416666666666667\",\"rgba(70,19,97,1)\"],[\"0.0833333333333333\",\"rgba(72,32,111,1)\"],[\"0.125\",\"rgba(71,45,122,1)\"],[\"0.166666666666667\",\"rgba(68,58,128,1)\"],[\"0.208333333333333\",\"rgba(64,70,135,1)\"],[\"0.25\",\"rgba(60,82,138,1)\"],[\"0.291666666666667\",\"rgba(56,93,140,1)\"],[\"0.333333333333333\",\"rgba(49,104,142,1)\"],[\"0.375\",\"rgba(46,114,142,1)\"],[\"0.416666666666667\",\"rgba(42,123,142,1)\"],[\"0.458333333333333\",\"rgba(38,133,141,1)\"],[\"0.5\",\"rgba(37,144,140,1)\"],[\"0.541666666666667\",\"rgba(33,154,138,1)\"],[\"0.583333333333333\",\"rgba(39,164,133,1)\"],[\"0.625\",\"rgba(47,174,127,1)\"],[\"0.666666666666667\",\"rgba(53,183,121,1)\"],[\"0.708333333333333\",\"rgba(79,191,110,1)\"],[\"0.75\",\"rgba(98,199,98,1)\"],[\"0.791666666666667\",\"rgba(119,207,85,1)\"],[\"0.833333333333333\",\"rgba(147,214,70,1)\"],[\"0.875\",\"rgba(172,220,52,1)\"],[\"0.916666666666667\",\"rgba(199,225,42,1)\"],[\"0.958333333333333\",\"rgba(226,228,40,1)\"],[\"1\",\"rgba(253,231,37,1)\"]],\"showscale\":true,\"x\":[-4.11222323909044,-3.76275945114626,-3.41329566320208,-3.0638318752579,-2.71436808731372,-2.36490429936954,-2.01544051142536,-1.66597672348118,-1.316512935537,-0.967049147592815,-0.617585359648634,-0.268121571704453,0.0813422162397277,0.430806004183909,0.780269792128089,1.12973358007227,1.47919736801645,1.82866115596063,2.17812494390481,2.52758873184899,2.87705251979317,3.22651630773736,3.57598009568154,3.92544388362572,4.2749076715699],\"y\":[-4.32381413035071,-3.95784855910568,-3.59188298786066,-3.22591741661563,-2.85995184537061,-2.49398627412558,-2.12802070288055,-1.76205513163553,-1.3960895603905,-1.03012398914547,-0.664158417900448,-0.298192846655422,0.0677727245896049,0.433738295834631,0.799703867079657,1.16566943832468,1.53163500956971,1.89760058081474,2.26356615205976,2.62953172330479,2.99549729454982,3.36146286579484,3.72742843703987,4.09339400828489,4.45935957952992],\"z\":[[3.40651108352134e-09,1.41934533126133e-08,8.54786240302624e-08,0.000130831863209747,1.94776526567504e-06,1.49783603255103e-06,1.1170089576991e-08,6.01986954373106e-12,1.16817732135535e-10,1.50245544102462e-14,4.62944974810078e-23,4.83295093316628e-35,2.28048400569722e-45,8.78734985512727e-51,2.21962779786052e-61,3.67504668072926e-77,3.98846726370328e-98,2.83738455537123e-124,1.16702068177763e-153,1.56588648116791e-183,5.9460095882168e-217,3.04648237511363e-242,1.0476778777822e-272,2.36166828733039e-308,0],[4.39462560522794e-05,6.94943900679841e-05,1.04291502349634e-05,5.75970473307081e-05,0.000176906604268204,0.000370540209494104,1.55421446807263e-05,8.30475843056959e-07,1.53069632670964e-05,7.14342142452053e-09,1.13543480848847e-15,2.9038893623358e-25,2.64561847471716e-28,1.01950388004498e-33,2.57520093025581e-44,4.26377054766638e-60,4.6281649856682e-81,2.42118913413043e-104,5.00622985414094e-129,7.25515626339583e-159,3.68875889960785e-180,1.93530271945878e-205,6.65546074071442e-236,5.25171440440826e-271,5.21884573812369e-305],[9.55774448047614e-05,0.000177213516750328,0.000316039775630404,0.000475626271585416,0.000761122825446468,0.000814816903847166,0.000578652080468251,0.000157642005236617,0.000152603615623742,3.79131793396399e-06,7.51171055499296e-11,3.17899382836251e-15,5.96544729558909e-16,2.29881835031841e-21,5.80666661659396e-32,9.62751627134557e-48,6.45601148716749e-65,2.03894997743999e-84,4.22210611955478e-109,5.68993288800346e-128,4.55423370733433e-148,2.3893730364403e-173,9.74271181456202e-204,3.23808866743861e-233,4.50467722508192e-267],[1.98596665642571e-07,4.68000995544877e-05,0.000509090380019503,0.000931319298108951,0.0012891264719117,0.00255519224543074,0.00194691180666576,0.00139812985945186,0.000387322200480871,0.000138389622336007,1.12962183753118e-05,4.51541808458966e-08,2.61431851364547e-08,1.00740783248176e-13,2.57450769746435e-24,2.19535111827777e-35,1.05790746618256e-49,3.3419444921475e-69,1.11809791229766e-85,1.36529655130866e-100,1.09278610207721e-120,5.81233702380819e-146,2.55947654424468e-171,5.43203463930242e-200,7.55679638075802e-234],[2.0971717790889e-11,2.45146152673218e-05,0.00101641626246237,0.0012023963529308,0.00431348854715178,0.00596725675304324,0.00681722538407796,0.00633846543983796,0.00269032102983323,0.00186745629509051,0.000257016293377211,6.68099172102812e-05,2.23554936688109e-05,9.43773499495428e-11,9.51160167439667e-16,6.99272785694416e-25,3.37970089697892e-39,2.8443677530022e-53,5.21415549375954e-63,6.36695308508056e-78,5.10133947007011e-98,2.57749276005559e-119,8.34462177624758e-143,1.77101149161936e-171,2.46374961111803e-205],[2.18739954530607e-13,8.27469962250889e-07,0.00068247158549802,0.00129956984621859,0.00404868380339934,0.0102606158585002,0.0148087501034371,0.0152333593380476,0.0125919827053159,0.00699472312030991,0.00241781085109058,0.000326864762138592,1.64609783322298e-05,5.34463376690191e-06,5.93226571697135e-10,5.36558733277978e-19,1.90647639364607e-28,2.53683060667389e-35,4.72578158624974e-45,5.77104072981931e-60,3.31061440322712e-77,1.63303711875425e-95,5.28749916069209e-119,1.12218648450566e-147,1.56113414734455e-181],[2.95266849169562e-16,2.85416661335113e-08,8.90740945415943e-05,0.00122580118110615,0.0046414034091961,0.0107569609558745,0.0239117407486324,0.0345320261172182,0.034266290423328,0.025908337162062,0.0111683859733492,0.00396670124627087,0.00103938025934649,0.000215424763750705,2.74471340647353e-07,1.04918685044655e-11,1.59258336217706e-17,4.46886513511614e-22,8.32438239306983e-32,5.50420318373213e-45,4.07127773250312e-58,2.01105763346145e-76,6.51146592352183e-100,1.38195370474173e-128,2.93245589422197e-157],[5.39964840899981e-19,5.73783566121195e-10,4.95237822889483e-06,0.000356036530448518,0.00364161528795007,0.0112329442468965,0.0252826501600385,0.0504539247890418,0.0644047045560643,0.0565147591080807,0.0365725560107204,0.0168018818177516,0.00511766159567819,0.00114102783214639,0.000134221597433633,3.14802960871893e-07,5.45629826051782e-09,1.53072361775968e-13,1.41245242401531e-22,1.29303645153607e-30,9.74415078109988e-44,4.81324295289534e-62,1.55844700619099e-85,4.43400824553211e-109,2.84966144455127e-127],[8.08171755432348e-23,9.9520282620662e-12,8.72151014566793e-06,0.000237656044981198,0.00242087074777216,0.0074732039291603,0.022384642393563,0.0557037311872487,0.0912557128673284,0.111817977555221,0.0876421013472796,0.0510910440320731,0.0211567749509494,0.00631968870616185,0.00125306808856439,0.000249914243381994,3.94877458670163e-05,1.74347212052722e-09,5.23218109941235e-13,6.0146277187387e-21,4.53254441838339e-34,2.23890921563308e-52,8.54657858913127e-71,8.37418644669075e-84,5.38198765821467e-102],[1.77556608338451e-26,4.68244714950935e-15,5.72836682532587e-08,5.26618049520792e-05,0.000520971666093416,0.00358304354991811,0.0146024372316178,0.0418007880446392,0.0937576081086299,0.158070989476187,0.157995985258691,0.117472705761148,0.068309234060372,0.0258290121813925,0.00614303473251792,0.00140371367897623,0.000338744362715045,2.87186516456263e-05,4.72966243885067e-08,5.43755630957161e-16,4.12176724282202e-29,8.46961929462488e-42,3.13499804301411e-50,3.07380889542921e-63,1.97549954784854e-81],[3.73881979289422e-28,4.1820126805177e-15,3.42658639075899e-07,0.000213096739325229,4.3973222484619e-05,0.00128105280915237,0.00620857351658763,0.0236609682820968,0.0673959425125629,0.142023226278179,0.202085537513268,0.206177388365867,0.142910430049431,0.0718865969637724,0.0247087506133945,0.0047660988724505,0.0012606718949474,0.000106045234620241,1.61011212783354e-07,3.22788996902712e-14,9.2123618335293e-20,1.49536811118862e-26,2.23643511113796e-34,2.19278426565827e-47,1.4092757463806e-65],[3.96017717925257e-29,3.86645225973798e-16,2.47948115467607e-08,1.04690276048912e-05,9.33739859692154e-08,0.000133111110976272,0.001505336639134,0.0100449990636382,0.0356202331310127,0.105081641208442,0.19439947445164,0.245025075795557,0.223771691425712,0.143465906225543,0.0646419650813796,0.0193175819154857,0.00436838485724641,0.000892066964783552,3.18041827586292e-05,1.69881000386951e-07,1.59463339843398e-12,2.07291272771527e-15,3.10070286927428e-23,3.04018320512746e-36,1.95388872614587e-54],[9.27339116358244e-35,9.03850964769535e-22,5.77463739774986e-14,2.41842863581794e-11,3.88926919292566e-09,0.000100098427596149,0.00050944399843051,0.00360939499961912,0.0136893590316382,0.0543814561636372,0.125589050531115,0.214168898320003,0.252702330848491,0.212680258807483,0.12368371559332,0.0571604244308721,0.0148492657453032,0.00428301746930206,0.000533538675367115,2.75095327364781e-05,2.44919907449026e-06,5.58559793676326e-09,8.35504525271334e-17,8.19197108729206e-30,5.26488017941314e-48],[4.22630081869033e-45,4.11918272416941e-32,2.63161451387286e-24,3.34109926960455e-18,4.16151119979132e-09,3.41162097549106e-05,8.99545384914694e-05,0.000537014515485226,0.00565794795375072,0.0201673293936082,0.0650968150283119,0.13459457027411,0.216709166154952,0.233737316709245,0.179942550046156,0.0954030715862073,0.0358967231160644,0.00978785209447172,0.00200550639931911,0.000394946604594165,0.000128582191560498,2.92511773464097e-07,4.37544553451306e-15,4.29280429019131e-28,6.30606127729647e-38],[3.74346108554796e-60,3.64858019840399e-47,6.70536258912719e-37,1.26938304068891e-22,1.58065154101849e-13,1.29158993030982e-09,1.61465392359957e-06,9.08018401722032e-05,0.000992221126994708,0.00512632101729583,0.0213674249325609,0.0609771333181536,0.127073954333846,0.182795988224094,0.182286136161845,0.128019925458391,0.0639035259991266,0.0214065384771248,0.00490871234422249,0.000973054976315337,4.01022180114187e-05,5.72791275188721e-09,9.59043068097496e-17,2.97039793505775e-18,6.78914545169897e-25],[6.44423115594109e-80,1.76612292089083e-65,4.93647515191911e-46,9.37777211109363e-32,1.1698365693386e-22,1.41425275871238e-13,6.22698386517161e-07,2.62951805516803e-05,0.000279527597873221,0.00157860429446793,0.00602574560623074,0.018752616701671,0.0543021443993639,0.103895733283513,0.132977779790837,0.128374603771506,0.0753939336135714,0.0355212183761688,0.0120559569069517,0.00206194514165532,0.000441096970059341,2.73484240954569e-07,1.78469373193845e-08,6.21521805008958e-10,1.42055105743125e-16],[7.68729358424888e-104,2.44560642444526e-79,7.08775698856484e-60,1.3645720073284e-45,1.85668279000812e-30,1.24717099176323e-18,5.51514928616487e-12,3.59878422919363e-08,7.11836377827706e-06,0.000206159016212575,0.000677559737625132,0.00454096610629842,0.0184411701444843,0.0423810497069583,0.0716411419156444,0.0888352172498334,0.0766481090433616,0.0426458883542985,0.0175314894554273,0.00410447707852974,0.00104229547613349,0.000236141437094331,7.29387726175071e-05,2.52746047466519e-06,5.77674769488895e-13],[1.54348158058503e-122,6.82438055278491e-98,2.1764367130903e-78,3.10524776593914e-57,3.18217737427384e-40,2.1376226328524e-28,2.96521296109842e-21,3.35038012197265e-15,1.97523298476773e-08,0.000133046448270912,0.000137471144441657,0.000903339786529172,0.00339562223667828,0.0128631814378422,0.0284907613212608,0.0459004645516009,0.0504343969800885,0.0368454386741711,0.020295131275482,0.00834622530427719,0.0025276260264015,0.000264485978452582,7.42808296982338e-05,2.97754176124738e-07,5.54723640489585e-14],[8.37072222983159e-146,6.47496277221125e-121,6.61607426510692e-94,1.03435132478381e-71,1.05997695834429e-54,7.26629325820164e-43,3.44825400430606e-33,1.16750358152517e-20,8.87833074222978e-12,6.03705086913571e-08,3.0979146677307e-07,0.000111121155685573,0.000546159808841194,0.00234731614653475,0.00811613899679378,0.01524872508983,0.0224969610775458,0.0222048655285225,0.0165153003974538,0.00796127257796058,0.00238983759119942,0.000568475706754498,0.000111703499381798,1.37762505288305e-06,7.78323799691101e-13],[5.8174658995359e-173,1.79576621930351e-140,4.28308842051526e-113,6.69614350285288e-91,6.86338053828388e-74,5.70790798535558e-61,9.45947538521377e-43,1.05207977853767e-28,8.00037164310086e-20,5.43819520219381e-16,1.1447107087918e-12,7.6069411229749e-08,1.88824406030061e-05,0.000282589139759991,0.0013566840600888,0.0043332775154336,0.00841566316788047,0.0115467512308974,0.00989353732973917,0.00702460127430449,0.00248407446365753,0.000835282652146337,0.00019689042809369,3.98684425041365e-05,1.13279935581737e-06],[6.20932658184517e-197,2.25939039635564e-164,5.3888801122331e-137,8.42494444063686e-115,9.85285809081692e-98,9.81016236238191e-75,1.65677535778078e-55,1.84264779117487e-41,1.40112690321962e-32,9.7734482363793e-29,8.84275975640076e-21,5.42678565856387e-14,3.55725848792818e-09,2.50688031203498e-05,0.00037257061396806,0.000652072224755515,0.00220596575329706,0.00390824530472625,0.00383520710782124,0.00356746514374532,0.00198660746096792,0.000847086231459706,0.000420124430561813,0.000206161951735914,0.000139297549047621],[1.51834614100114e-225,5.52481278783358e-193,1.31772509679596e-165,2.06533081524484e-143,1.29673322046541e-116,3.33931942363595e-92,5.63955821152384e-73,6.27221302516466e-59,4.76902554018659e-50,2.05571003722159e-43,6.4564082722214e-32,9.97509200941749e-22,2.50203874102328e-11,5.38184636508631e-06,2.28640215213753e-05,5.21287951737725e-05,0.000417456509937771,0.000641775046044822,0.00116730324640233,0.00158181795727826,0.00100667520344559,0.00068510033767778,0.000277599060128235,4.61300248449355e-05,4.35426880886139e-05],[7.215756742882e-259,2.6256005832423e-226,6.26274913779807e-199,2.18370540673512e-168,8.57861654858231e-139,2.20914667283235e-114,3.73088057671666e-95,4.14938831485597e-81,3.15554639168223e-72,1.05662622923261e-59,1.43227275358807e-42,5.4931932302565e-27,1.4524397658288e-16,3.79389505892861e-11,2.20909001199427e-10,3.05546580679959e-09,4.35913186858356e-06,3.31707747133925e-05,0.000430542207310076,0.000586742208506192,0.000307810148878761,0.000253683181760847,0.000409041984564786,7.35977011753656e-06,5.00851432147429e-07],[6.66465670367594e-297,2.42507689762034e-264,4.68473831753259e-230,2.80766623244054e-195,1.10298265871409e-165,2.84037672197857e-141,4.79691936622069e-122,5.33497231006159e-108,2.51418740546229e-97,2.69430717937953e-73,1.56978231833671e-52,6.05179120216435e-37,1.68469487817489e-26,5.83767588635578e-21,4.46168128161558e-20,1.47718573329587e-15,3.03760156043252e-12,1.11175862458942e-08,4.77448480759622e-07,1.37527946349091e-05,3.27369657863926e-05,4.5069603918654e-05,2.18665863961594e-05,2.45790160940866e-07,2.16743981653795e-12],[0,1.28033478220917e-301,1.17063504610327e-261,7.01587297133337e-227,2.75616313180305e-197,7.09761020470235e-173,1.1986662995098e-153,1.33312158277165e-139,6.45923897222376e-114,5.73686958901279e-88,3.34560845825795e-67,1.30290708566137e-51,3.98283248267262e-41,1.95445068709012e-35,2.5163612212255e-34,2.13073194576148e-26,2.2103622973781e-22,1.36299881951402e-16,5.4223823620928e-13,9.64890337003241e-07,4.75103088380026e-05,1.74076683148872e-08,2.3982844765835e-05,4.12736376796499e-05,4.65593304437425e-10]],\"type\":\"surface\",\"frame\":null}],\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.2,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}\nFigure 4: Imagem 3-D Interativa de uma distribuição Multivariada Normal\n\n\n\nMetropolis e Metropolis-Hastings\nO primeiro algoritmo MCMC amplamente utilizado para gerar amostras de correntes Markov foi originário na física na década de 1950 (inclusive uma relação muito próxima com a bomba atômica no projeto Manhattan) e chama-se Metropolis (Metropolis, Rosenbluth, Rosenbluth, Teller, & Teller, 1953) em homenagem ao primeiro autor Nicholas Metropolis (figura 5). Em síntese, o algoritmo de Metropolis é uma adaptação de um passeio aleatório (random walk) com uma regra de aceitação/rejeição para convergir à distribuição-alvo.\nO algorimo de Metropolis usa uma distribuição de propostas \\(J_t(\\theta^*)\\) (\\(J\\) quer dizer jumping distribution e \\(t\\) indica em qual estado da corrente Markov estamos) para definir próximos valores da distribuição \\(P^*(\\theta^* | \\text{data})\\). Essa distribuição deve ser simétrica:\n\\[\nJ_t (\\theta^* | \\theta^{t-1}) = J_t(\\theta^{t-1}|\\theta^*).\n\\]\nNa década de 1970, surgiu um generalização do algoritmo de Metropolis que não necessita que as distribuições de proposta sejam simétricas. A generalização foi proposta por Wilfred Keith Hastings (Hastings, 1970) (figura 5) e chama-se algoritmo de Metropolis-Hastings.\n\n\n\nFigure 5: Da esquerda para direita: Nicholas Metropolis e Wilfred Hastings – Figuras de https://www.wikipedia.org\n\n\n\nAlgoritmo de Metropolis\nA essência do algoritmo é um passeio aleatório (random walk) pelo espaço amostral dos parâmetros, onde a probabilidade da corrente Markov mudar de estado é definida como:\n\\[\nP_{\\text{mudar}} = \\min\\left({\\frac{P (\\theta_{\\text{proposto}})}{P (\\theta_{\\text{atual}})}},1\\right).\n\\]\nIsso quer dizer a corrente Markov somente mudará para um novo estado em duas condições:\nQuando a probabilidade dos parâmetros propostos pelo passeio aleatório \\(P(\\theta_{\\text{proposto}})\\) é maior que a probabilidade dos parâmetros do estado atual \\(P(\\theta_{\\text{atual}})\\), mudamos com 100% de probabilidade. Vejam que se \\(P(\\theta_{\\text{proposto}}) > P(\\theta_{\\text{atual}})\\) então a função \\(\\min\\) escolhe o valor 1 que quer dizer 100%.\nQuando a probabilidade dos parâmetros propostos pelo passeio aleatório \\(P(\\theta_{\\text{proposto}})\\) é menor que a probabilidade dos parâmetros do estado atual \\(P(\\theta_{\\text{atual}})\\), mudamos com probabilidade igual a proporção dessa diferença. Vejam que se \\(P(\\theta_{\\text{proposto}}) < P(\\theta_{\\text{atual}})\\) então a função \\(\\min\\) não escolhe o valor 1, mas sim o valor \\(\\frac{P (\\theta_{\\text{proposto}})}{P (\\theta_{\\text{atual}})}\\) que equivale a proporção da probabilidade dos parâmetros propostos pela probabilidade dos parâmetros do estado atual.\nDe qualquer maneira, a cada iteração do algoritmo de Metropolis, mesmo que a corrente muda de estado ou não, amostramos o parâmetro \\(\\theta\\) de qualquer maneira. Ou seja, se a corrente não mudar em um certo estado \\(\\theta\\) será amostrado duas vezes (ou mais caso a corrente fique estacionária no mesmo estado).\nO algoritmo de Metropolis-Hastings pode ser descrito na seguinte maneira3 (\\(\\theta\\) é o parâmetro, ou conjunto de parâmetros, de interesse e \\(y\\) são os dados):\nDefina um ponto inicial \\(\\theta^0\\) do qual \\(p(\\theta^0|y) > 0\\), ou amostre-o de uma distribuição inicial \\(p_0 (\\theta)\\). \\(p_0(\\theta)\\) pode ser uma distribuição normal ou uma distribuição prévia de \\(\\theta\\) (\\(p(\\theta)\\)).\nPara \\(t = 1, 2, \\dots\\):\nAmostra uma proposta \\(\\theta^*\\) de uma distribuição de propostas no tempo \\(t\\), \\(J_t (\\theta^* | \\theta^{t-1})\\).\nCalcule a proporção das probabilidades:\nMetropolis: \\(r = \\frac{p(\\theta^* | y)}{p(\\theta^{t-1} | y)}\\)\nMetropolis-Hastings: \\(r = \\frac{\\frac{p(\\theta^* | y)}{J_t(\\theta^*|\\theta^{t-1})}}{\\frac{p(\\theta^{t-1} | y)}{J_t(\\theta^{t-1}|\\theta^*)}}\\)\n\nDesigne:\n\\[\\theta^t =\n  \\begin{cases}\n  \\theta^* & \\text{com probabilidade $\\min(r,1)$}\\\\\n  \\theta^{t-1} & \\text{caso contrário}\n  \\end{cases}\\]\n\nLimitações do Algoritmo de Metropolis\nAs limitações do algoritmo de Metropolis-Hastings são principalmente computacionais. Com propostas geradas aleatoriamente, geralmente leva um grande número de iterações para entrar em áreas de densidade posterior mais alta (mais provável). Mesmo algoritmos de Metropolis-Hastings eficientes às vezes aceitam menos de 25% das propostas (Roberts, Gelman, & Gilks, 1997). Em situações dimensionais mais baixas, o poder computacional aumentado pode compensar a eficiência mais baixa até certo ponto. Mas em situações de modelagem de dimensões mais altas e mais complexas, computadores maiores e mais rápidos sozinhos raramente são suficientes para superar o desafio.\nMetropolis – Implementação\nNo nosso exemplo didático vamos partir do pressuposto que \\(J_t(\\theta^* | \\theta^{t-1})\\) é simétrico à \\(J_t (\\theta^* | \\theta^{t-1}) = J_t(\\theta^{t-1}|\\theta^*)\\), portanto vamos apenas demonstrar o algoritmo de Metropolis (e não o algoritmo de Metropolis-Hastings).\nO Stan (Carpenter et al., 2017) (e consequentemente seu ecossistema inteiro de pacotes) não tem implementações de outros algoritmos a não ser o HMC (Hamiltonean Monte Carlo), portanto abaixo criei um amostrador Metropolis para o nosso exemplo didático. No fim ele imprime a porcentagem total de aceitação das propostas. Aqui estamos usando a mesma distribuição de propostas para tanto \\(X\\) e \\(Y\\): uma distribuição uniforme parameterizada com um parâmetro largura width:\n\\[\nX \\sim \\text{Uniforme} \\left( X - \\frac{\\text{largura}}{2}, X + \\frac{\\text{largura}}{2} \\right) \\\\\nY \\sim \\text{Uniforme} \\left( Y - \\frac{\\text{largura}}{2}, Y + \\frac{\\text{largura}}{2} \\right)\n\\] O pacote mnormt possui algumas funcionalidades para lidar com distribuições multivariadas, a função dmnorm() em especial calcula a função densidade de probabilidade (FDP)4 de uma distribuição normal multivariada, que é usada no cálculo proporção das probabilidades \\(r\\):\n\\[\n\\begin{aligned}\nr &= \\frac{\n\\operatorname{FDP}\\left(\n\\text{Normal Multivariada} \\left(\n\\begin{bmatrix}\nx_{\\text{proposto}} \\\\\ny_{\\text{proposto}}\n\\end{bmatrix}\n\\right)\n\\Bigg|\n\\text{Normal Multivariada} \\left(\n\\begin{bmatrix}\n\\mu_X \\\\\n\\mu_Y\n\\end{bmatrix}, \\mathbf{\\Sigma}\n\\right)\n\\right)}\n{\n\\operatorname{FDP}\\left(\n\\text{Normal Multivariada} \\left(\n\\begin{bmatrix}\nx_{\\text{atual}} \\\\\ny_{\\text{atual}}\n\\end{bmatrix}\n\\right)\n\\Bigg|\n\\text{Normal Multivariada} \\left(\n\\begin{bmatrix}\n\\mu_X \\\\\n\\mu_Y\n\\end{bmatrix}, \\mathbf{\\Sigma}\n\\right)\n\\right)}\\\\\n&=\\frac{\\operatorname{FDP}_{\\text{proposto}}}{\\operatorname{FDP}_{\\text{atual}}}\\\\\n&= \\exp\\Big(\n\\log\\left(\\operatorname{FDP}_{\\text{proposto}}\\right)\n-\n\\log\\left(\\operatorname{FDP}_{\\text{atual}}\\right)\n\\Big)\n\\end{aligned}\n\\]\n\n\nmetropolis <- function(S, half_width,\n                       mu_X = 0, mu_Y = 0,\n                       sigma_X = 1, sigma_Y = 1,\n                       rho,\n                       start_x, start_y,\n                       seed = 123) {\n   set.seed(seed)\n   Sigma <- diag(2)\n   Sigma[1, 2] <- rho\n   Sigma[2, 1] <- rho\n   draws <- matrix(nrow = S, ncol = 2)\n   x <- start_x\n   y <- start_y\n   accepted <- 0\n   draws[1, 1] <- x\n   draws[1, 2] <- y\n   for (s in 2:S) {\n      x_ <- runif(1, x - half_width, x + half_width)\n      y_ <- runif(1, y - half_width, y + half_width)\n      r <- exp(mnormt::dmnorm(c(x_, y_), mean = c(mu_X, mu_Y), varcov = Sigma, log = TRUE) -\n                        mnormt::dmnorm(c(x, y), mean = c(mu_X, mu_Y), varcov = Sigma, log = TRUE))\n      if (r > runif(1, 0, 1)) {\n        x <- x_\n        y <- y_\n        accepted <- accepted + 1\n      }\n      draws[s, 1] <- x\n      draws[s, 2] <- y\n   }\n   print(paste0(\"Taxa de aceitação \", accepted / S))\n   return(draws)\n}\n\n\n\n\n\nn_sim <- 1e4\n\n\n\nVamos executar nosso algoritmo Metropolis com 10,000 iterações.\n\n\nX_met <- metropolis(\n  S = n_sim, half_width = 2.75,\n  mu_X = 0, mu_Y = 0,\n  sigma_X = 1, sigma_Y = 1,\n  rho = r,\n  start_x = -2.5, start_y = 2.5\n)\n\n\n[1] \"Taxa de aceitação 0.2076\"\n\nhead(X_met, 7)\n\n\n      [,1] [,2]\n[1,] -2.50  2.5\n[2,] -2.50  2.5\n[3,] -2.50  2.5\n[4,] -2.50  2.5\n[5,] -2.50  2.5\n[6,] -1.52  2.9\n[7,]  0.68  1.5\n\nNa nossa primeira execução do algoritmo Metropolis temos como resultado uma matriz X_met com 10,000 linhas e 2 colunas (uma para cada valor de \\(X\\) e \\(Y\\), que passarei a chamar de \\(\\theta_1\\) e \\(\\theta_2\\), respectivamente). Vejam que a aceitação das propostas ficou em 20.8%, o esperado para algoritmos Metropolis (em torno de 20-25%) (Roberts, Gelman, & Gilks, 1997).\nPara métricas de convergência e desempenho vamos usar a função rstan::monitor() que simula um print(stanfit)5mas para matrizes.\n\n\nres <- monitor(X_met, digits_summary = 1)\n\n\nInference for the input samples (2 chains: each with iter = 10000; warmup = 5000):\n\n     Q5 Q50 Q95 Mean SD  Rhat Bulk_ESS Tail_ESS\nV1 -1.6   0 1.7    0  1     1      952      909\n\nFor each parameter, Bulk_ESS and Tail_ESS are crude measures of \neffective sample size for bulk and tail quantities respectively (an ESS > 100 \nper chain is considered good), and Rhat is the potential scale reduction \nfactor on rank normalized split chains (at convergence, Rhat <= 1.05).\n\nneff <- res[, \"n_eff\"]\nreff <- mean(neff / (nrow(X_met))) #  9.5%\n\n\n\nVejam que o número de amostras eficientes em relação ao número total de iterações reff é 9,5% para todas as iterações incluindo warm-up.\nMetropolis – Intuição Visual\nEu acredito que uma boa intuição visual, mesmo que você não tenha entendido nenhuma fórmula matemática, é a chave para você começar a jornada de aprendizagem. Portanto fiz algumas animações com GIFs.\nA animação na figura 6 mostra as 100 primeiras simulações do algoritmo Metropolis usado para gerar X_met. Vejam que em diversas iterações a proposta é recusada e o algoritmo amostra os parâmetros \\(\\theta_1\\) e \\(\\theta_2\\) do estado anterior (que se torna o atual, pois a proposta é recusada).\nObservação: HPD é a sigla para Highest Probability Density (que é o intervalo de 90% de probabilidade da posterior).\n\n\ndf100 <- data.frame(\n    id = rep(1, 100),\n    iter = 1:100,\n    th1 = X_met[1:100, 1],\n    th2 = X_met[1:100, 2],\n    th1l = c(X_met[1, 1], X_met[1:(100 - 1), 1]),\n    th2l = c(X_met[1, 2], X_met[1:(100 - 1), 2])\n)\n\nlabs1 <- c(\"Amostras\", \"Iterações do Algoritmo\", \"90% HPD\")\n\np1 <- ggplot() +\n  geom_jitter(data = df100, width = 0.05, height = 0.05,\n             aes(th1, th2, group = id, color = \"1\"), alpha = 0.3) +\n  geom_segment(data = df100, aes(x = th1, xend = th1l, color = \"2\",\n                                 y = th2, yend = th2l)) +\n  stat_ellipse(data = dft, aes(x = X1, y = X2, color = \"3\"), level = 0.9) +\n  coord_cartesian(xlim = c(-3, 3), ylim = c(-3, 3)) +\n  labs(\n    title = \"Metropolis\", subtitle = \"100 Amostragens Iniciais\",\n    x = expression(theta[1]), y = expression(theta[2])) +\n  scale_color_manual(values = c(\"red\", \"forestgreen\", \"blue\"), labels = labs1) +\n  guides(color = guide_legend(override.aes = list(\n    shape = c(16, NA, NA), linetype = c(0, 1, 1)))) +\n  theme(legend.position = \"bottom\", legend.title = element_blank())\n\nanimate(p1 +\n  transition_reveal(along = iter) +\n  shadow_trail(0.01),\n  # animation options\n  height = 7, width = 7, units = \"in\", res = 300\n)\n\n\n\n\nFigure 6: Animação Metropolis\n\n\n\nNa figura 7 é possível ver como ficaram as primeiras 1.000 simulações excluindo 1.000 iterações iniciais como warmup.\n\n\n# Take all the 10,000 observations after warmup of 1,000\nwarm <- 1e3\ndfs <- data.frame(\n  th1 = X_met[(warm + 1):nrow(X_met), 1],\n  th2 = X_met[(warm + 1):nrow(X_met), 2]\n)\n\nlabs2 <- c(\"Amostras\", \"90% HPD\")\n\nggplot() +\n  geom_point(data = dfs[1:1000, ],\n             aes(th1, th2, color = \"1\"), alpha = 0.3) +\n  stat_ellipse(data = dft, aes(x = X1, y = X2, color = \"2\"), level = 0.9) +\n  coord_cartesian(xlim = c(-3, 3), ylim = c(-3, 3)) +\n  labs(\n    title = \"Metropolis\", subtitle = \"1.000 Amostragens Iniciais\",\n    x = expression(theta[1]), y = expression(theta[2])) +\n  scale_color_manual(values = c(\"steelblue\", \"blue\"), labels = labs2) +\n  guides(color = guide_legend(override.aes = list(\n    shape = c(16, NA), linetype = c(0, 1), alpha = c(1, 1)))) +\n  theme(legend.position = \"bottom\", legend.title = element_blank())\n\n\n\n\nFigure 7: Primeiras 1.000 simulações Metropolis após descarte de 1.000 iterações como warmup\n\n\n\nE na figura 8 é possível ver as restantes 9.000 simulações excluindo 1.000 iterações iniciais como warmup.\n\n\n# Show all 10,000 samples\nggplot() +\n  geom_point(data = dfs,\n             aes(th1, th2, color = \"1\"), alpha = 0.3) +\n  stat_ellipse(data = dft, aes(x = X1, y = X2, color = \"2\"), level = 0.9) +\n  coord_cartesian(xlim = c(-3, 3), ylim = c(-3, 3)) +\n  labs(\n    title = \"Metropolis\", subtitle = \"10.000 Amostragens\",\n    x = expression(theta[1]), y = expression(theta[2])) +\n  scale_color_manual(values = c(\"steelblue\", \"blue\"), labels = labs2) +\n  guides(color = guide_legend(override.aes = list(\n    shape = c(16, NA), linetype = c(0, 1), alpha = c(1, 1)))) +\n  theme(legend.position = \"bottom\", legend.title = element_blank())\n\n\n\n\nFigure 8: 9.000 simulações Metropolis após descarte de 1.000 iterações como warmup\n\n\n\nGibbs\nPara contornar o problema de baixa taxa de aceitação do algoritmo de Metropolis (e Metropolis-Hastings) foi desenvolvido o algoritmo de Gibbs que não possui uma regra de aceitação/rejeição para a mudança de estado da corrente Markov. Todas as propostas são aceitas.\nO algoritmo de Gibbs teve ideia original concebida pelo físico Josiah Willard Gibbs (figura 9), em referência a uma analogia entre um algoritmo de amostragem e a física estatística (statistical physics um ramo da física que tem sua base em mecânica estatística statistical mechanics). O algoritmo foi descrito pelos irmãos Stuart e Donald Geman (figura 9) em 1984 (Geman & Geman, 1984), cerca de oito décadas após a morte de Gibbs.\n\n\n\nFigure 9: Da esquerda para direita: Josiah Gibbs,Stuart Geman e Donald Geman – Figuras de https://www.wikipedia.org\n\n\n\nO algoritmo de Gibbs é muito útil em espaços amostrais multidimensionais (no qual há bem mais que 2 parâmetros a serem amostrados da probabilidade posterior). Também é conhecido como amostragem condicional alternativa (alternating conditional sampling), pois amostramos sempre um parâmetro condicionado à probabilidade dos outros parâmetros do modelo.\nO algoritmo de Gibbs pode ser visto como um caso especial do algoritmo de Metropolis-Hastings porque todas as propostas são aceitas (Gelman, 1992).\nAlgoritmo de Gibbs\nA essência do algoritmo de Gibbs é a amostragem de parâmetros condicionada à outros parâmetros \\(P(\\theta_1 | \\theta_2, \\dots \\theta_n)\\).\nO algoritmo de Gibbs pode ser descrito na seguinte maneira6 (\\(\\theta\\) é o parâmetro, ou conjunto de parâmetros, de interesse e \\(y\\) são os dados):\nDefina \\(p(\\theta_1), p(\\theta_2), \\dots, p(\\theta_n)\\): a probabilidade prévia (prior) de cada um dos parâmetros \\(\\theta_n\\).\nAmostre um ponto inicial \\(\\theta^0_1, \\theta^0_2, \\dots, \\theta^0_n\\). Geralmente amostramos de uma distribuição normal ou de uma distribuição especificada como a distribuição prévia (prior) de \\(\\theta_n\\).\nPara \\(t = 1,2,\\dots\\):\n\\[\\begin{aligned}\n \\theta^t_1 &\\sim p(\\theta_1 | \\theta^0_2, \\dots, \\theta^0_n) \\\\\n \\theta^t_2 &\\sim p(\\theta_2 | \\theta^{t-1}_1, \\dots, \\theta^0_n) \\\\\n &\\vdots \\\\\n \\theta^t_n &\\sim p(\\theta_n | \\theta^{t-1}_1, \\dots, \\theta^{t-1}_{n-1})\n \\end{aligned}\\]\nLimitações do Algoritmo de Gibbs\nA principal limitação do algoritmo de Gibbs é com relação a amostragem condicional alternativa.\nSe compararmos com o algoritmo Metropolis (e consequentemente Metropolis-Hastings) temos propostas aleatórias de uma distribuição de propostas na qual amostramos cada parâmetro incondicionalmente à outros parâmetros. Para que as propostas nos levem a locais corretos da probabilidade posterior para amostrarmos temos uma regra de aceitação/rejeição dessas propostas, se não as amostras do algoritmo de Metropolis não se aproximariam à distribuição-alvo de interesse. As mudanças de estado da corrente Markov são então executadas multidimensionalmente7. Como você viu nas figuras 6, 7 e 8 de intuição visual do algoritmo de Metropolis, em um espaço 2-D (como é o nosso exemplo didático bivariado normal), quando há uma mudança de estado na corrente Markov, o novo local de proposta considera tanto \\(\\theta_1\\) quanto \\(\\theta_2\\), provocando uma movimentação na diagonal no espaço amostral 2-D.\nNo caso do algoritmo de Gibbs, no nosso exemplo, essa movimentação se dá apenas em um único parâmetro, pois amostramos sequencialmente e condicionalmente à outros parâmetros. Isto provoca movimentos horizontais (no caso de \\(\\theta_1\\)) e movimentos verticais (no caso de \\(\\theta_2\\)), mas nunca movimentos diagonais como o que vemos no algoritmo de Metropolis.\nGibbs – Implementação\nO Stan (Carpenter et al., 2017) (e consequentemente seu ecossistema inteiro de pacotes) não tem implementações de outros algoritmos a não ser o HMC (Hamiltonian Monte Carlo), portanto abaixo criei um amostrador Gibbs para o nosso exemplo didático.\nAqui temos algumas coisas novas comparando com a implementação do amostrador Metropolis. Primeiro para amostrar condicionalmente os parâmetros \\(P(\\theta_1 | \\theta_2)\\) e \\(P(\\theta_2 | \\theta_1)\\), precisamos criar duas variáveis novas beta (\\(\\beta\\)) e lambda (\\(\\lambda\\)). Essas variáveis representam a correlação entre \\(X\\) e \\(Y\\) (\\(\\theta_1\\) e \\(\\theta_2\\) respectivamente). E então usamos essas variáveis na amostragem de \\(\\theta_1\\) e \\(\\theta_2\\):\n\\[\n\\begin{aligned}\n\\beta &= \\rho \\cdot \\frac{\\sigma_Y}{\\sigma_X} = \\rho \\\\\n\\lambda &= \\rho \\cdot \\frac{\\sigma_X}{\\sigma_Y} = \\rho \\\\\n\\sigma_{YX} &= 1 - \\rho^2\\\\\n\\sigma_{XY} &= 1 - \\rho^2\\\\\n\\theta_1 &\\sim \\text{Normal} \\bigg( \\mu_X + \\lambda \\cdot (y^* - \\mu_Y), \\sigma_{XY} \\bigg) \\\\\n\\theta_2 &\\sim \\text{Normal} \\bigg( \\mu_y + \\beta \\cdot (x^* - \\mu_X), \\sigma_{YX} \\bigg).\n\\end{aligned}\n\\]\n\n\ngibbs <- function(S,\n                  mu_X = 0, mu_Y = 0,\n                  sigma_X = 1, sigma_Y = 1,\n                  rho,\n                  start_x, start_y,\n                  seed = 123) {\n   set.seed(seed)\n   Sigma <- diag(2)\n   Sigma[1, 2] <- rho\n   Sigma[2, 1] <- rho\n   draws <- matrix(nrow = S, ncol = 2)\n   x <- start_x\n   y <- start_y\n   beta <- rho * sigma_Y / sigma_X\n   lambda <- rho * sigma_X / sigma_Y\n   sqrt1mrho2 <- sqrt(1 - rho^2)\n   sigma_YX <- sigma_Y * sqrt1mrho2\n   sigma_XY <- sigma_X * sqrt1mrho2\n   draws[1, 1] <- x\n   draws[1, 2] <- y\n   for (s in 2:S) {\n     if (s %% 2 == 0) {\n        y <- rnorm(1, mu_Y + beta * (x - mu_X), sigma_YX)\n     }\n     else {\n        x <- rnorm(1, mu_X + lambda * (y - mu_Y), sigma_XY)\n     }\n     draws[s, 1] <- x\n     draws[s, 2] <- y\n   }\n   return(draws)\n}\n\n\n\nVamos executar nosso algoritmo Gibbs com 10,000 iterações.\n\n\nX_gibbs <- gibbs(\n  S = n_sim,\n  mu_X = 0, mu_Y = 0,\n  sigma_X = 1, sigma_Y = 1,\n  rho = r,\n  start_x = -2.5, start_y = 2.5\n)\nhead(X_gibbs, 7)\n\n\n      [,1]  [,2]\n[1,] -2.50  2.50\n[2,] -2.50 -2.34\n[3,] -2.01 -2.34\n[4,] -2.01 -0.67\n[5,] -0.49 -0.67\n[6,] -0.49 -0.32\n[7,]  0.77 -0.32\n\nNa nossa primeira execução do algoritmo Gibbs temos como resultado uma matriz X_gibbs com 10,000 linhas e 2 colunas (as mesmas condições já mostradas no exemplo anterior com algoritmo Metropolis).\n\n\nres <- monitor(X_gibbs, digits_summary = 1)\n\n\nInference for the input samples (2 chains: each with iter = 10000; warmup = 5000):\n\n     Q5 Q50 Q95 Mean SD  Rhat Bulk_ESS Tail_ESS\nV1 -1.7   0 1.6    0  1     1     1156     1972\n\nFor each parameter, Bulk_ESS and Tail_ESS are crude measures of \neffective sample size for bulk and tail quantities respectively (an ESS > 100 \nper chain is considered good), and Rhat is the potential scale reduction \nfactor on rank normalized split chains (at convergence, Rhat <= 1.05).\n\nneff <- res[, \"n_eff\"]\nreff <- mean(neff / (nrow(X_gibbs) / 2)) #  23.2%\n\n\n\nVejam que o número de amostras eficientes em relação ao número total de iterações reff8 é 23% para todas as iterações incluindo warm-up. A eficiência do algoritmo Gibbs, no nosso exemplo didático, é o mais que dobro da eficiência do algoritmo de Metropolis (9,5% vs 23%).\nGibbs – Intuição Visual\nA animação na figura 10 mostra as 100 primeiras simulações do algoritmo Gibbs usado para gerar X_gibbs. Vejam que aqui não há movimentação na diagonal no espaço amostral devido à amostragem condicional alternativa dos parâmetros \\(\\theta_1\\) e \\(\\theta_2\\). A movimentação do algoritmo Gibbs no espaço amostral está condicionada a apenas um movimento por dimensão de parâmetro (que no nosso exemplo didático 2-D são as dimensões horizontais \\(\\theta_1\\) e verticais \\(\\theta_2\\)).\n\n\ndf100 <- data.frame(\n    id = rep(1, 100),\n    iter = 1:100,\n    th1 = X_gibbs[1:100, 1],\n    th2 = X_gibbs[1:100, 2],\n    th1l = c(X_gibbs[1, 1], X_gibbs[1:(100 - 1), 1]),\n    th2l = c(X_gibbs[1, 2], X_gibbs[1:(100 - 1), 2])\n)\n\nlabs1 <- c(\"Amostras\", \"Iterações do Algoritmo\", \"90% HPD\")\n\nind1 <- (1:50) * 2 - 1\ndf100s <- df100\ndf100s[ind1 + 1, 3:4] <- df100s[ind1, 3:4]\np1 <- ggplot() +\n  geom_point(data = df100s,\n             aes(th1, th2, group = id, color = \"1\")) +\n  geom_segment(data = df100, aes(x = th1, xend = th1l, color = \"2\",\n                                 y = th2, yend = th2l)) +\n  stat_ellipse(data = dft, aes(x = X1, y = X2, color = \"3\"), level = 0.9) +\n  coord_cartesian(xlim = c(-3, 3), ylim = c(-3, 3)) +\n  labs(\n    title = \"Gibbs\", subtitle = \"100 Amostragens Iniciais\",\n    x = expression(theta[1]), y = expression(theta[2])) +\n  scale_color_manual(values = c(\"red\", \"forestgreen\", \"blue\"), labels = labs1) +\n  guides(color = guide_legend(override.aes = list(\n    shape = c(16, NA, NA), linetype = c(0, 1, 1)))) +\n  theme(legend.position = \"bottom\", legend.title = element_blank())\n\nanimate(p1 +\n  transition_reveal(along = iter) +\n  shadow_trail(0.01),\n  # animation options\n  height = 7, width = 7, units = \"in\", res = 300\n)\n\n\n\n\nFigure 10: Animação Gibbs\n\n\n\nNa figura 11 é possível ver como ficaram as primeiras 1.000 simulações excluindo 1.000 iterações iniciais como warmup.\n\n\n# Take all the 10,000 observations after warmup of 1,000\nwarm <- 1e3\ndfs <- data.frame(\n  th1 = X_gibbs[(warm + 1):nrow(X_gibbs), 1],\n  th2 = X_gibbs[(warm + 1):nrow(X_gibbs), 2]\n)\n\nlabs2 <- c(\"Amostras\", \"90% HPD\")\n\nggplot() +\n  geom_point(data = dfs[1:1000, ],\n             aes(th1, th2, color = \"1\"), alpha = 0.3) +\n  stat_ellipse(data = dft, aes(x = X1, y = X2, color = \"2\"), level = 0.9) +\n  coord_cartesian(xlim = c(-3, 3), ylim = c(-3, 3)) +\n  labs(\n    title = \"Gibbs\", subtitle = \"1.000 Amostragens Iniciais\",\n    x = expression(theta[1]), y = expression(theta[2])) +\n  scale_color_manual(values = c(\"steelblue\", \"blue\"), labels = labs2) +\n  guides(color = guide_legend(override.aes = list(\n    shape = c(16, NA), linetype = c(0, 1), alpha = c(1, 1)))) +\n  theme(legend.position = \"bottom\", legend.title = element_blank())\n\n\n\n\nFigure 11: Primeiras 1.000 simulações Gibbs após descarte de 1.000 iterações como warmup\n\n\n\nE na figura 12 é possível ver as restantes 9.000 simulações excluindo 1.000 iterações iniciais como warmup.\n\n\n# Show all 10,000 samples\nggplot() +\n  geom_point(data = dfs,\n             aes(th1, th2, color = \"1\"), alpha = 0.3) +\n  stat_ellipse(data = dft, aes(x = X1, y = X2, color = \"2\"), level = 0.9) +\n  coord_cartesian(xlim = c(-3, 3), ylim = c(-3, 3)) +\n  labs(\n    title = \"Gibbs\", subtitle = \"10.000 Amostragens\",\n    x = expression(theta[1]), y = expression(theta[2])) +\n  scale_color_manual(values = c(\"steelblue\", \"blue\"), labels = labs2) +\n  guides(color = guide_legend(override.aes = list(\n    shape = c(16, NA), linetype = c(0, 1), alpha = c(1, 1)))) +\n  theme(legend.position = \"bottom\", legend.title = element_blank())\n\n\n\n\nFigure 12: 9.000 simulações Gibbs após descarte de 1.000 iterações como warmup\n\n\n\nO que acontece quando rodamos correntes Markov em paralelo?\nComo as correntes Markov são independentes, podemos executá-las em paralelo no computador. A chave para isso é definir pontos iniciais diferentes de cada corrente Markov (caso você use como ponto inicial uma amostra de uma distribuição prévia dos parâmetros isto não é um problema). Vamos usar o mesmo exemplo didático de uma distribuição normal bivariada \\(X\\) e \\(Y\\) que usamos nos exemplos anteriores, mas agora com 4 correntes Markov com diferentes pontos de início.\n\n\nstarts <- list(c(-2.5, 2.5),\n               c(2.5, -2.5),\n               c(-2.5, -2.5),\n               c(2.5, 2.5)\n               )\n\n\n\nCorrentes Markov em Paralelo – Metropolis\nPara criar 4 correntes Markov com pontos diferentes de início dos parâmetros, usamos 4 vezes o amostrador Metropolis que codificamos anterior, mas agora passamos diferentes argumentos start_x e start_y, além de diferentes seed do pseudogerador de número aleatórios para termos diferentes comportamentos das correntes Markov. Todo o resultado é combinado em um dataframe com uma coluna id representando o número de cada corrente (de 1 a 4).\n\n\nlibrary(dplyr)\nn_sim <- 100\nXs_met <- bind_rows(\n  as_tibble(metropolis(S = n_sim, half_width = 2.75,\n                       mu_X = 0, mu_Y = 0,\n                       sigma_X = 1, sigma_Y = 1,\n                       rho = r,\n                       start_x = -2.5, start_y = 2.5,\n                       seed = 1)),\n  as_tibble(metropolis(S = n_sim, half_width = 2.75,\n                       mu_X = 0, mu_Y = 0,\n                       sigma_X = 1, sigma_Y = 1,\n                       rho = r,\n                       start_x = 2.5, start_y = -2.5,\n                       seed = 2)),\n  as_tibble(metropolis(S = n_sim, half_width = 2.75,\n                       mu_X = 0, mu_Y = 0,\n                       sigma_X = 1, sigma_Y = 1,\n                       rho = r,\n                       start_x = -2.5, start_y = -2.5,\n                       seed = 3)),\n  as_tibble(metropolis(S = n_sim, half_width = 2.75,\n                       mu_X = 0, mu_Y = 0,\n                       sigma_X = 1, sigma_Y = 1,\n                       rho = r,\n                       start_x = 2.5, start_y = 2.5,\n                       seed = 4)),\n  .id = \"chain\")\n\n\n[1] \"Taxa de aceitação 0.28\"\n[1] \"Taxa de aceitação 0.19\"\n[1] \"Taxa de aceitação 0.29\"\n[1] \"Taxa de aceitação 0.15\"\n\nVejam que aqui não estamos interessados em muitas iterações, portanto cada corrente Markov amostrará 100 amostras dando um total de 400 amostras.\nHouveram algumas mudanças significativas na taxa de aprovação das propostas Metropolis. Todas ficaram em torno de 15%-29%, isso é por conta do baixo número de amostras (100), caso as amostras fosse maiores veremos esses valores convergirem para próximo de 20% conforme o exemplo anterior de 10.000 amostras com uma única corrente. errores Na figura 13 é possível ver as 4 correntes Markov do algoritmo de Metropolis explorando o espaço amostral.\n\n\ndfs100_met <- Xs_met %>%\n  group_by(chain) %>%\n  transmute(\n    chain,\n    iter = 1:n_sim,\n    th1 = V1,\n    th2 = V2,\n    th1l = dplyr::lag(V1, default = V1[1]),\n    th2l = dplyr::lag(V2, default = V2[1])\n  ) %>%\n  ungroup()\np1 <- ggplot(dfs100_met) +\n  geom_jitter(width = 0.05, height = 0.05,\n              aes(th1, th2, group = chain, color = chain), alpha = 0.3) +\n  geom_segment(aes(x = th1, xend = th1l, y = th2, yend = th2l,\n                   color = chain)) +\n  #geom_point(aes(x = th1, y = th2, color = chain)) +\n  stat_ellipse(data = dft, aes(x = X1, y = X2), color = \"black\", level = 0.9) +\n  coord_cartesian(xlim = c(-3, 3), ylim = c(-3, 3)) +\n  labs(\n    title = \"Metropolis\",subtitle = \"100 Amostragens Iniciais\",\n    x = expression(theta[1]), y = expression(theta[2])) +\n  scale_color_brewer(palette = \"Set1\") +\n  theme(legend.position = \"NULL\")\n\nanimate(p1 +\n          transition_reveal(along = iter) +\n          shadow_trail(0.01),\n        # animation options\n        height = 7, width = 7, units = \"in\", res = 300\n)\n\n\n\n\nFigure 13: Animação Metropolis – 4 correntes Markov em Paralelo\n\n\n\nCorrentes Markov em Paralelo – Gibbs\nSimilar ao exemplo das correntes Markov em paralelo com o algoritmo Metropoli, para criarmos 4 correntes Markov com pontos diferentes de início dos parâmetros, usamos 4 vezes o amostrador Gibbs que codificamos anterior, mas agora passamos diferentes argumentos start_x e start_y, além de diferentes seed do pseudogerador de número aleatórios para termos diferentes comportamentos das correntes Markov. Todo o resultado é combinado em um dataframe com uma coluna id representando o número de cada corrente (de 1 a 4).\n\n\nXs_gibbs <- bind_rows(\n  as_tibble(gibbs(S = n_sim,\n                       mu_X = 0, mu_Y = 0,\n                       sigma_X = 1, sigma_Y = 1,\n                       rho = r,\n                       start_x = -2.5, start_y = 2.5,\n                       seed = 1)),\n  as_tibble(gibbs(S = n_sim,\n                       mu_X = 0, mu_Y = 0,\n                       sigma_X = 1, sigma_Y = 1,\n                       rho = r,\n                       start_x = 2.5, start_y = -2.5,\n                       seed = 2)),\n  as_tibble(gibbs(S = n_sim,\n                       mu_X = 0, mu_Y = 0,\n                       sigma_X = 1, sigma_Y = 1,\n                       rho = r,\n                       start_x = -2.5, start_y = -2.5,\n                       seed = 3)),\n  as_tibble(gibbs(S = n_sim,\n                       mu_X = 0, mu_Y = 0,\n                       sigma_X = 1, sigma_Y = 1,\n                       rho = r,\n                       start_x = 2.5, start_y = 2.5,\n                       seed = 4)),\n  .id = \"chain\")\n\n\n\nVejam que aqui não estamos interessados em muitas iterações, portanto cada corrente Markov amostrará 100 amostras dando um total de 400 amostras.\nNa figura 14 é possível ver as 4 correntes Markov do algoritmo de Gibbs explorando o espaço amostral.\n\n\ndfs100_gibbs <- Xs_gibbs %>%\n  group_by(chain) %>%\n  transmute(\n    chain,\n    iter = 1:n_sim,\n    th1 = V1,\n    th2 = V2,\n    th1l = dplyr::lag(V1, default = V1[1]),\n    th2l = dplyr::lag(V2, default = V2[1])\n  ) %>%\n  ungroup()\np1 <- ggplot(dfs100_gibbs) +\n  geom_point(aes(x = th1, y = th2, group = chain, color = chain)) +\n  geom_segment(aes(x = th1, xend = th1l, y = th2, yend = th2l,\n                   color = chain)) +\n  stat_ellipse(data = dft, aes(x = X1, y = X2), color = \"black\", level = 0.9) +\n  coord_cartesian(xlim = c(-3, 3), ylim = c(-3, 3)) +\n  labs(\n    title = \"Gibbs\", subtitle = \"100 Amostragens Iniciais\",\n    x = expression(theta[1]), y = expression(theta[2])) +\n  scale_color_brewer(palette = \"Set1\") +\n  theme(legend.position = \"NULL\")\n\nanimate(p1 +\n  transition_reveal(along = iter) +\n  shadow_trail(0.01),\n  # animation options\n  height = 7, width = 7, units = \"in\", res = 300\n)\n\n\n\n\nFigure 14: Animação Gibbs – 4 correntes Markov em Paralelo\n\n\n\nHamiltonian Monte Carlo – HMC\nOs problemas de baixas taxas de aceitação de propostas das técnicas de Metropolis e do desempenho baixo do algoritmo de Gibbs em problemas multidimensionais nas quais a topologia da posterior é complexa fizeram com que surgisse uma nova técnica MCMC usando dinâmica Hamiltoniana (em homenagem ao físico irlandês William Rowan Hamilton (1805-1865) figura 15). O nome em inglês dessa técnica é Hamiltonean Monte Carlo – HMC.\n\n\n\nFigure 15: William Rowan Hamilton. Figura de https://www.wikipedia.org\n\n\n\nO HMC é uma adaptação da técnica de Metropolis e emprega um esquema guiado de geração de novas proposta: isso melhora a taxa de aceitação de propostas e, consequentemente, a eficiência. Mais especificamente, o HMC usa o gradiente do log posterior para direcionar a cadeia de Markov para regiões de maior densidade posterior, onde a maioria das amostras são coletadas. Como resultado, uma corrente Markov com o algoritmo HMC bem ajustada aceitará propostas em uma taxa muito mais alta do que o algoritmo Metropolis tradicional (Roberts, Gelman, & Gilks, 1997).\nHMC foi inicialmente descrito na literatura de física Duane, Kennedy, Pendleton, & Roweth (1987) (que chamaram de “hybrid” Monte Carlo – HMC). Logo depois, HMC foi aplicado a problemas estatísticos por Radford M. Neal (1994) (que chamou de Hamiltonean Monte Carlo – HMC). Para uma discussão aprofundada (que não é o foco deste conteúdo) de HMC eu recomendo Radford M. Neal (2011) e Betancourt (2017).\nHMC usa dinâmica Hamiltoniana aplicada para partículas explorando a topologia de uma probabilidade posterior. Em algumas simulações Metropolis possui taxa de aceitação de aproximadamente 23%, enquanto HMC 65% (Gelman et al., 2013b). Além de explorar melhor a topologia da posterior e tolerar topologias complexas, HMC é muito mais eficiente que Metropolis e não sofre do problema de correlação dos parâmetros que Gibbs.\nPara cada componente \\(\\theta_j\\), o HMC adiciona uma variável de momento \\(\\phi_j\\). A densidade posterior \\(P(\\theta | y)\\) é incrementada por uma distribuição independente \\(P(\\phi)\\) dos momentos, definindo assim uma distribuição conjunta:\n\\[\nP(\\theta, \\phi | y) = P(\\phi) \\cdot P(\\theta|y)\n\\]\nO HMC usa uma distribuição de propostas que muda dependendo do estado atual na corrente Markov. O HMC descobre a direção em que a distribuição posterior aumenta, chamada de gradiente, e distorce a distribuição de propostas em direção ao gradiente. No algoritmo de Metropolis, a distribuição das propostas seria uma distribuição Normal (geralmente) centrada na posição atual, de modo que saltos acima ou abaixo da posição atual teriam a mesma probabilidade de serem propostos. Mas o HMC gera propostas de maneira bem diferente.\nVocê pode imaginar que para distribuições posteriores de alta dimensão que têm vales diagonais estreitos e até mesmo vales curvos, a dinâmica do HMC encontrará posições propostas que são muito mais promissoras do que uma distribuição de proposta simétrica ingênua, e mais promissoras do que a amostragem de Gibbs, que pode obter preso em paredes diagonais.\nA probabilidade da corrente Markov mudar de estado no algoritmo HMC é definida como:\n\\[\nP_{\\text{mudar}} = \\min\\left({\\frac{P(\\theta_{\\text{proposto}}) \\cdot P(\\phi_{\\text{proposto}})}{P(\\theta_{\\text{atual}})\\cdot P(\\phi_{\\text{atual}})}}, 1\\right),\n\\]\nonde \\(\\phi\\) é o momento.\nDistribuição dos Momentos – \\(P(\\phi)\\)\nNormalmente damos a \\(\\phi\\) uma distribuição normal multivariada com média 0 e covariância de \\(\\mathbf{M}\\), uma “matriz de massa.” Para mantêr as coisas um pouco mais simples, usamos uma matriz de massa diagonal \\(\\mathbf{M}\\). Isso faz com que os componentes de \\(\\phi\\) sejam independentes com \\(\\phi_j \\sim \\text{Normal}(0, M_{jj})\\)\nAlgoritmo de HMC\nO algoritmo de HM é bem similar ao algoritmo Metropolis mas com a inclusão do momento \\(\\phi\\) como uma maneira de quantificar o gradiente da posterior.\nAmostre \\(\\phi\\) de uma \\(\\text{Normal}(0,\\mathbf{M})\\)\nSimultaneamente amostre \\(\\theta\\) e \\(\\phi\\) com \\(L\\) leapfrog steps (não sei como traduzir isso, talvez múltiplos passos) cada um reduzido por um fator \\(\\epsilon\\). Em um leapfrog step, tanto \\(\\theta\\) quanto \\(\\phi\\) são alterados, um em relação ao outro. Repita os seguintes passos \\(L\\) vezes:\nUse o gradiente do log da posterior9 de \\(\\theta\\) para produzir um meio-salto(half-step) de \\(\\phi\\):\n\\[\\phi \\leftarrow \\phi + \\frac{1}{2} \\epsilon \\frac{d \\log p(\\theta | y)}{d \\theta}\\]\nUse o vetor de momentos \\(\\phi\\) para atualizar o vetor de parâmetros \\(\\theta\\):\n\\[\\theta \\leftarrow \\theta + \\epsilon \\mathbf{M}^{-1} \\phi\\]\nNovamente use o gradiente de \\(\\theta\\) para produzir um meio-salto(half-step) de \\(\\phi\\):\n\\[\\phi \\leftarrow \\phi + \\frac{1}{2} \\epsilon \\frac{d \\log p(\\theta | y)}{d \\theta}\\]\n\nDesigne \\(\\theta^{t-1}\\) e \\(\\phi^{t-1}\\) como os valores do vetor de parâmetros e do vetor de momentos, respectivamente, no início do processo de leapfrog (etapa 2) e \\(\\theta^*\\) e \\(\\phi^*\\) como os valores após \\(L\\) passos. Como regra de aceitação/rejeição calcule:\n\\[r = \\frac{p(\\theta^* | y) p(\\phi^*)}{p(\\theta^{t-1} | y) p(\\phi^{-1})}\\]\nDesigne:\n\\[\\theta^t\n \\begin{cases}\n \\theta^* & \\text{with probability min($r$,1)} \\\\\n \\theta^{t-1} & \\text{caso contrário}\n \\end{cases}\\]\nHMC – Implementação\nPara HMC, não vou codificar o algoritmo na mão, pois envolve derivadas que não vai ser muito eficiente no R. Para isso temos o Stan. O arquivo hmc.rds possui 1.000 amostragens com um leapfrog \\(L = 40\\), então no total são 40.001 iterações10. O exemplo é o mesmo que usamos para Metropolis e Gibbs, uma distribuição normal multivariada de \\(X\\) e \\(Y\\) (ambos com média 0 e desvio padrão 1), com correlação 0.8 (\\(\\rho = 0.8\\)):\n\\[\n\\begin{bmatrix}\nX \\\\\nY\n\\end{bmatrix} \\sim \\text{Normal Multivariada} \\left(\n\\begin{bmatrix}\n0 \\\\\n0\n\\end{bmatrix}, \\mathbf{\\Sigma}\n\\right) \\\\\n\\mathbf{\\Sigma} \\sim\n\\begin{pmatrix}\n1 & 0.8 \\\\\n0.8 & 1\n\\end{pmatrix}\n\\]\n\n\nload(here::here(\"R\", \"hmc.RData\"))\ndf <- tibble(id = rep(1, 40000),\n                 iter = rep(1:1000, each = 40),\n                 th1 = tt[1:40000, 1],\n                 th2 = tt[1:40000, 2],\n                 th1l = c(tt[1, 1], tt[1:(40000 - 1), 1]),\n                 th2l = c(tt[1, 2], tt[1:(40000 - 1), 2]))\n\n\n\n\n\nX_hmc <- tt[seq(2, 40001, by = 40), ]\nres <- monitor(X_hmc, digits_summary = 1)\n\n\nInference for the input samples (2 chains: each with iter = 1000; warmup = 500):\n\n     Q5  Q50 Q95 Mean  SD  Rhat Bulk_ESS Tail_ESS\nV1 -1.6 -0.1 1.4 -0.1 0.9     1      604      655\n\nFor each parameter, Bulk_ESS and Tail_ESS are crude measures of \neffective sample size for bulk and tail quantities respectively (an ESS > 100 \nper chain is considered good), and Rhat is the potential scale reduction \nfactor on rank normalized split chains (at convergence, Rhat <= 1.05).\n\nneff <- res[, \"n_eff\"]\nreff <- mean(neff / (nrow(X_hmc))) #  61%!!!\n\n\n\nNa nossa execução do algoritmo HMC temos como resultado uma matriz X_hmc com 100 linhas e 2 colunas (as mesmas condições já mostradas nos exemplos anteriores com algoritmo Metropolis e Gibbs, porém agora somente com 1.000 amostras).\nVejam que o número de amostras eficientes em relação ao número total de iterações reff é 61% para todas as iterações incluindo warm-up (no caso 1 leapfrog step \\(L = 1\\)). A eficiência do algoritmo HMC, no nosso exemplo didático, é o mais que 6x a eficiência do algoritmo de Metropolis (9,5% vs 61%) e quase 3x a eficiência do Gibbs (23% vs 61%).\nHMC – Intuição Visual\nA animação na figura 16 mostra as 50 primeiras simulações do algoritmo HMC usado para gerar X_hmc. Vejam que aqui temos em amarelo temos os leapfrog steps moldandos e distorcendo a distribuição de propostas em direção ao gradiente da posterior (conduzindo-as para áreas de maior probabilidade da posterior) e em vermelho temos as amostras após os 40 leapfrog step \\(L = 40\\) de cada interação. Notem como a exploração da posterior é muito mais eficiente e focada em locais onde realmente a distribuição de interesse possui maior probabilidade.\n\n\nlabs3 <- c(\"Amostras\", \"Iterações do Algoritmo\", \"90% HPD\", \"Leapfrog\")\n# base plot\np0 <- ggplot() +\n  stat_ellipse(data = dft, aes(x = X1, y = X2, color = \"3\"), level = 0.9) +\n  coord_cartesian(xlim = c(-3, 3), ylim = c(-3, 3)) +\n  labs(\n    title = \"HMC\", subtitle = \"50 Amostragens Iniciais\",\n    x = expression(theta[1]), y = expression(theta[2])) +\n  scale_color_manual(values = c(\"red\", \"forestgreen\", \"blue\", \"yellow\"), labels = labs3) +\n  guides(color = guide_legend(override.aes = list(\n    shape = c(16, NA, NA, 16), linetype = c(0, 1, 1, 0)))) +\n  theme(legend.position = \"bottom\", legend.title = element_blank())\n\n# first 100 iterations\ndf50 <- df %>% filter(iter <= 50)\npp <- p0 + geom_point(data = df50,\n                      aes(th1, th2, color = \"4\"), alpha = 0.3, size = 1) +\n  geom_segment(data = df50,\n               aes(x = th1, xend = th1l, color = \"2\", y = th2, yend = th2l),\n               alpha = 0.5) +\n        geom_point(data = df50[seq(1, nrow(df50), by = 40), ],\n                   aes(th1, th2, color = \"1\"), size = 2)\n\nanimate(pp +\n  transition_manual(iter, cumulative = TRUE) +\n  shadow_trail(0.05),\n  # animation options\n  height = 7, width = 7, units = \"in\", res = 300\n)\n\n\n\n\nFigure 16: Animação HMC\n\n\n\nNa figura 17 é possível ver como ficaram as 1.000 simulações excluindo o primeiro leapfrog step \\(L = 1\\) como warmup.\n\n\n# Take all the 1,000 observations after warmup of 1,000\nwarm <- 1\ndfs <- data.frame(\n  th1 = tt[(warm + 1):nrow(tt), 1],\n  th2 = tt[(warm + 1):nrow(tt), 2]\n)\n\nggplot() +\n  geom_point(data = dfs[seq(1, nrow(dfs), by = 40), ],\n             aes(th1, th2, color = \"1\"), alpha = 0.3) +\n  stat_ellipse(data = dft, aes(x = X1, y = X2, color = \"2\"), level = 0.9) +\n  coord_cartesian(xlim = c(-3, 3), ylim = c(-3, 3)) +\n  labs(\n    title = \"HMC\", subtitle = \"1.000 Amostragens\",\n    x = expression(theta[1]), y = expression(theta[2])) +\n  scale_color_manual(values = c(\"steelblue\", \"blue\"), labels = labs2) +\n  guides(color = guide_legend(override.aes = list(\n    shape = c(16, NA), linetype = c(0, 1), alpha = c(1, 1)))) +\n  theme(legend.position = \"bottom\", legend.title = element_blank())\n\n\n\n\nFigure 17: 1.000 simulações HMC após descarte da primeira iteração como warmup\n\n\n\n“Não entendi nada…”\nSe você não entendeu nada até agora, não se desespere. Pule todas as fórmulas e pegue a intuição visual dos algoritmos. Veja as limitações de Metropolis e Gibbs e compare as animações e figuras com as do HMC. A superioridade de eficiência (mais amostras com baixa autocorrelação) e eficácia (mais amostras próximas das áreas de maior probabilidade da distribuição-alvo) é autoexplicativa pelas imagens.\nAlém disso, você provavelmente nunca terá que codificar o seu algoritmo HMC (Gibbs, Metropolis ou qualquer outro MCMC) na mão. Para isso há pacotes como Stan (e seu ecossistema de pacotes: rstan, PyStan, brms, rstanarm, Stan.jl etc.). Além disso, Stan implementa um HMC modificado com uma técnica chamada No-U-Turn Sampling (NUTS) (Hoffman & Gelman, 2011) que seleciona automaticamente os valores de \\(\\epsilon\\) (fator de redução) e \\(L\\) (quantidade de leapfrog steps).11 O desempenho do HMC é altamente sensível à esses dois “hiperparâmetros” (parâmetros que devem ser especificados pelo usuário). Em particular, se \\(L\\) for muito pequeno, o algoritmo exibe comportamento indesejável de um passeio aleatório, enquanto se \\(L\\) for muito grande, o algoritmo desperdiça eficiência computacional. NUTS usa um algoritmo recursivo para construir um conjunto de pontos candidatos prováveis que abrangem uma ampla faixa da distribuição de propostas, parando automaticamente quando começa a voltar e refazer seus passos (por isso que ele não dá meia-volta – No U-turn), adicionalmente NUTS também calibra automaticamente (e de maneira simultânea) \\(L\\) e \\(\\epsilon\\).\nImplementação com o rstanarm\nComo configuração padrão, o pacote rstanarm utiliza HMC com NUTS. Além disso, os argumentos padrões do HMC no rstanarm são:\n4 correntes Markov de amostragem (chains = 4); e\n2.000 iterações de cada corrente (iter = 2000)12.\nRelembrando o exemplo da aula de regressão linear, vamos usar o mesmo dataset kidiq. São dados de uma survey de mulheres adultas norte-americanas e seus respectivos filhos. Datado de 2007 possui 434 observações e 4 variáveis:\nkid_score: QI da criança;\nmom_hs: binária (0 ou 1) se a mãe possui diploma de ensino médio;\nmom_iq: QI da mãe; e\nmom_age: idade da mãe.\nVamos estimar um modelo de regressão linear Bayesiano na qual a variável dependente é kid_score e as independentes são mom_hs e mom_iq.\nO modelo é o especificado da seguinte maneira:\n\\[\n\\begin{aligned}\n\\alpha &\\sim \\text{Normal}(\\mu_y, s_y) \\\\\n\\beta_k &\\sim \\text{Normal}(0, 2.5 \\cdot \\frac{s_y}{s_x}) \\\\\n\\sigma &\\sim \\text{Exponencial}(\\frac{1}{s_y})\\\\\ny &\\sim \\text{Normal}(\\alpha + \\beta_1 x_1 + \\dots + \\beta_K x_K, \\sigma),\n\\end{aligned}\n\\]\nonde \\(s_x = \\tt{sd(x)}\\), \\[\ns_y =\n\\begin{cases}\n\\tt{sd(y)} & \\text{se } \\tt{family = gaussian}, \\\\\n1 & \\text{caso contrário}.\n\\end{cases}\n\\] e \\[\n\\mu_y =\n\\begin{cases}\n\\tt{mean(y)} & \\text{se } \\tt{family = gaussian}, \\\\\n0 & \\text{caso contrário}.\n\\end{cases}\n\\]\nNo caso temos apenas duas variáveis independentes, então \\(K=2\\) e \\(\\beta_1 = \\tt{mom\\_hs}\\) e \\(\\beta_2 = \\tt{mom\\_iq}\\); variável dependente \\(y = \\tt{kid\\_score}\\) e o erro do modelo $= _score ~ mom_hs + mom_iq`.\n\n\noptions(mc.cores = parallel::detectCores())\noptions(Ncpus = parallel::detectCores())\n\nlibrary(rstanarm)\nmodel <- stan_glm(\n  kid_score ~ mom_hs + mom_iq,\n  data = kidiq\n)\n\n\n\nMétricas da simulação MCMC\nUm modelo estimado pelo rstanarm pode ser inspecionado em relação ao desempenho da amostragem MCMC. Ao chamarmos a função summary() no modelo estimado há uma parte chamada MCMC diagnostics.\n\n\nsummary(model)\n\n\n\nModel Info:\n function:     stan_glm\n family:       gaussian [identity]\n formula:      kid_score ~ mom_hs + mom_iq\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 434\n predictors:   3\n\nEstimates:\n              mean   sd   10%   50%   90%\n(Intercept) 26.0    6.0 18.4  26.0  33.4 \nmom_hs       5.9    2.2  3.1   5.9   8.8 \nmom_iq       0.6    0.1  0.5   0.6   0.6 \nsigma       18.2    0.6 17.4  18.1  19.0 \n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 86.8    1.3 85.2  86.8  88.4 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.1  1.0  5365 \nmom_hs        0.0  1.0  4079 \nmom_iq        0.0  1.0  4724 \nsigma         0.0  1.0  3809 \nmean_PPD      0.0  1.0  4289 \nlog-posterior 0.0  1.0  1801 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nA seção MCMC diagnostics possui três colunas de valores para cada parâmetro estimado do modelo.\nNo nosso caso, temos três parâmetros importantes:\nvalor do coeficiente da variável mom_hs;\nvalor do coeficiente da variável mom_iq; e\nvalor do erro residual do modelo linear sigma. As três métricas são:\nmcse: Monte Carlo Standard Error, o erro de mensuração da amostragem Monte Carlo do parâmetro;\nn_eff: uma aproximação crua do número de amostras efetivas amostradas pelo MCMC estimada pelo valor de Rhat; e\nRhat: uma métrica de convergência e estabilidade da corrente Markov.\nA métrica mais importante para levarmos em consideração é a Rhat que é uma métrica que mensura se as correntes Markov são estáveis e convergiram para um valor durante o progresso total das simulações. Ela é basicamente a proporção de variação ao compararmos duas metades das correntes após o descarte dos warmups. Valor de 1 implica em convergência e estabilidade. Como padrão o Rhat deve ser menor que 1.01 para que a estimação Bayesiana seja válida (S. P. Brooks & Gelman, 1998; Gelman & Rubin, 1992).\nO que fazer se não obtermos convergência?\nDependendo do modelo e dos dados é possível que HMC (mesmo com NUTS) não atinja convergência. Nesse caso, ao rodar o modelo rstanarm dará diversos avisos de divergências. Aqui vou restringir o amostrador HMC do rstanarm para apenas 200 iterações com warmup padrão de metade das iterações (100) com duas correntes em paralelo (chains). Portanto, teremos \\(2 \\cdot (200 - 100) = 200\\) amostras de MCMC. se atente as mensagens de erro.\n\n\nbad_model <- stan_glm(\n  kid_score ~ mom_hs + mom_iq,\n  data = kidiq,\n  chains = 2,\n  iter = 200\n  )\n\n\n\nEsta é uma vantagem dos pacotes do ecossistema do Stan (incluindo o rstanarm). Quando o amostrador MCMC mostra problemas ele falha de uma maneira bem escandalosa com diversos avisos. Nunca ignore esses avisos, eles estão lá para te ajudar e indicar que seu modelo possui problemas sérios que devem ser inspecionados e sanados.\nE vemos que o Rhat dos parâmetros estimados do modelo estão bem acima do limiar de \\(1.01\\).\n\n\nsummary(bad_model)\n\n\n\nModel Info:\n function:     stan_glm\n family:       gaussian [identity]\n formula:      kid_score ~ mom_hs + mom_iq\n algorithm:    sampling\n sample:       200 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 434\n predictors:   3\n\nEstimates:\n              mean   sd    10%   50%   90%\n(Intercept)  13.6   17.3 -10.5  20.2  30.7\nmom_hs        5.9    3.3   2.3   5.6  10.2\nmom_iq        0.6    0.1   0.5   0.6   0.7\nsigma        24.6    9.5  17.9  19.1  42.1\n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 75.4   15.1 48.8  82.5  88.2 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse  Rhat  n_eff\n(Intercept)    12.7   1.9   2  \nmom_hs          0.2   1.0 305  \nmom_iq          0.0   1.0 245  \nsigma           6.1   2.6   2  \nmean_PPD       12.1   3.4   2  \nlog-posterior 102.6   3.2   2  \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nGráficos de Diagnósticos do MCMC\nO pacote rstanarm tem diversos gráficos interessantes de diagnósticos de convergência das simulações MCMC. Eu recomendo um guia de visualizações de modelos Bayesianos de Gabry, Simpson, Vehtari, Betancourt, & Gelman (2019).\nTraceplot\nA primeira coisa que devemos ver quando há mensagens de avisos sobre divergências ou valores indesejáveis de Rhat é inspecionar as correntes Markov para ver se elas estão estacionárias ou se divergiram durante a amostragem do MCMC. Fazemos isso com a função plot(stanreg, \"trace\"). Objetos stanreg são modelos oriundos do rstanarm. No nosso caso temos dois objetos stanreg: o model e o bad_model.\nO traceplot é a sobreposição das amostragens MCMC das correntes para cada parâmetro estimado (eixo vertical). A ideia é que as correntes se misturam e que não haja nenhuma inclinação ao longo das iterações (eixo horizontal). Isso demonstra que elas convergiram para um certo valor do parâmetro e se mantiveram nessa região durante boa parte (ou toda) da(a) amostragem das correntes Markov.\nDetalhe: o traceplot usa somente as iterações válidas, após a remoção das iterações de warmup.\nVejam na figura 18 o traceplot do modelo que as correntes Markov convergiram e ficaram estacionárias durante a amostragem do MCMC (afinal esse é o modelo model que designamos iter = 2.000 e chains = 4, ambos padrões do rstanarm). O ideal é sempre esse padrão no qual as correntes não apresentam uma tendência específica, ou seja, elas ficam geralmente “planas” na horizontal e não há uma grande variação de valores no eixo vertical (valor dos parâmetros). Esse padrão é muito parecido com “taturana.”\n\n\nplot(model, \"trace\")\n\n\n\n\nFigure 18: Traceplot do model\n\n\n\nNa figura 19 temos o traceplot do modelo que as correntes Markov não convergiram, o bad_model (designamos iter = 200 e chains = 2). Aqui você vê que se aumentarmos o período de warmup e o número de iterações, provavelmente as correntes Markov convergiriam e ficariam estacionárias na região de maior probabilidade da posterior (e, consequentemente, dos parâmetros de interesse).\n\n\nplot(bad_model, \"trace\")\n\n\n\n\nFigure 19: Traceplot do bad_model\n\n\n\nPosterior Predictive Check\nUm bom gráfico de diagnóstico é o posterior predictive check (PPC) que compara o histograma da variável dependente \\(y\\) contra o histograma variáveis dependentes simuladas pelo modelo \\(y_{\\text{rep}}\\) após a estimação dos parâmetros. A ideia é que os histogramas reais e simulados se misturem e não haja divergências. Fazemos isso com a função pp_check(stanreg).\nVejam na figura 20 o PPC do modelo que as correntes Markov convergiram e ficaram estacionárias durante a amostragem do MCMC (model). Podemos ver que as simulações \\(y_{\\text{rep}}\\) realmente capturaram a natureza da variável dependente \\(y\\).\n\n\npp_check(model)\n\n\n\n\nFigure 20: Posterior Preditive Check do model\n\n\n\nJá na na figura 21 temos o PPC do modelo que as correntes Markov não convergiram, o bad_model. Aqui vemos que as simulações \\(y_{\\text{rep}}\\) falharam em capturar a natureza da variável dependente \\(y\\). O PPC do bad_model também indica que se mantivéssemos um periodo maior de warmup e mais iterações das correntes Markov, provavelmente conseguiríamos ter um modelo que representasse muito bem o processo de geração de dados da nossa variável dependente \\(y\\).\n\n\npp_check(bad_model)\n\n\n\n\nFigure 21: Posterior Preditive Check do bad_model\n\n\n\nO quê fazer para convergir suas correntes Markov\nPrimeiro: Antes de fazer ajustes finos no número de correntes chains ou no número de iterações iter (entre outros …) saiba que o amostrador HMC-NUTS do Stan e seu ecossistema de pacotes (rstanarm incluso) é muito eficiente e eficaz em explorar as mais diversas complexas e “malucas” topologias de distribuições-alvo posterior. Os argumentos padrões (iter = 2000, chains = 4 e warmup = floor(iter/2)) funcionam perfeitamente para 99% dos casos (mesmo em modelos complexos). Dito isto, na maioria das vezes quando você possui problemas de amostragem e computacionais no seu modelo Bayesiano, o problema está na especificação do modelo e não no algoritmo de amostragem MCMC. Esta frase foi dita por Andrew Gelman (o “pai” do Stan) e é conhecido como o Folk Theorem (Gelman, 2008): “When you have computational problems, often there’s a problem with your model”.\nSe o seu modelo Bayesiano está com problemas de convergência há alguns passos que podem ser tentados13. Aqui listados do mais simples para o mais complexo:\nAumentar o número de iterações e correntes: primeira opção é aumentar o número de iterações do MCMC com o argumento iter = XXX e também é possível aumentar o número de correntes com o argumento chains = X. Lembrando que o padrão é iter = 2000 e chains = 4.\nAlterar a rotina de adaptação do HMC: a segunda opção é fazer com que o algoritmo de amostragem HMC fique mais conservador (com proposições de pulos menores). Isto pode ser alterado com o argumento adapt_delta da lista de opções control. control=list(adapt_delta=0.9). O padrão do adapt_delta é control=list(adapt_delta=0.8). Então qualquer valor entre \\(0.8\\) e \\(1.0\\) o torna mais conservador.\nReparametrização do Modelo: a terceira opção é reparametrizar o modelo. Há duas maneiras de parametrizar o modelo: a primeira com parametrização centrada (centered parameterization) e a segunda com parametrização não-centrada (non-centered parameterization). Não são assuntos que vamos cobrir aqui no curso. Recomendo o material de um dos desenvolvedores da linguagem Stan, Michael Betancourt.\nColetar mais dados: às vezes o modelo é complexo demais e precisamos de uma amostragem maior para conseguirmos estimativas estáveis.\nRepensar o modelo: falha de convergência quando temos uma amostragem adequada geralmente é por conta de uma especificação de priors e verossimilhança que não são compatíveis com os dados. Nesse caso, é preciso repensar o processo generativo de dados no qual os pressupostos do modelo estão ancorados.\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.4 (2021-02-15)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 20.10\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.9.0\nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.9.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n [1] rstanarm_2.21.1      Rcpp_1.0.6           dplyr_1.0.5         \n [4] patchwork_1.1.1      cowplot_1.1.1        rstan_2.21.2        \n [7] StanHeaders_2.21.0-7 MASS_7.3-53.1        ggforce_0.3.3       \n[10] gganimate_1.0.7      plotly_4.9.3         ggplot2_3.3.3       \n\nloaded via a namespace (and not attached):\n  [1] minqa_1.2.4        colorspace_2.0-0   ellipsis_0.3.1    \n  [4] ggridges_0.5.3     rsconnect_0.8.16   rprojroot_2.0.2   \n  [7] markdown_1.1       base64enc_0.1-3    farver_2.1.0      \n [10] DT_0.17            fansi_0.4.2        splines_4.0.4     \n [13] codetools_0.2-18   downlit_0.2.1      mnormt_2.0.2      \n [16] knitr_1.31         shinythemes_1.2.0  polyclip_1.10-0   \n [19] bayesplot_1.8.0    jsonlite_1.7.2     nloptr_1.2.2.2    \n [22] png_0.1-7          shiny_1.6.0        compiler_4.0.4    \n [25] httr_1.4.2         Matrix_1.3-2       assertthat_0.2.1  \n [28] fastmap_1.1.0      lazyeval_0.2.2     cli_2.3.1         \n [31] later_1.1.0.1      tweenr_1.0.1       htmltools_0.5.1.1 \n [34] prettyunits_1.1.1  tools_4.0.4        igraph_1.2.6      \n [37] gtable_0.3.0       glue_1.4.2         reshape2_1.4.4    \n [40] V8_3.4.0           jquerylib_0.1.3    vctrs_0.3.6       \n [43] nlme_3.1-152       debugme_1.1.0      crosstalk_1.1.1   \n [46] xfun_0.22          stringr_1.4.0      ps_1.6.0          \n [49] lme4_1.1-26        miniUI_0.1.1.1     mime_0.10         \n [52] lifecycle_1.0.0    gtools_3.8.2       statmod_1.4.35    \n [55] zoo_1.8-9          scales_1.1.1       colourpicker_1.1.0\n [58] ragg_1.1.1         hms_1.0.0          promises_1.2.0.1  \n [61] parallel_4.0.4     inline_0.3.17      shinystan_2.5.0   \n [64] RColorBrewer_1.1-2 yaml_2.2.1         curl_4.3          \n [67] gridExtra_2.3      loo_2.4.1          sass_0.3.1        \n [70] distill_1.2        stringi_1.5.3      highr_0.8         \n [73] dygraphs_1.1.1.6   gifski_0.8.7.1     boot_1.3-27       \n [76] pkgbuild_1.2.0     rlang_0.4.10       pkgconfig_2.0.3   \n [79] systemfonts_1.0.1  matrixStats_0.58.0 evaluate_0.14     \n [82] lattice_0.20-41    purrr_0.3.4        rstantools_2.1.1  \n [85] htmlwidgets_1.5.3  labeling_0.4.2     processx_3.4.5    \n [88] tidyselect_1.1.0   here_1.0.1         plyr_1.8.6        \n [91] magrittr_2.0.1     R6_2.5.0           magick_2.7.0      \n [94] generics_0.1.0     DBI_1.1.1          pillar_1.5.1      \n [97] withr_2.4.1        xts_0.12.1         survival_3.2-7    \n[100] tibble_3.1.0       crayon_1.4.1       utf8_1.1.4        \n[103] tmvnsim_1.0-2      rmarkdown_2.7      jpeg_0.1-8.1      \n[106] progress_1.2.2     grid_4.0.4         isoband_0.2.4     \n[109] data.table_1.14.0  callr_3.5.1        threejs_0.3.3     \n[112] digest_0.6.27      xtable_1.8-4       tidyr_1.1.3       \n[115] httpuv_1.5.5       textshaping_0.3.2  RcppParallel_5.0.3\n[118] stats4_4.0.4       munsell_0.5.0      viridisLite_0.3.0 \n[121] bslib_0.2.4        shinyjs_2.0.0     \n\n\n\n\nBetancourt, M. (2017, January 9). A Conceptual Introduction to Hamiltonian Monte Carlo. Retrieved November 6, 2019, from http://arxiv.org/abs/1701.02434\n\n\nBrooks, S., Gelman, A., Jones, G., & Meng, X.-L. (2011). Handbook of Markov Chain Monte Carlo. Retrieved from http://books.google.com?id=qfRsAIKZ4rIC\n\n\nBrooks, S. P., & Gelman, A. (1998). General Methods for Monitoring Convergence of Iterative Simulations. Journal of Computational and Graphical Statistics, 7(4), 434–455. https://doi.org/10.1080/10618600.1998.10474787\n\n\nCarpenter, B., Gelman, A., Hoffman, M. D., Lee, D., Goodrich, B., Betancourt, M., … Riddell, A. (2017). Stan : A Probabilistic Programming Language. Journal of Statistical Software, 76(1). https://doi.org/10.18637/jss.v076.i01\n\n\nCasella, G., & George, E. I. (1992). Explaining the gibbs sampler. The American Statistician, 46(3), 167–174. https://doi.org/10.1080/00031305.1992.10475878\n\n\nChib, S., & Greenberg, E. (1995). Understanding the Metropolis-Hastings Algorithm. The American Statistician, 49(4), 327–335. https://doi.org/10.1080/00031305.1995.10476177\n\n\nDuane, S., Kennedy, A. D., Pendleton, B. J., & Roweth, D. (1987). Hybrid Monte Carlo. Physics Letters B, 195(2), 216–222. https://doi.org/10.1016/0370-2693(87)91197-X\n\n\nEckhardt, R. (1987). Stan Ulam, John von Neumann, and the Monte Carlo Method. Los Alamos Science, 15(30), 131–136.\n\n\nGabry, J., Simpson, D., Vehtari, A., Betancourt, M., & Gelman, A. (2019). Visualization in Bayesian workflow. Journal of the Royal Statistical Society: Series A (Statistics in Society), 182(2), 389–402. https://doi.org/10.1111/rssa.12378\n\n\nGelman, A. (1992). Iterative and Non-Iterative Simulation Algorithms. Computing Science and Statistics (Interface Proceedings), 24, 457–511. PROCEEDINGS PUBLISHED BY VARIOUS PUBLISHERS.\n\n\nGelman, A. (2008). The folk theorem of statistical computing. Retrieved from https://statmodeling.stat.columbia.edu/2008/05/13/the_folk_theore/\n\n\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013a). Basics of Markov Chain Simulation. In Bayesian Data Analysis. Chapman and Hall/CRC.\n\n\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013b). Bayesian Data Analysis. Chapman and Hall/CRC.\n\n\nGelman, A., & Rubin, D. B. (1992). Inference from Iterative Simulation Using Multiple Sequences. Statistical Science, 7(4), 457–472. https://doi.org/10.1214/ss/1177011136\n\n\nGeman, S., & Geman, D. (1984). Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images. IEEE Transactions on Pattern Analysis and Machine Intelligence, PAMI-6(6), 721–741. https://doi.org/10.1109/TPAMI.1984.4767596\n\n\nHastings, W. K. (1970). Monte Carlo sampling methods using Markov chains and their applications. Biometrika, 57(1), 97–109. https://doi.org/10.1093/biomet/57.1.97\n\n\nHoffman, M. D., & Gelman, A. (2011). The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo. Journal of Machine Learning Research, 15(1), 1593–1623. Retrieved from http://arxiv.org/abs/1111.4246\n\n\nMetropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H., & Teller, E. (1953). Equation of State Calculations by Fast Computing Machines. The Journal of Chemical Physics, 21(6), 1087–1092. https://doi.org/10.1063/1.1699114\n\n\nNeal, Radford M. (1994). An Improved Acceptance Procedure for the Hybrid Monte Carlo Algorithm. Journal of Computational Physics, 111(1), 194–203. https://doi.org/10.1006/jcph.1994.1054\n\n\nNeal, Radford M. (2011). MCMC using Hamiltonian dynamics. In S. Brooks, A. Gelman, G. L. Jones, & X.-L. Meng (Eds.), Handbook of markov chain monte carlo.\n\n\nRoberts, G. O., Gelman, A., & Gilks, W. R. (1997). Weak convergence and optimal scaling of random walk Metropolis algorithms. Annals of Applied Probability, 7(1), 110–120. https://doi.org/10.1214/aoap/1034625254\n\n\no símbolo \\(\\propto\\) (\\propto) deve ser lido como “proporcional à.”↩︎\nAlgumas referências chamam esse processo de burnin.↩︎\nCaso queira uma melhor explanação do algoritmo de Metropolis e Metropolis-Hastings sugiro ver Chib & Greenberg (1995)↩︎\ndo ingles probability density function (PDF).↩︎\nobjetos stanfit são objetos resultantes de modelos rstan ou rstanarm.↩︎\nCaso queira uma melhor explanação do algoritmo de Gibbs sugiro ver Casella & George (1992).↩︎\nisto ficará claro nas imagens e animações.↩︎\nVejam que aqui eu propositalmente dividi a neff por nrow(X_gibbs) / 2 (metade do número de iterações). Isso foi necessário, pois da maneira que eu codifiquei o algoritmo Gibbs ele amostra um parâmetro a cada interação e geralmente não se implementa um amostrador Gibbs dessa maneira (amostra-se todos os parâmetros por iteração). Eu fiz de propósito pois quero gerar nos GIFs animados na figura 10 a real trajetória do amostrador Gibbs no espaço amostral (vertical e horizontal, e não diagonal).↩︎\npor questões de transbordamento numérico (numeric overflow) sempre trabalhamos com log de probabilidades.↩︎\n1.000 * 40 = 40.000. Esse 1 a mais é que usei a primeira iteração com Leapfrog \\(L = 1\\) como warmup.↩︎\nalém disso, todos os pacotes do ecossistema Stan aplicam uma decomposição QR na matriz \\(X\\) de dados, criando uma base ortogonal (não correlacionada) para amostragem. Isso faz com a distribuição-alvo (posterior) fique muito mais amigável do ponto de vista topológico/geométrico para o amostrador MCMC explorá-la de maneira mais eficiente e eficaz.↩︎\nSendo que, por padrão, Stan e rstanarm descartam a primeira metade (1.000) das iterações como aquecimento (warmup = floor(iter/2)).↩︎\nalém disso, vale a pena ativar a decomposição QR na matriz \\(X\\) de dados, criando uma base ortogonal (não correlacionada) para amostragem. Isso faz com a distribuição-alvo (posterior) fique muito mais amigável do ponto de vista topológico/geométrico para o amostrador MCMC explorá-la de maneira mais eficiente e eficaz. Só você especificar o argumento QR = TRUE dentro da funções do rstanarm, exemplo stan_glm(..., QR = TRUE).↩︎\n",
      "last_modified": "2021-03-14T09:39:04-03:00"
    },
    {
      "path": "5-Regressao_Linear.html",
      "title": "Regressão Linear",
      "description": "Regressão Linear Bayesiana",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 2, 2021",
      "contents": "\n\nContents\nrstanarm\nRegressão Linear\nExemplo - Score de QI de crianças\nDescritivo das variáveis\nModelo 1 - mom_hs\nModelo 2 - mom_iq\nModelo 3 - mom_hs + mom_iq\nModelo 4 - mom_hs * mom_iq\n\nVariáveis qualitativas\nAtividade Prática\nWHO Life Expectancy\nWine Quality Kaggle Dataset\n\nReferências\nAmbiente\n\n\n\nA principal ferramenta para computação Bayesiana é a linguagem probabilística Stan. O nome homenageia Stanislaw Ulam: um matemático polonês membro do projeto Manhattan (bomba atômica americana) e um dos principais criadores do método de Monte Carlo de simulação. Stan foi lançado em 2012 e é a principal ferramenta utilizada hoje para inferência estatística Bayesiana. O programa roda em linguagem C++, mas possui interfaces para R, Python, MATLAB, Julia, Stata, Mathematica, Scala e Shell.\nO problema do Stan é que ele é uma linguagem de programação e, portanto, possui um acesso dificultado a não-programadores. Abaixo um código que mostra como é um programa escrito em Stan:\n\ndata {\n  int<lower=0> N;\n  vector<lower=0, upper=200>[N] kid_score;\n  vector<lower=0, upper=200>[N] mom_iq;\n}\nparameters {\n  vector[2] beta;\n  real<lower=0> sigma;\n}\nmodel {\n  sigma ~ cauchy(0, 2.5);\n  kid_score ~ normal(beta[1] + beta[2] * mom_iq, sigma);\n}\n\nrstanarm\nPara remediar isso, temos interfaces abstratas que interpretam a intenção do usuário e lidam com a parte mais obral de codificação. A principal delas é o pacote rstanarm, que a etimologia pode ser quebrada em:\nr: pacote para R\nstan: usa a linguagem probabilística Stan\narm: acrônimo para Applied Regression Modeling\nO código anterior de Stan ficaria assim no rstanarm:\n\n\nstan_glm(kid_score ~ mom_iq, data = dataset)\n\n\n\nRegressão Linear\nA ideia aqui é modelar uma variável dependente sendo a combinação linear de variáveis independentes.\n\\[y = \\alpha + \\boldsymbol{\\beta} \\textbf{X} + \\epsilon\\]\nAonde \\(y\\) é a variável dependente, \\(\\alpha\\) um constante, \\(\\boldsymbol{\\beta}\\) um vetor de coeficientes, \\(\\textbf{X}\\) uma matriz de dados e \\(\\epsilon\\) o erro do modelo.\nExemplo - Score de QI de crianças\nVamos aplicar modelagem estatística Bayesiana em um dataset famoso chamado kidiq. São dados de uma survey de mulheres adultas norte-americanas e seus respectivos filhos. Datado de 2007 possui 434 observações e 4 variáveis:\nkid_score: QI da criança;\nmom_hs: binária (0 ou 1) se a mãe possui diploma de ensino médio;\nmom_iq: QI da mãe; e\nmom_age: idade da mãe.\nVamos usar 4 modelos para modelar QI da criança (kid_score). Os primeiros dois modelos terão apenas um único preditor (mom_hs ou mom_iq), o terceiro usará dois preditores (mom_hs + mom_iq) e o quarto incluirá uma interação entre esses dois preditores (mom_hs * mom_iq),\nDescritivo das variáveis\nAntes de tudo, analise SEMPRE os dados em mãos. Graficamente e com tabelas.\nGráficos\n\n\n# Detectar quantos cores/processadores\noptions(mc.cores = parallel::detectCores())\noptions(Ncpus = parallel::detectCores())\n\nlibrary(rstanarm)\ndata(kidiq)\n\nboxplot(kidiq)\n\n\n\n\nTabelas\nPessoalmente uso o pacote skimr com a função skim():\n\n\nlibrary(skimr)\n\nskim(kidiq)\n\n\nTable 1: Data summary\nName\nkidiq\nNumber of rows\n434\nNumber of columns\n4\n_______________________\n\nColumn type frequency:\n\nnumeric\n4\n________________________\n\nGroup variables\nNone\nVariable type: numeric\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\nkid_score\n0\n1\n86.80\n20.41\n20\n74\n90\n102\n144\n▁▃▇▇▁\nmom_hs\n0\n1\n0.79\n0.41\n0\n1\n1\n1\n1\n▂▁▁▁▇\nmom_iq\n0\n1\n100.00\n15.00\n71\n89\n98\n110\n139\n▃▇▆▃▂\nmom_age\n0\n1\n22.79\n2.70\n17\n21\n23\n25\n29\n▂▅▇▃▂\n\nModelo 1 - mom_hs\nPrimeiro modelo é apenas a variável mom_hs como preditora:\n\n\nmodel_1 <- stan_glm(\n  kid_score ~ mom_hs,\n  data = kidiq\n  )\n\n\n\nPara ver os valores estimados pelo modelo usamos a função print:\n\n\nprint(model_1)\n\n\nstan_glm\n family:       gaussian [identity]\n formula:      kid_score ~ mom_hs\n observations: 434\n predictors:   2\n------\n            Median MAD_SD\n(Intercept) 77.5    2.0  \nmom_hs      11.8    2.3  \n\nAuxiliary parameter(s):\n      Median MAD_SD\nsigma 19.9    0.7  \n\n------\n* For help interpreting the printed output see ?print.stanreg\n* For info on the priors used see ?prior_summary.stanreg\n\nAlém disso, temos a função summary que traz tudo que queremos:\n\n\nsummary(model_1)\n\n\n\nModel Info:\n function:     stan_glm\n family:       gaussian [identity]\n formula:      kid_score ~ mom_hs\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 434\n predictors:   2\n\nEstimates:\n              mean   sd   10%   50%   90%\n(Intercept) 77.5    2.1 74.9  77.5  80.3 \nmom_hs      11.8    2.4  8.8  11.8  14.9 \nsigma       19.9    0.7 19.1  19.9  20.8 \n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 86.8    1.3 85.1  86.8  88.6 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.0  1.0  4013 \nmom_hs        0.0  1.0  4209 \nsigma         0.0  1.0  3966 \nmean_PPD      0.0  1.0  4031 \nlog-posterior 0.0  1.0  1713 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nModelo 2 - mom_iq\nSegundo modelo é apenas a variável mom_iq como preditora:\n\n\nmodel_2 <- stan_glm(\n  kid_score ~ mom_iq,\n  data = kidiq\n  )\n\n\n\nPodemos também especificar os percentis desejados no sumário:\n\n\nsummary(model_2, probs = c(0.025, 0.975))\n\n\n\nModel Info:\n function:     stan_glm\n family:       gaussian [identity]\n formula:      kid_score ~ mom_iq\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 434\n predictors:   2\n\nEstimates:\n              mean   sd   2.5%   98%\n(Intercept) 25.7    5.9 14.2   37.5 \nmom_iq       0.6    0.1  0.5    0.7 \nsigma       18.3    0.6 17.2   19.5 \n\nFit Diagnostics:\n           mean   sd   2.5%   98%\nmean_PPD 86.8    1.2 84.3   89.2 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.1  1.0  4041 \nmom_iq        0.0  1.0  4076 \nsigma         0.0  1.0  3670 \nmean_PPD      0.0  1.0  3664 \nlog-posterior 0.0  1.0  1760 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nModelo 3 - mom_hs + mom_iq\nTerceiro modelo usa as duas variáveis mom_hs e mom_iq como preditoras:\n\n\nmodel_3 <- stan_glm(\n  kid_score ~ mom_hs + mom_iq,\n  data = kidiq\n  )\n\n\n\n\n\nprint(model_3)\n\n\nstan_glm\n family:       gaussian [identity]\n formula:      kid_score ~ mom_hs + mom_iq\n observations: 434\n predictors:   3\n------\n            Median MAD_SD\n(Intercept) 25.6    5.7  \nmom_hs       5.9    2.2  \nmom_iq       0.6    0.1  \n\nAuxiliary parameter(s):\n      Median MAD_SD\nsigma 18.2    0.6  \n\n------\n* For help interpreting the printed output see ?print.stanreg\n* For info on the priors used see ?prior_summary.stanreg\n\nModelo 4 - mom_hs * mom_iq\nQuarto modelo usa as duas variáveis mom_hs e mom_iq como preditoras por meio de uma interação entre as duas:\n\n\nmodel_4 <- stan_glm(\n  kid_score ~ mom_hs * mom_iq,\n  data = kidiq\n  )\n\n\n\n\n\nprint(model_4)\n\n\nstan_glm\n family:       gaussian [identity]\n formula:      kid_score ~ mom_hs * mom_iq\n observations: 434\n predictors:   4\n------\n              Median MAD_SD\n(Intercept)   -10.6   13.6 \nmom_hs         50.3   14.8 \nmom_iq          1.0    0.1 \nmom_hs:mom_iq  -0.5    0.2 \n\nAuxiliary parameter(s):\n      Median MAD_SD\nsigma 18.0    0.6  \n\n------\n* For help interpreting the printed output see ?print.stanreg\n* For info on the priors used see ?prior_summary.stanreg\n\nVariáveis qualitativas\nPara as variáveis qualitativas, o R usa um tipo especial de variável chamado factor. A codificação é em números inteiros \\(1,2,\\dots,K\\) mas a relação é distinta/nominal. Ou seja 1 é distinto de 2 e não 1 é 2x menor que 2. Não há relação quantitativa entre os valores das variáveis factor.\nIsso resolve o problema de termos variáveis qualitativas (também chamadas de dummy) em modelos de regressão. Para um factor com \\(K\\) quantidade de classes distintas, temos a possibilidade de criar \\(K-1\\) coeficientes de regressão. Um para cada classe e usando uma como basal (baseline).\n\n\nlibrary(gapminder)\nlevels(gapminder$continent)\n\n\n[1] \"Africa\"   \"Americas\" \"Asia\"     \"Europe\"   \"Oceania\" \n\nmodel_5 <- stan_glm(lifeExp ~ gdpPercap + factor(continent), data = gapminder)\n\n\n\n\n\nprint(model_5)\n\n\nstan_glm\n family:       gaussian [identity]\n formula:      lifeExp ~ gdpPercap + factor(continent)\n observations: 1704\n predictors:   6\n------\n                          Median MAD_SD\n(Intercept)               47.9    0.3  \ngdpPercap                  0.0    0.0  \nfactor(continent)Americas 13.6    0.6  \nfactor(continent)Asia      8.7    0.6  \nfactor(continent)Europe   17.6    0.6  \nfactor(continent)Oceania  18.2    1.8  \n\nAuxiliary parameter(s):\n      Median MAD_SD\nsigma 8.4    0.1   \n\n------\n* For help interpreting the printed output see ?print.stanreg\n* For info on the priors used see ?prior_summary.stanreg\n\nObs: para mudar o basal de referência de um factor use a função relevel() do R.\nAtividade Prática\nDois datasets estão disponíveis na pasta datasets/:\nWHO Life Expectancy Kaggle Dataset: datasets/WHO_Life_Exp.csv\nWine Quality Kaggle Dataset: datasets/Wine_Quality.csv\nWHO Life Expectancy\nEsse dataset possui 193 países nos últimos 15 anos.\nVariáveis\ncountry\nyear\nstatus\nlife_expectancy\nadult_mortality\ninfant_deaths\nalcohol\npercentage_expenditure\nhepatitis_b\nmeasles\nbmi\nunder_five_deaths\npolio\ntotal_expenditure\ndiphtheria\nhiv_aids\ngdp\npopulation\nthinness_1_19_years\nthinness_5_9_years\nincome_composition_of_resources\nschooling\nWine Quality Kaggle Dataset\nEsse dataset possui 1599 vinhos e estão relacionados com variantes tintas do vinho “Vinho Verde” português. Para mais detalhes, consulte a referência [Cortez et al., 2009]. Devido a questões de privacidade e logística, apenas variáveis físico-químicas (entradas) e sensoriais (a saída) estão disponíveis (por exemplo, não há dados sobre os tipos de uva, marca de vinho, preço de venda do vinho, etc.).\nfixed_acidity\nvolatile_acidity\ncitric_acid\nresidual_sugar\nchlorides\nfree_sulfur_dioxide\ntotal_sulfur_dioxide\ndensity\np_h\nsulphates\nalcohol\nquality\n\n\n###\n\n\n\nReferências\nP. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.4 (2021-02-15)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n [1] gapminder_0.3.0      skimr_2.1.2          dplyr_1.0.4         \n [4] rstan_2.21.2         StanHeaders_2.21.0-7 MASS_7.3-53.1       \n [7] ggforce_0.3.2        gganimate_1.0.7      plotly_4.9.3        \n[10] carData_3.0-4        rstanarm_2.21.1      Rcpp_1.0.6          \n[13] readxl_1.3.1         tibble_3.1.0         ggplot2_3.3.3       \n[16] patchwork_1.1.1      cowplot_1.1.1       \n\nloaded via a namespace (and not attached):\n  [1] systemfonts_1.0.1  plyr_1.8.6         igraph_1.2.6      \n  [4] repr_1.1.3         lazyeval_0.2.2     splines_4.0.4     \n  [7] crosstalk_1.1.1    rstantools_2.1.1   inline_0.3.17     \n [10] digest_0.6.27      htmltools_0.5.1.1  magick_2.6.0      \n [13] rsconnect_0.8.16   fansi_0.4.2        magrittr_2.0.1    \n [16] RcppParallel_5.0.3 matrixStats_0.58.0 xts_0.12.1        \n [19] prettyunits_1.1.1  jpeg_0.1-8.1       colorspace_2.0-0  \n [22] textshaping_0.3.1  xfun_0.21          callr_3.5.1       \n [25] crayon_1.4.1       jsonlite_1.7.2     lme4_1.1-26       \n [28] survival_3.2-7     zoo_1.8-8          glue_1.4.2        \n [31] polyclip_1.10-0    gtable_0.3.0       V8_3.4.0          \n [34] pkgbuild_1.2.0     scales_1.1.1       DBI_1.1.1         \n [37] miniUI_0.1.1.1     isoband_0.2.3      viridisLite_0.3.0 \n [40] xtable_1.8-4       progress_1.2.2     tmvnsim_1.0-2     \n [43] stats4_4.0.4       DT_0.17            htmlwidgets_1.5.3 \n [46] httr_1.4.2         threejs_0.3.3      RColorBrewer_1.1-2\n [49] ellipsis_0.3.1     pkgconfig_2.0.3    loo_2.4.1         \n [52] farver_2.1.0       sass_0.3.1         here_1.0.1        \n [55] utf8_1.1.4         tidyselect_1.1.0   labeling_0.4.2    \n [58] rlang_0.4.10       reshape2_1.4.4     later_1.1.0.1     \n [61] munsell_0.5.0      cellranger_1.1.0   tools_4.0.4       \n [64] cli_2.3.1          generics_0.1.0     gifski_0.8.7      \n [67] ggridges_0.5.3     evaluate_0.14      stringr_1.4.0     \n [70] fastmap_1.1.0      yaml_2.2.1         ragg_1.1.1        \n [73] processx_3.4.5     knitr_1.31         purrr_0.3.4       \n [76] nlme_3.1-152       mime_0.10          xml2_1.3.2        \n [79] compiler_4.0.4     bayesplot_1.8.0    shinythemes_1.2.0 \n [82] rstudioapi_0.13    png_0.1-7          curl_4.3          \n [85] statmod_1.4.35     tweenr_1.0.1       bslib_0.2.4       \n [88] stringi_1.5.3      highr_0.8          ps_1.6.0          \n [91] lattice_0.20-41    Matrix_1.3-2       nloptr_1.2.2.2    \n [94] markdown_1.1       shinyjs_2.0.0      vctrs_0.3.6       \n [97] pillar_1.5.0       lifecycle_1.0.0    jquerylib_0.1.3   \n[100] data.table_1.14.0  httpuv_1.5.5       R6_2.5.0          \n[103] bookdown_0.21      promises_1.2.0.1   gridExtra_2.3     \n[106] codetools_0.2-18   distill_1.2        boot_1.3-27       \n[109] colourpicker_1.1.0 gtools_3.8.2       assertthat_0.2.1  \n[112] rprojroot_2.0.2    withr_2.4.1        mnormt_2.0.2      \n[115] shinystan_2.5.0    parallel_4.0.4     hms_1.0.0         \n[118] grid_4.0.4         tidyr_1.1.2        minqa_1.2.4       \n[121] rmarkdown_2.7      downlit_0.2.1      shiny_1.6.0       \n[124] lubridate_1.7.10   base64enc_0.1-3    dygraphs_1.1.1.6  \n\n\n\n\n",
      "last_modified": "2021-03-12T08:08:23-03:00"
    },
    {
      "path": "6-Regressao_Binomial.html",
      "title": "Regressão Binomial",
      "description": "Modelos Lineares Generalizados -- Binomial",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 2, 2021",
      "contents": "\n\nContents\nComparativo com a Regressão Linear\nExemplo\n\nRegressão logística com o rstanarm\nInterpretação dos coeficientes\nPriors\nAtividade Prática\nAmbiente\n\n\nSaindo do universo dos modelos lineares, começamos a nos aventurar nos modelos linares generalizados (generalized linear models - GLM). O primeiro deles é a regressão logística (também chamada de regressão binomial).\nUma regressão logística se comporta exatamente como um modelo linear: faz uma predição simplesmente computando uma soma ponderada das variáveis independentes, mais uma constante. Porém ao invés de retornar um valor contínuo, como a regressão linear, retorna a função logística desse valor.\n\\[\\operatorname{Logística}(x) = \\frac{1}{1 + e^{(-x)}}\\]\nUsamos regressão logística quando a nossa variável dependente é binária. Ela possui apenas dois valores distintos, geralmente codificados como \\(0\\) ou \\(1\\).\n\n\nx <- seq(-10, 10, length.out = 100)\nsig <- 1 / (1 + exp(-x))\nplot(x, sig, type = \"l\", lwd = 2, ylab = \"Logística(x)\")\n\n\n\n\nComparativo com a Regressão Linear\n\\[ \\operatorname{Linear} = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\dots + \\theta_n x_n\\]\n\\(\\operatorname{Linear}\\) - regressão linear\n\\(\\theta\\) - parâmetro do modelo\n\\(n\\) - número de atributos (features)\n\\(x_i\\) - o valor do inésimo atributo (feature)\n\\(\\hat{p} = \\sigma(\\operatorname{Linear}) = \\frac{1}{1 + e^{-\\operatorname{Linear}}}\\)\n\\(\\hat{p}\\) - probabilidade prevista da observação ser 1\n\\(\\hat{y}=\\left\\{\\begin{array}{ll} 0 & \\text { se } \\hat{p} < 0.5 \\\\ 1 & \\text { se } \\hat{p} \\geq 0.5 \\end{array}\\right.\\)\nExemplo\n\\[\\mathrm{Previsão~de~Morte} = \\sigma \\big(-10 + 10\\times \\mathrm{cancer} + 12 \\times \\mathrm{diabetes} + 8 \\times \\mathrm{obesidade} \\big)\\]\nRegressão logística com o rstanarm\nO rstanarm pode tolerar qualquer modelo linear generalizado e regressão logística não é uma exceção. Para rodar um modelo binomial no rstanarm é preciso simplesmente alterar o argumento family da função stan_glm.\nPara exemplo, usaremos um dataset chamado wells do pacote rstanarm. É uma survey com 3200 residentes de uma pequena área de Bangladesh na qual os lençóis freáticos estão contaminados por arsênico. Respondentes com altos níveis de arsênico nos seus poços foram encorajados para trocar a sua fonte de água para uma níveis seguros de arsênico.\nPossui as seguintes variáveis:\nswitch: dependente indicando se o respondente trocou ou não de poço\narsenic: nível de arsênico do poço do respondente\ndist: distância em metros da casa do respondente até o poço seguro mais próximo\nassociation: dummy se os membros da casa do respondente fazem parte de alguma organização da comunidade\neduc: quantidade de anos de educação que o chefe da família respondente possui\n\n\noptions(mc.cores = parallel::detectCores())\noptions(Ncpus = parallel::detectCores())\n\nlibrary(rstanarm)\ndata(wells)\n\nmodel_binomial <- stan_glm(\n  switch ~ dist + arsenic + assoc + educ,\n  data = wells,\n  family = binomial()\n    )\n\n\n\n\n\nsummary(model_binomial)\n\n\n\nModel Info:\n function:     stan_glm\n family:       binomial [logit]\n formula:      switch ~ dist + arsenic + assoc + educ\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 3020\n predictors:   5\n\nEstimates:\n              mean   sd   10%   50%   90%\n(Intercept) -0.2    0.1 -0.3  -0.2   0.0 \ndist         0.0    0.0  0.0   0.0   0.0 \narsenic      0.5    0.0  0.4   0.5   0.5 \nassoc       -0.1    0.1 -0.2  -0.1   0.0 \neduc         0.0    0.0  0.0   0.0   0.1 \n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 0.6    0.0  0.6   0.6   0.6  \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.0  1.0  5878 \ndist          0.0  1.0  5628 \narsenic       0.0  1.0  4660 \nassoc         0.0  1.0  6220 \neduc          0.0  1.0  4816 \nmean_PPD      0.0  1.0  4196 \nlog-posterior 0.0  1.0  1735 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nInterpretação dos coeficientes\nAo vermos a fórmula de regressão binomial vemos que para analisarmos o efeito de um preditor na variável dependente temos que calcular o valor logístico dos coeficientes do preditor. E interpretamos como chances (odds ratio) na qual 1 é neutro e qualquer valor abaixo de 1 tende a respostas codificadas como 0 e qualquer valor acima de 1 tende a respostas codificadas como 1.\n\\[\\text{odds ratio} = e^{(x)}\\]\n\n\ncoeff <- exp(model_binomial$coefficients)\ncoeff\n\n\n(Intercept)        dist     arsenic       assoc        educ \n       0.85        0.99        1.60        0.88        1.04 \n\n(Intercept): a chance basal de respondentes mudarem de poço (15% de não mudarem)\ndist: a cada metro de distância diminui a chance de troca de poço em 1%\narsenic: a cada incremento do nível de arsênico aumenta a chance de troca de poço em 60%\nassoc: residências com membros que fazem parte de alguma organização da comunidade diminui a chance de troca de poço em 12%\neduc: a cada incremento dos anos de estudo aumenta a chance de troca de poço em 4%\nPriors\nrstanarm possui as seguintes configurações como padrão de priors para regressão binomial:\nConstante (Intercept): centralizada com média \\(\\mu = 0\\) e desvio padrão de \\(2.5 \\sigma_y\\) - prior_intercept = normal(0, 2.5 * sd_y)\nCoeficientes: para cada coeficiente média \\(\\mu = 0\\) and standard deviation of \\(2.5\\times\\frac{1}{\\sigma_{x_k}}\\) - prior = normal(0, 2.5 * 1/sd_xk)\nErro residual (prior_aux): uma distribuição exponencial com taxa \\(\\frac{1}{\\sigma_y}\\): prior_aux = exponential(1/sd_y)\nAtividade Prática\nDois datasets estão disponíveis na pasta datasets/:\nTitanic Survival: datasets/Titanic_Survival.csv\nIBM HR Analytics Employee Attrition & Performance: datasets/IBM_HR_Attrition.csv\n\n\n###\n\n\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.4 (2021-02-15)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n [1] gapminder_0.3.0      skimr_2.1.2          dplyr_1.0.4         \n [4] rstan_2.21.2         StanHeaders_2.21.0-7 MASS_7.3-53.1       \n [7] ggforce_0.3.2        gganimate_1.0.7      plotly_4.9.3        \n[10] carData_3.0-4        rstanarm_2.21.1      Rcpp_1.0.6          \n[13] readxl_1.3.1         tibble_3.1.0         ggplot2_3.3.3       \n[16] patchwork_1.1.1      cowplot_1.1.1       \n\nloaded via a namespace (and not attached):\n  [1] systemfonts_1.0.1  plyr_1.8.6         igraph_1.2.6      \n  [4] repr_1.1.3         lazyeval_0.2.2     splines_4.0.4     \n  [7] crosstalk_1.1.1    rstantools_2.1.1   inline_0.3.17     \n [10] digest_0.6.27      htmltools_0.5.1.1  magick_2.6.0      \n [13] rsconnect_0.8.16   fansi_0.4.2        magrittr_2.0.1    \n [16] RcppParallel_5.0.3 matrixStats_0.58.0 xts_0.12.1        \n [19] prettyunits_1.1.1  jpeg_0.1-8.1       colorspace_2.0-0  \n [22] textshaping_0.3.1  xfun_0.21          callr_3.5.1       \n [25] crayon_1.4.1       jsonlite_1.7.2     lme4_1.1-26       \n [28] survival_3.2-7     zoo_1.8-8          glue_1.4.2        \n [31] polyclip_1.10-0    gtable_0.3.0       V8_3.4.0          \n [34] pkgbuild_1.2.0     scales_1.1.1       DBI_1.1.1         \n [37] miniUI_0.1.1.1     isoband_0.2.3      viridisLite_0.3.0 \n [40] xtable_1.8-4       progress_1.2.2     tmvnsim_1.0-2     \n [43] stats4_4.0.4       DT_0.17            htmlwidgets_1.5.3 \n [46] httr_1.4.2         threejs_0.3.3      RColorBrewer_1.1-2\n [49] ellipsis_0.3.1     pkgconfig_2.0.3    loo_2.4.1         \n [52] farver_2.1.0       sass_0.3.1         here_1.0.1        \n [55] utf8_1.1.4         tidyselect_1.1.0   labeling_0.4.2    \n [58] rlang_0.4.10       reshape2_1.4.4     later_1.1.0.1     \n [61] munsell_0.5.0      cellranger_1.1.0   tools_4.0.4       \n [64] cli_2.3.1          generics_0.1.0     gifski_0.8.7      \n [67] ggridges_0.5.3     evaluate_0.14      stringr_1.4.0     \n [70] fastmap_1.1.0      yaml_2.2.1         ragg_1.1.1        \n [73] processx_3.4.5     knitr_1.31         purrr_0.3.4       \n [76] nlme_3.1-152       mime_0.10          xml2_1.3.2        \n [79] compiler_4.0.4     bayesplot_1.8.0    shinythemes_1.2.0 \n [82] rstudioapi_0.13    png_0.1-7          curl_4.3          \n [85] statmod_1.4.35     tweenr_1.0.1       bslib_0.2.4       \n [88] stringi_1.5.3      highr_0.8          ps_1.6.0          \n [91] lattice_0.20-41    Matrix_1.3-2       nloptr_1.2.2.2    \n [94] markdown_1.1       shinyjs_2.0.0      vctrs_0.3.6       \n [97] pillar_1.5.0       lifecycle_1.0.0    jquerylib_0.1.3   \n[100] data.table_1.14.0  httpuv_1.5.5       R6_2.5.0          \n[103] bookdown_0.21      promises_1.2.0.1   gridExtra_2.3     \n[106] codetools_0.2-18   distill_1.2        boot_1.3-27       \n[109] colourpicker_1.1.0 gtools_3.8.2       assertthat_0.2.1  \n[112] rprojroot_2.0.2    withr_2.4.1        mnormt_2.0.2      \n[115] shinystan_2.5.0    parallel_4.0.4     hms_1.0.0         \n[118] grid_4.0.4         tidyr_1.1.2        minqa_1.2.4       \n[121] rmarkdown_2.7      downlit_0.2.1      shiny_1.6.0       \n[124] lubridate_1.7.10   base64enc_0.1-3    dygraphs_1.1.1.6  \n\n\n\n\n",
      "last_modified": "2021-03-12T08:08:23-03:00"
    },
    {
      "path": "7-Regressao_Poisson.html",
      "title": "Regressão de Poisson",
      "description": "Modelos Lineares Generalizados -- Poisson",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 2, 2021",
      "contents": "\n\nContents\nRegressão de Poisson com o rstanarm\nInterpretação dos coeficientes\nPriors\nAtividade Prática\nAmbiente\n\n\nSaindo do universo dos modelos lineares, começamos a nos aventurar nos modelos linares generalizados (generalized linear models - GLM). O segundo deles é a regressão de Poisson.\nUma regressão de Poisson se comporta exatamente como um modelo linear: faz uma predição simplesmente computando uma soma ponderada das variáveis independentes, mais uma constante. Porém ao invés de retornar um valor contínuo, como a regressão linear, retorna o logarítmo natural desse valor.\n\\[\\log(y)= \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\dots + \\theta_n x_n\\] que é o mesmo que\n\\[y = e^{(\\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\dots + \\theta_n x_n)}\\] Regressão de Poisson é usada quando a nossa variável dependente só pode tomar valores positivos e discretos (número inteiros), geralmente em contextos de dados de contagem.\n\n\nx <- seq(-5, 5, length.out = 100)\nplot(x, exp(x), type = \"l\", lwd = 2, ylab = \"Exponencial(x)\")\n\n\n\n\nRegressão de Poisson com o rstanarm\nO rstanarm pode tolerar qualquer modelo linear generalizado e regressão de Poisson não é uma exceção. Para rodar um modelo de Poisson no rstanarm é preciso simplesmente alterar o argumento family da função stan_glm.\nPara exemplo, usaremos um dataset chamado roaches do pacote rstanarm. É uma base de dados com 262 observações sobre a eficácia de um sistema de controle de pragas em reduzir o número de baratas (roaches) em apartamentos urbanos.\nPossui as seguintes variáveis:\ny: variável dependente - número de baratas mortas\nroach1: número de baratas antes da dedetização\ntreatment: dummy para indicar se o apartamento foi dedetizado ou não\nsenior: dummy para indicar se há apenas idosos no apartamento\nexposure2: número de dias que as armadilhas de baratas foram usadas\n\n\noptions(mc.cores = parallel::detectCores())\noptions(Ncpus = parallel::detectCores())\n\nlibrary(rstanarm)\ndata(roaches)\n\nmodel_poisson <- stan_glm(\n  y ~ roach1 + treatment + senior,\n  data = roaches,\n  family = poisson()\n    )\n\n\n\n\n\nsummary(model_poisson)\n\n\n\nModel Info:\n function:     stan_glm\n family:       poisson [log]\n formula:      y ~ roach1 + treatment + senior\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 262\n predictors:   4\n\nEstimates:\n              mean   sd   10%   50%   90%\n(Intercept)  3.1    0.0  3.1   3.1   3.2 \nroach1       0.0    0.0  0.0   0.0   0.0 \ntreatment   -0.5    0.0 -0.5  -0.5  -0.5 \nsenior      -0.4    0.0 -0.4  -0.4  -0.3 \n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 25.7    0.4 25.1  25.6  26.2 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.0  1.0  3627 \nroach1        0.0  1.0  3630 \ntreatment     0.0  1.0  3362 \nsenior        0.0  1.0  3110 \nmean_PPD      0.0  1.0  3275 \nlog-posterior 0.0  1.0  1940 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nInterpretação dos coeficientes\nAo vermos a fórmula de regressão de Poisson vemos que para analisarmos o efeito de um preditor na variável dependente temos que calcular o valor \\(e\\) elevado ao coeficiente do preditor\n\\[y = e^{(\\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\dots + \\theta_n x_n)}\\]\n\n\ncoeff <- exp(model_poisson$coefficients)\ncoeff\n\n\n(Intercept)      roach1   treatment      senior \n      23.03        1.01        0.60        0.69 \n\n(Intercept): a taxa basal de exterminação das baratas \\(y\\)\nroach1: a cada uma barata antes da exterminação há um aumento de 1.01 barata exterminada a mais\ntreatment: se o apartamento foi dedetizado há um aumento de 0.6 barata exterminada a mais\nsenior: se o apartamento possui somente idoso há um aumento de 0.69 barata exterminada a mais\nPriors\nrstanarm possui as seguintes configurações como padrão de priors para regressão de Poisson:\nConstante (Intercept): centralizada com média \\(\\mu = 0\\) e desvio padrão de \\(2.5 \\sigma_y\\) - prior_intercept = normal(0, 2.5 * sd_y)\nCoeficientes: para cada coeficiente média \\(\\mu = 0\\) and standard deviation of \\(2.5\\times\\frac{1}{\\sigma_{x_k}}\\) - prior = normal(0, 2.5 * 1/sd_xk)\nErro residual (prior_aux): uma distribuição exponencial com taxa \\(\\frac{1}{\\sigma_y}\\): prior_aux = exponential(1/sd_y)\nAtividade Prática\nUm datasets está disponível na pasta datasets/:\nNew York City - East River Bicycle Crossings: datasets/NYC_bicycle.csv\n\n\n###\n\n\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.4 (2021-02-15)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n [1] gapminder_0.3.0      skimr_2.1.2          dplyr_1.0.4         \n [4] rstan_2.21.2         StanHeaders_2.21.0-7 MASS_7.3-53.1       \n [7] ggforce_0.3.2        gganimate_1.0.7      plotly_4.9.3        \n[10] carData_3.0-4        rstanarm_2.21.1      Rcpp_1.0.6          \n[13] readxl_1.3.1         tibble_3.1.0         ggplot2_3.3.3       \n[16] patchwork_1.1.1      cowplot_1.1.1       \n\nloaded via a namespace (and not attached):\n  [1] systemfonts_1.0.1  plyr_1.8.6         igraph_1.2.6      \n  [4] repr_1.1.3         lazyeval_0.2.2     splines_4.0.4     \n  [7] crosstalk_1.1.1    rstantools_2.1.1   inline_0.3.17     \n [10] digest_0.6.27      htmltools_0.5.1.1  magick_2.6.0      \n [13] rsconnect_0.8.16   fansi_0.4.2        magrittr_2.0.1    \n [16] RcppParallel_5.0.3 matrixStats_0.58.0 xts_0.12.1        \n [19] prettyunits_1.1.1  jpeg_0.1-8.1       colorspace_2.0-0  \n [22] textshaping_0.3.1  xfun_0.21          callr_3.5.1       \n [25] crayon_1.4.1       jsonlite_1.7.2     lme4_1.1-26       \n [28] survival_3.2-7     zoo_1.8-8          glue_1.4.2        \n [31] polyclip_1.10-0    gtable_0.3.0       V8_3.4.0          \n [34] pkgbuild_1.2.0     scales_1.1.1       DBI_1.1.1         \n [37] miniUI_0.1.1.1     isoband_0.2.3      viridisLite_0.3.0 \n [40] xtable_1.8-4       progress_1.2.2     tmvnsim_1.0-2     \n [43] stats4_4.0.4       DT_0.17            htmlwidgets_1.5.3 \n [46] httr_1.4.2         threejs_0.3.3      RColorBrewer_1.1-2\n [49] ellipsis_0.3.1     pkgconfig_2.0.3    loo_2.4.1         \n [52] farver_2.1.0       sass_0.3.1         here_1.0.1        \n [55] utf8_1.1.4         tidyselect_1.1.0   labeling_0.4.2    \n [58] rlang_0.4.10       reshape2_1.4.4     later_1.1.0.1     \n [61] munsell_0.5.0      cellranger_1.1.0   tools_4.0.4       \n [64] cli_2.3.1          generics_0.1.0     gifski_0.8.7      \n [67] ggridges_0.5.3     evaluate_0.14      stringr_1.4.0     \n [70] fastmap_1.1.0      yaml_2.2.1         ragg_1.1.1        \n [73] processx_3.4.5     knitr_1.31         purrr_0.3.4       \n [76] nlme_3.1-152       mime_0.10          xml2_1.3.2        \n [79] compiler_4.0.4     bayesplot_1.8.0    shinythemes_1.2.0 \n [82] rstudioapi_0.13    png_0.1-7          curl_4.3          \n [85] statmod_1.4.35     tweenr_1.0.1       bslib_0.2.4       \n [88] stringi_1.5.3      highr_0.8          ps_1.6.0          \n [91] lattice_0.20-41    Matrix_1.3-2       nloptr_1.2.2.2    \n [94] markdown_1.1       shinyjs_2.0.0      vctrs_0.3.6       \n [97] pillar_1.5.0       lifecycle_1.0.0    jquerylib_0.1.3   \n[100] data.table_1.14.0  httpuv_1.5.5       R6_2.5.0          \n[103] bookdown_0.21      promises_1.2.0.1   gridExtra_2.3     \n[106] codetools_0.2-18   distill_1.2        boot_1.3-27       \n[109] colourpicker_1.1.0 gtools_3.8.2       assertthat_0.2.1  \n[112] rprojroot_2.0.2    withr_2.4.1        mnormt_2.0.2      \n[115] shinystan_2.5.0    parallel_4.0.4     hms_1.0.0         \n[118] grid_4.0.4         tidyr_1.1.2        minqa_1.2.4       \n[121] rmarkdown_2.7      downlit_0.2.1      shiny_1.6.0       \n[124] lubridate_1.7.10   base64enc_0.1-3    dygraphs_1.1.1.6  \n\n\n\n\n",
      "last_modified": "2021-03-12T08:08:23-03:00"
    },
    {
      "path": "8-Regressao_Robusta.html",
      "title": "Regressão Robusta",
      "description": "Modelos Lineares Generalizados -- $t$ de Student",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 2, 2021",
      "contents": "\n\nContents\nComparativo Normal vs Student\nModelos Lineares Robustos com o pacote brms\nExemplo com os dados de Prestígio de Duncan (1961)\nPriors do brms\n\nAtividade Prática\nAmbiente\n\n\nLembrando da curva normal gaussiana que possui um formato de sino. Ela não é muito alongada nas “pontas.” Ou seja, as observações não fogem muito da média. Quando usamos essa distribuição como verossimilhança na inferência modelos Bayesianos, forçamos a que todas as estimativas sejam condicionadas à uma distribuição normal da variável dependente. Se nos dados houverem muitas observações com valores discrepantes (bem diferentes da média - outliers), isso faz com que as estimativas dos coeficientes das variáveis independentes fiquem instáveis. Isso ocorre porquê a distribuição normal não consegue contemplar observações muito divergentes da média sem mudar a média de local.\n\n\nx <- seq(-4, 4, length = 100)\nplot(x, dnorm(x),\n     type = \"l\",\n     col = \"red\",\n     lwd = 3,\n     xlab = \"valor de x\",\n     ylab = \"Densidade\",\n     main = \"Distribuição Normal\",\n     sub = \"Média 0 e Desvio Padrão 1\",\n     xlim = c(-4, 4),\n     ylim = c(0, 0.4))\n\n\n\n\nEntão precisamos de uma distribuição mais “maleável” como verossimilhança. Precisamos de uma distribuição que seja mais robusta à observações discrepantes (outliers). Precisamos de uma distribuição similar à Normal mas que possua caudas mais longas para justamente contemplar observações muito longe da média sem ter que mudar a média de local. Para isso temos a distribuição t de Student. Lembrando o formato dela:\n\n\nx <- seq(-4, 4, length = 100)\nplot(x, dt(x, 2),\n     type = \"l\",\n     col = \"blue\",\n     lwd = 3,\n     xlab = \"valor de x\",\n     ylab = \"Densidade\",\n     main = \"Distribuição t de Student\",\n     sub = \"Média 0 e Graus de Liberdade 2\",\n     xlim = c(-4, 4),\n     ylim = c(0, 0.4))\n\n\n\n\nComparativo Normal vs Student\nReparem nas caudas:\n\n\nplot(NA, xlab = \"valor de x\",\n  ylab = \"Densidade\",\n  main = \"Comparativo de Distribuições\",\n  sub = \"Normal vs t de Student\",\n  xlim = c(-4, 4),\n  ylim = c(0, 0.4))\nlines(x, dnorm(x), lwd = 2, col = \"red\")\nlines(x, dt(x, df = 2), lwd = 2, col = \"blue\")\nlegend(\"topright\", legend = c(\"Normal\", \"Student\"),\n       col = c(\"red\", \"blue\"), title = \"Distribuições\", lty = 1)\n\n\n\n\nModelos Lineares Robustos com o pacote brms\nO rstanarm não possui a possibilidade de usar distribuições t de Student como verossimilhança do modelo Bayesiano. Para usarmos distribuições t de Student, precisamos do pacote brms. O brms usa a mesma síntaxe que o rstanarm e a única diferença é que o brms não possui os modelos pré-compilados então os modelos devem ser todos compilados antes de serem rodados. A diferença prática é que você irá esperar alguns instantes antes do R começar a simular MCMC e amostrar do modelo.\nA função que usa-se para designar modelos lineares no brms é a brm():\n\n\nbrm(y ~ x1 + x2 + x3,\n    data = df,\n    family = student)\n\n\n\nExemplo com os dados de Prestígio de Duncan (1961)\nPara exemplicar regressão robusta vamos usar um dataset que tem muitas observações discrepantes (outliers) chamado Duncan. Ele possui 45 observações sobre ocupações nos EUA e 4 variáveis:\ntype: Tipo de ocupação. Uma variável qualitativa:\nprof - profissional ou de gestão\nwc - white-collar (colarinho branco)\nbc - blue-collar (colarinho azul)\n\nincome: Porcentagem de pessoas da ocupação que ganham acima $ 3.500 por ano em 1950 (mais ou menos $36.000 em 2017);\neducation: Porcentagem de pessoas da ocupação que possuem diploma de ensino médio em 1949 (que, sendo cínicos, podemos dizer que é de certa maneira equivalente com diploma de Doutorado em 2017); e\nprestige:Porcentagem de respondentes na pesquisa que classificam a sua ocupação como no mínimo “boa” em respeito à prestígio.\n\n\nduncan <- read.csv2(\"datasets/Duncan.csv\", row.names = 1, stringsAsFactors = TRUE)\n\nhist(duncan$prestige,\n     main = \"Histograma do Prestígio\",\n     xlab = \"Prestígio\",\n     ylab = \"Frequência\")\n\n\n\n\nPrimeiro modelo: Regressão Linear\nVamos estimar primeiramente uma regressão linear usando a distribuição Normal como verossimilhança:\n\n\nlibrary(rstanarm)\nmodel_1 <- stan_glm(\n  prestige ~ income + education,\n  data = duncan,\n  family = gaussian\n)\n\n\n\nE na sequência o sumário das estimativas do modelo, assim como os diagnósticos da MCMC:\n\n\nsummary(model_1)\n\n\n\nModel Info:\n function:     stan_glm\n family:       gaussian [identity]\n formula:      prestige ~ income + education\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 45\n predictors:   3\n\nEstimates:\n              mean   sd    10%   50%   90%\n(Intercept)  -6.1    4.5 -11.9  -6.2  -0.4\nincome        0.6    0.1   0.4   0.6   0.8\neducation     0.5    0.1   0.4   0.5   0.7\nsigma        13.7    1.6  11.8  13.6  15.8\n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 47.6    2.9 44.0  47.6  51.3 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.1  1.0  4669 \nincome        0.0  1.0  1879 \neducation     0.0  1.0  1822 \nsigma         0.0  1.0  2673 \nmean_PPD      0.0  1.0  3561 \nlog-posterior 0.0  1.0  1582 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nAparentemente parece que o modelo possui boas métricas mas quando olhamos o posterior predictive check, vemos uma bagunça:\n\n\npp_check(model_1, nsamples = 45)\n\n\n\n\nSegundo modelo: Regressão Robusta\nPara rodar um modelo Bayesiano que usa como verossimilhança a distribuição t de Student é somente usar a mesma síntaxe que o stan_glm mas colocando argumento family = student:\n\n\nlibrary(brms)\nmodel_2 <- brm(\n  prestige ~ income + education,\n  data = duncan,\n  family = student)\n\n\n\nE na sequência o sumário das estimativas do modelo, assim como os diagnósticos da MCMC. Vemos que as estimativas não alteraram muito. Além disso temos um novo parâmetro estimado pelo modelo que é o parâmetro nu (\\(\\nu\\)), que é os graus de liberdade da distribuição t de Student usada como verossimilhança:\n\n\nsummary(model_2, prob =  0.9)\n\n\n Family: student \n  Links: mu = identity; sigma = identity; nu = identity \nFormula: prestige ~ income + education \n   Data: duncan (Number of observations: 45) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-90% CI u-90% CI Rhat Bulk_ESS Tail_ESS\nIntercept    -6.78      4.17   -13.51     0.16 1.00     4571     3354\nincome        0.66      0.14     0.43     0.88 1.00     1911     2060\neducation     0.51      0.11     0.33     0.70 1.00     2027     2303\n\nFamily Specific Parameters: \n      Estimate Est.Error l-90% CI u-90% CI Rhat Bulk_ESS Tail_ESS\nsigma    12.27      1.87     9.23    15.35 1.00     1861     1718\nnu       17.57     13.32     3.56    43.24 1.00     1923     1674\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nMas a posterior predictive check ficou com um aspecto muito melhor que o modelo linear:\n\n\npp_check(model_2, nsamples = 45)\n\n\n\n\nPriors do brms\nbrms possui as seguintes configurações como padrão de priors para regressão robusta usando t de Student:\nConstante (Intercept): t de Student com média \\(\\mu = \\text{median}_y\\), desvio padrão de \\(\\max(2.5, MAD(y)\\) e graus de liberdade \\(3\\) - prior = student_t(3, median_y, mad_y), class = intercept\nCoeficientes: para cada coeficiente média \\(\\mu = 0\\) e desvio padrão de \\(2.5\\times\\frac{1}{\\sigma_{x_k}}\\) - prior = normal(0, 2.5 * 1/sd_xk)\nErro residual (sigma): t de Student com média \\(\\mu = 0\\), desvio padrão de \\(\\max(2.5, MAD(y)\\) e graus de liberdade \\(3\\) - prior = student_t(3, 0, mad_y), class = sigma\nGraus de liberdade (nu): distribuição gamma com \\(\\alpha = 2\\) e \\(\\beta = 0.1\\) - prior = gamma(2, 0.1), class = nu\nAtividade Prática\nO dataset Boston Housing está disponível em datasets/Boston_Housing.csv. Possui 506 observações e possui 14 variáveis:\nCRIM - per capita crime rate by town\nZN - proportion of residential land zoned for lots over 25,000 sq.ft.\nINDUS - proportion of non-retail business acres per town.\nCHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\nNOX - nitric oxides concentration (parts per 10 million)\nRM - average number of rooms per dwelling\nAGE - proportion of owner-occupied units built prior to 1940\nDIS - weighted distances to five Boston employment centres\nRAD - index of accessibility to radial highways\nTAX - full-value property-tax rate per $10,000\nPTRATIO - pupil-teacher ratio by town\nB - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\nLSTAT - % lower status of the population\nMEDV - Median value of owner-occupied homes in $1000’s\n\n\n###\n\n\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.4 (2021-02-15)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n [1] brms_2.14.4          gapminder_0.3.0      skimr_2.1.2         \n [4] dplyr_1.0.4          rstan_2.21.2         StanHeaders_2.21.0-7\n [7] MASS_7.3-53.1        ggforce_0.3.2        gganimate_1.0.7     \n[10] plotly_4.9.3         carData_3.0-4        rstanarm_2.21.1     \n[13] Rcpp_1.0.6           readxl_1.3.1         tibble_3.1.0        \n[16] ggplot2_3.3.3        patchwork_1.1.1      cowplot_1.1.1       \n\nloaded via a namespace (and not attached):\n  [1] backports_1.2.1      systemfonts_1.0.1    plyr_1.8.6          \n  [4] igraph_1.2.6         repr_1.1.3           lazyeval_0.2.2      \n  [7] splines_4.0.4        crosstalk_1.1.1      TH.data_1.0-10      \n [10] rstantools_2.1.1     inline_0.3.17        digest_0.6.27       \n [13] htmltools_0.5.1.1    magick_2.6.0         rsconnect_0.8.16    \n [16] fansi_0.4.2          magrittr_2.0.1       RcppParallel_5.0.3  \n [19] matrixStats_0.58.0   sandwich_3.0-0       xts_0.12.1          \n [22] prettyunits_1.1.1    jpeg_0.1-8.1         colorspace_2.0-0    \n [25] textshaping_0.3.1    xfun_0.21            callr_3.5.1         \n [28] crayon_1.4.1         jsonlite_1.7.2       lme4_1.1-26         \n [31] survival_3.2-7       zoo_1.8-8            glue_1.4.2          \n [34] polyclip_1.10-0      gtable_0.3.0         emmeans_1.5.4       \n [37] V8_3.4.0             pkgbuild_1.2.0       abind_1.4-5         \n [40] scales_1.1.1         mvtnorm_1.1-1        DBI_1.1.1           \n [43] miniUI_0.1.1.1       isoband_0.2.3        viridisLite_0.3.0   \n [46] xtable_1.8-4         progress_1.2.2       tmvnsim_1.0-2       \n [49] stats4_4.0.4         DT_0.17              htmlwidgets_1.5.3   \n [52] httr_1.4.2           threejs_0.3.3        RColorBrewer_1.1-2  \n [55] ellipsis_0.3.1       pkgconfig_2.0.3      loo_2.4.1           \n [58] farver_2.1.0         sass_0.3.1           here_1.0.1          \n [61] utf8_1.1.4           tidyselect_1.1.0     labeling_0.4.2      \n [64] rlang_0.4.10         reshape2_1.4.4       later_1.1.0.1       \n [67] munsell_0.5.0        cellranger_1.1.0     tools_4.0.4         \n [70] cli_2.3.1            generics_0.1.0       gifski_0.8.7        \n [73] ggridges_0.5.3       evaluate_0.14        stringr_1.4.0       \n [76] fastmap_1.1.0        yaml_2.2.1           ragg_1.1.1          \n [79] processx_3.4.5       knitr_1.31           purrr_0.3.4         \n [82] nlme_3.1-152         projpred_2.0.2       mime_0.10           \n [85] xml2_1.3.2           compiler_4.0.4       bayesplot_1.8.0     \n [88] shinythemes_1.2.0    rstudioapi_0.13      gamm4_0.2-6         \n [91] png_0.1-7            curl_4.3             statmod_1.4.35      \n [94] tweenr_1.0.1         bslib_0.2.4          stringi_1.5.3       \n [97] highr_0.8            ps_1.6.0             Brobdingnag_1.2-6   \n[100] lattice_0.20-41      Matrix_1.3-2         nloptr_1.2.2.2      \n[103] markdown_1.1         shinyjs_2.0.0        vctrs_0.3.6         \n[106] pillar_1.5.0         lifecycle_1.0.0      bridgesampling_1.0-0\n[109] jquerylib_0.1.3      estimability_1.3     data.table_1.14.0   \n[112] httpuv_1.5.5         R6_2.5.0             bookdown_0.21       \n[115] promises_1.2.0.1     gridExtra_2.3        codetools_0.2-18    \n[118] distill_1.2          boot_1.3-27          colourpicker_1.1.0  \n[121] gtools_3.8.2         assertthat_0.2.1     rprojroot_2.0.2     \n[124] withr_2.4.1          mnormt_2.0.2         shinystan_2.5.0     \n[127] multcomp_1.4-16      mgcv_1.8-34          parallel_4.0.4      \n[130] hms_1.0.0            grid_4.0.4           coda_0.19-4         \n[133] tidyr_1.1.2          minqa_1.2.4          rmarkdown_2.7       \n[136] downlit_0.2.1        shiny_1.6.0          lubridate_1.7.10    \n[139] base64enc_0.1-3      dygraphs_1.1.1.6    \n\n\n\n\n",
      "last_modified": "2021-03-12T08:08:23-03:00"
    },
    {
      "path": "9-Regressao_Multinivel.html",
      "title": "Modelos Multiniveis",
      "description": "Modelos Multiniveis ou Modelos Hierárquicos",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 2, 2021",
      "contents": "\n\nContents\nQuando usar Modelos Multiníveis?\nHyperprior\nTrês abordagens\nRandom Intercept Model\nRandom Slope Model\nRandom Intercept-Slope Model\nExemplo com o dataset cheese\n\nPriors de Modelos Multiníveis\nAtividade Prática\nAmbiente\n\n\nModelos hierárquicos Bayesianos (também chamados de modelos multiníveis) são um modelo estatístico escrito em níveis múltiplos (forma hierárquica) que estima os parâmetros da distribuição posterior usando o método Bayesiano. Os submodelos se combinam para formar o modelo hierárquico, e o teorema de Bayes é usado para integrá-los aos dados observados e contabilizar toda a incerteza que está presente. O resultado dessa integração é a distribuição posterior, também conhecida como estimativa de probabilidade atualizada, à medida que evidências adicionais sobre a distribuição anterior são adquiridas.\nA modelagem hierárquica é usada quando as informações estão disponíveis em vários níveis diferentes de unidades de observação. A forma hierárquica de análise e organização auxilia no entendimento de problemas multiparâmetros e também desempenha um papel importante no desenvolvimento de estratégias computacionais.\nOs modelos hierárquicos são descrições matemáticas que envolvem vários parâmetros, de modo que as estimativas de alguns parâmetros dependem significativamente dos valores de outros parâmetros.\nModelo HierárquicoQuando usar Modelos Multiníveis?\nModelos multiníveis são particularmente apropriados para projetos de pesquisa onde os dados dos participantes são organizados em mais de um nível (ou seja, dados aninhados - nested data). As unidades de análise geralmente são indivíduos (em um nível inferior) que estão aninhados em unidades contextuais/agregadas (em um nível superior).\nHá um pressuposto principal que não pode ser violado em modelos multiníveis que é o de permutabilidade. Esse pressuposto parte do princípio que os grupos são permutáveis. Se esse pressuposto é violado na sua inferência, então modelos multiníveis não são apropriados.\nHyperprior\nComo as priors dos parâmetros são amostradas de uma outra prior do hiperparâmetro (parâmetro do nível superior), as priors do nível superior são chamadas de hyperpriors. Isso faz com que estimativas de um grupo ajudem o modelo a estimar melhor os outros grupos e dando estimativas mais robustas e estáveis.\nTrês abordagens\nModelos multiníveis geralmente se dividem em três abordagens:\nRandom intercept model: Modelo no qual cada grupo recebe uma constante (intercept) diferente\nRandom slope model: Modelo no qual cada grupo recebe um coeficiente diferente para cada variável independente\nRandom intercept-slope model: Modelo no qual cada grupo recebe tanto uma constante (intercept) quanto um coeficiente diferente para cada variável independente\nRandom Intercept Model\nA primeira abordagem é o random intercept model na qual especificamos para cada grupo uma constante diferente. Essas constantes são amostrada de uma hyperprior.\nO pacote rstanarm tem as funcionalidades completas para rodar modelos multiníveis e a única coisa a se fazer é alterar a formula. Há uma segunda mudança também que não usamos mais a função stan_glm() mas sim a função stan_glmer().\nNo caso de random intercept model, a formula a ser usada segue este padrão:\ny ~ (1 | group) + x1 + x2\nRandom Slope Model\nA segunda abordagem é o random slope model na qual especificamos para cada grupo um coeficiente diferente para cada variável independente. Esses coeficientes são amostrada de uma hyperprior.\nNo caso de random slope model, a formula a ser usada segue este padrão:\ny ~ (0 + x1 | group) + (0 + x2 | group)\nRandom Intercept-Slope Model\nA terceira abordagem é o random intercept-slope model na qual especificamos para cada grupo uma constante diferente além de coeficientes diferentes para cada variável independente. Essas constantes e coeficientes são amostrados de duas ou mais hyperpriors.\nNo caso de random intercept-slope model, a formula a ser usada segue este padrão:\ny ~ (1 + x1 | group) + (1 + x2 | group)\nExemplo com o dataset cheese\nO dataset cheese possui 160 observações de avaliações de queijo. Um grupo de 10 avaliadores “rurais” e 10 “urbanos” avaliaram 4 queijos diferentes \\((A,B,C,D)\\) em duas amostras. Portanto \\(4 \\cdot 20 \\cdot 2 = 160\\). Possui 4 variáveis:\ncheese: tipo do queijo \\((A,B,C,D)\\)\nrater: avaliador \\((1,\\dots, 10)\\)\nbackground: origem do avaliador em “urbano” ou “rural”\ny: variável dependente - nota da avaliação\n\n\ncheese <- read.csv2(\"datasets/cheese.csv\", stringsAsFactors = TRUE, row.names = 1)\n\n\n\nRandom Intercept Model\nNo primeiro exemplo vamos usar um modelo que cada grupo de cheese recebe uma constante diferente:\n\n\nlibrary(rstanarm)\nrandom_intercept <- stan_glmer(\n  y ~ (1 | cheese) + background,\n  data = cheese\n)\n\n\n\nNo sumário do modelo vemos que os avaliadores urbanos avaliam melhor os queijos que os avaliadores rurais, mas também observamos que cada queijo possui uma “taxa basal” de avaliação. Sendo \\(B\\) o pior queijo e \\(C\\) o melhor queijo:\n\n\nsummary(random_intercept)\n\n\n\nModel Info:\n function:     stan_glmer\n family:       gaussian [identity]\n formula:      y ~ (1 | cheese) + background\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 160\n groups:       cheese (4)\n\nEstimates:\n                                        mean   sd    10%   50%   90%\n(Intercept)                            67.1    5.6  60.5  67.4  73.5\nbackgroundurban                         7.4    1.1   5.9   7.4   8.8\nb[(Intercept) cheese:A]                 3.9    5.6  -2.5   3.7  10.5\nb[(Intercept) cheese:B]               -14.0    5.6 -20.4 -14.2  -7.4\nb[(Intercept) cheese:C]                 8.6    5.6   2.3   8.4  15.2\nb[(Intercept) cheese:D]                 1.5    5.6  -5.0   1.3   8.2\nsigma                                   7.1    0.4   6.6   7.0   7.6\nSigma[cheese:(Intercept),(Intercept)] 134.4  124.8  41.7  98.3 269.9\n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 70.8    0.8 69.8  70.8  71.9 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n                                      mcse Rhat n_eff\n(Intercept)                           0.2  1.0  1054 \nbackgroundurban                       0.0  1.0  3739 \nb[(Intercept) cheese:A]               0.2  1.0  1025 \nb[(Intercept) cheese:B]               0.2  1.0  1073 \nb[(Intercept) cheese:C]               0.2  1.0  1043 \nb[(Intercept) cheese:D]               0.2  1.0  1052 \nsigma                                 0.0  1.0  3254 \nSigma[cheese:(Intercept),(Intercept)] 3.4  1.0  1321 \nmean_PPD                              0.0  1.0  4182 \nlog-posterior                         0.1  1.0  1091 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nRandom Slope Model\nNo segundo exemplo vamos usar um modelo que cada grupo de cheese recebe um coeficiente diferente para background:\n\n\nrandom_slope <- stan_glmer(\n  y ~ (0 + background | cheese),\n  data = cheese\n)\n\n\n\nAqui vemos que todos os queijos recebem a mesma constante mas cada queijo possui um coeficiente diferente para background do avaliador:\n\n\nsummary(random_slope)\n\n\n\nModel Info:\n function:     stan_glmer\n family:       gaussian [identity]\n formula:      y ~ (0 + background | cheese)\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 160\n groups:       cheese (4)\n\nEstimates:\n                                                mean   sd    10%\n(Intercept)                                    69.7    5.9  62.4\nb[backgroundrural cheese:A]                     1.1    6.0  -6.3\nb[backgroundurban cheese:A]                     9.0    6.1   1.5\nb[backgroundrural cheese:B]                   -15.4    6.3 -23.4\nb[backgroundurban cheese:B]                   -10.0    5.9 -17.3\nb[backgroundrural cheese:C]                     5.6    6.0  -1.9\nb[backgroundurban cheese:C]                    13.9    6.1   6.2\nb[backgroundrural cheese:D]                    -0.4    6.0  -7.8\nb[backgroundurban cheese:D]                     5.7    6.1  -1.6\nsigma                                           7.1    0.4   6.6\nSigma[cheese:backgroundrural,backgroundrural] 130.7  117.9  39.9\nSigma[cheese:backgroundurban,backgroundrural]  74.0   87.4   5.5\nSigma[cheese:backgroundurban,backgroundurban] 165.2  153.7  51.7\n                                                50%   90%\n(Intercept)                                    69.7  77.0\nb[backgroundrural cheese:A]                     1.1   8.4\nb[backgroundurban cheese:A]                     9.0  16.4\nb[backgroundrural cheese:B]                   -15.2  -7.8\nb[backgroundurban cheese:B]                   -10.0  -3.0\nb[backgroundrural cheese:C]                     5.6  13.0\nb[backgroundurban cheese:C]                    13.9  21.6\nb[backgroundrural cheese:D]                    -0.3   7.0\nb[backgroundurban cheese:D]                     5.8  13.1\nsigma                                           7.1   7.7\nSigma[cheese:backgroundrural,backgroundrural]  94.4 258.1\nSigma[cheese:backgroundurban,backgroundrural]  53.0 168.6\nSigma[cheese:backgroundurban,backgroundurban] 121.3 319.3\n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 70.8    0.8 69.8  70.9  71.8 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n                                              mcse Rhat n_eff\n(Intercept)                                   0.2  1.0   763 \nb[backgroundrural cheese:A]                   0.2  1.0   790 \nb[backgroundurban cheese:A]                   0.2  1.0   811 \nb[backgroundrural cheese:B]                   0.2  1.0   807 \nb[backgroundurban cheese:B]                   0.2  1.0   821 \nb[backgroundrural cheese:C]                   0.2  1.0   798 \nb[backgroundurban cheese:C]                   0.2  1.0   800 \nb[backgroundrural cheese:D]                   0.2  1.0   793 \nb[backgroundurban cheese:D]                   0.2  1.0   786 \nsigma                                         0.0  1.0  3990 \nSigma[cheese:backgroundrural,backgroundrural] 2.8  1.0  1748 \nSigma[cheese:backgroundurban,backgroundrural] 2.5  1.0  1216 \nSigma[cheese:backgroundurban,backgroundurban] 4.2  1.0  1328 \nmean_PPD                                      0.0  1.0  4042 \nlog-posterior                                 0.1  1.0  1101 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nRandom Intercept-Slope Model\nNo terceiro exemplo vamos usar um modelo que cada grupo de cheese recebe uma constante diferente e um coeficiente diferente para background:\n\n\nrandom_intercept_slope <- stan_glmer(\n  y ~ (1 + background | cheese),\n  data = cheese\n)\n\n\n\nAqui vemos que os queijos recebem a constantes diferentes e que cada queijo possui um coeficiente diferente para background do avaliador:\n\n\nsummary(random_intercept_slope)\n\n\n\nModel Info:\n function:     stan_glmer\n family:       gaussian [identity]\n formula:      y ~ (1 + background | cheese)\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 160\n groups:       cheese (4)\n\nEstimates:\n                                                mean   sd    10%\n(Intercept)                                    65.3    7.5  56.3\nb[(Intercept) cheese:A]                         5.5    7.6  -3.6\nb[backgroundurban cheese:A]                     7.8    2.1   5.1\nb[(Intercept) cheese:B]                       -10.8    7.8 -20.3\nb[backgroundurban cheese:B]                     4.7    2.3   1.8\nb[(Intercept) cheese:C]                         9.9    7.5   0.9\nb[backgroundurban cheese:C]                     8.4    2.2   5.6\nb[(Intercept) cheese:D]                         3.9    7.5  -5.1\nb[backgroundurban cheese:D]                     6.0    2.1   3.4\nsigma                                           7.1    0.4   6.6\nSigma[cheese:(Intercept),(Intercept)]         152.5  153.2  44.7\nSigma[cheese:backgroundurban,(Intercept)]      21.8   76.7 -49.0\nSigma[cheese:backgroundurban,backgroundurban]  86.4   84.2  26.2\n                                                50%   90%\n(Intercept)                                    65.4  74.4\nb[(Intercept) cheese:A]                         5.5  14.7\nb[backgroundurban cheese:A]                     7.8  10.6\nb[(Intercept) cheese:B]                       -10.7  -1.4\nb[backgroundurban cheese:B]                     4.7   7.6\nb[(Intercept) cheese:C]                         9.9  18.9\nb[backgroundurban cheese:C]                     8.4  11.2\nb[(Intercept) cheese:D]                         3.9  12.9\nb[backgroundurban cheese:D]                     6.0   8.7\nsigma                                           7.1   7.7\nSigma[cheese:(Intercept),(Intercept)]         106.8 307.7\nSigma[cheese:backgroundurban,(Intercept)]      17.1  95.3\nSigma[cheese:backgroundurban,backgroundurban]  62.4 170.5\n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 70.8    0.8 69.8  70.9  71.9 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n                                              mcse Rhat n_eff\n(Intercept)                                   0.3  1.0   716 \nb[(Intercept) cheese:A]                       0.3  1.0   735 \nb[backgroundurban cheese:A]                   0.0  1.0  4987 \nb[(Intercept) cheese:B]                       0.3  1.0   726 \nb[backgroundurban cheese:B]                   0.0  1.0  2882 \nb[(Intercept) cheese:C]                       0.3  1.0   734 \nb[backgroundurban cheese:C]                   0.0  1.0  4247 \nb[(Intercept) cheese:D]                       0.3  1.0   713 \nb[backgroundurban cheese:D]                   0.0  1.0  4840 \nsigma                                         0.0  1.0  3814 \nSigma[cheese:(Intercept),(Intercept)]         4.0  1.0  1498 \nSigma[cheese:backgroundurban,(Intercept)]     2.6  1.0   857 \nSigma[cheese:backgroundurban,backgroundurban] 1.9  1.0  2063 \nmean_PPD                                      0.0  1.0  3851 \nlog-posterior                                 0.1  1.0  1173 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nPriors de Modelos Multiníveis\nRelembrando a tabela de priors da Aula 4:\nArgumento\nUsado em\nAplica-se à\nprior_intercept\nTodas funções de modelagem exceto stan_polr and stan_nlmer\nConstante (intercept) do modelo, após centralização dos preditores\nprior\nTodas funções de modelagem\nCoeficientes de Regressão, não inclui coeficientes que variam por grupo em modelos multiníveis (veja prior_covariance)\nprior_aux\nstan_glm, stan_glmer, stan_gamm4, stan_nlmer\nParâmetro auxiliar (ex: desvio padrão (standard error - DP), interpretação depende do modelo\nprior_covariance\nstan_glmer, stan_gamm4, stan_nlmer\nMatrizes de covariância em modelos multiníveis\nConstante(Intercept): centralizada com média \\(\\mu_{y_{group}}\\) para cada grupo e desvio padrão de \\(2.5 \\sigma_{y_{group}}\\) para cada grupo - prior_intercept = normal(mean_y_group, 2.5 * sd_y_group)\nCoeficientes: aqui não especifica-se uma prior para cada coeficiente, mas sim uma prior para a matriz de correlação das variáveis independentes usando uma distribuição LKJ - prior_covariance = lkj(regularization = 1, concentration = 1, shape = 1, scale = 1)\nAtividade Prática\nPara atividade prática, temos o dataset rikz em datasets/rikz.csv.\nFor each of 9 intertidal areas (denoted ‘Beaches’), the researchers sampled five sites (denoted ‘Sites’) and at each site they measured abiotic variables and the diversity of macro-fauna (e.g. aquatic invertebrates). Here, species richness refers to the total number of species found at a given site while NAP ( i.e. Normal Amsterdams Peil) refers to the height of the sampling location relative to the mean sea level and represents a measure of the amount of food available for birds, etc. For our purpose, the main question is:\nWhat is the influence of NAP on species richness?\nRikz Dataset\n\nrikz <- read.csv2(\"datasets/rikz.csv\", row.names = 1)\nrikz$Beach <- as.factor(rikz$Beach)\nrikz$Site <- as.factor(rikz$Site)\n\n\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.4 (2021-02-15)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n [1] brms_2.14.4          gapminder_0.3.0      skimr_2.1.2         \n [4] dplyr_1.0.4          rstan_2.21.2         StanHeaders_2.21.0-7\n [7] MASS_7.3-53.1        ggforce_0.3.2        gganimate_1.0.7     \n[10] plotly_4.9.3         carData_3.0-4        rstanarm_2.21.1     \n[13] Rcpp_1.0.6           readxl_1.3.1         tibble_3.1.0        \n[16] ggplot2_3.3.3        patchwork_1.1.1      cowplot_1.1.1       \n\nloaded via a namespace (and not attached):\n  [1] backports_1.2.1      systemfonts_1.0.1    plyr_1.8.6          \n  [4] igraph_1.2.6         repr_1.1.3           lazyeval_0.2.2      \n  [7] splines_4.0.4        crosstalk_1.1.1      TH.data_1.0-10      \n [10] rstantools_2.1.1     inline_0.3.17        digest_0.6.27       \n [13] htmltools_0.5.1.1    magick_2.6.0         rsconnect_0.8.16    \n [16] fansi_0.4.2          magrittr_2.0.1       RcppParallel_5.0.3  \n [19] matrixStats_0.58.0   sandwich_3.0-0       xts_0.12.1          \n [22] prettyunits_1.1.1    jpeg_0.1-8.1         colorspace_2.0-0    \n [25] textshaping_0.3.1    xfun_0.21            callr_3.5.1         \n [28] crayon_1.4.1         jsonlite_1.7.2       lme4_1.1-26         \n [31] survival_3.2-7       zoo_1.8-8            glue_1.4.2          \n [34] polyclip_1.10-0      gtable_0.3.0         emmeans_1.5.4       \n [37] V8_3.4.0             pkgbuild_1.2.0       abind_1.4-5         \n [40] scales_1.1.1         mvtnorm_1.1-1        DBI_1.1.1           \n [43] miniUI_0.1.1.1       isoband_0.2.3        viridisLite_0.3.0   \n [46] xtable_1.8-4         progress_1.2.2       tmvnsim_1.0-2       \n [49] stats4_4.0.4         DT_0.17              htmlwidgets_1.5.3   \n [52] httr_1.4.2           threejs_0.3.3        RColorBrewer_1.1-2  \n [55] ellipsis_0.3.1       pkgconfig_2.0.3      loo_2.4.1           \n [58] farver_2.1.0         sass_0.3.1           here_1.0.1          \n [61] utf8_1.1.4           tidyselect_1.1.0     labeling_0.4.2      \n [64] rlang_0.4.10         reshape2_1.4.4       later_1.1.0.1       \n [67] munsell_0.5.0        cellranger_1.1.0     tools_4.0.4         \n [70] cli_2.3.1            generics_0.1.0       gifski_0.8.7        \n [73] ggridges_0.5.3       evaluate_0.14        stringr_1.4.0       \n [76] fastmap_1.1.0        yaml_2.2.1           ragg_1.1.1          \n [79] processx_3.4.5       knitr_1.31           purrr_0.3.4         \n [82] nlme_3.1-152         projpred_2.0.2       mime_0.10           \n [85] xml2_1.3.2           compiler_4.0.4       bayesplot_1.8.0     \n [88] shinythemes_1.2.0    rstudioapi_0.13      gamm4_0.2-6         \n [91] png_0.1-7            curl_4.3             statmod_1.4.35      \n [94] tweenr_1.0.1         bslib_0.2.4          stringi_1.5.3       \n [97] highr_0.8            ps_1.6.0             Brobdingnag_1.2-6   \n[100] lattice_0.20-41      Matrix_1.3-2         nloptr_1.2.2.2      \n[103] markdown_1.1         shinyjs_2.0.0        vctrs_0.3.6         \n[106] pillar_1.5.0         lifecycle_1.0.0      bridgesampling_1.0-0\n[109] jquerylib_0.1.3      estimability_1.3     data.table_1.14.0   \n[112] httpuv_1.5.5         R6_2.5.0             bookdown_0.21       \n[115] promises_1.2.0.1     gridExtra_2.3        codetools_0.2-18    \n[118] distill_1.2          boot_1.3-27          colourpicker_1.1.0  \n[121] gtools_3.8.2         assertthat_0.2.1     rprojroot_2.0.2     \n[124] withr_2.4.1          mnormt_2.0.2         shinystan_2.5.0     \n[127] multcomp_1.4-16      mgcv_1.8-34          parallel_4.0.4      \n[130] hms_1.0.0            grid_4.0.4           coda_0.19-4         \n[133] tidyr_1.1.2          minqa_1.2.4          rmarkdown_2.7       \n[136] downlit_0.2.1        shiny_1.6.0          lubridate_1.7.10    \n[139] base64enc_0.1-3      dygraphs_1.1.1.6    \n\n\n\n\n",
      "last_modified": "2021-03-12T08:08:23-03:00"
    },
    {
      "path": "aux-Dados_Faltantes.html",
      "title": "Dados Faltantes",
      "description": "Dados Faltantes",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 2, 2021",
      "contents": "\n\nContents\nRemover dados faltantes\nImputar valores nos dados faltantes\nImputar a média\nImputar a mediana\nImputar o último valor ocorrido\n\nComparação dos resultados\nAmbiente\n\n\nDados faltantes são um problema comum em qualquer análise de dados. Tanto o rstan, quanto brms e rstanarm usam observações completas nas suas inferências. Então, toma observação que contiver qualquer dado faltante será removida por completa. Temos duas abordagens básicas para lidar com dados faltantes1:\nremover os dados faltantes\nimputar valores nos dados faltantes\nRemover dados faltantes\nA remoção de dados faltantes se divide em duas principais abordagens usando a função na.omit() do pacote base stats:\nremoção de observações com dados faltantes: aqui removemos as linhas com dados faltantes df <- na.omit(df)\nremoção de variáveis com dados faltantes: aqui removemos as colunas com dados faltantes df <- t(na.omit(t(df)))\nImputar valores nos dados faltantes\nDentre as diversas maneiras de imputar valores ao dados faltantes, as mais comuns são três:\nimputar a média\nimputar a mediana\nimputar o último valor ocorrido (muito usada em séries temporais)\nMas ainda há maneiras mais avançadas e que desempenham melhor em certas condições (não cobriremos essas técnicas nesse curso):\nk-nearest neighbors imputation\nrandom forest imputation\nHá um pacote de R chamado DescTools que é uma coleção de funções focadas especialmente na parte descritiva de análise de um dataset.\nPara mostrar as abordagens, geramos um dataset de uma série temporal de uma semana com dados faltantes:\n\n\nlibrary(DescTools)\nset.seed(123)\ndf <- data.frame(\n  dia = c(\"seg\", \"ter\", \"qua\", \"qui\", \"sex\", \"sab\", \"dom\"),\n  valor = runif(7))\nindices_aleatorios <- sample(1:nrow(df), 2)\ndf[indices_aleatorios[1], 2] <- NA\ndf[indices_aleatorios[2], 2] <- NA\n\n\n\nImputar a média\n\n\ndf$media <- Impute(df$valor, FUN = mean(df$valor, na.rm = T))\n\n\n\nImputar a mediana\n\n\ndf$mediana <- Impute(df$valor, FUN = median(df$valor, na.rm = T))\n\n\n\nImputar o último valor ocorrido\n\n\ndf$ultimo <- LOCF(df$valor)\n\n\n\nComparação dos resultados\n\n\ndf\n\n\n  dia valor media mediana ultimo\n1 seg  0.29  0.29    0.29   0.29\n2 ter  0.79  0.79    0.79   0.79\n3 qua    NA  0.69    0.79   0.79\n4 qui  0.88  0.88    0.88   0.88\n5 sex  0.94  0.94    0.94   0.94\n6 sab    NA  0.69    0.79   0.94\n7 dom  0.53  0.53    0.53   0.53\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.4 (2021-02-15)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n [1] DescTools_0.99.40    brms_2.14.4          gapminder_0.3.0     \n [4] skimr_2.1.2          dplyr_1.0.4          rstan_2.21.2        \n [7] StanHeaders_2.21.0-7 MASS_7.3-53.1        ggforce_0.3.2       \n[10] gganimate_1.0.7      plotly_4.9.3         carData_3.0-4       \n[13] rstanarm_2.21.1      Rcpp_1.0.6           readxl_1.3.1        \n[16] tibble_3.1.0         ggplot2_3.3.3        patchwork_1.1.1     \n[19] cowplot_1.1.1       \n\nloaded via a namespace (and not attached):\n  [1] backports_1.2.1      systemfonts_1.0.1    plyr_1.8.6          \n  [4] igraph_1.2.6         repr_1.1.3           lazyeval_0.2.2      \n  [7] splines_4.0.4        crosstalk_1.1.1      TH.data_1.0-10      \n [10] rstantools_2.1.1     inline_0.3.17        digest_0.6.27       \n [13] htmltools_0.5.1.1    magick_2.6.0         rsconnect_0.8.16    \n [16] fansi_0.4.2          magrittr_2.0.1       RcppParallel_5.0.3  \n [19] matrixStats_0.58.0   sandwich_3.0-0       xts_0.12.1          \n [22] prettyunits_1.1.1    jpeg_0.1-8.1         colorspace_2.0-0    \n [25] textshaping_0.3.1    xfun_0.21            callr_3.5.1         \n [28] crayon_1.4.1         jsonlite_1.7.2       Exact_2.1           \n [31] lme4_1.1-26          survival_3.2-7       zoo_1.8-8           \n [34] glue_1.4.2           polyclip_1.10-0      gtable_0.3.0        \n [37] emmeans_1.5.4        V8_3.4.0             pkgbuild_1.2.0      \n [40] abind_1.4-5          scales_1.1.1         mvtnorm_1.1-1       \n [43] DBI_1.1.1            miniUI_0.1.1.1       isoband_0.2.3       \n [46] viridisLite_0.3.0    xtable_1.8-4         progress_1.2.2      \n [49] tmvnsim_1.0-2        stats4_4.0.4         DT_0.17             \n [52] htmlwidgets_1.5.3    httr_1.4.2           threejs_0.3.3       \n [55] RColorBrewer_1.1-2   ellipsis_0.3.1       pkgconfig_2.0.3     \n [58] loo_2.4.1            farver_2.1.0         sass_0.3.1          \n [61] here_1.0.1           utf8_1.1.4           tidyselect_1.1.0    \n [64] labeling_0.4.2       rlang_0.4.10         reshape2_1.4.4      \n [67] later_1.1.0.1        munsell_0.5.0        cellranger_1.1.0    \n [70] tools_4.0.4          cli_2.3.1            generics_0.1.0      \n [73] gifski_0.8.7         ggridges_0.5.3       evaluate_0.14       \n [76] stringr_1.4.0        fastmap_1.1.0        yaml_2.2.1          \n [79] ragg_1.1.1           processx_3.4.5       knitr_1.31          \n [82] purrr_0.3.4          rootSolve_1.8.2.1    nlme_3.1-152        \n [85] projpred_2.0.2       mime_0.10            xml2_1.3.2          \n [88] compiler_4.0.4       bayesplot_1.8.0      shinythemes_1.2.0   \n [91] rstudioapi_0.13      gamm4_0.2-6          png_0.1-7           \n [94] curl_4.3             e1071_1.7-4          statmod_1.4.35      \n [97] tweenr_1.0.1         bslib_0.2.4          stringi_1.5.3       \n[100] highr_0.8            ps_1.6.0             Brobdingnag_1.2-6   \n[103] lattice_0.20-41      Matrix_1.3-2         nloptr_1.2.2.2      \n[106] markdown_1.1         shinyjs_2.0.0        vctrs_0.3.6         \n[109] pillar_1.5.0         lifecycle_1.0.0      bridgesampling_1.0-0\n[112] jquerylib_0.1.3      estimability_1.3     data.table_1.14.0   \n[115] lmom_2.8             httpuv_1.5.5         R6_2.5.0            \n[118] bookdown_0.21        promises_1.2.0.1     gridExtra_2.3       \n[121] gld_2.6.2            codetools_0.2-18     distill_1.2         \n[124] boot_1.3-27          colourpicker_1.1.0   gtools_3.8.2        \n[127] assertthat_0.2.1     rprojroot_2.0.2      withr_2.4.1         \n[130] mnormt_2.0.2         shinystan_2.5.0      multcomp_1.4-16     \n[133] expm_0.999-6         mgcv_1.8-34          parallel_4.0.4      \n[136] hms_1.0.0            grid_4.0.4           class_7.3-18        \n[139] coda_0.19-4          tidyr_1.1.2          minqa_1.2.4         \n[142] rmarkdown_2.7        downlit_0.2.1        shiny_1.6.0         \n[145] lubridate_1.7.10     base64enc_0.1-3      dygraphs_1.1.1.6    \n\n\nhá uma terceira que é modelar os dados faltantes, veja a vinheta do brms para mais detalhes↩︎\n",
      "last_modified": "2021-03-12T08:08:23-03:00"
    },
    {
      "path": "aux-Regressao_Coeficientes.html",
      "title": "Coeficientes de uma Regressão",
      "description": "Diferenças entre Coeficientes Padronizados vs Brutos",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 2, 2021",
      "contents": "\n\nContents\nSimulação\nMédia e Desvio Padrões\nCoeficientes Brutos vs Padronizados\n\nAmbiente\n\n\nEm tabelas de regressão temos geralmente temos duas opções de reportar os coeficientes:\nCoeficientes Brutos: não há transformações e as associações das variáveis independentes/controles (covariáveis) com a dependente são reportadas em suas medidas originais. Exemplo: A cada 1 unidades de aumento de \\(x\\), \\(y\\) aumenta 0.45.\nCoeficientes Padronizados: os coeficientes são transformados para expressarem as associações das variáveis independentes/controles (covariáveis) com a dependente em relação à variação dos seus desvios padrões. Exemplo: A cada 1 desvio padrão de variação positiva de \\(x\\), \\(y\\) possui variação de 0.1 desvio padrão.\nSimulação\nPara explicar melhor esses conceitos, simularemos alguns dados:\n\\(x\\): 1,000 observações amostradas de uma distribuição normal com média 1 e desvio padrão 0.1. \\(x \\sim \\mathcal{N} (1, 0.1)\\)\n\\(y\\): uma combinação linear de \\(100x\\) com uma constante e um erro pequeno normalmente distribuído. \\(y = 10 + 100x + \\epsilon\\) e \\(\\epsilon \\sim \\mathcal{N} (0, 1)\\).\n\n\nN <- 1000\nx <- rnorm(N, 1, 0.1)\nerror <- rnorm(N, 0, 1)\ny <- rep(10, N) + 100*x + error\n\ndf <- data.frame(x, y)\n\n\n\n\n\nlibrary(skimr)\nskim(df)\n\n\nTable 1: Data summary\nName\ndf\nNumber of rows\n1000\nNumber of columns\n2\n_______________________\n\nColumn type frequency:\n\nnumeric\n2\n________________________\n\nGroup variables\nNone\nVariable type: numeric\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\nx\n0\n1\n1\n0.1\n0.67\n0.93\n1\n1.1\n1.3\n▁▃▇▃▁\ny\n0\n1\n110\n10.1\n75.94\n103.01\n109\n116.5\n142.7\n▁▃▇▃▁\n\nMédia e Desvio Padrões\nPrestem atenção:\n\\(x\\): média 1, desvio padrão 0.1\n\\(y\\): média 109.6, desvio padrão 10.05\nCoeficientes Brutos vs Padronizados\nAgora vamos rodar uma regressão e mostrar coeficientes tanto os coeficientes brutos e os padronizados\n\n\nlibrary(lm.beta)\nmodel <- lm.beta(lm(y ~ x, df))\nsummary(model)\n\n\n\nCall:\nlm(formula = y ~ x, data = df)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-3.701 -0.727 -0.009  0.683  2.728 \n\nCoefficients:\n            Estimate Standardized Std. Error t value\n(Intercept)    9.460        0.000      0.324    29.2\nx            100.506        0.995      0.324   310.5\n                       Pr(>|t|)    \n(Intercept) <0.0000000000000002 ***\nx           <0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1 on 998 degrees of freedom\nMultiple R-squared:  0.99,  Adjusted R-squared:  0.99 \nF-statistic: 9.64e+04 on 1 and 998 DF,  p-value: <0.0000000000000002\n\nPor fim, ambas colunas mostram a mesma coisa\nColuna não padronizada Estimate: a cada 1 unidade que \\(x\\) aumenta, \\(y\\) aumenta 100.51\nColuna padronizada Standardized: a cada 1 desvio padrão de \\(x\\) de incremento (dp = 0.1), há um aumento de 0.99 desvio padrão de \\(y\\) (10). Um total de 100.51. \\(\\big( \\frac{0.955 * \\operatorname{sd}_y}{\\operatorname{sd}_x}\\big)\\)\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.4 (2021-02-15)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n [1] lm.beta_1.5-1        DescTools_0.99.40    brms_2.14.4         \n [4] gapminder_0.3.0      skimr_2.1.2          dplyr_1.0.4         \n [7] rstan_2.21.2         StanHeaders_2.21.0-7 MASS_7.3-53.1       \n[10] ggforce_0.3.2        gganimate_1.0.7      plotly_4.9.3        \n[13] carData_3.0-4        rstanarm_2.21.1      Rcpp_1.0.6          \n[16] readxl_1.3.1         tibble_3.1.0         ggplot2_3.3.3       \n[19] patchwork_1.1.1      cowplot_1.1.1       \n\nloaded via a namespace (and not attached):\n  [1] utf8_1.1.4           tidyselect_1.1.0     lme4_1.1-26         \n  [4] htmlwidgets_1.5.3    grid_4.0.4           munsell_0.5.0       \n  [7] codetools_0.2-18     ragg_1.1.1           distill_1.2         \n [10] statmod_1.4.35       DT_0.17              gifski_0.8.7        \n [13] miniUI_0.1.1.1       withr_2.4.1          Brobdingnag_1.2-6   \n [16] colorspace_2.0-0     highr_0.8            knitr_1.31          \n [19] rstudioapi_0.13      stats4_4.0.4         bayesplot_1.8.0     \n [22] labeling_0.4.2       emmeans_1.5.4        repr_1.1.3          \n [25] mnormt_2.0.2         polyclip_1.10-0      farver_2.1.0        \n [28] bridgesampling_1.0-0 rprojroot_2.0.2      coda_0.19-4         \n [31] vctrs_0.3.6          generics_0.1.0       TH.data_1.0-10      \n [34] xfun_0.21            R6_2.5.0             markdown_1.1        \n [37] isoband_0.2.3        gamm4_0.2-6          projpred_2.0.2      \n [40] assertthat_0.2.1     promises_1.2.0.1     scales_1.1.1        \n [43] multcomp_1.4-16      rootSolve_1.8.2.1    gtable_0.3.0        \n [46] downlit_0.2.1        processx_3.4.5       lmom_2.8            \n [49] sandwich_3.0-0       rlang_0.4.10         systemfonts_1.0.1   \n [52] splines_4.0.4        lazyeval_0.2.2       inline_0.3.17       \n [55] yaml_2.2.1           reshape2_1.4.4       abind_1.4-5         \n [58] threejs_0.3.3        crosstalk_1.1.1      backports_1.2.1     \n [61] httpuv_1.5.5         rsconnect_0.8.16     tools_4.0.4         \n [64] bookdown_0.21        ellipsis_0.3.1       jquerylib_0.1.3     \n [67] RColorBrewer_1.1-2   ggridges_0.5.3       plyr_1.8.6          \n [70] base64enc_0.1-3      progress_1.2.2       purrr_0.3.4         \n [73] ps_1.6.0             prettyunits_1.1.1    zoo_1.8-8           \n [76] here_1.0.1           magrittr_2.0.1       data.table_1.14.0   \n [79] magick_2.6.0         colourpicker_1.1.0   tmvnsim_1.0-2       \n [82] mvtnorm_1.1-1        matrixStats_0.58.0   hms_1.0.0           \n [85] shinyjs_2.0.0        mime_0.10            evaluate_0.14       \n [88] xtable_1.8-4         shinystan_2.5.0      jpeg_0.1-8.1        \n [91] gridExtra_2.3        rstantools_2.1.1     compiler_4.0.4      \n [94] V8_3.4.0             crayon_1.4.1         minqa_1.2.4         \n [97] htmltools_0.5.1.1    mgcv_1.8-34          later_1.1.0.1       \n[100] tidyr_1.1.2          expm_0.999-6         Exact_2.1           \n[103] RcppParallel_5.0.3   lubridate_1.7.10     DBI_1.1.1           \n[106] tweenr_1.0.1         boot_1.3-27          Matrix_1.3-2        \n[109] cli_2.3.1            parallel_4.0.4       igraph_1.2.6        \n[112] pkgconfig_2.0.3      xml2_1.3.2           dygraphs_1.1.1.6    \n[115] bslib_0.2.4          estimability_1.3     stringr_1.4.0       \n[118] callr_3.5.1          digest_0.6.27        rmarkdown_2.7       \n[121] cellranger_1.1.0     gld_2.6.2            curl_4.3            \n[124] shiny_1.6.0          gtools_3.8.2         nloptr_1.2.2.2      \n[127] lifecycle_1.0.0      nlme_3.1-152         jsonlite_1.7.2      \n[130] viridisLite_0.3.0    fansi_0.4.2          pillar_1.5.0        \n[133] lattice_0.20-41      loo_2.4.1            fastmap_1.1.0       \n[136] httr_1.4.2           pkgbuild_1.2.0       survival_3.2-7      \n[139] glue_1.4.2           xts_0.12.1           png_0.1-7           \n[142] shinythemes_1.2.0    class_7.3-18         stringi_1.5.3       \n[145] sass_0.3.1           textshaping_0.3.1    e1071_1.7-4         \n\n\n\n\n",
      "last_modified": "2021-03-12T08:08:23-03:00"
    },
    {
      "path": "aux-Tabelas_para_Publicacao.html",
      "title": "Tabelas para Publicação",
      "description": "Como montar tabelas de modelos Bayesianos prontas para publicação",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 2, 2021",
      "contents": "\n\nContents\nEstatísticas Descritivas\nTabela de Correlações\nRegressão Linear Bayesiana\nTabela de Regressão Linear\n\nModelo de Regressão Binomial/Logística\nTabela de Regressão Binomial/Logística\n\nAmbiente\n\n\n\nknitr::opts_chunk$set(echo = TRUE)\n# Detectar quantos cores/processadores\noptions(mc.cores = parallel::detectCores())\noptions(Ncpus = parallel::detectCores())\n\nlibrary(dplyr)\nlibrary(rstanarm)\nlibrary(gtsummary)\nlibrary(sjPlot)\n\n# algumas modificações no datadset kidiq\nkidiq <- kidiq %>%\n  mutate(mom_hs = factor(mom_hs, labels = c(\"no\", \"yes\")))\n\n\n\n\nAo invés de ser obrigado a passar horas a fio formatando tabelas em Excel softwares pagos, você pode usar pacotes gratuitos do R para formatar automaticamente suas tabelas:\nEstatísticas Descritivas: gtsummary::tbl_summary()\nCorrelações: sjPlot::tab_corr()\nRegressões: sjPlot::tab_model()\nEstatísticas Descritivas\nO pacote gtsummary possui um conjunto de funções para sumarizar dados e tabelas. Eu particularmente gosto da função gtsummary::tbl_summary(). Ela formata uma tabela de Estatística Descritiva de maneira bem conveniente.\n\n\ngtsummary::tbl_summary(\n  kidiq,\n  by = mom_hs,\n  type = all_continuous() ~ \"continuous2\",\n  statistic = list(\n    all_continuous() ~ c(\"{N_nonmiss}\",\n                         \"{median} ({p25}, {p75})\",\n                         \"{min}, {max}\"),\n    all_categorical() ~ \"{n} ({p}%)\"),\n  missing = \"no\",\n  digits = all_continuous() ~ 2) %>%\n  # add p value and overall\n  add_p(pvalue_fun = ~style_pvalue(.x, digits = 2)) %>%\n  add_overall() %>%\n  # bold variable labels, italicize levels\n  bold_labels() %>%\n  italicize_levels() %>%\n  # change stuff\n  modify_header(label ~ \"**Variable**\") %>%\n  modify_spanning_header(c(\"stat_1\", \"stat_2\") ~ \"**Mom High School**\") %>%\n  add_n()\n\n\nhtml {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#pkiiayrfbm .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#pkiiayrfbm .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#pkiiayrfbm .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#pkiiayrfbm .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 4px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#pkiiayrfbm .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pkiiayrfbm .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#pkiiayrfbm .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#pkiiayrfbm .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#pkiiayrfbm .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#pkiiayrfbm .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#pkiiayrfbm .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#pkiiayrfbm .gt_group_heading {\n  padding: 8px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#pkiiayrfbm .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#pkiiayrfbm .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#pkiiayrfbm .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#pkiiayrfbm .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#pkiiayrfbm .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 12px;\n}\n\n#pkiiayrfbm .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pkiiayrfbm .gt_first_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n}\n\n#pkiiayrfbm .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pkiiayrfbm .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#pkiiayrfbm .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#pkiiayrfbm .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pkiiayrfbm .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#pkiiayrfbm .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding: 4px;\n}\n\n#pkiiayrfbm .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#pkiiayrfbm .gt_sourcenote {\n  font-size: 90%;\n  padding: 4px;\n}\n\n#pkiiayrfbm .gt_left {\n  text-align: left;\n}\n\n#pkiiayrfbm .gt_center {\n  text-align: center;\n}\n\n#pkiiayrfbm .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#pkiiayrfbm .gt_font_normal {\n  font-weight: normal;\n}\n\n#pkiiayrfbm .gt_font_bold {\n  font-weight: bold;\n}\n\n#pkiiayrfbm .gt_font_italic {\n  font-style: italic;\n}\n\n#pkiiayrfbm .gt_super {\n  font-size: 65%;\n}\n\n#pkiiayrfbm .gt_footnote_marks {\n  font-style: italic;\n  font-size: 65%;\n}\nVariable\n      N\n      Overall, N = 434\n      \n        Mom High School\n      \n      p-value1\n    no, N = 93\n      yes, N = 341\n    kid_score\n      434.00\n      \n      \n      \n      <0.001\n    N\n      \n      434.00\n      93.00\n      341.00\n      \n    Median (IQR)\n      \n      90.00 (74.00, 102.00)\n      80.00 (58.00, 95.00)\n      92.00 (77.00, 103.00)\n      \n    Range\n      \n      20.00, 144.00\n      20.00, 136.00\n      38.00, 144.00\n      \n    mom_iq\n      434.00\n      \n      \n      \n      <0.001\n    N\n      \n      434.00\n      93.00\n      341.00\n      \n    Median (IQR)\n      \n      97.92 (88.66, 110.27)\n      88.66 (81.83, 99.16)\n      100.24 (90.45, 113.17)\n      \n    Range\n      \n      71.04, 138.89\n      74.23, 127.54\n      71.04, 138.89\n      \n    mom_age\n      434.00\n      \n      \n      \n      <0.001\n    N\n      \n      434.00\n      93.00\n      341.00\n      \n    Median (IQR)\n      \n      23.00 (21.00, 25.00)\n      21.00 (20.00, 24.00)\n      23.00 (21.00, 25.00)\n      \n    Range\n      \n      17.00, 29.00\n      17.00, 28.00\n      17.00, 29.00\n      \n    \n        \n          1\n          \n           \n          Wilcoxon rank sum test\n          \n      \n    \n\nTabela de Correlações\nPara as tabelas de correlações, eu uso o pacote sjPlot com a função sjPlot::tab_cor()\nOs astericos significam:\n* - \\(p < 0.05\\)\n** - \\(p < 0.01\\)\n*** - \\(p < 0.001\\)\n\n\nsjPlot::tab_corr(\n  kidiq %>% mutate(mom_hs = as.integer(mom_hs)),\n  digits = 2,\n  triangle = \"lower\"\n)\n\n\n\n \n\n\nkid_score\n\n\nmom_hs\n\n\nmom_iq\n\n\nmom_age\n\n\nkid_score\n\n\n \n\n\n \n\n\n \n\n\n \n\n\nmom_hs\n\n\n0.24***\n\n\n \n\n\n \n\n\n \n\n\nmom_iq\n\n\n0.45***\n\n\n0.28***\n\n\n \n\n\n \n\n\nmom_age\n\n\n0.09\n\n\n0.21***\n\n\n0.09\n\n\n \n\n\nComputed correlation used pearson-method with listwise-deletion.\n\n\nRegressão Linear Bayesiana\nVamos começar com o caso simples da Aula 5 - Regressão Linear\n\n\nmodel <- stan_glm(\n  kid_score ~ mom_hs + mom_iq,\n  data = kidiq\n  )\n\n\n\nTabela de Regressão Linear\nPara as tabelas de regressões eu geralmente uso o mesmo pacote sjPlot, mas agora com a função sjPlot::tab_model() que aceita um modelo bayesiano.\n\n\ntab_model(model, show.reflvl = TRUE)\n\n\n\n \n\n\nkid_score\n\n\nPredictors\n\n\nEstimates\n\n\nCI (95%)\n\n\n(Intercept)\n\n\n25.80\n\n\n14.22 – 37.44\n\n\nno\n\n\nReference\n\n\n\n\nyes\n\n\n5.95\n\n\n1.57 – 10.47\n\n\nmom_iq\n\n\n0.56\n\n\n0.44 – 0.68\n\n\nObservations\n\n\n434\n\n\nR2 Bayes\n\n\n0.214\n\n\nModelo de Regressão Binomial/Logística\nVamos utilizar o caso da Aula 6 - Regressão Binomial\n\n\nmodel_binomial <- stan_glm(\n  switch ~ dist + arsenic + assoc + educ,\n  data = wells,\n  family = binomial()\n)\n\n\n\nTabela de Regressão Binomial/Logística\nA função sjPlot::tab_model() quando aplicada à um modelo bayesiano linear generalizado (binomial, Poisson etc.) já faz a transformação necessária para uma melhor interpretação dos coeficientes.\nNo caso de modelos binomiais/logísticos geralmente é aplicada uma exponenciação (exp()) dos coeficientes para transformá-los em razões de probabilidades (odds ratio)\nCaso queira deixar os coeficientes brutos (raw coefficients) use transform = NULL\n\n\ntab_model(model_binomial, show.reflvl = TRUE)\n\n\n\n \n\n\nswitch\n\n\nPredictors\n\n\nOdds Ratios\n\n\nCI (95%)\n\n\n(Intercept)\n\n\n0.85\n\n\n0.71 – 1.04\n\n\narsenic\n\n\n1.60\n\n\n1.47 – 1.73\n\n\nassoc\n\n\n0.88\n\n\n0.76 – 1.03\n\n\ndist\n\n\n0.99\n\n\n0.99 – 0.99\n\n\neduc\n\n\n1.04\n\n\n1.02 – 1.06\n\n\nObservations\n\n\n3020\n\n\nR2 Bayes\n\n\n0.067\n\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.4 (2021-02-15)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n [1] sjPlot_2.8.7         gtsummary_1.3.7      lm.beta_1.5-1       \n [4] DescTools_0.99.40    brms_2.14.4          gapminder_0.3.0     \n [7] skimr_2.1.2          dplyr_1.0.4          rstan_2.21.2        \n[10] StanHeaders_2.21.0-7 MASS_7.3-53.1        ggforce_0.3.2       \n[13] gganimate_1.0.7      plotly_4.9.3         carData_3.0-4       \n[16] rstanarm_2.21.1      Rcpp_1.0.6           readxl_1.3.1        \n[19] tibble_3.1.0         ggplot2_3.3.3        patchwork_1.1.1     \n[22] cowplot_1.1.1       \n\nloaded via a namespace (and not attached):\n  [1] utf8_1.1.4           tidyselect_1.1.0     lme4_1.1-26         \n  [4] htmlwidgets_1.5.3    grid_4.0.4           munsell_0.5.0       \n  [7] effectsize_0.4.3     codetools_0.2-18     ragg_1.1.1          \n [10] distill_1.2          statmod_1.4.35       DT_0.17             \n [13] gifski_0.8.7         miniUI_0.1.1.1       withr_2.4.1         \n [16] Brobdingnag_1.2-6    colorspace_2.0-0     highr_0.8           \n [19] knitr_1.31           rstudioapi_0.13      stats4_4.0.4        \n [22] bayesplot_1.8.0      labeling_0.4.2       emmeans_1.5.4       \n [25] repr_1.1.3           mnormt_2.0.2         polyclip_1.10-0     \n [28] farver_2.1.0         bridgesampling_1.0-0 rprojroot_2.0.2     \n [31] coda_0.19-4          vctrs_0.3.6          generics_0.1.0      \n [34] TH.data_1.0-10       xfun_0.21            R6_2.5.0            \n [37] markdown_1.1         isoband_0.2.3        gamm4_0.2-6         \n [40] projpred_2.0.2       assertthat_0.2.1     promises_1.2.0.1    \n [43] scales_1.1.1         multcomp_1.4-16      rootSolve_1.8.2.1   \n [46] gtable_0.3.0         downlit_0.2.1        processx_3.4.5      \n [49] lmom_2.8             sandwich_3.0-0       rlang_0.4.10        \n [52] systemfonts_1.0.1    splines_4.0.4        lazyeval_0.2.2      \n [55] checkmate_2.0.0      broom_0.7.5          inline_0.3.17       \n [58] modelr_0.1.8         yaml_2.2.1           reshape2_1.4.4      \n [61] abind_1.4-5          threejs_0.3.3        crosstalk_1.1.1     \n [64] backports_1.2.1      httpuv_1.5.5         rsconnect_0.8.16    \n [67] usethis_2.0.1        tools_4.0.4          bookdown_0.21       \n [70] ellipsis_0.3.1       jquerylib_0.1.3      RColorBrewer_1.1-2  \n [73] ggridges_0.5.3       plyr_1.8.6           base64enc_0.1-3     \n [76] progress_1.2.2       purrr_0.3.4          ps_1.6.0            \n [79] prettyunits_1.1.1    zoo_1.8-8            fs_1.5.0            \n [82] here_1.0.1           magrittr_2.0.1       data.table_1.14.0   \n [85] magick_2.6.0         colourpicker_1.1.0   tmvnsim_1.0-2       \n [88] mvtnorm_1.1-1        sjmisc_2.8.6         matrixStats_0.58.0  \n [91] hms_1.0.0            shinyjs_2.0.0        mime_0.10           \n [94] evaluate_0.14        xtable_1.8-4         shinystan_2.5.0     \n [97] sjstats_0.18.1       jpeg_0.1-8.1         ggeffects_1.0.1     \n[100] gridExtra_2.3        rstantools_2.1.1     compiler_4.0.4      \n[103] gt_0.2.2             V8_3.4.0             crayon_1.4.1        \n[106] minqa_1.2.4          htmltools_0.5.1.1    mgcv_1.8-34         \n[109] later_1.1.0.1        tidyr_1.1.2          expm_0.999-6        \n[112] Exact_2.1            RcppParallel_5.0.3   lubridate_1.7.10    \n[115] DBI_1.1.1            sjlabelled_1.1.7     tweenr_1.0.1        \n[118] broom.helpers_1.2.1  boot_1.3-27          Matrix_1.3-2        \n[121] cli_2.3.1            insight_0.13.1       parallel_4.0.4      \n[124] igraph_1.2.6         forcats_0.5.1        pkgconfig_2.0.3     \n[127] xml2_1.3.2           dygraphs_1.1.1.6     bslib_0.2.4         \n[130] estimability_1.3     snakecase_0.11.0     stringr_1.4.0       \n[133] callr_3.5.1          digest_0.6.27        parameters_0.12.0   \n[136] rmarkdown_2.7        cellranger_1.1.0     gld_2.6.2           \n[139] curl_4.3             commonmark_1.7       shiny_1.6.0         \n[142] gtools_3.8.2         nloptr_1.2.2.2       lifecycle_1.0.0     \n[145] nlme_3.1-152         jsonlite_1.7.2       viridisLite_0.3.0   \n[148] fansi_0.4.2          pillar_1.5.0         lattice_0.20-41     \n[151] loo_2.4.1            fastmap_1.1.0        httr_1.4.2          \n[154] pkgbuild_1.2.0       survival_3.2-7       glue_1.4.2          \n[157] xts_0.12.1           bayestestR_0.8.2     png_0.1-7           \n[160] shinythemes_1.2.0    performance_0.7.0    class_7.3-18        \n[163] stringi_1.5.3        sass_0.3.1           textshaping_0.3.1   \n[166] e1071_1.7-4         \n\n\n\n\n",
      "last_modified": "2021-03-12T08:08:23-03:00"
    },
    {
      "path": "index.html",
      "title": "Estatística Bayesiana com R e Stan",
      "description": "Companion para a disciplina de Estatística Bayesiana para alunos de Mestrado e Doutorado da UNINOVE",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 2, 2021",
      "contents": "\n\nContents\nStan\nComo usar esse conteúdo?\nAulas\nO que esta disciplina não é\nRStudio na Núvem Gratuito\nProfessor\nComo usar esse conteúdo?\nReferências\nLivros\nArtigos\n\nConteúdos Similares\nComo citar esse conteúdo\nLicença\n\n\n\nA Estatística Bayesiana é uma abordagem de Estatística inferencial que não usa hipóteses nulas (\\(H_0\\)) e \\(p\\)-valores. Se você não sabe o que é um \\(p\\)-valor, recomendo olhar o tutorial sobre o que são \\(p\\)-valores. Muitos cientistas e pesquisadores acreditam que sabe o que é um \\(p\\)-valor, mas sua compreensão é falha e imperfeita, por isso, mesmo que você acredite que saiba o que é um \\(p\\)-valor, eu ainda recomendo que veja o tutorial sobre o que são \\(p\\)-valores.\nStan\nStan (Carpenter et al., 2017) é uma plataforma para modelagem e computação estatística de alto desempenho. Milhares de usuários contam com Stan para modelagem estatística, análise de dados e previsão nas ciências sociais, biológicas e físicas, engenharia e negócios. Stan tem mais de 3.600 citações no Google Scholar1. Além disso, Stan tem o suporte financeiro da NumFOCUS, uma fundação sem fins lucrativos que dá apoio financeiro à projetos de softwares opensource. Dentre os patrocinadores da NumFOCUS podemos citar AWS Amazon, Bloomberg, Microsoft, IBM, RStudio, Facebook, NVIDIA, Netflix, entre outras.\nOs modelos em Stan são especificados pela sua própria linguagem (similar à C++) e são compilados em um arquivo executável que gera inferências estatísticas Bayesiana com amostragem Monte Carlo de correntes Markov (Markov Chain Monte Carlo – MCMC) de alto desempenho. Stan possui interfaces para as seguintes linguagens de programação2:\nR: RStan e CmdStanR\nPython: PyStan e CmdStanPy\nShell (Linha de Comando): CmdStan\nJulia: Stan.jl\nScala: ScalaStan\nMatlab: MatlabStan\nStata: StataStan\nMathematica: MathematicaStan\nA linguagem Stan possui uma curva de aprendizagem bem desafiadora, por isso Stan possui um ecossistema de pacotes de interfaces que muitas vezes ajudam e simplificam a sua utilização:\nrstanarm: ajuda o usuário a especificar modelos usando a síntaxe familiar de fórmulas do R.\nbrms: similar ao rstanarm pois usa a síntaxe familiar de fórmulas do R, mas dá maior flexibilidade na especificação de modelos mais complexos3.\nStan4 usa um amostrador MCMC que utiliza dinâmica Hamiltoniana (Hamiltonian Monte Carlo – HMC) para guiar as propostas de amostragem de novos parâmetros no sentido do gradiente da densidade de probabilidade da posterior. Isto implica em um amostrador mais eficiente e que consegue explorar todo o espaço amostral da posterior com menos iterações; e também mais eficaz que consegue tolerar diferentes topologias de espaços amostrais da posterior. Em outras palavras, Stan usa técnicas de amostragem avançadas que permite com que modelos complexos Bayesianos atinjam convergência de maneira rápida. No Stan, raramente deve-se ajustar os parâmetros do algoritmo HMC, pois geralmente os parâmetros padrões (out-of-the-box) funcionam muito bem. Assim, o usuário foca no que é importante: a especificação dos componentes probabilísticos do seu modelo Bayesiano.\nComo usar esse conteúdo?\nEste conteúdo possui licença livre para uso (CC BY-SA). Caso queira utilizar o conteúdo para um curso ou estudos, por favor colabore nesse repositório quaisquer aprimorações que foram realizadas. O propósito do conteúdo não é o rigor matemático geralmente adotado em disciplinas e tutoriais de estatística Bayesiana, mas gerar uma forte intuição deixando de lado o rigor matemático e focar no ferramental (primariamente rstanarm e um pouco de brms).\nPara configurar um ambiente local:\nClone o repositório do GitHub: git clone https://github.com/storopoli/Estatistica-Bayesiana.git\nAcesse o diretório: cd Estatistica-Bayesiana\nInstale os pacotes necessários: Rscript .binder/install.R\nAulas\nO que são p-valores?\nO que é Estatística Bayesiana\nConteúdos Primários:\nComandos Básicos de R\nDistribuições Estatísticas\nPriors\nMarkov Chain Montecarlo (MCMC)\nRegressão Linear\nRegressão Binomial\nRegressão de Poisson\nRegressão Robusta\nModelos Multiníveis\nConteúdos Auxiliares:\nDados Faltantes\nCoeficientes de uma Regressão\nTabelas para Publicação\nO que esta disciplina não é\nNão será coberto conteúdos sobre leitura, manipulação e exportação de dados com R. Para isso recomendo fortemente o livro R para Data Science (Figura 1) que pode ser encontrado gratuitamente aqui e possui uma versão impressa em português5.\n\n\n\nFigure 1: R for Data Science\n\n\n\nRStudio na Núvem Gratuito\nClique no ícone abaixo para abrir uma sessão do RStudio no Projeto Binder.\n\nProfessor\nProf. Dr. José Eduardo Storopoli    \nComo usar esse conteúdo?\nEste conteúdo possui licença livre para uso (CC BY-SA). Caso queira utilizar o conteúdo para um curso ou estudos, por favor colabore nesse repositório quaisquer aprimorações que foram realizadas.\nPara configurar um ambiente local:\nClone o repositório do GitHub: git clone https://github.com/storopoli/Estatistica-Bayesiana.git\nAcesse o diretório: cd Estatistica-Bayesiana\nInstale os pacotes necessários: Rscript .binder/install.R\nReferências\nLivros\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian Data Analysis. Chapman and Hall/CRC.\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan. CRC press.\nGelman, A., Hill, J., & Vehtari, A. (2020). Regression and other stories. Cambridge University Press.\nBrooks, S., Gelman, A., Jones, G., & Meng, X.-L. (2011). Handbook of Markov Chain Monte Carlo. CRC Press. http://books.google.com?id=qfRsAIKZ4rIC\nGeyer, C. J. (2011). Introduction to markov chain monte carlo. In S. Brooks, A. Gelman, G. L. Jones, & X.-L. Meng (Eds.), Handbook of markov chain monte carlo.\n\nArtigos\nBásicos\nvan de Schoot, R., Depaoli, S., King, R., Kramer, B., Märtens, K., Tadesse, M. G., Vannucci, M., Gelman, A., Veen, D., Willemsen, J., & Yau, C. (2021). Bayesian statistics and modelling. Nature Reviews Methods Primers, 1(1, 1), 1–26. https://doi.org/10.1038/s43586-020-00001-2\nGelman, A., Vehtari, A., Simpson, D., Margossian, C. C., Carpenter, B., Yao, Y., Kennedy, L., Gabry, J., Bürkner, P.-C., & Modr’ak, M. (2020, November 3). Bayesian Workflow. http://arxiv.org/abs/2011.01808\nGabry, J., Simpson, D., Vehtari, A., Betancourt, M., & Gelman, A. (2019). Visualization in Bayesian workflow. Journal of the Royal Statistical Society: Series A (Statistics in Society), 182(2), 389–402. https://doi.org/10.1111/rssa.12378\nBenjamin, D. J., Berger, J. O., Johannesson, M., Nosek, B. A., Wagenmakers, E.-J., Berk, R., Bollen, K. A., Brembs, B., Brown, L., Camerer, C., Cesarini, D., Chambers, C. D., Clyde, M., Cook, T. D., De Boeck, P., Dienes, Z., Dreber, A., Easwaran, K., Efferson, C., … Johnson, V. E. (2018). Redefine statistical significance. Nature Human Behaviour, 2(1), 6–10. https://doi.org/10.1038/s41562-017-0189-z\nCarpenter, B., Gelman, A., Hoffman, M. D., Lee, D., Goodrich, B., Betancourt, M., Brubaker, M., Guo, J., Li, P., & Riddell, A. (2017). Stan : A Probabilistic Programming Language. Journal of Statistical Software, 76(1). https://doi.org/10.18637/jss.v076.i01\nEtz, A. (2018). Introduction to the Concept of Likelihood and Its Applications. Advances in Methods and Practices in Psychological Science, 1(1), 60–69. https://doi.org/10.1177/2515245917744314\nEtz, A., Gronau, Q. F., Dablander, F., Edelsbrunner, P. A., & Baribault, B. (2018). How to become a Bayesian in eight easy steps: An annotated reading list. Psychonomic Bulletin & Review, 25(1), 219–234. https://doi.org/10.3758/s13423-017-1317-5\nMcShane, B. B., Gal, D., Gelman, A., Robert, C., & Tackett, J. L. (2019). Abandon Statistical Significance. American Statistician, 73, 235–245. https://doi.org/10.1080/00031305.2018.1527253\nAmrhein, V., Greenland, S., & McShane, B. (2019). Scientists rise up against statistical significance. Nature, 567(7748), 305–307. https://doi.org/10.1038/d41586-019-00857-9\nvan Ravenzwaaij, D., Cassey, P., & Brown, S. D. (2018). A simple introduction to Markov Chain Monte–Carlo sampling. Psychonomic Bulletin and Review, 25(1), 143–154. https://doi.org/10.3758/s13423-016-1015-8\nVandekerckhove, J., Matzke, D., Wagenmakers, E.-J., & others. (2015). Model comparison and the principle of parsimony. In J. R. Busemeyer, Z. Wang, J. T. Townsend, & A. Eidels (Eds.), Oxford handbook of computational and mathematical psychology (pp. 300–319). Oxford University Press Oxford.\nvan de Schoot, R., Kaplan, D., Denissen, J., Asendorpf, J. B., Neyer, F. J., & van Aken, M. A. G. (2014). A Gentle Introduction to Bayesian Analysis: Applications to Developmental Research. Child Development, 85(3), 842–860. https://doi.org/10.1111/cdev.12169_eprint: https://srcd.onlinelibrary.wiley.com/doi/pdf/10.1111/cdev.12169\nWagenmakers, E.-J. (2007). A practical solution to the pervasive problems of p values. Psychonomic Bulletin & Review, 14(5), 779–804. https://doi.org/10.3758/BF03194105\nComplementares\nCohen, J. (1994). The earth is round (p \\(<\\) .05). American Psychologist, 49(12), 997–1003. https://doi.org/10.1037/0003-066X.49.12.997\nDienes, Z. (2011). Bayesian Versus Orthodox Statistics: Which Side Are You On? Perspectives on Psychological Science, 6(3), 274–290. https://doi.org/10.1177/1745691611406920\nEtz, A., & Vandekerckhove, J. (2018). Introduction to Bayesian Inference for Psychology. Psychonomic Bulletin & Review, 25(1), 5–34. https://doi.org/10.3758/s13423-017-1262-3\nJ’unior, C. A. M. (2020). Quanto vale o valor-p? Arquivos de Ciências Do Esporte, 7(2).\nKerr, N. L. (1998). HARKing: Hypothesizing after the results are known. Personality and Social Psychology Review, 2(3), 196–217. https://doi.org/10.1207/s15327957pspr0203_4\nKruschke, J. K., & Vanpaemel, W. (2015). Bayesian estimation in hierarchical models. In J. R. Busemeyer, Z. Wang, J. T. Townsend, & A. Eidels (Eds.), The Oxford handbook of computational and mathematical psychology (pp. 279–299). Oxford University Press Oxford, UK.\nKruschke, J. K., & Liddell, T. M. (2018). Bayesian data analysis for newcomers. Psychonomic Bulletin & Review, 25(1), 155–177. https://doi.org/10.3758/s13423-017-1272-1\nKruschke, J. K., & Liddell, T. M. (2018). The Bayesian New Statistics: Hypothesis testing, estimation, meta-analysis, and power analysis from a Bayesian perspective. Psychonomic Bulletin & Review, 25(1), 178–206. https://doi.org/10.3758/s13423-016-1221-4\nLakens, D., Adolfi, F. G., Albers, C. J., Anvari, F., Apps, M. A. J., Argamon, S. E., Baguley, T., Becker, R. B., Benning, S. D., Bradford, D. E., Buchanan, E. M., Caldwell, A. R., Van Calster, B., Carlsson, R., Chen, S. C., Chung, B., Colling, L. J., Collins, G. S., Crook, Z., … Zwaan, R. A. (2018). Justify your alpha. Nature Human Behaviour, 2(3), 168–171. https://doi.org/10.1038/s41562-018-0311-x\nMorey, R. D., Hoekstra, R., Rouder, J. N., Lee, M. D., & Wagenmakers, E.-J. (2016). The fallacy of placing confidence in confidence intervals. Psychonomic Bulletin & Review, 23(1), 103–123. https://doi.org/10.3758/s13423-015-0947-8\nMurphy, K. R., & Aguinis, H. (2019). HARKing: How Badly Can Cherry-Picking and Question Trolling Produce Bias in Published Results? Journal of Business and Psychology, 34(1). https://doi.org/10.1007/s10869-017-9524-7\nStark, P. B., & Saltelli, A. (2018). Cargo-cult statistics and scientific crisis. Significance, 15(4), 40–43. https://doi.org/10.1111/j.1740-9713.2018.01174.x\nConteúdos Similares\nExistem alguns conteúdos em português similares que eu indico:\nMarco Inácio — Apostila de Stan\nUm dos desenvolvedores da equipe do Stan. A apostila está um pouco desatualizada (2018). O foco é o rigor matemático e a linguagem Stan. Muito bem escrita e com bons exemplos.\nRicardo Ehlers (USP) — Inferência Bayesiana (Notas de Aula)\nNotas de uma disciplina da USP pelo professor Ricardo Ehlers. O foco é o rigor matemática e as ferramentas utilizadas são desatualizadas (BUGS e JAGS). Também muito bem escrita e com bons exemplos.\nLuís Gustavo Esteves, Rafael Izbicki e Rafael Bassi Stern (UFSCar) — Inferência Bayesiana (Notas de Aula)\nNotas de uma disciplina da UFSCar pelos professores Luís Gustavo Esteves, Rafael Izbicki e Rafael Bassi Stern. O foco é o rigor matemático, mas o conteúdo é um pouco mais acessível com uma forte introdução à lógica Bayesiana. Fala um pouco da linguagem Stan e sua interface do R (rstan) no finalzinho.\nComo citar esse conteúdo\nPara citar o conteúdo use:\nStoropoli (2021). Estatística Bayesiana com R e Stan. Disponível em: https://storopoli.io/Estatistica-Bayesiana.\nOu em formato BibTeX para LaTeX:\n@misc{storopoli2021estatisticabayesianaR,\n  author = {Storopoli, Jose},\n  title = {Estatística Bayesiana com R e Stan},\n  url = {https://storopoli.io/Estatistica-Bayesiana},\n  year = {2021}\n}\nLicença\nEste obra está licenciado com uma Licença Creative Commons Atribuição-CompartilhaIgual 4.0 Internacional.\n\n\nconforme consulta em 14 de Março de 2021.↩︎\nestou riscando as linguagens que não são opensource por uma questão de princípios.↩︎\ne geralmente a amostragem é um pouco mais rápida que o rstanarm.↩︎\ne consequentemente todas suas interfaces com diversas linguagens de programação e todos os pacotes do seu ecossistema.↩︎\nNão temos nada a ver com a Amazon. Caso queira comprar em qualquer outra loja fique à vontade, ou algum sebo… Jeff Bezos nem sabe que eu existo…↩︎\n",
      "last_modified": "2021-03-14T09:31:58-03:00"
    }
  ],
  "collections": []
}
