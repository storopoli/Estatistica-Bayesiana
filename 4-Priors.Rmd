---
title: "Priors"
description: "As famosas e controversas Priors"
author:
  - name: Jose Storopoli
    url: https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en
    affiliation: UNINOVE
    affiliation_url: https://www.uninove.br
    orcid_id: 0000-0002-0559-5176
date: August 1, 2021
citation_url: https://storopoli.io/Estatistica-Bayesiana/4-Priors.html
slug: storopoli2021priorbayesR
bibliography: bib/bibliografia.bib
csl: bib/apa.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css"/>

```{r mtcars, include=FALSE}
data(mtcars)
```

A Estatística Bayesiana é caracterizada pelo uso de informação prévia embutida como probabilidade prévia $P(\theta)$, chamada de *a priori*:

$$
\underbrace{P(\theta \mid y)}_{\textit{Posteriori}} = \frac{\overbrace{P(y \mid  \theta)}^{\text{Verossimilhança}} \cdot \overbrace{P(\theta)}^{\textit{Priori}}}{\underbrace{P(y)}_{\text{Constante Normalizadora}}},
$$

## Subjetividade da *Priori*

Muitas críticas à estatística Bayesiana, se dá pela subjetividade da elucidação da probabilidade *a priori* de certas hipóteses ou parâmetros de modelos. A subjetividade é algo indesejado na idealização do cientista e do método científico. Ambos devem ser imparciais e guiados pelas evidências. Isto faz com que a objetividade seja o "Santo Graal" da ciência e do cientista. Vou falar uma coisa que talvez não tenha sido assimilada pelo leitor: tudo que envolve ação humana nunca será 100% objetivo. Temos subjetividade em tudo, e ciência não é um exceção^[caso discorde, dê uma estudada no rico campo da economia comportamental que provém uma montanha de evidências que os seres humanos são extremamente suscetíveis à vieses e, de maneira geral, não são bons tomadores de decisão.].

O próprio processo dedutivo e criativo de formulação de teoria e hipóteses não é algo objetivo. Há muita subjetividade incorporada em novas proposições teóricas. A estatística frequentista, que bane o uso de probabilidades *a priori*^[lembrando que sob a tutela da estatística frequentista, estamos proibidos de conjecturar probabilidade de parâmetros, pois eles são fixos e dependem apenas dos dados que temos. O que é conjecturado probabilisticamente são os dados em sí: a inferência é sempre elaborada a partir de um processo de frequência na qual há o pressuposto de "amostragem de $N$ amostras de uma mesma população" no limite de $N \to \infty$.] também é subjetiva, pois há **MUITA** subjetividade em especificar um modelo e uma função de verossimilhança [@jaynesProbabilityTheoryLogic2003; @vandeschootBayesianStatisticsModelling2021]. Ao fazermos isso, estamos inserindo pressupostos bem fortes e opinados sobre o processo de geração dos dados que estamos analisando. Isto quer dizer que, mesmo usando estatística frequentista, ainda sim estamos sendo bem subjetivos ao escolhermos como analisar os dados, pois muitas técnicas frequentistas possuem fortes pressupostos sobre os dados. Ainda mais, quando acoplamos esses pressupostos da estatística frequentista com a inexistência da elucidação desses pressupostos^[veja que muitas disciplinas de estatística nem mencionam pressupostos das diferentes técnicas frequentistas.] faz com que a idealização da objetividade da ciência e da estatística caiam por água baixo. Isto é um problema sério pois não é só a falha da objetividade, mas sim uma falha silenciosa e sorrateira. O véu de objetividade científica se desfaz e continuamos a acreditar que ele ainda está lá.

A estatística Bayesiana abraça a subjetividade enquanto a estatística frequentista a proíbe. Para a estatística Bayesiana, subjetividade guiam nossas inferências e nos levam a modelos mais robustos, confiáveis e que podem auxiliar à tomada de decisão. Já para a estatística frequentista, subjetividade é um tabu e todas inferências devem ser objetivas, mesmo que isso resulte em esconder pressupostos dos modelos embaixo dos panos. Consequentemente modelos oriundos da estatística frequentista, extremamente enviesados por pressupostos ocultos, não são robustos, podendo ser ilusórios e muitas vezes podem distorcer a realidade prejudicando o processo de tomada de decisão. Para concluir, estatística Bayesiana possui também pressupostos e subjetividade, **mas estes são enunciados e formalizados**. Ou seja, reconhecemos que a ação humana, mesmo em cenários científicos, é subjetiva e toda a subjetividade e os pressupostos do modelo são expostos de maneira transparente e auditável. Para mim isto faz toda diferença, uma vez que podemos desacoplar fatos de opinião e discutí-los separadamente ou de maneira conjunta.

Portanto, caro leitor, abrace a incerteza e subjetividade, mas nunca esconda-a e sempre deixe-as à vista de maneira transparente e auditável.

## Tipos de *Prioris*

De maneira geral, podemos ter 3 tipos de *priori* em uma abordagem Bayesiana [@gelman2013bayesian; @mcelreath2020statistical; @vandeschootBayesianStatisticsModelling2021]:

-   uniforme (*flat*): não recomendada
-   fracamente informativa (*weakly informative*): pequena restrição com um pouco de senso comum e baixo conhecimento de domínio incorporado
-   informativa (*informative*): conhecimento de domínio incorporado

Para se aprofundar mais recomendo a [vinheta do `rstanarm` sobre priors](https://cran.r-project.org/web/packages/rstanarm/vignettes/priors.html)

## *Prioris* para os Modelos `rstanarm`

O `rstanarm` possui as seguintes *prioris* incorporadas como padrão nos seus modelos. Recomendo fortemente que você use uma *prior* específica e não se atenha às *prioris* padrões do `rstanarm`. Apesar de refletirem as boas práticas e a fronteira do conhecimento científico sobre elucidação de *prioris*, elas podem mudar conforme são lançadas novas versões do `rstanarm` ou são incorporados novas diretrizes de elucidação de *prioris*. Isto pode prejudicar a robustez do seu modelo (e em especial do seu código), pois caso executado com versões diferentes do `rstanarm`, a opção de *prioris* padrão pode levar à diferentes elucidações de *prioris*.

+--------------------+----------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------+
| **Argumento**      | **Usado em**                                                   | **Aplica-se à**                                                                                                          |
+:==================:+:==============================================================:+:========================================================================================================================:+
| `prior_intercept`  | Todas funções de modelagem exceto `stan_polr` and `stan_nlmer` | Constante (*intercept*) do modelo, após centralização dos preditores                                                     |
+--------------------+----------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------+
| `prior`            | Todas funções de modelagem                                     | Coeficientes de Regressão, não inclui coeficientes que variam por grupo em modelos multiníveis (veja `prior_covariance`) |
+--------------------+----------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------+
| `prior_aux`        | `stan_glm`, `stan_glmer`, `stan_gamm4`, `stan_nlmer`           | Parâmetro auxiliar (ex: desvio padrão (*standard error* - DP), interpretação depende do modelo                          |
+--------------------+----------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------+
| `prior_covariance` | `stan_glmer`, `stan_gamm4`, `stan_nlmer`                       | Matrizes de covariância em modelos multiníveis                                                                           |
+--------------------+----------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------+

### Uniforme (*flat*)

Especifica-se colocando o valor `NULL` (nulo em `R`) nos argumentos `prior_*` dos modelos `rstanarm`. Exemplo:

-   `prior_intercept = NULL` -- constante possuirá *priori* uniforme sobre todos os números reais $[-\infty, +\infty]$
-   `prior = NULL` -- parâmetros possuirão *prioris* uniformes sobre todo os números reais $[-\infty, +\infty]$
-   `prior_aux = NULL` -- parâmetros auxiliares (geralmente o erro do modelo) possuirão *prioris* uniforme sobre todos os números reais $[-\infty, +\infty]$. No caso de erro do modelo, isto se restringe aos numeros reais positivos: $(0, +\infty]$

Colocando na função de modelo ficaria `stan_glm(y ~ x1 + x2, data = df, prior = NULL, prior_intercept = NULL, prior_aux = NULL)`

### Informativas

Coloca-se qualquer distribuição nos argumentos. Exemplo:

-   `prior = normal(0, 5)`
-   `prior_intercept = student_t(4, 0, 10)`
-   `prior_aux = cauchy(0, 3)`

Colocando na função de modelo ficaria `stan_glm(y ~ x1 + x2, data = df, prior = normal(0, 5), prior_intercept = student_t(4, 0, 10), prior_aux = cauchy(0, 3))`

### Padrões do `rstanarm`

Acontece se você não especifica nada nos argumentos de priors. O comportamento difere conforme o modelo. Aqui divido em modelos gaussianos (segue uma likelihood gaussiana ou normal) e outros (binomial, poisson etc)

#### Modelos Gaussianos

-   Constante(*Intercept*): centralizada com média $\mu_y$ e desvio padrão de $2.5 \sigma_y$ - `prior_intercept = normal(mean_y, 2.5 * sd_y)`
-   Coeficientes: para cada coeficiente média $\mu = 0$ e desvio padrão de $2.5\times\frac{\sigma_y}{\sigma_{x_k}}$ - `prior = normal(0, 2.5 * sd_y/sd_xk)`

#### Outros Modelos (Binomial, Poisson etc.)

-   Constante(*Intercept*): centralizada com média $\mu = 0$ e desvio padrão de $2.5 \sigma_y$ - `prior_intercept = normal(0, 2.5 * sd_y)`
-   Coeficientes: para cada coeficiente média $\mu = 0$ e desvio padrão de $2.5\times\frac{1}{\sigma_{x_k}}$ - `prior = normal(0, 2.5 * 1/sd_xk)`

> OBS: em todos os modelos `prior_aux`, o desvio padrão do erro do modelo, a prior padrão é uma distribuição exponencial com taxa $\frac{1}{\sigma_y}$: `prior_aux = exponential(1/sd_y)`

### Exemplo usando o `mtcars`

Vamos estimar modelos Bayesianos usando o dataset já conhecido `mtcars`. Para constar, calcularemos alguns valores antes de ver o sumário das priors:

-   $\mu_y$: média do `mpg` - `r mean(mtcars$mpg)`
-   $2.5 \sigma_y$: `2.5 * sd(mtcars$mpg)` - `r 2.5 * sd(mtcars$mpg)`
-   $2.5\times\frac{\sigma_y}{\sigma_{x_{\text{wt}}}}$: `2.5 * (sd(mtcars$mpg)/sd(mtcars$wt))` - `r 2.5 * (sd(mtcars$mpg)/sd(mtcars$wt))`
-   $2.5\times\frac{\sigma_y}{\sigma_{x_{\text{am}}}}$: `2.5 * (sd(mtcars$mpg)/sd(mtcars$am))` - `r 2.5 * (sd(mtcars$mpg)/sd(mtcars$am))`
-   $\frac{1}{\sigma_y}$: `1/sd(mtcars$mpg)` - `r 1/sd(mtcars$mpg)`

A função `prior_summary` resulta um sumário conciso das priors utilizadas em um modelo. Coloque como argumento o modelo estimado:

```{r prior_summary}
library(rstanarm)
default_prior_test <- stan_glm(mpg ~ wt + am, data = mtcars, chains = 1)

prior_summary(default_prior_test)
```

Agora com priors especificadas:

Como há dois coeficientes eu especifico médias iguais ($0$), porém desvios padrões diferentes ($5$ para `wt` e $6$ para `am`) usando a função de combinar do `R` (*combine*) - `c()`

```{r custom_prior_summary}
custom_prior_test <- stan_glm(mpg ~ wt + am, data = mtcars, chains = 1,
         prior = normal(c(0, 0), c(5, 6)),
         prior_intercept = student_t(4, 0, 10),
         prior_aux = cauchy(0, 3))

prior_summary(custom_prior_test)
```

## Por quê não é interessante usar priors uniformes (*flat priors*)

Uma prior totalmente uniforme ou chapada (*flat*) é algo que devemos evitar pelo simples motivo que ela parte da premissa de que "tudo é possível". Não há limites na crença de que tamanho o valor deve ser.

Priors chapadas e super-vagas geralmente não são recomendadas e algum esforço deve ser incluído para ter, pelo menos, priors um pouco informativa. Por exemplo, é comum esperar que os tamanhos de efeito realistas sejam da ordem de magnitude $0.1$ em uma escala padronizada (por exemplo, uma inovação educacional que pode melhorar as pontuações dos testes em $0.1$ desvios padrão). Nesse caso, um prior de $N \sim (0,1)$ poderia ser considerado muito informativo, de uma maneira ruim, pois coloca a maior parte de sua massa em valores de parâmetro que são irrealisticamente grandes em valor absoluto. O ponto geral aqui é que se considerarmos uma prior como "fraca" ou "forte", isso é uma propriedade não apenas da prior, mas também da pergunta que está sendo feita.

Quando dizemos que a prior é "pouco informativa", o que queremos dizer é que, se houver uma quantidade razoavelmente grande de dados, a likelihood dominará e a prior não será importante. Se os dados forem fracos, porém, esta "prior fracamente informativo" influenciará fortemente a inferência posterior.

Não se esqueça que distribuição normal tem suporte $\mathbb{R}$, ou seja pode acontecer qualquer número entre $-\infty$ até $\infty$ independente da média $\mu$ ou desvio padrão $\sigma$.

### Atividade

Regressão linear pensando nas priors. Usar o dataset do pacote `carData` chamado `Salaries`

```{r atividade}
library(carData)
data("Salaries")
?Salaries
```

## Ambiente

```{r SessionInfo}
sessionInfo()
```
