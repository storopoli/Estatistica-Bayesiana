---
title: "Modelos Lineares Generalizados - Regressão Robusta"
description: |
  Modelos Lineares Generalizados - Regressão Robusta
author:
  - name: Jose Storopoli
    url: https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en
    affiliation: UNINOVE
    affiliation_url: https://www.uninove.br
    orcid_id: 0000-0002-0559-5176
date: August 2, 2021
citation_url: https://storopoli.io/Estatistica-Bayesiana/8-Regressao_Robusta.html
slug: storopoli2021regressaorosbustabayesR
bibliography: bib/bibliografia.bib
csl: bib/apa.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(brms.backend = "rstan")
```

<link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css"/>

Lembrando da curva normal gaussiana que possui um formato de sino. Ela não é muito alongada nas "pontas". Ou seja, as observações não fogem muito da média. Quando usamos essa distribuição como verossimilhança na inferência modelos Bayesianos, forçamos a que todas as estimativas sejam condicionadas à uma distribuição normal da variável dependente. Se nos dados houverem muitas observações com valores discrepantes (bem diferentes da média - *outliers*), isso faz com que as estimativas dos coeficientes das variáveis independentes fiquem instáveis. Isso ocorre porquê a distribuição normal não consegue contemplar observações muito divergentes da média sem mudar a média de local.

```{r normal-distribution}
x <- seq(-4, 4, length = 100)
plot(x, dnorm(x),
     type = "l",
     col = "red",
     lwd = 3,
     xlab = "valor de x",
     ylab = "Densidade",
     main = "Distribuição Normal",
     sub = "Média 0 e Desvio Padrão 1",
     xlim = c(-4, 4),
     ylim = c(0, 0.4))
```

Então precisamos de uma distribuição mais "maleável" como verossimilhança. Precisamos de uma distribuição que seja mais robusta à observações discrepantes (*outliers*). Precisamos de uma distribuição similar à Normal mas que possua caudas mais longas para justamente contemplar observações muito longe da média sem ter que mudar a média de local. Para isso temos a distribuição t de Student. Lembrando o formato dela:

```{r t-Student-distribution}
x <- seq(-4, 4, length = 100)
plot(x, dt(x, 2),
     type = "l",
     col = "blue",
     lwd = 3,
     xlab = "valor de x",
     ylab = "Densidade",
     main = "Distribuição t de Student",
     sub = "Média 0 e Graus de Liberdade 2",
     xlim = c(-4, 4),
     ylim = c(0, 0.4))
```

## Comparativo Normal vs Student

Reparem nas caudas:

```{r compare-normal-student}
plot(NA, xlab = "valor de x",
  ylab = "Densidade",
  main = "Comparativo de Distribuições",
  sub = "Normal vs t de Student",
  xlim = c(-4, 4),
  ylim = c(0, 0.4))
lines(x, dnorm(x), lwd = 2, col = "red")
lines(x, dt(x, df = 2), lwd = 2, col = "blue")
legend("topright", legend = c("Normal", "Student"),
       col = c("red", "blue"), title = "Distribuições", lty = 1)
```

## Modelos Lineares Robustos com o pacote `brms`

O `rstanarm` não possui a possibilidade de usar distribuições t de Student como verossimilhança do modelo Bayesiano. Para usarmos distribuições t de Student, precisamos do pacote [`brms`](https://paul-buerkner.github.io/brms/). O `brms` usa a mesma síntaxe que o `rstanarm` e a única diferença é que o `brms` não possui os modelos pré-compilados então os modelos devem ser todos compilados antes de serem rodados. A diferença prática é que você irá esperar alguns instantes antes do R começar a simular MCMC e amostrar do modelo.

A função que usa-se para designar modelos lineares no `brms` é a `brm()`:

```{r, eval=FALSE}
brm(y ~ x1 + x2 + x3,
    data = df,
    family = student)
```

### Exemplo com os dados de Prestígio de Duncan (1961)

Para exemplicar regressão robusta vamos usar um *dataset* que tem muitas observações discrepantes (*outliers*) chamado `Duncan`. Ele possui 45 observações sobre ocupações nos EUA e 4 variáveis:

-   `type`: Tipo de ocupação. Uma variável qualitativa:

    -   `prof` - profissional ou de gestão
    -   `wc` - white-collar (colarinho branco)
    -   `bc` - blue-collar (colarinho azul)

-   `income`: Porcentagem de pessoas da ocupação que ganham acima \$ 3.500 por ano em 1950 (mais ou menos \$36.000 em 2017);

-   `education`: Porcentagem de pessoas da ocupação que possuem diploma de ensino médio em 1949 (que, sendo cínicos, podemos dizer que é de certa maneira equivalente com diploma de Doutorado em 2017); e

-   `prestige`:Porcentagem de respondentes na pesquisa que classificam a sua ocupação como no mínimo "boa" em respeito à prestígio.

```{r duncan-data}
duncan <- read.csv2("datasets/Duncan.csv", row.names = 1, stringsAsFactors = TRUE)

hist(duncan$prestige,
     main = "Histograma do Prestígio",
     xlab = "Prestígio",
     ylab = "Frequência")
```

#### Primeiro modelo: Regressão Linear

Vamos estimar primeiramente uma regressão linear usando a distribuição Normal como verossimilhança:

```{r duncan_model_normal}
library(rstanarm)
model_1 <- stan_glm(
  prestige ~ income + education,
  data = duncan,
  family = gaussian
)
```

E na sequência o sumário das estimativas do modelo, assim como os diagnósticos da MCMC:

```{r summary_duncan_model_normal}
summary(model_1)
```

Aparentemente parece que o modelo possui boas métricas mas quando olhamos o *posterior predictive check*, vemos uma bagunça:

```{r pp_check_linear}
pp_check(model_1, nsamples = 45)
```

#### Segundo modelo: Regressão Robusta

Para rodar um modelo Bayesiano que usa como verossimilhança a distribuição t de Student é somente usar a mesma síntaxe que o `stan_glm` mas colocando argumento `family = student`:

```{r duncan_model_student}
library(brms)
model_2 <- brm(
  prestige ~ income + education,
  data = duncan,
  family = student)
```

E na sequência o sumário das estimativas do modelo, assim como os diagnósticos da MCMC. Vemos que as estimativas não alteraram muito. Além disso temos um novo parâmetro estimado pelo modelo que é o parâmetro `nu` ($\nu$), que é os graus de liberdade da distribuição t de Student usada como verossimilhança:

```{r summary_duncan_model_student}
summary(model_2, prob =  0.9)
```

Mas a *posterior predictive check* ficou com um aspecto muito melhor que o modelo linear:

```{r pp_check}
pp_check(model_2, nsamples = 45)
```

### Priors do `brms`

`brms` possui as seguintes configurações como padrão de priors para regressão robusta usando t de Student:

-   Constante (*Intercept*): t de Student com média $\mu = \text{median}_y$, desvio padrão de $\max(2.5, MAD(y)$ e graus de liberdade $3$ - `prior = student_t(3, median_y, mad_y), class = intercept`
-   Coeficientes: para cada coeficiente média $\mu = 0$ e desvio padrão de $2.5\times\frac{1}{\sigma_{x_k}}$ - `prior = normal(0, 2.5 * 1/sd_xk)`
-   Erro residual (`sigma`): t de Student com média $\mu = 0$, desvio padrão de $\max(2.5, MAD(y)$ e graus de liberdade $3$ - `prior = student_t(3, 0, mad_y), class = sigma`
-   Graus de liberdade (`nu`): distribuição gamma com $\alpha = 2$ e $\beta = 0.1$ - `prior = gamma(2, 0.1), class = nu`

## Atividade Prática

O *dataset* [Boston Housing](https://www.kaggle.com/altavish/boston-housing-dataset) está disponível em `datasets/Boston_Housing.csv`. Possui 506 observações e possui 14 variáveis:

-   `CRIM` - per capita crime rate by town
-   `ZN` - proportion of residential land zoned for lots over 25,000 sq.ft.
-   `INDUS` - proportion of non-retail business acres per town.
-   `CHAS` - Charles River dummy variable (1 if tract bounds river; 0 otherwise)
-   `NOX` - nitric oxides concentration (parts per 10 million)
-   `RM` - average number of rooms per dwelling
-   `AGE` - proportion of owner-occupied units built prior to 1940
-   `DIS` - weighted distances to five Boston employment centres
-   `RAD` - index of accessibility to radial highways
-   `TAX` - full-value property-tax rate per \$10,000
-   `PTRATIO` - pupil-teacher ratio by town
-   `B` - 1000(Bk - 0.63)\^2 where Bk is the proportion of blacks by town
-   `LSTAT` - % lower status of the population
-   `MEDV` - Median value of owner-occupied homes in \$1000's

```{r atividade}
###
```

## Ambiente

```{r SessionInfo}
sessionInfo()
```
