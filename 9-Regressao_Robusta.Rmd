---
title: "Regressão Robusta Bayesiana"
description: "Modelos Lineares Generalizados -- $t$ de Student"
author:
  - name: Jose Storopoli
    url: https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en
    affiliation: UNINOVE
    affiliation_url: https://www.uninove.br
    orcid_id: 0000-0002-0559-5176
date: August 1, 2021
citation_url: https://storopoli.io/Estatistica-Bayesiana/9-Regressao_Robusta.html
slug: storopoli2021regressaorosbustabayesR
bibliography: bib/bibliografia.bib
csl: bib/apa.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(tibble)
library(readr)
theme_set(theme_minimal())
options(brms.backend = "rstan",
        brms.normalize = TRUE)
set.seed(123)
```

<link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css"/>

Vamos lembrar da curva Gaussiana/Normal que possui um formato de sino (figura \@ref(fig:normal)). Ela não é muito alongada nas "pontas". Ou seja, as observações não fogem muito da média. Quando usamos essa distribuição como verossimilhança na inferência modelos Bayesianos, forçamos a que todas as estimativas sejam condicionadas à uma distribuição normal da variável dependente. Se nos dados houverem muitas observações com valores discrepantes (bem diferentes da média -- *outliers*), isso faz com que as estimativas dos coeficientes das variáveis independentes fiquem instáveis. Isso ocorre porquê a distribuição normal não consegue contemplar observações muito divergentes da média sem ter que mudar a média de posição. Em outras palavras, ela precisa se "deslocar" para conseguir estimar observações com valores discrepantes causando instabilidade da inferência.

```{r normal, fig.cap='Distribuição Normal'}
ggplot(data = tibble(x = seq(-4, 4, length = 100))) +
  labs(
    title = "Distribuição Normais",
    subtitle = expression(list(mu == 0, sigma == 1)),
    x = expression(theta),
    y = "Densidade"
  ) +
  geom_line(aes(x, y = dnorm(x, mean = 0, sd = 1)), color = "steelblue", size = 2)
```

Então precisamos de uma distribuição mais "maleável" como verossimilhança. Uma distribuição que seja mais robusta à observações discrepantes (*outliers*). Uma distribuição similar à Normal mas que possua caudas mais longas para justamente contemplar observações muito longe da média sem ter que mudar a média de posição e ter que se "contorser" toda. Para isso temos a distribuição $t$ de Student. Lembrando o formato dela na figura \@ref(fig:student):

```{r student, fig.cap='Distribuição $t$ de Student'}
ggplot(data = tibble(x = seq(-4, 4, length = 100))) +
  labs(
    title = "Distribuição t de Student",
    subtitle = expression(list(nu == 3, mu == 0, sigma == 1)),
    x = expression(theta),
    y = "Densidade"
  ) +
  geom_line(aes(x, y = dt(x, df = 3)), color = "red", size = 2)
```

## Comparativo Normal vs Student

Reparem nas caudas na figura \@ref(fig:compare-normal-student):

```{r compare-normal-student, fig.cap='Comparativo Distribuições Normal vs $t$ de Student'}
ggplot(data = tibble(x = seq(-4, 4, length = 100))) +
  labs(
    title = "Comparativo Distribuições Normal vs t de Student",
    subtitle = expression(list(nu == 3, mu == 0, sigma == 1)),
    x = expression(theta),
    y = "Densidade"
  ) +
  geom_line(aes(x, y = dnorm(x, mean = 0, sd = 1), color = "Normal"), size = 2) +
  geom_line(aes(x, y = dt(x, df = 3), color = "Student"), size = 2) +
  scale_color_manual(
    name = "Distribuições",
    values = c("steelblue", "red")
  )
```

## Regressão Robusta Bayesiana

A abordagem padrão para modelarmos uma variável dependente contínua é com um função de verossimilhança Gaussiana/Normal. Isto implica que o erro do modelo, $\sigma$ da função de verossimilhança Gaussiana/Normal seja distribuído como uma distribuição normal:

$$
\begin{aligned}
y &\sim \text{Normal}\left( \alpha + \textbf{X} \cdot \boldsymbol{\beta}, \sigma \right) \\
\alpha &\sim \text{Normal}(\mu_\alpha, \sigma_\alpha) \\
\boldsymbol{\beta} &\sim \text{Normal}(\mu_{\boldsymbol{\beta}}, \sigma_{\boldsymbol{\beta}}) \\
\sigma &\sim \text{Exponencial}(\lambda_\sigma)
\end{aligned}
$$

Do ponto de vista Bayesiano, não há nada especial na verossimilhança Gaussiana/Normal. É apenas uma distribuição probabilística especificada em um modelo. Podemos deixar o modelo mais robusto ao usarmos uma distribuição $t$ de Student como função de verossimilhança. Isto implica que o erro do modelo, $\sigma$ não segue uma distribuição normal, mas sim uma distribuição $t$ de Student:

$$
\begin{aligned}
y &\sim \text{Student}\left( \nu, \alpha + \textbf{X} \cdot \boldsymbol{\beta}, \sigma \right) \\
\alpha &\sim \text{Normal}(\mu_\alpha, \sigma_\alpha) \\
\boldsymbol{\beta} &\sim \text{Normal}(\mu_{\boldsymbol{\beta}}, \sigma_{\boldsymbol{\beta}}) \\
\nu &\sim \text{Log-Normal}(2, 1) \\
\sigma &\sim \text{Exponencial}(\lambda_\sigma)
\end{aligned}
$$

Aqui temos algumas diferenças:

1. A função de verossimilhança $t$ de Student requer 1 parâmetro adicional: $\nu$, os graus de liberdade. Esses controlam o quão "longas" serão as caudas. Valores $\nu > 20$ fazem a distribuição $t$ de Student praticamente se tornar uma distribuição normal.
2. Não há nada especial em $\nu$. É apenas mais um parâmetro para o modelo estimar. Então é só eluciar uma *priori*. No caso, estou usando uma Distribuição Log-Normal com média 2 e desvio padrão 1.

Veja que não há nada de especial também nas *prioris* dos coeficientes $\boldsymbol{\beta}$ ou da constante $\alpha$. Poderíamos muito bem também colocar outras distribuições ou até deixar o modelo mais robustos ainda à *outliers* colocando *prioris* $t$ de Student:

$$
\begin{aligned}
\alpha &\sim \text{Student}(\nu_\alpha, \mu_\alpha, \sigma_\alpha) \\
\boldsymbol{\beta} &\sim \text{Student}(\nu_{\boldsymbol{\beta}}, \mu_{\boldsymbol{\beta}}, \sigma_{\boldsymbol{\beta}}) \\
\nu_\alpha &\sim \text{Log-Normal}(1, 1) \\
\nu_{\boldsymbol{\beta}} &\sim \text{Log-Normal}(1, 1)
\end{aligned}
$$

## Modelos Lineares Robustos com o pacote `brms`

O `rstanarm` não nos dá a possibilidade de usar distribuições $t$ de Student como função de verossimilhança de modelos Bayesiano. Para usarmos distribuições $t$ de Student, precisamos usar o `brms` [@brms]. O `brms` usa a mesma síntaxe que o `rstanarm` e possui as mesmas famílias de funções de verossimilhança, mas com algumas diferenças:

* `rstanarm` todos os modelos são pré-compilados e `brms` não possui os modelos pré-compilados então os modelos devem ser todos compilados antes de serem rodados. A diferença prática é que você irá esperar alguns instantes antes do R começar a amostrar do modelo.
* Como `brms` compila os modelos conforme a especificação do usuário (não possui modelos pré-compilados) ele pode criar modelos um pouco mais eficientes que o `rstanarm`. Caso o tempo de compilação dos modelos `brms` seja menor que ganho de velocidade em amostragem do modelo, é vantajoso especificar seu modelo com `brms`.
* `brms` dá maior poder e flexibilidade ao usuário na especificação de funções de verossimilhança e também permite modelos mais complexos que o `rstanarm`.

A função que usamose para designar modelos Bayesianos no `brms` é a `brm()`:

```{r, eval=FALSE}
brm(y ~ ...,
    data = ...,
    family = student)
```

### Exemplo - Prestígio de Duncan (1961)

Para exemplicar regressão robusta vamos usar um *dataset* que tem muitas observações discrepantes (*outliers*) chamado `Duncan` [@duncan1961socioeconomic]. Ele possui 45 observações sobre ocupações nos EUA e 5 variáveis:

-   `profession`: Nome da profissão

-   `type`: Tipo de ocupação. Uma variável qualitativa:

    -   `prof` - profissional ou de gestão
    -   `wc` - white-collar (colarinho branco)
    -   `bc` - blue-collar (colarinho azul)

-   `income`: Porcentagem de pessoas da ocupação que ganham acima U\$ 3.500 por ano em 1950 (mais ou menos U\$36.000 em 2017);

-   `education`: Porcentagem de pessoas da ocupação que possuem diploma de ensino médio em 1949 (que, sendo cínicos, podemos dizer que é de certa maneira equivalente com diploma de Doutorado em 2017); e

-   `prestige`: Porcentagem de respondentes na pesquisa que classificam a sua ocupação como no mínimo "boa" em respeito à prestígio.

Como sempre eu gosto de usar o pacote `skimr` [@skimr] com a função `skim()`:

```{r duncan-data, message=FALSE, warning=FALSE}
library(skimr)
duncan <- read_csv2("datasets/Duncan.csv", col_types = "ffiii")
skim(duncan)
```

Eu acho que variável dependente `prestige` merece uma atenção maior, vejam o histograma dela na figura \@ref(fig:hist-prestige). Parece que temos uma multimodalidade rolando por aqui:

```{r hist-prestige, fig.cap='Histograma da variável `prestige`'}
ggplot(duncan, aes(prestige)) +
  geom_histogram(bins = 15, fill = "steelblue") +
  labs(
    title = "Histograma da variável prestige",
    y = "Frequência"
  )
```


#### Primeiro modelo: Regressão Linear

Vamos estimar primeiramente uma regressão linear usando a distribuição Normal como verossimilhança no `rstanarm`. Para exemplificação vou manter as *prioris* padrões do `rstanarm`:

```{r duncan_model_normal}
# Detectar quantos cores/processadores
options(mc.cores = parallel::detectCores())
options(Ncpus = parallel::detectCores())

library(rstanarm)

model_1 <- stan_glm(
  prestige ~ income + education,
  data = duncan,
  family = gaussian # nem precisaria pois é o argumento padrão
)
```

E na sequência o sumário das estimativas do modelo, assim como os diagnósticos da MCMC:

```{r summary-duncan_model_normal}
summary(model_1)
```

Aparentemente parece que o modelo possui boas métricas (todos `Rhat` menores que 1.01) mas quando olhamos o *Posterior Predictive Check* (figura \@ref(fig:pp-check-linear)), vemos uma bagunça:

```{r pp-check-linear, fig.cap='*Posterior Preditive Check* do modelo Gaussiano/Normal'}
pp_check(model_1, nreps = 40)
```

#### Segundo modelo: Regressão Robusta

Para rodar um modelo Bayesiano que usa como verossimilhança a distribuição $t$ de Student basta somente usar a mesma síntaxe que o `stan_glm` mas colocando argumento `family = student`. Aqui vou usar as mesmas priors que o padrão do `rstanarm` (caso queira, é só verificá-las com o `prior_summary(model_1)`):

```{r duncan_model_student}
library(brms)
model_2 <- brm(
  prestige ~ income + education,
  data = duncan,
  family = student,
  prior = c(
    prior(normal(0, 3.22), class = b, coef = income),
    prior(normal(0, 2.65), class = b, coef = education),
    prior(normal(48, 79), class = Intercept),
    prior(exponential(0.032), class = sigma),
    prior(lognormal(2, 1), class = nu)
  )
)
```

E na sequência o sumário das estimativas do modelo com verossimilhança $t$ de Student (estou colocando o `prob = 0.9` para que o sumário do modelo `brms` seja o mesmo que o sumário do `rstanarm`), assim como os diagnósticos da MCMC:

```{r summary_duncan_model_student}
summary(model_2, prob =  0.9)
```

Vemos que o erro do modelo `sigma` reduziu de $\approx 14$ para $\approx 11$, o que implica em uma melhor inferência do modelo. Além disso, temos um novo parâmetro estimado pelo modelo que é o parâmetro `nu` ($\nu$): os graus de liberdade da distribuição $t$ de Student usada como verossimilhança.

E para concluir, vejam que p *Posterior Predictive Check* (figura \@ref(fig:pp-check-student)) ficou com um aspecto muito melhor que o modelo linear:

```{r pp-check-student, fig.cap='*Posterior Preditive Check* do modelo $t$ de Student'}
pp_check(model_2, nsamples = 40)
```

## Atividade Prática

O *dataset* [Boston Housing](https://www.kaggle.com/altavish/boston-housing-dataset) está disponível em `datasets/Boston_Housing.csv`. Possui 506 observações e possui 14 variáveis:

-   `CRIM` - per capita crime rate by town
-   `ZN` - proportion of residential land zoned for lots over 25,000 sq.ft.
-   `INDUS` - proportion of non-retail business acres per town.
-   `CHAS` - Charles River dummy variable (1 if tract bounds river; 0 otherwise)
-   `NOX` - nitric oxides concentration (parts per 10 million)
-   `RM` - average number of rooms per dwelling
-   `AGE` - proportion of owner-occupied units built prior to 1940
-   `DIS` - weighted distances to five Boston employment centres
-   `RAD` - index of accessibility to radial highways
-   `TAX` - full-value property-tax rate per \$10,000
-   `PTRATIO` - pupil-teacher ratio by town
-   `B` - 1000(Bk - 0.63)\^2 where Bk is the proportion of blacks by town
-   `LSTAT` - % lower status of the population
-   `MEDV` - Median value of owner-occupied homes in \$1000's

```{r atividade}
###
```

## Ambiente

```{r SessionInfo}
sessionInfo()
```
